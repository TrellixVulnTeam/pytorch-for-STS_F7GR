The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.
The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.
The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.

Loading data...

Parameters:
	BATCH_SIZE=64
	CUDA=False
	DEVICE=-1
	DROPOUT=0.5
	EARLY_STOP=1500
	EMBED_DIM=100
	EMBED_NUM=10242
	EPOCHS=256
	KERNEL_NUM=100
	KERNEL_SIZES=[3, 4, 5]
	LOG_INTERVAL=1
	LR=0.001
	MAX_NORM=3.0
	PREDICT=None
	SAVE_BEST=True
	SAVE_DIR=snapshot/2021-07-15_22-00-47
	SAVE_INTERVAL=1000
	SHUFFLE=False
	SNAPSHOT=None
	STATIC=False
	TEST=False
	TEST_INTERVAL=100

Batch[1] - loss: 0.087650 best_pearson: 0.0000
Batch[2] - loss: 0.087172 best_pearson: 0.0000
Batch[3] - loss: 0.084980 best_pearson: 0.0000
Batch[4] - loss: 0.071323 best_pearson: 0.0000
Batch[5] - loss: 0.078369 best_pearson: 0.0000
Batch[6] - loss: 0.084165 best_pearson: 0.0000
Batch[7] - loss: 0.086051 best_pearson: 0.0000
Batch[8] - loss: 0.090841 best_pearson: 0.0000
Batch[9] - loss: 0.087304 best_pearson: 0.0000
Batch[10] - loss: 0.079351 best_pearson: 0.0000
Batch[11] - loss: 0.085163 best_pearson: 0.0000
Batch[12] - loss: 0.092693 best_pearson: 0.0000
Batch[13] - loss: 0.089633 best_pearson: 0.0000
Batch[14] - loss: 0.080757 best_pearson: 0.0000
Batch[15] - loss: 0.090375 best_pearson: 0.0000
Batch[16] - loss: 0.081849 best_pearson: 0.0000
Batch[17] - loss: 0.087662 best_pearson: 0.0000
Batch[18] - loss: 0.079917 best_pearson: 0.0000
Batch[19] - loss: 0.076455 best_pearson: 0.0000
Batch[20] - loss: 0.074177 best_pearson: 0.0000
Batch[21] - loss: 0.084499 best_pearson: 0.0000
Batch[22] - loss: 0.081330 best_pearson: 0.0000
Batch[23] - loss: 0.096327 best_pearson: 0.0000
Batch[24] - loss: 0.073169 best_pearson: 0.0000
Batch[25] - loss: 0.073160 best_pearson: 0.0000
Batch[26] - loss: 0.060212 best_pearson: 0.0000
Batch[27] - loss: 0.090642 best_pearson: 0.0000
Batch[28] - loss: 0.067464 best_pearson: 0.0000
Batch[29] - loss: 0.092875 best_pearson: 0.0000
Batch[30] - loss: 0.079002 best_pearson: 0.0000
Batch[31] - loss: 0.081196 best_pearson: 0.0000
Batch[32] - loss: 0.066651 best_pearson: 0.0000
Batch[33] - loss: 0.075532 best_pearson: 0.0000
Batch[34] - loss: 0.092748 best_pearson: 0.0000
Batch[35] - loss: 0.065016 best_pearson: 0.0000
Batch[36] - loss: 0.072694 best_pearson: 0.0000
Batch[37] - loss: 0.094450 best_pearson: 0.0000
Batch[38] - loss: 0.081249 best_pearson: 0.0000
Batch[39] - loss: 0.067624 best_pearson: 0.0000
Batch[40] - loss: 0.085287 best_pearson: 0.0000
Batch[41] - loss: 0.092580 best_pearson: 0.0000
Batch[42] - loss: 0.072787 best_pearson: 0.0000
Batch[43] - loss: 0.061085 best_pearson: 0.0000
Batch[44] - loss: 0.068490 best_pearson: 0.0000
Batch[45] - loss: 0.069956 best_pearson: 0.0000
Batch[46] - loss: 0.064741 best_pearson: 0.0000
Batch[47] - loss: 0.051753 best_pearson: 0.0000
Batch[48] - loss: 0.067722 best_pearson: 0.0000
Batch[49] - loss: 0.053503 best_pearson: 0.0000
Batch[50] - loss: 0.055304 best_pearson: 0.0000
Batch[51] - loss: 0.071268 best_pearson: 0.0000
Batch[52] - loss: 0.067902 best_pearson: 0.0000
Batch[53] - loss: 0.060979 best_pearson: 0.0000
Batch[54] - loss: 0.069822 best_pearson: 0.0000
Batch[55] - loss: 0.060354 best_pearson: 0.0000
Batch[56] - loss: 0.057342 best_pearson: 0.0000
Batch[57] - loss: 0.063085 best_pearson: 0.0000
Batch[58] - loss: 0.054249 best_pearson: 0.0000
Batch[59] - loss: 0.068923 best_pearson: 0.0000
Batch[60] - loss: 0.060149 best_pearson: 0.0000
Batch[61] - loss: 0.065966 best_pearson: 0.0000
Batch[62] - loss: 0.058328 best_pearson: 0.0000
Batch[63] - loss: 0.066020 best_pearson: 0.0000
Batch[64] - loss: 0.054700 best_pearson: 0.0000
Batch[65] - loss: 0.077744 best_pearson: 0.0000
Batch[66] - loss: 0.047931 best_pearson: 0.0000
Batch[67] - loss: 0.056241 best_pearson: 0.0000
Batch[68] - loss: 0.072521 best_pearson: 0.0000
Batch[69] - loss: 0.074322 best_pearson: 0.0000
Batch[70] - loss: 0.051769 best_pearson: 0.0000
Batch[71] - loss: 0.036389 best_pearson: 0.0000
Batch[72] - loss: 0.044918 best_pearson: 0.0000
Batch[73] - loss: 0.043688 best_pearson: 0.0000
Batch[74] - loss: 0.041656 best_pearson: 0.0000
Batch[75] - loss: 0.049118 best_pearson: 0.0000
Batch[76] - loss: 0.037771 best_pearson: 0.0000
Batch[77] - loss: 0.044714 best_pearson: 0.0000
Batch[78] - loss: 0.040976 best_pearson: 0.0000
Batch[79] - loss: 0.052124 best_pearson: 0.0000
Batch[80] - loss: 0.031544 best_pearson: 0.0000
Batch[81] - loss: 0.041490 best_pearson: 0.0000
Batch[82] - loss: 0.036794 best_pearson: 0.0000
Batch[83] - loss: 0.052491 best_pearson: 0.0000
Batch[84] - loss: 0.040521 best_pearson: 0.0000
Batch[85] - loss: 0.032304 best_pearson: 0.0000
Batch[86] - loss: 0.037635 best_pearson: 0.0000
Batch[87] - loss: 0.035086 best_pearson: 0.0000
Batch[88] - loss: 0.034348 best_pearson: 0.0000
Batch[89] - loss: 0.035348 best_pearson: 0.0000
Batch[90] - loss: 0.032779 best_pearson: 0.0000
Batch[91] - loss: 0.036425 best_pearson: 0.0000
Batch[92] - loss: 0.040440 best_pearson: 0.0000
Batch[93] - loss: 0.051454 best_pearson: 0.0000
Batch[94] - loss: 0.032015 best_pearson: 0.0000
Batch[95] - loss: 0.040354 best_pearson: 0.0000
Batch[96] - loss: 0.032161 best_pearson: 0.0000
Batch[97] - loss: 0.043325 best_pearson: 0.0000
Batch[98] - loss: 0.042368 best_pearson: 0.0000
Batch[99] - loss: 0.029860 best_pearson: 0.0000
Batch[100] - loss: 0.043993 best_pearson: 0.0000

Evaluation - loss: 0.000055 pearson: 0.6617 

Batch[101] - loss: 0.034788 best_pearson: 0.6617
Batch[102] - loss: 0.037244 best_pearson: 0.6617
Batch[103] - loss: 0.035204 best_pearson: 0.6617
Batch[104] - loss: 0.031439 best_pearson: 0.6617
Batch[105] - loss: 0.034051 best_pearson: 0.6617
Batch[106] - loss: 0.035566 best_pearson: 0.6617
Batch[107] - loss: 0.029330 best_pearson: 0.6617
Batch[108] - loss: 0.034219 best_pearson: 0.6617
Batch[109] - loss: 0.029295 best_pearson: 0.6617
Batch[110] - loss: 0.047974 best_pearson: 0.6617
Batch[111] - loss: 0.043262 best_pearson: 0.6617
Batch[112] - loss: 0.037569 best_pearson: 0.6617
Batch[113] - loss: 0.026769 best_pearson: 0.6617
Batch[114] - loss: 0.034486 best_pearson: 0.6617
Batch[115] - loss: 0.038592 best_pearson: 0.6617
Batch[116] - loss: 0.028941 best_pearson: 0.6617
Batch[117] - loss: 0.037480 best_pearson: 0.6617
Batch[118] - loss: 0.043645 best_pearson: 0.6617
Batch[119] - loss: 0.039988 best_pearson: 0.6617
Batch[120] - loss: 0.034184 best_pearson: 0.6617
Batch[121] - loss: 0.034074 best_pearson: 0.6617
Batch[122] - loss: 0.039098 best_pearson: 0.6617
Batch[123] - loss: 0.041409 best_pearson: 0.6617
Batch[124] - loss: 0.052855 best_pearson: 0.6617
Batch[125] - loss: 0.036792 best_pearson: 0.6617
Batch[126] - loss: 0.026147 best_pearson: 0.6617
Batch[127] - loss: 0.034492 best_pearson: 0.6617
Batch[128] - loss: 0.030232 best_pearson: 0.6617
Batch[129] - loss: 0.031000 best_pearson: 0.6617
Batch[130] - loss: 0.029124 best_pearson: 0.6617
Batch[131] - loss: 0.041298 best_pearson: 0.6617
Batch[132] - loss: 0.028177 best_pearson: 0.6617
Batch[133] - loss: 0.032297 best_pearson: 0.6617
Batch[134] - loss: 0.031847 best_pearson: 0.6617
Batch[135] - loss: 0.052054 best_pearson: 0.6617
Batch[136] - loss: 0.037407 best_pearson: 0.6617
Batch[137] - loss: 0.034518 best_pearson: 0.6617
Batch[138] - loss: 0.037041 best_pearson: 0.6617
Batch[139] - loss: 0.019100 best_pearson: 0.6617
Batch[140] - loss: 0.015313 best_pearson: 0.6617
Batch[141] - loss: 0.009825 best_pearson: 0.6617
Batch[142] - loss: 0.016058 best_pearson: 0.6617
Batch[143] - loss: 0.018951 best_pearson: 0.6617
Batch[144] - loss: 0.017970 best_pearson: 0.6617
Batch[145] - loss: 0.021603 best_pearson: 0.6617
Batch[146] - loss: 0.015073 best_pearson: 0.6617
Batch[147] - loss: 0.016474 best_pearson: 0.6617
Batch[148] - loss: 0.020055 best_pearson: 0.6617
Batch[149] - loss: 0.019722 best_pearson: 0.6617
Batch[150] - loss: 0.014951 best_pearson: 0.6617
Batch[151] - loss: 0.015315 best_pearson: 0.6617
Batch[152] - loss: 0.024839 best_pearson: 0.6617
Batch[153] - loss: 0.022043 best_pearson: 0.6617
Batch[154] - loss: 0.014959 best_pearson: 0.6617
Batch[155] - loss: 0.015997 best_pearson: 0.6617
Batch[156] - loss: 0.018590 best_pearson: 0.6617
Batch[157] - loss: 0.015941 best_pearson: 0.6617
Batch[158] - loss: 0.023203 best_pearson: 0.6617
Batch[159] - loss: 0.015188 best_pearson: 0.6617
Batch[160] - loss: 0.020392 best_pearson: 0.6617
Batch[161] - loss: 0.014095 best_pearson: 0.6617
Batch[162] - loss: 0.017411 best_pearson: 0.6617
Batch[163] - loss: 0.017882 best_pearson: 0.6617
Batch[164] - loss: 0.014614 best_pearson: 0.6617
Batch[165] - loss: 0.019229 best_pearson: 0.6617
Batch[166] - loss: 0.017749 best_pearson: 0.6617
Batch[167] - loss: 0.022861 best_pearson: 0.6617
Batch[168] - loss: 0.015773 best_pearson: 0.6617
Batch[169] - loss: 0.017086 best_pearson: 0.6617
Batch[170] - loss: 0.010319 best_pearson: 0.6617
Batch[171] - loss: 0.016573 best_pearson: 0.6617
Batch[172] - loss: 0.010241 best_pearson: 0.6617
Batch[173] - loss: 0.015160 best_pearson: 0.6617
Batch[174] - loss: 0.017121 best_pearson: 0.6617
Batch[175] - loss: 0.013502 best_pearson: 0.6617
Batch[176] - loss: 0.015252 best_pearson: 0.6617
Batch[177] - loss: 0.015582 best_pearson: 0.6617
Batch[178] - loss: 0.017587 best_pearson: 0.6617
Batch[179] - loss: 0.018256 best_pearson: 0.6617
Batch[180] - loss: 0.027002 best_pearson: 0.6617
Batch[181] - loss: 0.017939 best_pearson: 0.6617
Batch[182] - loss: 0.017228 best_pearson: 0.6617
Batch[183] - loss: 0.013389 best_pearson: 0.6617
Batch[184] - loss: 0.016529 best_pearson: 0.6617
Batch[185] - loss: 0.022301 best_pearson: 0.6617
Batch[186] - loss: 0.013705 best_pearson: 0.6617
Batch[187] - loss: 0.014748 best_pearson: 0.6617
Batch[188] - loss: 0.018949 best_pearson: 0.6617
Batch[189] - loss: 0.018120 best_pearson: 0.6617
Batch[190] - loss: 0.015792 best_pearson: 0.6617
Batch[191] - loss: 0.020474 best_pearson: 0.6617
Batch[192] - loss: 0.018423 best_pearson: 0.6617
Batch[193] - loss: 0.025233 best_pearson: 0.6617
Batch[194] - loss: 0.014106 best_pearson: 0.6617
Batch[195] - loss: 0.018112 best_pearson: 0.6617
Batch[196] - loss: 0.017867 best_pearson: 0.6617
Batch[197] - loss: 0.022403 best_pearson: 0.6617
Batch[198] - loss: 0.015518 best_pearson: 0.6617
Batch[199] - loss: 0.013737 best_pearson: 0.6617
Batch[200] - loss: 0.022777 best_pearson: 0.6617

Evaluation - loss: 0.000048 pearson: 0.7012 

Batch[201] - loss: 0.016439 best_pearson: 0.7012
Batch[202] - loss: 0.024363 best_pearson: 0.7012
Batch[203] - loss: 0.024691 best_pearson: 0.7012
Batch[204] - loss: 0.014207 best_pearson: 0.7012
Batch[205] - loss: 0.016933 best_pearson: 0.7012
Batch[206] - loss: 0.015486 best_pearson: 0.7012
Batch[207] - loss: 0.018970 best_pearson: 0.7012
Batch[208] - loss: 0.008344 best_pearson: 0.7012
Batch[209] - loss: 0.006065 best_pearson: 0.7012
Batch[210] - loss: 0.007090 best_pearson: 0.7012
Batch[211] - loss: 0.005563 best_pearson: 0.7012
Batch[212] - loss: 0.009886 best_pearson: 0.7012
Batch[213] - loss: 0.006377 best_pearson: 0.7012
Batch[214] - loss: 0.008881 best_pearson: 0.7012
Batch[215] - loss: 0.010592 best_pearson: 0.7012
Batch[216] - loss: 0.008105 best_pearson: 0.7012
Batch[217] - loss: 0.012456 best_pearson: 0.7012
Batch[218] - loss: 0.008416 best_pearson: 0.7012
Batch[219] - loss: 0.010416 best_pearson: 0.7012
Batch[220] - loss: 0.007892 best_pearson: 0.7012
Batch[221] - loss: 0.007827 best_pearson: 0.7012
Batch[222] - loss: 0.009316 best_pearson: 0.7012
Batch[223] - loss: 0.005888 best_pearson: 0.7012
Batch[224] - loss: 0.006678 best_pearson: 0.7012
Batch[225] - loss: 0.007909 best_pearson: 0.7012
Batch[226] - loss: 0.007022 best_pearson: 0.7012
Batch[227] - loss: 0.006463 best_pearson: 0.7012
Batch[228] - loss: 0.007717 best_pearson: 0.7012
Batch[229] - loss: 0.005624 best_pearson: 0.7012
Batch[230] - loss: 0.006723 best_pearson: 0.7012
Batch[231] - loss: 0.006520 best_pearson: 0.7012
Batch[232] - loss: 0.006404 best_pearson: 0.7012
Batch[233] - loss: 0.006963 best_pearson: 0.7012
Batch[234] - loss: 0.005609 best_pearson: 0.7012
Batch[235] - loss: 0.005812 best_pearson: 0.7012
Batch[236] - loss: 0.010600 best_pearson: 0.7012
Batch[237] - loss: 0.007105 best_pearson: 0.7012
Batch[238] - loss: 0.005460 best_pearson: 0.7012
Batch[239] - loss: 0.009765 best_pearson: 0.7012
Batch[240] - loss: 0.007020 best_pearson: 0.7012
Batch[241] - loss: 0.006441 best_pearson: 0.7012
Batch[242] - loss: 0.005913 best_pearson: 0.7012
Batch[243] - loss: 0.008947 best_pearson: 0.7012
Batch[244] - loss: 0.006414 best_pearson: 0.7012
Batch[245] - loss: 0.008452 best_pearson: 0.7012
Batch[246] - loss: 0.007335 best_pearson: 0.7012
Batch[247] - loss: 0.012528 best_pearson: 0.7012
Batch[248] - loss: 0.011297 best_pearson: 0.7012
Batch[249] - loss: 0.010235 best_pearson: 0.7012
Batch[250] - loss: 0.005646 best_pearson: 0.7012
Batch[251] - loss: 0.010536 best_pearson: 0.7012
Batch[252] - loss: 0.009582 best_pearson: 0.7012
Batch[253] - loss: 0.007401 best_pearson: 0.7012
Batch[254] - loss: 0.013507 best_pearson: 0.7012
Batch[255] - loss: 0.012193 best_pearson: 0.7012
Batch[256] - loss: 0.010276 best_pearson: 0.7012
Batch[257] - loss: 0.004365 best_pearson: 0.7012
Batch[258] - loss: 0.008447 best_pearson: 0.7012
Batch[259] - loss: 0.008979 best_pearson: 0.7012
Batch[260] - loss: 0.005668 best_pearson: 0.7012
Batch[261] - loss: 0.009304 best_pearson: 0.7012
Batch[262] - loss: 0.007575 best_pearson: 0.7012
Batch[263] - loss: 0.007121 best_pearson: 0.7012
Batch[264] - loss: 0.005529 best_pearson: 0.7012
Batch[265] - loss: 0.004680 best_pearson: 0.7012
Batch[266] - loss: 0.006668 best_pearson: 0.7012
Batch[267] - loss: 0.005951 best_pearson: 0.7012
Batch[268] - loss: 0.008684 best_pearson: 0.7012
Batch[269] - loss: 0.007214 best_pearson: 0.7012
Batch[270] - loss: 0.006426 best_pearson: 0.7012
Batch[271] - loss: 0.006971 best_pearson: 0.7012
Batch[272] - loss: 0.006810 best_pearson: 0.7012
Batch[273] - loss: 0.011413 best_pearson: 0.7012
Batch[274] - loss: 0.009504 best_pearson: 0.7012
Batch[275] - loss: 0.008914 best_pearson: 0.7012
Batch[276] - loss: 0.007254 best_pearson: 0.7012
Batch[277] - loss: 0.003787 best_pearson: 0.7012
Batch[278] - loss: 0.005127 best_pearson: 0.7012
Batch[279] - loss: 0.004032 best_pearson: 0.7012
Batch[280] - loss: 0.005840 best_pearson: 0.7012
Batch[281] - loss: 0.004048 best_pearson: 0.7012
Batch[282] - loss: 0.004044 best_pearson: 0.7012
Batch[283] - loss: 0.003832 best_pearson: 0.7012
Batch[284] - loss: 0.004231 best_pearson: 0.7012
Batch[285] - loss: 0.004458 best_pearson: 0.7012
Batch[286] - loss: 0.003509 best_pearson: 0.7012
Batch[287] - loss: 0.004199 best_pearson: 0.7012
Batch[288] - loss: 0.004818 best_pearson: 0.7012
Batch[289] - loss: 0.003536 best_pearson: 0.7012
Batch[290] - loss: 0.003413 best_pearson: 0.7012
Batch[291] - loss: 0.006859 best_pearson: 0.7012
Batch[292] - loss: 0.005425 best_pearson: 0.7012
Batch[293] - loss: 0.003797 best_pearson: 0.7012
Batch[294] - loss: 0.003700 best_pearson: 0.7012
Batch[295] - loss: 0.004604 best_pearson: 0.7012
Batch[296] - loss: 0.005308 best_pearson: 0.7012
Batch[297] - loss: 0.004169 best_pearson: 0.7012
Batch[298] - loss: 0.002436 best_pearson: 0.7012
Batch[299] - loss: 0.005520 best_pearson: 0.7012
Batch[300] - loss: 0.004294 best_pearson: 0.7012

Evaluation - loss: 0.000047 pearson: 0.7096 

Batch[301] - loss: 0.003921 best_pearson: 0.7096
Batch[302] - loss: 0.006147 best_pearson: 0.7096
Batch[303] - loss: 0.005066 best_pearson: 0.7096
Batch[304] - loss: 0.004818 best_pearson: 0.7096
Batch[305] - loss: 0.002929 best_pearson: 0.7096
Batch[306] - loss: 0.003260 best_pearson: 0.7096
Batch[307] - loss: 0.004514 best_pearson: 0.7096
Batch[308] - loss: 0.003405 best_pearson: 0.7096
Batch[309] - loss: 0.002831 best_pearson: 0.7096
Batch[310] - loss: 0.003777 best_pearson: 0.7096
Batch[311] - loss: 0.004913 best_pearson: 0.7096
Batch[312] - loss: 0.002993 best_pearson: 0.7096
Batch[313] - loss: 0.004877 best_pearson: 0.7096
Batch[314] - loss: 0.004325 best_pearson: 0.7096
Batch[315] - loss: 0.002917 best_pearson: 0.7096
Batch[316] - loss: 0.003656 best_pearson: 0.7096
Batch[317] - loss: 0.003178 best_pearson: 0.7096
Batch[318] - loss: 0.003172 best_pearson: 0.7096
Batch[319] - loss: 0.003511 best_pearson: 0.7096
Batch[320] - loss: 0.003605 best_pearson: 0.7096
Batch[321] - loss: 0.004700 best_pearson: 0.7096
Batch[322] - loss: 0.003648 best_pearson: 0.7096
Batch[323] - loss: 0.003642 best_pearson: 0.7096
Batch[324] - loss: 0.004479 best_pearson: 0.7096
Batch[325] - loss: 0.006022 best_pearson: 0.7096
Batch[326] - loss: 0.004345 best_pearson: 0.7096
Batch[327] - loss: 0.003807 best_pearson: 0.7096
Batch[328] - loss: 0.004674 best_pearson: 0.7096
Batch[329] - loss: 0.004637 best_pearson: 0.7096
Batch[330] - loss: 0.003186 best_pearson: 0.7096
Batch[331] - loss: 0.004003 best_pearson: 0.7096
Batch[332] - loss: 0.002287 best_pearson: 0.7096
Batch[333] - loss: 0.003859 best_pearson: 0.7096
Batch[334] - loss: 0.003203 best_pearson: 0.7096
Batch[335] - loss: 0.005598 best_pearson: 0.7096
Batch[336] - loss: 0.004773 best_pearson: 0.7096
Batch[337] - loss: 0.003560 best_pearson: 0.7096
Batch[338] - loss: 0.005277 best_pearson: 0.7096
Batch[339] - loss: 0.004731 best_pearson: 0.7096
Batch[340] - loss: 0.002829 best_pearson: 0.7096
Batch[341] - loss: 0.005050 best_pearson: 0.7096
Batch[342] - loss: 0.005076 best_pearson: 0.7096
Batch[343] - loss: 0.005181 best_pearson: 0.7096
Batch[344] - loss: 0.004256 best_pearson: 0.7096
Batch[345] - loss: 0.002772 best_pearson: 0.7096
Batch[346] - loss: 0.003323 best_pearson: 0.7096
Batch[347] - loss: 0.002127 best_pearson: 0.7096
Batch[348] - loss: 0.003016 best_pearson: 0.7096
Batch[349] - loss: 0.003311 best_pearson: 0.7096
Batch[350] - loss: 0.003865 best_pearson: 0.7096
Batch[351] - loss: 0.002394 best_pearson: 0.7096
Batch[352] - loss: 0.002606 best_pearson: 0.7096
Batch[353] - loss: 0.003750 best_pearson: 0.7096
Batch[354] - loss: 0.003035 best_pearson: 0.7096
Batch[355] - loss: 0.003037 best_pearson: 0.7096
Batch[356] - loss: 0.003685 best_pearson: 0.7096
Batch[357] - loss: 0.002886 best_pearson: 0.7096
Batch[358] - loss: 0.002165 best_pearson: 0.7096
Batch[359] - loss: 0.002608 best_pearson: 0.7096
Batch[360] - loss: 0.002923 best_pearson: 0.7096
Batch[361] - loss: 0.005010 best_pearson: 0.7096
Batch[362] - loss: 0.002622 best_pearson: 0.7096
Batch[363] - loss: 0.002657 best_pearson: 0.7096
Batch[364] - loss: 0.003246 best_pearson: 0.7096
Batch[365] - loss: 0.003945 best_pearson: 0.7096
Batch[366] - loss: 0.003041 best_pearson: 0.7096
Batch[367] - loss: 0.002766 best_pearson: 0.7096
Batch[368] - loss: 0.004185 best_pearson: 0.7096
Batch[369] - loss: 0.002783 best_pearson: 0.7096
Batch[370] - loss: 0.003104 best_pearson: 0.7096
Batch[371] - loss: 0.004480 best_pearson: 0.7096
Batch[372] - loss: 0.004098 best_pearson: 0.7096
Batch[373] - loss: 0.002792 best_pearson: 0.7096
Batch[374] - loss: 0.003575 best_pearson: 0.7096
Batch[375] - loss: 0.002553 best_pearson: 0.7096
Batch[376] - loss: 0.002888 best_pearson: 0.7096
Batch[377] - loss: 0.003605 best_pearson: 0.7096
Batch[378] - loss: 0.003420 best_pearson: 0.7096
Batch[379] - loss: 0.004407 best_pearson: 0.7096
Batch[380] - loss: 0.002573 best_pearson: 0.7096
Batch[381] - loss: 0.002617 best_pearson: 0.7096
Batch[382] - loss: 0.002190 best_pearson: 0.7096
Batch[383] - loss: 0.003037 best_pearson: 0.7096
Batch[384] - loss: 0.002783 best_pearson: 0.7096
Batch[385] - loss: 0.003177 best_pearson: 0.7096
Batch[386] - loss: 0.002789 best_pearson: 0.7096
Batch[387] - loss: 0.003935 best_pearson: 0.7096
Batch[388] - loss: 0.002812 best_pearson: 0.7096
Batch[389] - loss: 0.003521 best_pearson: 0.7096
Batch[390] - loss: 0.002176 best_pearson: 0.7096
Batch[391] - loss: 0.004578 best_pearson: 0.7096
Batch[392] - loss: 0.002159 best_pearson: 0.7096
Batch[393] - loss: 0.003080 best_pearson: 0.7096
Batch[394] - loss: 0.002916 best_pearson: 0.7096
Batch[395] - loss: 0.003053 best_pearson: 0.7096
Batch[396] - loss: 0.003220 best_pearson: 0.7096
Batch[397] - loss: 0.002794 best_pearson: 0.7096
Batch[398] - loss: 0.003588 best_pearson: 0.7096
Batch[399] - loss: 0.003059 best_pearson: 0.7096
Batch[400] - loss: 0.001710 best_pearson: 0.7096

Evaluation - loss: 0.000048 pearson: 0.7049 

Batch[401] - loss: 0.003345 best_pearson: 0.7096
Batch[402] - loss: 0.003539 best_pearson: 0.7096
Batch[403] - loss: 0.003826 best_pearson: 0.7096
Batch[404] - loss: 0.003343 best_pearson: 0.7096
Batch[405] - loss: 0.003124 best_pearson: 0.7096
Batch[406] - loss: 0.003209 best_pearson: 0.7096
Batch[407] - loss: 0.002875 best_pearson: 0.7096
Batch[408] - loss: 0.003095 best_pearson: 0.7096
Batch[409] - loss: 0.002598 best_pearson: 0.7096
Batch[410] - loss: 0.002027 best_pearson: 0.7096
Batch[411] - loss: 0.003030 best_pearson: 0.7096
Batch[412] - loss: 0.003009 best_pearson: 0.7096
Batch[413] - loss: 0.003245 best_pearson: 0.7096
Batch[414] - loss: 0.002953 best_pearson: 0.7096
Batch[415] - loss: 0.003239 best_pearson: 0.7096
Batch[416] - loss: 0.001863 best_pearson: 0.7096
Batch[417] - loss: 0.002066 best_pearson: 0.7096
Batch[418] - loss: 0.001983 best_pearson: 0.7096
Batch[419] - loss: 0.003919 best_pearson: 0.7096
Batch[420] - loss: 0.003317 best_pearson: 0.7096
Batch[421] - loss: 0.003153 best_pearson: 0.7096
Batch[422] - loss: 0.004346 best_pearson: 0.7096
Batch[423] - loss: 0.003721 best_pearson: 0.7096
Batch[424] - loss: 0.003942 best_pearson: 0.7096
Batch[425] - loss: 0.002144 best_pearson: 0.7096
Batch[426] - loss: 0.003237 best_pearson: 0.7096
Batch[427] - loss: 0.003145 best_pearson: 0.7096
Batch[428] - loss: 0.002461 best_pearson: 0.7096
Batch[429] - loss: 0.003961 best_pearson: 0.7096
Batch[430] - loss: 0.003210 best_pearson: 0.7096
Batch[431] - loss: 0.002963 best_pearson: 0.7096
Batch[432] - loss: 0.004986 best_pearson: 0.7096
Batch[433] - loss: 0.003775 best_pearson: 0.7096
Batch[434] - loss: 0.002222 best_pearson: 0.7096
Batch[435] - loss: 0.002262 best_pearson: 0.7096
Batch[436] - loss: 0.004486 best_pearson: 0.7096
Batch[437] - loss: 0.005030 best_pearson: 0.7096
Batch[438] - loss: 0.004188 best_pearson: 0.7096
Batch[439] - loss: 0.003394 best_pearson: 0.7096
Batch[440] - loss: 0.003088 best_pearson: 0.7096
Batch[441] - loss: 0.004554 best_pearson: 0.7096
Batch[442] - loss: 0.003959 best_pearson: 0.7096
Batch[443] - loss: 0.003047 best_pearson: 0.7096
Batch[444] - loss: 0.002952 best_pearson: 0.7096
Batch[445] - loss: 0.004763 best_pearson: 0.7096
Batch[446] - loss: 0.003389 best_pearson: 0.7096
Batch[447] - loss: 0.002805 best_pearson: 0.7096
Batch[448] - loss: 0.004851 best_pearson: 0.7096
Batch[449] - loss: 0.003525 best_pearson: 0.7096
Batch[450] - loss: 0.003246 best_pearson: 0.7096
Batch[451] - loss: 0.003792 best_pearson: 0.7096
Batch[452] - loss: 0.003171 best_pearson: 0.7096
Batch[453] - loss: 0.004937 best_pearson: 0.7096
Batch[454] - loss: 0.003307 best_pearson: 0.7096
Batch[455] - loss: 0.002687 best_pearson: 0.7096
Batch[456] - loss: 0.003536 best_pearson: 0.7096
Batch[457] - loss: 0.004446 best_pearson: 0.7096
Batch[458] - loss: 0.002815 best_pearson: 0.7096
Batch[459] - loss: 0.003019 best_pearson: 0.7096
Batch[460] - loss: 0.002698 best_pearson: 0.7096
Batch[461] - loss: 0.003227 best_pearson: 0.7096
Batch[462] - loss: 0.002025 best_pearson: 0.7096
Batch[463] - loss: 0.002882 best_pearson: 0.7096
Batch[464] - loss: 0.002420 best_pearson: 0.7096
Batch[465] - loss: 0.005460 best_pearson: 0.7096
Batch[466] - loss: 0.003056 best_pearson: 0.7096
Batch[467] - loss: 0.003059 best_pearson: 0.7096
Batch[468] - loss: 0.003373 best_pearson: 0.7096
Batch[469] - loss: 0.004604 best_pearson: 0.7096
Batch[470] - loss: 0.001905 best_pearson: 0.7096
Batch[471] - loss: 0.002429 best_pearson: 0.7096
Batch[472] - loss: 0.004321 best_pearson: 0.7096
Batch[473] - loss: 0.002712 best_pearson: 0.7096
Batch[474] - loss: 0.003768 best_pearson: 0.7096
Batch[475] - loss: 0.003493 best_pearson: 0.7096
Batch[476] - loss: 0.002647 best_pearson: 0.7096
Batch[477] - loss: 0.003820 best_pearson: 0.7096
Batch[478] - loss: 0.002224 best_pearson: 0.7096
Batch[479] - loss: 0.003360 best_pearson: 0.7096
Batch[480] - loss: 0.004052 best_pearson: 0.7096
Batch[481] - loss: 0.005791 best_pearson: 0.7096
Batch[482] - loss: 0.003319 best_pearson: 0.7096
Batch[483] - loss: 0.003943 best_pearson: 0.7096
Batch[484] - loss: 0.002808 best_pearson: 0.7096
Batch[485] - loss: 0.003157 best_pearson: 0.7096
Batch[486] - loss: 0.003572 best_pearson: 0.7096
Batch[487] - loss: 0.003750 best_pearson: 0.7096
Batch[488] - loss: 0.005335 best_pearson: 0.7096
Batch[489] - loss: 0.004384 best_pearson: 0.7096
Batch[490] - loss: 0.004473 best_pearson: 0.7096
Batch[491] - loss: 0.002262 best_pearson: 0.7096
Batch[492] - loss: 0.005295 best_pearson: 0.7096
Batch[493] - loss: 0.003352 best_pearson: 0.7096
Batch[494] - loss: 0.004393 best_pearson: 0.7096
Batch[495] - loss: 0.005283 best_pearson: 0.7096
Batch[496] - loss: 0.001933 best_pearson: 0.7096
Batch[497] - loss: 0.003428 best_pearson: 0.7096
Batch[498] - loss: 0.006496 best_pearson: 0.7096
Batch[499] - loss: 0.004646 best_pearson: 0.7096
Batch[500] - loss: 0.003630 best_pearson: 0.7096

Evaluation - loss: 0.000049 pearson: 0.6999 

Batch[501] - loss: 0.002567 best_pearson: 0.7096
Batch[502] - loss: 0.003217 best_pearson: 0.7096
Batch[503] - loss: 0.003420 best_pearson: 0.7096
Batch[504] - loss: 0.005197 best_pearson: 0.7096
Batch[505] - loss: 0.004234 best_pearson: 0.7096
Batch[506] - loss: 0.004365 best_pearson: 0.7096
Batch[507] - loss: 0.003481 best_pearson: 0.7096
Batch[508] - loss: 0.002953 best_pearson: 0.7096
Batch[509] - loss: 0.005575 best_pearson: 0.7096
Batch[510] - loss: 0.003074 best_pearson: 0.7096
Batch[511] - loss: 0.004209 best_pearson: 0.7096
Batch[512] - loss: 0.004629 best_pearson: 0.7096
Batch[513] - loss: 0.003020 best_pearson: 0.7096
Batch[514] - loss: 0.003074 best_pearson: 0.7096
Batch[515] - loss: 0.005564 best_pearson: 0.7096
Batch[516] - loss: 0.002884 best_pearson: 0.7096
Batch[517] - loss: 0.004825 best_pearson: 0.7096
Batch[518] - loss: 0.004763 best_pearson: 0.7096
Batch[519] - loss: 0.002936 best_pearson: 0.7096
Batch[520] - loss: 0.004669 best_pearson: 0.7096
Batch[521] - loss: 0.005676 best_pearson: 0.7096
Batch[522] - loss: 0.003810 best_pearson: 0.7096
Batch[523] - loss: 0.003338 best_pearson: 0.7096
Batch[524] - loss: 0.004146 best_pearson: 0.7096
Batch[525] - loss: 0.004883 best_pearson: 0.7096
Batch[526] - loss: 0.004092 best_pearson: 0.7096
Batch[527] - loss: 0.003899 best_pearson: 0.7096
Batch[528] - loss: 0.006124 best_pearson: 0.7096
Batch[529] - loss: 0.003349 best_pearson: 0.7096
Batch[530] - loss: 0.003277 best_pearson: 0.7096
Batch[531] - loss: 0.004156 best_pearson: 0.7096
Batch[532] - loss: 0.006178 best_pearson: 0.7096
Batch[533] - loss: 0.002762 best_pearson: 0.7096
Batch[534] - loss: 0.002828 best_pearson: 0.7096
Batch[535] - loss: 0.003387 best_pearson: 0.7096
Batch[536] - loss: 0.003965 best_pearson: 0.7096
Batch[537] - loss: 0.004159 best_pearson: 0.7096
Batch[538] - loss: 0.003720 best_pearson: 0.7096
Batch[539] - loss: 0.003597 best_pearson: 0.7096
Batch[540] - loss: 0.004074 best_pearson: 0.7096
Batch[541] - loss: 0.002130 best_pearson: 0.7096
Batch[542] - loss: 0.003143 best_pearson: 0.7096
Batch[543] - loss: 0.005534 best_pearson: 0.7096
Batch[544] - loss: 0.004477 best_pearson: 0.7096
Batch[545] - loss: 0.004142 best_pearson: 0.7096
Batch[546] - loss: 0.003009 best_pearson: 0.7096
Batch[547] - loss: 0.004347 best_pearson: 0.7096
Batch[548] - loss: 0.004822 best_pearson: 0.7096
Batch[549] - loss: 0.003831 best_pearson: 0.7096
Batch[550] - loss: 0.002896 best_pearson: 0.7096
Batch[551] - loss: 0.003739 best_pearson: 0.7096
Batch[552] - loss: 0.008883 best_pearson: 0.7096
Batch[553] - loss: 0.004194 best_pearson: 0.7096
Batch[554] - loss: 0.001414 best_pearson: 0.7096
Batch[555] - loss: 0.003141 best_pearson: 0.7096
Batch[556] - loss: 0.003433 best_pearson: 0.7096
Batch[557] - loss: 0.004623 best_pearson: 0.7096
Batch[558] - loss: 0.004207 best_pearson: 0.7096
Batch[559] - loss: 0.005078 best_pearson: 0.7096
Batch[560] - loss: 0.002100 best_pearson: 0.7096
Batch[561] - loss: 0.002886 best_pearson: 0.7096
Batch[562] - loss: 0.006707 best_pearson: 0.7096
Batch[563] - loss: 0.005084 best_pearson: 0.7096
Batch[564] - loss: 0.004657 best_pearson: 0.7096
Batch[565] - loss: 0.004472 best_pearson: 0.7096
Batch[566] - loss: 0.005496 best_pearson: 0.7096
Batch[567] - loss: 0.003237 best_pearson: 0.7096
Batch[568] - loss: 0.003810 best_pearson: 0.7096
Batch[569] - loss: 0.003719 best_pearson: 0.7096
Batch[570] - loss: 0.003463 best_pearson: 0.7096
Batch[571] - loss: 0.004395 best_pearson: 0.7096
Batch[572] - loss: 0.004518 best_pearson: 0.7096
Batch[573] - loss: 0.003996 best_pearson: 0.7096
Batch[574] - loss: 0.005273 best_pearson: 0.7096
Batch[575] - loss: 0.004550 best_pearson: 0.7096
Batch[576] - loss: 0.003196 best_pearson: 0.7096
Batch[577] - loss: 0.006405 best_pearson: 0.7096
Batch[578] - loss: 0.003832 best_pearson: 0.7096
Batch[579] - loss: 0.004937 best_pearson: 0.7096
Batch[580] - loss: 0.002890 best_pearson: 0.7096
Batch[581] - loss: 0.003055 best_pearson: 0.7096
Batch[582] - loss: 0.006429 best_pearson: 0.7096
Batch[583] - loss: 0.008069 best_pearson: 0.7096
Batch[584] - loss: 0.005120 best_pearson: 0.7096
Batch[585] - loss: 0.002973 best_pearson: 0.7096
Batch[586] - loss: 0.007327 best_pearson: 0.7096
Batch[587] - loss: 0.007029 best_pearson: 0.7096
Batch[588] - loss: 0.004362 best_pearson: 0.7096
Batch[589] - loss: 0.003153 best_pearson: 0.7096
Batch[590] - loss: 0.003371 best_pearson: 0.7096
Batch[591] - loss: 0.004795 best_pearson: 0.7096
Batch[592] - loss: 0.004101 best_pearson: 0.7096
Batch[593] - loss: 0.003297 best_pearson: 0.7096
Batch[594] - loss: 0.006849 best_pearson: 0.7096
Batch[595] - loss: 0.004114 best_pearson: 0.7096
Batch[596] - loss: 0.004456 best_pearson: 0.7096
Batch[597] - loss: 0.003803 best_pearson: 0.7096
Batch[598] - loss: 0.004831 best_pearson: 0.7096
Batch[599] - loss: 0.004068 best_pearson: 0.7096
Batch[600] - loss: 0.002483 best_pearson: 0.7096

Evaluation - loss: 0.000048 pearson: 0.7082 

Batch[601] - loss: 0.005360 best_pearson: 0.7096
Batch[602] - loss: 0.005047 best_pearson: 0.7096
Batch[603] - loss: 0.003383 best_pearson: 0.7096
Batch[604] - loss: 0.003838 best_pearson: 0.7096
Batch[605] - loss: 0.005074 best_pearson: 0.7096
Batch[606] - loss: 0.003673 best_pearson: 0.7096
Batch[607] - loss: 0.006959 best_pearson: 0.7096
Batch[608] - loss: 0.004365 best_pearson: 0.7096
Batch[609] - loss: 0.005736 best_pearson: 0.7096
Batch[610] - loss: 0.004048 best_pearson: 0.7096
Batch[611] - loss: 0.004114 best_pearson: 0.7096
Batch[612] - loss: 0.002727 best_pearson: 0.7096
Batch[613] - loss: 0.004666 best_pearson: 0.7096
Batch[614] - loss: 0.004406 best_pearson: 0.7096
Batch[615] - loss: 0.005104 best_pearson: 0.7096
Batch[616] - loss: 0.004219 best_pearson: 0.7096
Batch[617] - loss: 0.004056 best_pearson: 0.7096
Batch[618] - loss: 0.004734 best_pearson: 0.7096
Batch[619] - loss: 0.003128 best_pearson: 0.7096
Batch[620] - loss: 0.004235 best_pearson: 0.7096
Batch[621] - loss: 0.003184 best_pearson: 0.7096
Batch[622] - loss: 0.003100 best_pearson: 0.7096
Batch[623] - loss: 0.004013 best_pearson: 0.7096
Batch[624] - loss: 0.003349 best_pearson: 0.7096
Batch[625] - loss: 0.007376 best_pearson: 0.7096
Batch[626] - loss: 0.004055 best_pearson: 0.7096
Batch[627] - loss: 0.005886 best_pearson: 0.7096
Batch[628] - loss: 0.004955 best_pearson: 0.7096
Batch[629] - loss: 0.002720 best_pearson: 0.7096
Batch[630] - loss: 0.003453 best_pearson: 0.7096
Batch[631] - loss: 0.003530 best_pearson: 0.7096
Batch[632] - loss: 0.002664 best_pearson: 0.7096
Batch[633] - loss: 0.004005 best_pearson: 0.7096
Batch[634] - loss: 0.004233 best_pearson: 0.7096
Batch[635] - loss: 0.007565 best_pearson: 0.7096
Batch[636] - loss: 0.003268 best_pearson: 0.7096
Batch[637] - loss: 0.005859 best_pearson: 0.7096
Batch[638] - loss: 0.004271 best_pearson: 0.7096
Batch[639] - loss: 0.003809 best_pearson: 0.7096
Batch[640] - loss: 0.005899 best_pearson: 0.7096
Batch[641] - loss: 0.003866 best_pearson: 0.7096
Batch[642] - loss: 0.003382 best_pearson: 0.7096
Batch[643] - loss: 0.004393 best_pearson: 0.7096
Batch[644] - loss: 0.004262 best_pearson: 0.7096
Batch[645] - loss: 0.003694 best_pearson: 0.7096
Batch[646] - loss: 0.004110 best_pearson: 0.7096
Batch[647] - loss: 0.004972 best_pearson: 0.7096
Batch[648] - loss: 0.003099 best_pearson: 0.7096
Batch[649] - loss: 0.003639 best_pearson: 0.7096
Batch[650] - loss: 0.003929 best_pearson: 0.7096
Batch[651] - loss: 0.004728 best_pearson: 0.7096
Batch[652] - loss: 0.003132 best_pearson: 0.7096
Batch[653] - loss: 0.004159 best_pearson: 0.7096
Batch[654] - loss: 0.005465 best_pearson: 0.7096
Batch[655] - loss: 0.004241 best_pearson: 0.7096
Batch[656] - loss: 0.002773 best_pearson: 0.7096
Batch[657] - loss: 0.004533 best_pearson: 0.7096
Batch[658] - loss: 0.004522 best_pearson: 0.7096
Batch[659] - loss: 0.003020 best_pearson: 0.7096
Batch[660] - loss: 0.004098 best_pearson: 0.7096
Batch[661] - loss: 0.006968 best_pearson: 0.7096
Batch[662] - loss: 0.004929 best_pearson: 0.7096
Batch[663] - loss: 0.005248 best_pearson: 0.7096
Batch[664] - loss: 0.004865 best_pearson: 0.7096
Batch[665] - loss: 0.003670 best_pearson: 0.7096
Batch[666] - loss: 0.005969 best_pearson: 0.7096
Batch[667] - loss: 0.005188 best_pearson: 0.7096
Batch[668] - loss: 0.003343 best_pearson: 0.7096
Batch[669] - loss: 0.004763 best_pearson: 0.7096
Batch[670] - loss: 0.003615 best_pearson: 0.7096
Batch[671] - loss: 0.003215 best_pearson: 0.7096
Batch[672] - loss: 0.004222 best_pearson: 0.7096
Batch[673] - loss: 0.003159 best_pearson: 0.7096
Batch[674] - loss: 0.004980 best_pearson: 0.7096
Batch[675] - loss: 0.004818 best_pearson: 0.7096
Batch[676] - loss: 0.004507 best_pearson: 0.7096
Batch[677] - loss: 0.004501 best_pearson: 0.7096
Batch[678] - loss: 0.004652 best_pearson: 0.7096
Batch[679] - loss: 0.005418 best_pearson: 0.7096
Batch[680] - loss: 0.005499 best_pearson: 0.7096
Batch[681] - loss: 0.004166 best_pearson: 0.7096
Batch[682] - loss: 0.006788 best_pearson: 0.7096
Batch[683] - loss: 0.002766 best_pearson: 0.7096
Batch[684] - loss: 0.003902 best_pearson: 0.7096
Batch[685] - loss: 0.002725 best_pearson: 0.7096
Batch[686] - loss: 0.004314 best_pearson: 0.7096
Batch[687] - loss: 0.004780 best_pearson: 0.7096
Batch[688] - loss: 0.004460 best_pearson: 0.7096
Batch[689] - loss: 0.003518 best_pearson: 0.7096
Batch[690] - loss: 0.005673 best_pearson: 0.7096
Batch[691] - loss: 0.004762 best_pearson: 0.7096
Batch[692] - loss: 0.003981 best_pearson: 0.7096
Batch[693] - loss: 0.003830 best_pearson: 0.7096
Batch[694] - loss: 0.003589 best_pearson: 0.7096
Batch[695] - loss: 0.005860 best_pearson: 0.7096
Batch[696] - loss: 0.005440 best_pearson: 0.7096
Batch[697] - loss: 0.003447 best_pearson: 0.7096
Batch[698] - loss: 0.005612 best_pearson: 0.7096
Batch[699] - loss: 0.005791 best_pearson: 0.7096
Batch[700] - loss: 0.005276 best_pearson: 0.7096

Evaluation - loss: 0.000049 pearson: 0.7063 

Batch[701] - loss: 0.003061 best_pearson: 0.7096
Batch[702] - loss: 0.003971 best_pearson: 0.7096
Batch[703] - loss: 0.005887 best_pearson: 0.7096
Batch[704] - loss: 0.005778 best_pearson: 0.7096
Batch[705] - loss: 0.006896 best_pearson: 0.7096
Batch[706] - loss: 0.004056 best_pearson: 0.7096
Batch[707] - loss: 0.007298 best_pearson: 0.7096
Batch[708] - loss: 0.004214 best_pearson: 0.7096
Batch[709] - loss: 0.004406 best_pearson: 0.7096
Batch[710] - loss: 0.004583 best_pearson: 0.7096
Batch[711] - loss: 0.005354 best_pearson: 0.7096
Batch[712] - loss: 0.006170 best_pearson: 0.7096
Batch[713] - loss: 0.004775 best_pearson: 0.7096
Batch[714] - loss: 0.004558 best_pearson: 0.7096
Batch[715] - loss: 0.004342 best_pearson: 0.7096
Batch[716] - loss: 0.004192 best_pearson: 0.7096
Batch[717] - loss: 0.002052 best_pearson: 0.7096
Batch[718] - loss: 0.005065 best_pearson: 0.7096
Batch[719] - loss: 0.004652 best_pearson: 0.7096
Batch[720] - loss: 0.003071 best_pearson: 0.7096
Batch[721] - loss: 0.005549 best_pearson: 0.7096
Batch[722] - loss: 0.005620 best_pearson: 0.7096
Batch[723] - loss: 0.007058 best_pearson: 0.7096
Batch[724] - loss: 0.004006 best_pearson: 0.7096
Batch[725] - loss: 0.003634 best_pearson: 0.7096
Batch[726] - loss: 0.004104 best_pearson: 0.7096
Batch[727] - loss: 0.004181 best_pearson: 0.7096
Batch[728] - loss: 0.003019 best_pearson: 0.7096
Batch[729] - loss: 0.004300 best_pearson: 0.7096
Batch[730] - loss: 0.003835 best_pearson: 0.7096
Batch[731] - loss: 0.003403 best_pearson: 0.7096
Batch[732] - loss: 0.002897 best_pearson: 0.7096
Batch[733] - loss: 0.003436 best_pearson: 0.7096
Batch[734] - loss: 0.004916 best_pearson: 0.7096
Batch[735] - loss: 0.003990 best_pearson: 0.7096
Batch[736] - loss: 0.004346 best_pearson: 0.7096
Batch[737] - loss: 0.005262 best_pearson: 0.7096
Batch[738] - loss: 0.002651 best_pearson: 0.7096
Batch[739] - loss: 0.005625 best_pearson: 0.7096
Batch[740] - loss: 0.003542 best_pearson: 0.7096
Batch[741] - loss: 0.004470 best_pearson: 0.7096
Batch[742] - loss: 0.005678 best_pearson: 0.7096
Batch[743] - loss: 0.004478 best_pearson: 0.7096
Batch[744] - loss: 0.002746 best_pearson: 0.7096
Batch[745] - loss: 0.004752 best_pearson: 0.7096
Batch[746] - loss: 0.003281 best_pearson: 0.7096
Batch[747] - loss: 0.004156 best_pearson: 0.7096
Batch[748] - loss: 0.004150 best_pearson: 0.7096
Batch[749] - loss: 0.004716 best_pearson: 0.7096
Batch[750] - loss: 0.005250 best_pearson: 0.7096
Batch[751] - loss: 0.005126 best_pearson: 0.7096
Batch[752] - loss: 0.005348 best_pearson: 0.7096
Batch[753] - loss: 0.004354 best_pearson: 0.7096
Batch[754] - loss: 0.003051 best_pearson: 0.7096
Batch[755] - loss: 0.004312 best_pearson: 0.7096
Batch[756] - loss: 0.003793 best_pearson: 0.7096
Batch[757] - loss: 0.004404 best_pearson: 0.7096
Batch[758] - loss: 0.003046 best_pearson: 0.7096
Batch[759] - loss: 0.003593 best_pearson: 0.7096
Batch[760] - loss: 0.004108 best_pearson: 0.7096
Batch[761] - loss: 0.002505 best_pearson: 0.7096
Batch[762] - loss: 0.006161 best_pearson: 0.7096
Batch[763] - loss: 0.001990 best_pearson: 0.7096
Batch[764] - loss: 0.002479 best_pearson: 0.7096
Batch[765] - loss: 0.002436 best_pearson: 0.7096
Batch[766] - loss: 0.003711 best_pearson: 0.7096
Batch[767] - loss: 0.004972 best_pearson: 0.7096
Batch[768] - loss: 0.003416 best_pearson: 0.7096
Batch[769] - loss: 0.004353 best_pearson: 0.7096
Batch[770] - loss: 0.006942 best_pearson: 0.7096
Batch[771] - loss: 0.004849 best_pearson: 0.7096
Batch[772] - loss: 0.004415 best_pearson: 0.7096
Batch[773] - loss: 0.003294 best_pearson: 0.7096
Batch[774] - loss: 0.003698 best_pearson: 0.7096
Batch[775] - loss: 0.004469 best_pearson: 0.7096
Batch[776] - loss: 0.004072 best_pearson: 0.7096
Batch[777] - loss: 0.003250 best_pearson: 0.7096
Batch[778] - loss: 0.005946 best_pearson: 0.7096
Batch[779] - loss: 0.004519 best_pearson: 0.7096
Batch[780] - loss: 0.004540 best_pearson: 0.7096
Batch[781] - loss: 0.006018 best_pearson: 0.7096
Batch[782] - loss: 0.005140 best_pearson: 0.7096
Batch[783] - loss: 0.002925 best_pearson: 0.7096
Batch[784] - loss: 0.005021 best_pearson: 0.7096
Batch[785] - loss: 0.005199 best_pearson: 0.7096
Batch[786] - loss: 0.005976 best_pearson: 0.7096
Batch[787] - loss: 0.004093 best_pearson: 0.7096
Batch[788] - loss: 0.003265 best_pearson: 0.7096
Batch[789] - loss: 0.007529 best_pearson: 0.7096
Batch[790] - loss: 0.002795 best_pearson: 0.7096
Batch[791] - loss: 0.004817 best_pearson: 0.7096
Batch[792] - loss: 0.004326 best_pearson: 0.7096
Batch[793] - loss: 0.005089 best_pearson: 0.7096
Batch[794] - loss: 0.004722 best_pearson: 0.7096
Batch[795] - loss: 0.004220 best_pearson: 0.7096
Batch[796] - loss: 0.003027 best_pearson: 0.7096
Batch[797] - loss: 0.003664 best_pearson: 0.7096
Batch[798] - loss: 0.003187 best_pearson: 0.7096
Batch[799] - loss: 0.002954 best_pearson: 0.7096
Batch[800] - loss: 0.004006 best_pearson: 0.7096

Evaluation - loss: 0.000047 pearson: 0.7127 

Batch[801] - loss: 0.005181 best_pearson: 0.7127
Batch[802] - loss: 0.002334 best_pearson: 0.7127
Batch[803] - loss: 0.004460 best_pearson: 0.7127
Batch[804] - loss: 0.003960 best_pearson: 0.7127
Batch[805] - loss: 0.003086 best_pearson: 0.7127
Batch[806] - loss: 0.003667 best_pearson: 0.7127
Batch[807] - loss: 0.004837 best_pearson: 0.7127
Batch[808] - loss: 0.002842 best_pearson: 0.7127
Batch[809] - loss: 0.004159 best_pearson: 0.7127
Batch[810] - loss: 0.003470 best_pearson: 0.7127
Batch[811] - loss: 0.003882 best_pearson: 0.7127
Batch[812] - loss: 0.004407 best_pearson: 0.7127
Batch[813] - loss: 0.004624 best_pearson: 0.7127
Batch[814] - loss: 0.004354 best_pearson: 0.7127
Batch[815] - loss: 0.003605 best_pearson: 0.7127
Batch[816] - loss: 0.004183 best_pearson: 0.7127
Batch[817] - loss: 0.005750 best_pearson: 0.7127
Batch[818] - loss: 0.003256 best_pearson: 0.7127
Batch[819] - loss: 0.006181 best_pearson: 0.7127
Batch[820] - loss: 0.004641 best_pearson: 0.7127
Batch[821] - loss: 0.002939 best_pearson: 0.7127
Batch[822] - loss: 0.003646 best_pearson: 0.7127
Batch[823] - loss: 0.004129 best_pearson: 0.7127
Batch[824] - loss: 0.003770 best_pearson: 0.7127
Batch[825] - loss: 0.002150 best_pearson: 0.7127
Batch[826] - loss: 0.003165 best_pearson: 0.7127
Batch[827] - loss: 0.006675 best_pearson: 0.7127
Batch[828] - loss: 0.007630 best_pearson: 0.7127
Batch[829] - loss: 0.003662 best_pearson: 0.7127
Batch[830] - loss: 0.002938 best_pearson: 0.7127
Batch[831] - loss: 0.001865 best_pearson: 0.7127
Batch[832] - loss: 0.003400 best_pearson: 0.7127
Batch[833] - loss: 0.002528 best_pearson: 0.7127
Batch[834] - loss: 0.003125 best_pearson: 0.7127
Batch[835] - loss: 0.004227 best_pearson: 0.7127
Batch[836] - loss: 0.004181 best_pearson: 0.7127
Batch[837] - loss: 0.004358 best_pearson: 0.7127
Batch[838] - loss: 0.003540 best_pearson: 0.7127
Batch[839] - loss: 0.004559 best_pearson: 0.7127
Batch[840] - loss: 0.003982 best_pearson: 0.7127
Batch[841] - loss: 0.002303 best_pearson: 0.7127
Batch[842] - loss: 0.007332 best_pearson: 0.7127
Batch[843] - loss: 0.002625 best_pearson: 0.7127
Batch[844] - loss: 0.003123 best_pearson: 0.7127
Batch[845] - loss: 0.003337 best_pearson: 0.7127
Batch[846] - loss: 0.005775 best_pearson: 0.7127
Batch[847] - loss: 0.002432 best_pearson: 0.7127
Batch[848] - loss: 0.003968 best_pearson: 0.7127
Batch[849] - loss: 0.005269 best_pearson: 0.7127
Batch[850] - loss: 0.003150 best_pearson: 0.7127
Batch[851] - loss: 0.004191 best_pearson: 0.7127
Batch[852] - loss: 0.003891 best_pearson: 0.7127
Batch[853] - loss: 0.003603 best_pearson: 0.7127
Batch[854] - loss: 0.004880 best_pearson: 0.7127
Batch[855] - loss: 0.004559 best_pearson: 0.7127
Batch[856] - loss: 0.004089 best_pearson: 0.7127
Batch[857] - loss: 0.004297 best_pearson: 0.7127
Batch[858] - loss: 0.005162 best_pearson: 0.7127
Batch[859] - loss: 0.005391 best_pearson: 0.7127
Batch[860] - loss: 0.003048 best_pearson: 0.7127
Batch[861] - loss: 0.003297 best_pearson: 0.7127
Batch[862] - loss: 0.003542 best_pearson: 0.7127
Batch[863] - loss: 0.002821 best_pearson: 0.7127
Batch[864] - loss: 0.003660 best_pearson: 0.7127
Batch[865] - loss: 0.003366 best_pearson: 0.7127
Batch[866] - loss: 0.003261 best_pearson: 0.7127
Batch[867] - loss: 0.002771 best_pearson: 0.7127
Batch[868] - loss: 0.003295 best_pearson: 0.7127
Batch[869] - loss: 0.002382 best_pearson: 0.7127
Batch[870] - loss: 0.003658 best_pearson: 0.7127
Batch[871] - loss: 0.004216 best_pearson: 0.7127
Batch[872] - loss: 0.004597 best_pearson: 0.7127
Batch[873] - loss: 0.003150 best_pearson: 0.7127
Batch[874] - loss: 0.004991 best_pearson: 0.7127
Batch[875] - loss: 0.003945 best_pearson: 0.7127
Batch[876] - loss: 0.001879 best_pearson: 0.7127
Batch[877] - loss: 0.002799 best_pearson: 0.7127
Batch[878] - loss: 0.002847 best_pearson: 0.7127
Batch[879] - loss: 0.003328 best_pearson: 0.7127
Batch[880] - loss: 0.002766 best_pearson: 0.7127
Batch[881] - loss: 0.003401 best_pearson: 0.7127
Batch[882] - loss: 0.002352 best_pearson: 0.7127
Batch[883] - loss: 0.003872 best_pearson: 0.7127
Batch[884] - loss: 0.002840 best_pearson: 0.7127
Batch[885] - loss: 0.003673 best_pearson: 0.7127
Batch[886] - loss: 0.003470 best_pearson: 0.7127
Batch[887] - loss: 0.002928 best_pearson: 0.7127
Batch[888] - loss: 0.003708 best_pearson: 0.7127
Batch[889] - loss: 0.004499 best_pearson: 0.7127
Batch[890] - loss: 0.004112 best_pearson: 0.7127
Batch[891] - loss: 0.002789 best_pearson: 0.7127
Batch[892] - loss: 0.003034 best_pearson: 0.7127
Batch[893] - loss: 0.005617 best_pearson: 0.7127
Batch[894] - loss: 0.003136 best_pearson: 0.7127
Batch[895] - loss: 0.002104 best_pearson: 0.7127
Batch[896] - loss: 0.003563 best_pearson: 0.7127
Batch[897] - loss: 0.004079 best_pearson: 0.7127
Batch[898] - loss: 0.003443 best_pearson: 0.7127
Batch[899] - loss: 0.001456 best_pearson: 0.7127
Batch[900] - loss: 0.002881 best_pearson: 0.7127

Evaluation - loss: 0.000047 pearson: 0.7114 

Batch[901] - loss: 0.004740 best_pearson: 0.7127
Batch[902] - loss: 0.003798 best_pearson: 0.7127
Batch[903] - loss: 0.002754 best_pearson: 0.7127
Batch[904] - loss: 0.003468 best_pearson: 0.7127
Batch[905] - loss: 0.003001 best_pearson: 0.7127
Batch[906] - loss: 0.007049 best_pearson: 0.7127
Batch[907] - loss: 0.002538 best_pearson: 0.7127
Batch[908] - loss: 0.005560 best_pearson: 0.7127
Batch[909] - loss: 0.003473 best_pearson: 0.7127
Batch[910] - loss: 0.003879 best_pearson: 0.7127
Batch[911] - loss: 0.006621 best_pearson: 0.7127
Batch[912] - loss: 0.002505 best_pearson: 0.7127
Batch[913] - loss: 0.006261 best_pearson: 0.7127
Batch[914] - loss: 0.003851 best_pearson: 0.7127
Batch[915] - loss: 0.003010 best_pearson: 0.7127
Batch[916] - loss: 0.007857 best_pearson: 0.7127
Batch[917] - loss: 0.004024 best_pearson: 0.7127
Batch[918] - loss: 0.005845 best_pearson: 0.7127
Batch[919] - loss: 0.006411 best_pearson: 0.7127
Batch[920] - loss: 0.003807 best_pearson: 0.7127
Batch[921] - loss: 0.003711 best_pearson: 0.7127
Batch[922] - loss: 0.002953 best_pearson: 0.7127
Batch[923] - loss: 0.004484 best_pearson: 0.7127
Batch[924] - loss: 0.005302 best_pearson: 0.7127
Batch[925] - loss: 0.002255 best_pearson: 0.7127
Batch[926] - loss: 0.004457 best_pearson: 0.7127
Batch[927] - loss: 0.003442 best_pearson: 0.7127
Batch[928] - loss: 0.004579 best_pearson: 0.7127
Batch[929] - loss: 0.004723 best_pearson: 0.7127
Batch[930] - loss: 0.002987 best_pearson: 0.7127
Batch[931] - loss: 0.003423 best_pearson: 0.7127
Batch[932] - loss: 0.003943 best_pearson: 0.7127
Batch[933] - loss: 0.003744 best_pearson: 0.7127
Batch[934] - loss: 0.004592 best_pearson: 0.7127
Batch[935] - loss: 0.003735 best_pearson: 0.7127
Batch[936] - loss: 0.004337 best_pearson: 0.7127
Batch[937] - loss: 0.003080 best_pearson: 0.7127
Batch[938] - loss: 0.002839 best_pearson: 0.7127
Batch[939] - loss: 0.003767 best_pearson: 0.7127
Batch[940] - loss: 0.005223 best_pearson: 0.7127
Batch[941] - loss: 0.002658 best_pearson: 0.7127
Batch[942] - loss: 0.003893 best_pearson: 0.7127
Batch[943] - loss: 0.002433 best_pearson: 0.7127
Batch[944] - loss: 0.003511 best_pearson: 0.7127
Batch[945] - loss: 0.003135 best_pearson: 0.7127
Batch[946] - loss: 0.004738 best_pearson: 0.7127
Batch[947] - loss: 0.001958 best_pearson: 0.7127
Batch[948] - loss: 0.002301 best_pearson: 0.7127
Batch[949] - loss: 0.003366 best_pearson: 0.7127
Batch[950] - loss: 0.005254 best_pearson: 0.7127
Batch[951] - loss: 0.002723 best_pearson: 0.7127
Batch[952] - loss: 0.002905 best_pearson: 0.7127
Batch[953] - loss: 0.003213 best_pearson: 0.7127
Batch[954] - loss: 0.003612 best_pearson: 0.7127
Batch[955] - loss: 0.002615 best_pearson: 0.7127
Batch[956] - loss: 0.002841 best_pearson: 0.7127
Batch[957] - loss: 0.002177 best_pearson: 0.7127
Batch[958] - loss: 0.003659 best_pearson: 0.7127
Batch[959] - loss: 0.005195 best_pearson: 0.7127
Batch[960] - loss: 0.003506 best_pearson: 0.7127
Batch[961] - loss: 0.003870 best_pearson: 0.7127
Batch[962] - loss: 0.004283 best_pearson: 0.7127
Batch[963] - loss: 0.003892 best_pearson: 0.7127
Batch[964] - loss: 0.003637 best_pearson: 0.7127
Batch[965] - loss: 0.002460 best_pearson: 0.7127
Batch[966] - loss: 0.005679 best_pearson: 0.7127
Batch[967] - loss: 0.004734 best_pearson: 0.7127
Batch[968] - loss: 0.003567 best_pearson: 0.7127
Batch[969] - loss: 0.003758 best_pearson: 0.7127
Batch[970] - loss: 0.002978 best_pearson: 0.7127
Batch[971] - loss: 0.002968 best_pearson: 0.7127
Batch[972] - loss: 0.002516 best_pearson: 0.7127
Batch[973] - loss: 0.003091 best_pearson: 0.7127
Batch[974] - loss: 0.004615 best_pearson: 0.7127
Batch[975] - loss: 0.006402 best_pearson: 0.7127
Batch[976] - loss: 0.003002 best_pearson: 0.7127
Batch[977] - loss: 0.003761 best_pearson: 0.7127
Batch[978] - loss: 0.006441 best_pearson: 0.7127
Batch[979] - loss: 0.006458 best_pearson: 0.7127
Batch[980] - loss: 0.005218 best_pearson: 0.7127
Batch[981] - loss: 0.004593 best_pearson: 0.7127
Batch[982] - loss: 0.003131 best_pearson: 0.7127
Batch[983] - loss: 0.003027 best_pearson: 0.7127
Batch[984] - loss: 0.005605 best_pearson: 0.7127
Batch[985] - loss: 0.005198 best_pearson: 0.7127
Batch[986] - loss: 0.003212 best_pearson: 0.7127
Batch[987] - loss: 0.005912 best_pearson: 0.7127
Batch[988] - loss: 0.003728 best_pearson: 0.7127
Batch[989] - loss: 0.004078 best_pearson: 0.7127
Batch[990] - loss: 0.003403 best_pearson: 0.7127
Batch[991] - loss: 0.005818 best_pearson: 0.7127
Batch[992] - loss: 0.003539 best_pearson: 0.7127
Batch[993] - loss: 0.004367 best_pearson: 0.7127
Batch[994] - loss: 0.004168 best_pearson: 0.7127
Batch[995] - loss: 0.003898 best_pearson: 0.7127
Batch[996] - loss: 0.003282 best_pearson: 0.7127
Batch[997] - loss: 0.004273 best_pearson: 0.7127
Batch[998] - loss: 0.002960 best_pearson: 0.7127
Batch[999] - loss: 0.004674 best_pearson: 0.7127
Batch[1000] - loss: 0.004464 best_pearson: 0.7127

Evaluation - loss: 0.000048 pearson: 0.7105 

Batch[1001] - loss: 0.003924 best_pearson: 0.7127
Batch[1002] - loss: 0.006256 best_pearson: 0.7127
Batch[1003] - loss: 0.002641 best_pearson: 0.7127
Batch[1004] - loss: 0.003360 best_pearson: 0.7127
Batch[1005] - loss: 0.003007 best_pearson: 0.7127
Batch[1006] - loss: 0.003351 best_pearson: 0.7127
Batch[1007] - loss: 0.003101 best_pearson: 0.7127
Batch[1008] - loss: 0.003887 best_pearson: 0.7127
Batch[1009] - loss: 0.006121 best_pearson: 0.7127
Batch[1010] - loss: 0.003183 best_pearson: 0.7127
Batch[1011] - loss: 0.003774 best_pearson: 0.7127
Batch[1012] - loss: 0.003441 best_pearson: 0.7127
Batch[1013] - loss: 0.003547 best_pearson: 0.7127
Batch[1014] - loss: 0.003641 best_pearson: 0.7127
Batch[1015] - loss: 0.003261 best_pearson: 0.7127
Batch[1016] - loss: 0.002360 best_pearson: 0.7127
Batch[1017] - loss: 0.003143 best_pearson: 0.7127
Batch[1018] - loss: 0.002225 best_pearson: 0.7127
Batch[1019] - loss: 0.002823 best_pearson: 0.7127
Batch[1020] - loss: 0.004316 best_pearson: 0.7127
Batch[1021] - loss: 0.004028 best_pearson: 0.7127
Batch[1022] - loss: 0.003180 best_pearson: 0.7127
Batch[1023] - loss: 0.002891 best_pearson: 0.7127
Batch[1024] - loss: 0.004830 best_pearson: 0.7127
Batch[1025] - loss: 0.002870 best_pearson: 0.7127
Batch[1026] - loss: 0.004968 best_pearson: 0.7127
Batch[1027] - loss: 0.004643 best_pearson: 0.7127
Batch[1028] - loss: 0.004269 best_pearson: 0.7127
Batch[1029] - loss: 0.002821 best_pearson: 0.7127
Batch[1030] - loss: 0.002976 best_pearson: 0.7127
Batch[1031] - loss: 0.004608 best_pearson: 0.7127
Batch[1032] - loss: 0.003431 best_pearson: 0.7127
Batch[1033] - loss: 0.004160 best_pearson: 0.7127
Batch[1034] - loss: 0.001538 best_pearson: 0.7127
Batch[1035] - loss: 0.004864 best_pearson: 0.7127
Batch[1036] - loss: 0.002128 best_pearson: 0.7127
Batch[1037] - loss: 0.001645 best_pearson: 0.7127
Batch[1038] - loss: 0.002315 best_pearson: 0.7127
Batch[1039] - loss: 0.003661 best_pearson: 0.7127
Batch[1040] - loss: 0.002385 best_pearson: 0.7127
Batch[1041] - loss: 0.003307 best_pearson: 0.7127
Batch[1042] - loss: 0.002816 best_pearson: 0.7127
Batch[1043] - loss: 0.004042 best_pearson: 0.7127
Batch[1044] - loss: 0.002474 best_pearson: 0.7127
Batch[1045] - loss: 0.004839 best_pearson: 0.7127
Batch[1046] - loss: 0.004670 best_pearson: 0.7127
Batch[1047] - loss: 0.002768 best_pearson: 0.7127
Batch[1048] - loss: 0.004852 best_pearson: 0.7127
Batch[1049] - loss: 0.003228 best_pearson: 0.7127
Batch[1050] - loss: 0.003124 best_pearson: 0.7127
Batch[1051] - loss: 0.002013 best_pearson: 0.7127
Batch[1052] - loss: 0.001949 best_pearson: 0.7127
Batch[1053] - loss: 0.002599 best_pearson: 0.7127
Batch[1054] - loss: 0.003226 best_pearson: 0.7127
Batch[1055] - loss: 0.003773 best_pearson: 0.7127
Batch[1056] - loss: 0.003358 best_pearson: 0.7127
Batch[1057] - loss: 0.004049 best_pearson: 0.7127
Batch[1058] - loss: 0.002587 best_pearson: 0.7127
Batch[1059] - loss: 0.002983 best_pearson: 0.7127
Batch[1060] - loss: 0.004105 best_pearson: 0.7127
Batch[1061] - loss: 0.003336 best_pearson: 0.7127
Batch[1062] - loss: 0.002969 best_pearson: 0.7127
Batch[1063] - loss: 0.002917 best_pearson: 0.7127
Batch[1064] - loss: 0.003166 best_pearson: 0.7127
Batch[1065] - loss: 0.002088 best_pearson: 0.7127
Batch[1066] - loss: 0.002499 best_pearson: 0.7127
Batch[1067] - loss: 0.003279 best_pearson: 0.7127
Batch[1068] - loss: 0.002878 best_pearson: 0.7127
Batch[1069] - loss: 0.003286 best_pearson: 0.7127
Batch[1070] - loss: 0.004618 best_pearson: 0.7127
Batch[1071] - loss: 0.001985 best_pearson: 0.7127
Batch[1072] - loss: 0.002555 best_pearson: 0.7127
Batch[1073] - loss: 0.002426 best_pearson: 0.7127
Batch[1074] - loss: 0.003961 best_pearson: 0.7127
Batch[1075] - loss: 0.003052 best_pearson: 0.7127
Batch[1076] - loss: 0.004727 best_pearson: 0.7127
Batch[1077] - loss: 0.003486 best_pearson: 0.7127
Batch[1078] - loss: 0.004410 best_pearson: 0.7127
Batch[1079] - loss: 0.004268 best_pearson: 0.7127
Batch[1080] - loss: 0.004504 best_pearson: 0.7127
Batch[1081] - loss: 0.004551 best_pearson: 0.7127
Batch[1082] - loss: 0.003048 best_pearson: 0.7127
Batch[1083] - loss: 0.002436 best_pearson: 0.7127
Batch[1084] - loss: 0.003845 best_pearson: 0.7127
Batch[1085] - loss: 0.005062 best_pearson: 0.7127
Batch[1086] - loss: 0.002291 best_pearson: 0.7127
Batch[1087] - loss: 0.002714 best_pearson: 0.7127
Batch[1088] - loss: 0.002990 best_pearson: 0.7127
Batch[1089] - loss: 0.004985 best_pearson: 0.7127
Batch[1090] - loss: 0.002324 best_pearson: 0.7127
Batch[1091] - loss: 0.003165 best_pearson: 0.7127
Batch[1092] - loss: 0.002410 best_pearson: 0.7127
Batch[1093] - loss: 0.003522 best_pearson: 0.7127
Batch[1094] - loss: 0.002791 best_pearson: 0.7127
Batch[1095] - loss: 0.003210 best_pearson: 0.7127
Batch[1096] - loss: 0.002836 best_pearson: 0.7127
Batch[1097] - loss: 0.004035 best_pearson: 0.7127
Batch[1098] - loss: 0.003399 best_pearson: 0.7127
Batch[1099] - loss: 0.002550 best_pearson: 0.7127
Batch[1100] - loss: 0.002506 best_pearson: 0.7127

Evaluation - loss: 0.000048 pearson: 0.7069 

Batch[1101] - loss: 0.004339 best_pearson: 0.7127
Batch[1102] - loss: 0.003460 best_pearson: 0.7127
Batch[1103] - loss: 0.003156 best_pearson: 0.7127
Batch[1104] - loss: 0.001648 best_pearson: 0.7127
Batch[1105] - loss: 0.002466 best_pearson: 0.7127
Batch[1106] - loss: 0.002532 best_pearson: 0.7127
Batch[1107] - loss: 0.003416 best_pearson: 0.7127
Batch[1108] - loss: 0.002344 best_pearson: 0.7127
Batch[1109] - loss: 0.005096 best_pearson: 0.7127
Batch[1110] - loss: 0.002308 best_pearson: 0.7127
Batch[1111] - loss: 0.002958 best_pearson: 0.7127
Batch[1112] - loss: 0.002027 best_pearson: 0.7127
Batch[1113] - loss: 0.001866 best_pearson: 0.7127
Batch[1114] - loss: 0.001674 best_pearson: 0.7127
Batch[1115] - loss: 0.002620 best_pearson: 0.7127
Batch[1116] - loss: 0.002669 best_pearson: 0.7127
Batch[1117] - loss: 0.003444 best_pearson: 0.7127
Batch[1118] - loss: 0.002837 best_pearson: 0.7127
Batch[1119] - loss: 0.003234 best_pearson: 0.7127
Batch[1120] - loss: 0.002806 best_pearson: 0.7127
Batch[1121] - loss: 0.002258 best_pearson: 0.7127
Batch[1122] - loss: 0.002988 best_pearson: 0.7127
Batch[1123] - loss: 0.002950 best_pearson: 0.7127
Batch[1124] - loss: 0.002765 best_pearson: 0.7127
Batch[1125] - loss: 0.003127 best_pearson: 0.7127
Batch[1126] - loss: 0.002782 best_pearson: 0.7127
Batch[1127] - loss: 0.003799 best_pearson: 0.7127
Batch[1128] - loss: 0.004088 best_pearson: 0.7127
Batch[1129] - loss: 0.003532 best_pearson: 0.7127
Batch[1130] - loss: 0.002267 best_pearson: 0.7127
Batch[1131] - loss: 0.002007 best_pearson: 0.7127
Batch[1132] - loss: 0.002350 best_pearson: 0.7127
Batch[1133] - loss: 0.002638 best_pearson: 0.7127
Batch[1134] - loss: 0.002269 best_pearson: 0.7127
Batch[1135] - loss: 0.004332 best_pearson: 0.7127
Batch[1136] - loss: 0.002625 best_pearson: 0.7127
Batch[1137] - loss: 0.002900 best_pearson: 0.7127
Batch[1138] - loss: 0.002818 best_pearson: 0.7127
Batch[1139] - loss: 0.002492 best_pearson: 0.7127
Batch[1140] - loss: 0.002822 best_pearson: 0.7127
Batch[1141] - loss: 0.002974 best_pearson: 0.7127
Batch[1142] - loss: 0.002473 best_pearson: 0.7127
Batch[1143] - loss: 0.002047 best_pearson: 0.7127
Batch[1144] - loss: 0.002415 best_pearson: 0.7127
Batch[1145] - loss: 0.002330 best_pearson: 0.7127
Batch[1146] - loss: 0.004559 best_pearson: 0.7127
Batch[1147] - loss: 0.002531 best_pearson: 0.7127
Batch[1148] - loss: 0.002530 best_pearson: 0.7127
Batch[1149] - loss: 0.003247 best_pearson: 0.7127
Batch[1150] - loss: 0.002705 best_pearson: 0.7127
Batch[1151] - loss: 0.001696 best_pearson: 0.7127
Batch[1152] - loss: 0.003569 best_pearson: 0.7127
Batch[1153] - loss: 0.001152 best_pearson: 0.7127
Batch[1154] - loss: 0.003846 best_pearson: 0.7127
Batch[1155] - loss: 0.002799 best_pearson: 0.7127
Batch[1156] - loss: 0.002389 best_pearson: 0.7127
Batch[1157] - loss: 0.001628 best_pearson: 0.7127
Batch[1158] - loss: 0.002619 best_pearson: 0.7127
Batch[1159] - loss: 0.003133 best_pearson: 0.7127
Batch[1160] - loss: 0.003677 best_pearson: 0.7127
Batch[1161] - loss: 0.005380 best_pearson: 0.7127
Batch[1162] - loss: 0.001816 best_pearson: 0.7127
Batch[1163] - loss: 0.001735 best_pearson: 0.7127
Batch[1164] - loss: 0.002685 best_pearson: 0.7127
Batch[1165] - loss: 0.003480 best_pearson: 0.7127
Batch[1166] - loss: 0.002889 best_pearson: 0.7127
Batch[1167] - loss: 0.002972 best_pearson: 0.7127
Batch[1168] - loss: 0.002327 best_pearson: 0.7127
Batch[1169] - loss: 0.003421 best_pearson: 0.7127
Batch[1170] - loss: 0.004033 best_pearson: 0.7127
Batch[1171] - loss: 0.002096 best_pearson: 0.7127
Batch[1172] - loss: 0.003280 best_pearson: 0.7127
Batch[1173] - loss: 0.003823 best_pearson: 0.7127
Batch[1174] - loss: 0.002108 best_pearson: 0.7127
Batch[1175] - loss: 0.002849 best_pearson: 0.7127
Batch[1176] - loss: 0.001672 best_pearson: 0.7127
Batch[1177] - loss: 0.003967 best_pearson: 0.7127
Batch[1178] - loss: 0.003959 best_pearson: 0.7127
Batch[1179] - loss: 0.003602 best_pearson: 0.7127
Batch[1180] - loss: 0.001988 best_pearson: 0.7127
Batch[1181] - loss: 0.002076 best_pearson: 0.7127
Batch[1182] - loss: 0.002099 best_pearson: 0.7127
Batch[1183] - loss: 0.002396 best_pearson: 0.7127
Batch[1184] - loss: 0.002670 best_pearson: 0.7127
Batch[1185] - loss: 0.001995 best_pearson: 0.7127
Batch[1186] - loss: 0.001939 best_pearson: 0.7127
Batch[1187] - loss: 0.002705 best_pearson: 0.7127
Batch[1188] - loss: 0.003873 best_pearson: 0.7127
Batch[1189] - loss: 0.002765 best_pearson: 0.7127
Batch[1190] - loss: 0.002725 best_pearson: 0.7127
Batch[1191] - loss: 0.003557 best_pearson: 0.7127
Batch[1192] - loss: 0.003988 best_pearson: 0.7127
Batch[1193] - loss: 0.004434 best_pearson: 0.7127
Batch[1194] - loss: 0.002840 best_pearson: 0.7127
Batch[1195] - loss: 0.002191 best_pearson: 0.7127
Batch[1196] - loss: 0.004308 best_pearson: 0.7127
Batch[1197] - loss: 0.002739 best_pearson: 0.7127
Batch[1198] - loss: 0.003087 best_pearson: 0.7127
Batch[1199] - loss: 0.001896 best_pearson: 0.7127
Batch[1200] - loss: 0.005369 best_pearson: 0.7127

Evaluation - loss: 0.000047 pearson: 0.7130 

Batch[1201] - loss: 0.002596 best_pearson: 0.7130
Batch[1202] - loss: 0.003062 best_pearson: 0.7130
Batch[1203] - loss: 0.002417 best_pearson: 0.7130
Batch[1204] - loss: 0.004651 best_pearson: 0.7130
Batch[1205] - loss: 0.005587 best_pearson: 0.7130
Batch[1206] - loss: 0.001726 best_pearson: 0.7130
Batch[1207] - loss: 0.002911 best_pearson: 0.7130
Batch[1208] - loss: 0.002849 best_pearson: 0.7130
Batch[1209] - loss: 0.001620 best_pearson: 0.7130
Batch[1210] - loss: 0.001691 best_pearson: 0.7130
Batch[1211] - loss: 0.003605 best_pearson: 0.7130
Batch[1212] - loss: 0.002182 best_pearson: 0.7130
Batch[1213] - loss: 0.002890 best_pearson: 0.7130
Batch[1214] - loss: 0.002935 best_pearson: 0.7130
Batch[1215] - loss: 0.002490 best_pearson: 0.7130
Batch[1216] - loss: 0.002559 best_pearson: 0.7130
Batch[1217] - loss: 0.002507 best_pearson: 0.7130
Batch[1218] - loss: 0.002694 best_pearson: 0.7130
Batch[1219] - loss: 0.003267 best_pearson: 0.7130
Batch[1220] - loss: 0.002408 best_pearson: 0.7130
Batch[1221] - loss: 0.003462 best_pearson: 0.7130
Batch[1222] - loss: 0.002774 best_pearson: 0.7130
Batch[1223] - loss: 0.003510 best_pearson: 0.7130
Batch[1224] - loss: 0.003692 best_pearson: 0.7130
Batch[1225] - loss: 0.002052 best_pearson: 0.7130
Batch[1226] - loss: 0.002660 best_pearson: 0.7130
Batch[1227] - loss: 0.001823 best_pearson: 0.7130
Batch[1228] - loss: 0.001855 best_pearson: 0.7130
Batch[1229] - loss: 0.002760 best_pearson: 0.7130
Batch[1230] - loss: 0.005127 best_pearson: 0.7130
Batch[1231] - loss: 0.003592 best_pearson: 0.7130
Batch[1232] - loss: 0.003347 best_pearson: 0.7130
Batch[1233] - loss: 0.002191 best_pearson: 0.7130
Batch[1234] - loss: 0.005517 best_pearson: 0.7130
Batch[1235] - loss: 0.002419 best_pearson: 0.7130
Batch[1236] - loss: 0.001614 best_pearson: 0.7130
Batch[1237] - loss: 0.003242 best_pearson: 0.7130
Batch[1238] - loss: 0.003116 best_pearson: 0.7130
Batch[1239] - loss: 0.002250 best_pearson: 0.7130
Batch[1240] - loss: 0.001787 best_pearson: 0.7130
Batch[1241] - loss: 0.001725 best_pearson: 0.7130
Batch[1242] - loss: 0.003146 best_pearson: 0.7130
Batch[1243] - loss: 0.002483 best_pearson: 0.7130
Batch[1244] - loss: 0.002493 best_pearson: 0.7130
Batch[1245] - loss: 0.002966 best_pearson: 0.7130
Batch[1246] - loss: 0.002605 best_pearson: 0.7130
Batch[1247] - loss: 0.002389 best_pearson: 0.7130
Batch[1248] - loss: 0.001420 best_pearson: 0.7130
Batch[1249] - loss: 0.003346 best_pearson: 0.7130
Batch[1250] - loss: 0.002409 best_pearson: 0.7130
Batch[1251] - loss: 0.004182 best_pearson: 0.7130
Batch[1252] - loss: 0.002127 best_pearson: 0.7130
Batch[1253] - loss: 0.002883 best_pearson: 0.7130
Batch[1254] - loss: 0.002806 best_pearson: 0.7130
Batch[1255] - loss: 0.002431 best_pearson: 0.7130
Batch[1256] - loss: 0.004044 best_pearson: 0.7130
Batch[1257] - loss: 0.003928 best_pearson: 0.7130
Batch[1258] - loss: 0.002911 best_pearson: 0.7130
Batch[1259] - loss: 0.001535 best_pearson: 0.7130
Batch[1260] - loss: 0.001488 best_pearson: 0.7130
Batch[1261] - loss: 0.002771 best_pearson: 0.7130
Batch[1262] - loss: 0.001757 best_pearson: 0.7130
Batch[1263] - loss: 0.003216 best_pearson: 0.7130
Batch[1264] - loss: 0.004362 best_pearson: 0.7130
Batch[1265] - loss: 0.003038 best_pearson: 0.7130
Batch[1266] - loss: 0.002592 best_pearson: 0.7130
Batch[1267] - loss: 0.003047 best_pearson: 0.7130
Batch[1268] - loss: 0.003315 best_pearson: 0.7130
Batch[1269] - loss: 0.003194 best_pearson: 0.7130
Batch[1270] - loss: 0.002597 best_pearson: 0.7130
Batch[1271] - loss: 0.002913 best_pearson: 0.7130
Batch[1272] - loss: 0.002726 best_pearson: 0.7130
Batch[1273] - loss: 0.004367 best_pearson: 0.7130
Batch[1274] - loss: 0.001083 best_pearson: 0.7130
Batch[1275] - loss: 0.001379 best_pearson: 0.7130
Batch[1276] - loss: 0.002986 best_pearson: 0.7130
Batch[1277] - loss: 0.003005 best_pearson: 0.7130
Batch[1278] - loss: 0.003418 best_pearson: 0.7130
Batch[1279] - loss: 0.002787 best_pearson: 0.7130
Batch[1280] - loss: 0.002304 best_pearson: 0.7130
Batch[1281] - loss: 0.003449 best_pearson: 0.7130
Batch[1282] - loss: 0.003860 best_pearson: 0.7130
Batch[1283] - loss: 0.002522 best_pearson: 0.7130
Batch[1284] - loss: 0.002736 best_pearson: 0.7130
Batch[1285] - loss: 0.003239 best_pearson: 0.7130
Batch[1286] - loss: 0.002749 best_pearson: 0.7130
Batch[1287] - loss: 0.002145 best_pearson: 0.7130
Batch[1288] - loss: 0.003018 best_pearson: 0.7130
Batch[1289] - loss: 0.003858 best_pearson: 0.7130
Batch[1290] - loss: 0.001815 best_pearson: 0.7130
Batch[1291] - loss: 0.003548 best_pearson: 0.7130
Batch[1292] - loss: 0.002787 best_pearson: 0.7130
Batch[1293] - loss: 0.005892 best_pearson: 0.7130
Batch[1294] - loss: 0.002160 best_pearson: 0.7130
Batch[1295] - loss: 0.001700 best_pearson: 0.7130
Batch[1296] - loss: 0.003930 best_pearson: 0.7130
Batch[1297] - loss: 0.002167 best_pearson: 0.7130
Batch[1298] - loss: 0.004942 best_pearson: 0.7130
Batch[1299] - loss: 0.002373 best_pearson: 0.7130
Batch[1300] - loss: 0.002667 best_pearson: 0.7130

Evaluation - loss: 0.000054 pearson: 0.6994 

Batch[1301] - loss: 0.004011 best_pearson: 0.7130
Batch[1302] - loss: 0.006182 best_pearson: 0.7130
Batch[1303] - loss: 0.002363 best_pearson: 0.7130
Batch[1304] - loss: 0.003442 best_pearson: 0.7130
Batch[1305] - loss: 0.004990 best_pearson: 0.7130
Batch[1306] - loss: 0.004770 best_pearson: 0.7130
Batch[1307] - loss: 0.003632 best_pearson: 0.7130
Batch[1308] - loss: 0.004240 best_pearson: 0.7130
Batch[1309] - loss: 0.003003 best_pearson: 0.7130
Batch[1310] - loss: 0.003111 best_pearson: 0.7130
Batch[1311] - loss: 0.002991 best_pearson: 0.7130
Batch[1312] - loss: 0.002778 best_pearson: 0.7130
Batch[1313] - loss: 0.001906 best_pearson: 0.7130
Batch[1314] - loss: 0.004313 best_pearson: 0.7130
Batch[1315] - loss: 0.002656 best_pearson: 0.7130
Batch[1316] - loss: 0.003158 best_pearson: 0.7130
Batch[1317] - loss: 0.001754 best_pearson: 0.7130
Batch[1318] - loss: 0.002947 best_pearson: 0.7130
Batch[1319] - loss: 0.003348 best_pearson: 0.7130
Batch[1320] - loss: 0.002289 best_pearson: 0.7130
Batch[1321] - loss: 0.002208 best_pearson: 0.7130
Batch[1322] - loss: 0.004040 best_pearson: 0.7130
Batch[1323] - loss: 0.004078 best_pearson: 0.7130
Batch[1324] - loss: 0.003510 best_pearson: 0.7130
Batch[1325] - loss: 0.003080 best_pearson: 0.7130
Batch[1326] - loss: 0.004006 best_pearson: 0.7130
Batch[1327] - loss: 0.005869 best_pearson: 0.7130
Batch[1328] - loss: 0.004881 best_pearson: 0.7130
Batch[1329] - loss: 0.003380 best_pearson: 0.7130
Batch[1330] - loss: 0.002408 best_pearson: 0.7130
Batch[1331] - loss: 0.003286 best_pearson: 0.7130
Batch[1332] - loss: 0.004110 best_pearson: 0.7130
Batch[1333] - loss: 0.005410 best_pearson: 0.7130
Batch[1334] - loss: 0.004249 best_pearson: 0.7130
Batch[1335] - loss: 0.004602 best_pearson: 0.7130
Batch[1336] - loss: 0.002718 best_pearson: 0.7130
Batch[1337] - loss: 0.005097 best_pearson: 0.7130
Batch[1338] - loss: 0.002206 best_pearson: 0.7130
Batch[1339] - loss: 0.003704 best_pearson: 0.7130
Batch[1340] - loss: 0.002971 best_pearson: 0.7130
Batch[1341] - loss: 0.002904 best_pearson: 0.7130
Batch[1342] - loss: 0.004602 best_pearson: 0.7130
Batch[1343] - loss: 0.003731 best_pearson: 0.7130
Batch[1344] - loss: 0.002027 best_pearson: 0.7130
Batch[1345] - loss: 0.002776 best_pearson: 0.7130
Batch[1346] - loss: 0.004027 best_pearson: 0.7130
Batch[1347] - loss: 0.001888 best_pearson: 0.7130
Batch[1348] - loss: 0.002645 best_pearson: 0.7130
Batch[1349] - loss: 0.002447 best_pearson: 0.7130
Batch[1350] - loss: 0.002565 best_pearson: 0.7130
Batch[1351] - loss: 0.002193 best_pearson: 0.7130
Batch[1352] - loss: 0.002708 best_pearson: 0.7130
Batch[1353] - loss: 0.001838 best_pearson: 0.7130
Batch[1354] - loss: 0.002094 best_pearson: 0.7130
Batch[1355] - loss: 0.003763 best_pearson: 0.7130
Batch[1356] - loss: 0.003680 best_pearson: 0.7130
Batch[1357] - loss: 0.003718 best_pearson: 0.7130
Batch[1358] - loss: 0.001450 best_pearson: 0.7130
Batch[1359] - loss: 0.005599 best_pearson: 0.7130
Batch[1360] - loss: 0.004495 best_pearson: 0.7130
Batch[1361] - loss: 0.002210 best_pearson: 0.7130
Batch[1362] - loss: 0.002002 best_pearson: 0.7130
Batch[1363] - loss: 0.004028 best_pearson: 0.7130
Batch[1364] - loss: 0.002542 best_pearson: 0.7130
Batch[1365] - loss: 0.002237 best_pearson: 0.7130
Batch[1366] - loss: 0.003058 best_pearson: 0.7130
Batch[1367] - loss: 0.003316 best_pearson: 0.7130
Batch[1368] - loss: 0.002494 best_pearson: 0.7130
Batch[1369] - loss: 0.003551 best_pearson: 0.7130
Batch[1370] - loss: 0.003538 best_pearson: 0.7130
Batch[1371] - loss: 0.002838 best_pearson: 0.7130
Batch[1372] - loss: 0.002874 best_pearson: 0.7130
Batch[1373] - loss: 0.002761 best_pearson: 0.7130
Batch[1374] - loss: 0.002090 best_pearson: 0.7130
Batch[1375] - loss: 0.003979 best_pearson: 0.7130
Batch[1376] - loss: 0.003257 best_pearson: 0.7130
Batch[1377] - loss: 0.003806 best_pearson: 0.7130
Batch[1378] - loss: 0.002024 best_pearson: 0.7130
Batch[1379] - loss: 0.002864 best_pearson: 0.7130
Batch[1380] - loss: 0.001858 best_pearson: 0.7130
Batch[1381] - loss: 0.003860 best_pearson: 0.7130
Batch[1382] - loss: 0.001940 best_pearson: 0.7130
Batch[1383] - loss: 0.002106 best_pearson: 0.7130
Batch[1384] - loss: 0.004561 best_pearson: 0.7130
Batch[1385] - loss: 0.002002 best_pearson: 0.7130
Batch[1386] - loss: 0.002452 best_pearson: 0.7130
Batch[1387] - loss: 0.002629 best_pearson: 0.7130
Batch[1388] - loss: 0.002414 best_pearson: 0.7130
Batch[1389] - loss: 0.002299 best_pearson: 0.7130
Batch[1390] - loss: 0.002522 best_pearson: 0.7130
Batch[1391] - loss: 0.002642 best_pearson: 0.7130
Batch[1392] - loss: 0.002451 best_pearson: 0.7130
Batch[1393] - loss: 0.002026 best_pearson: 0.7130
Batch[1394] - loss: 0.001895 best_pearson: 0.7130
Batch[1395] - loss: 0.002213 best_pearson: 0.7130
Batch[1396] - loss: 0.002102 best_pearson: 0.7130
Batch[1397] - loss: 0.003498 best_pearson: 0.7130
Batch[1398] - loss: 0.001493 best_pearson: 0.7130
Batch[1399] - loss: 0.002137 best_pearson: 0.7130
Batch[1400] - loss: 0.003594 best_pearson: 0.7130

Evaluation - loss: 0.000048 pearson: 0.7108 

Batch[1401] - loss: 0.002687 best_pearson: 0.7130
Batch[1402] - loss: 0.004000 best_pearson: 0.7130
Batch[1403] - loss: 0.001375 best_pearson: 0.7130
Batch[1404] - loss: 0.002854 best_pearson: 0.7130
Batch[1405] - loss: 0.001318 best_pearson: 0.7130
Batch[1406] - loss: 0.002872 best_pearson: 0.7130
Batch[1407] - loss: 0.002605 best_pearson: 0.7130
Batch[1408] - loss: 0.003540 best_pearson: 0.7130
Batch[1409] - loss: 0.003779 best_pearson: 0.7130
Batch[1410] - loss: 0.002626 best_pearson: 0.7130
Batch[1411] - loss: 0.002963 best_pearson: 0.7130
Batch[1412] - loss: 0.003147 best_pearson: 0.7130
Batch[1413] - loss: 0.002078 best_pearson: 0.7130
Batch[1414] - loss: 0.001566 best_pearson: 0.7130
Batch[1415] - loss: 0.001734 best_pearson: 0.7130
Batch[1416] - loss: 0.003568 best_pearson: 0.7130
Batch[1417] - loss: 0.002181 best_pearson: 0.7130
Batch[1418] - loss: 0.003399 best_pearson: 0.7130
Batch[1419] - loss: 0.003565 best_pearson: 0.7130
Batch[1420] - loss: 0.002530 best_pearson: 0.7130
Batch[1421] - loss: 0.002180 best_pearson: 0.7130
Batch[1422] - loss: 0.002120 best_pearson: 0.7130
Batch[1423] - loss: 0.003275 best_pearson: 0.7130
Batch[1424] - loss: 0.003619 best_pearson: 0.7130
Batch[1425] - loss: 0.001699 best_pearson: 0.7130
Batch[1426] - loss: 0.002378 best_pearson: 0.7130
Batch[1427] - loss: 0.002881 best_pearson: 0.7130
Batch[1428] - loss: 0.002494 best_pearson: 0.7130
Batch[1429] - loss: 0.002997 best_pearson: 0.7130
Batch[1430] - loss: 0.003358 best_pearson: 0.7130
Batch[1431] - loss: 0.002006 best_pearson: 0.7130
Batch[1432] - loss: 0.002826 best_pearson: 0.7130
Batch[1433] - loss: 0.002585 best_pearson: 0.7130
Batch[1434] - loss: 0.003679 best_pearson: 0.7130
Batch[1435] - loss: 0.001727 best_pearson: 0.7130
Batch[1436] - loss: 0.002983 best_pearson: 0.7130
Batch[1437] - loss: 0.003906 best_pearson: 0.7130
Batch[1438] - loss: 0.002956 best_pearson: 0.7130
Batch[1439] - loss: 0.003305 best_pearson: 0.7130
Batch[1440] - loss: 0.002801 best_pearson: 0.7130
Batch[1441] - loss: 0.002471 best_pearson: 0.7130
Batch[1442] - loss: 0.004510 best_pearson: 0.7130
Batch[1443] - loss: 0.003812 best_pearson: 0.7130
Batch[1444] - loss: 0.002529 best_pearson: 0.7130
Batch[1445] - loss: 0.003432 best_pearson: 0.7130
Batch[1446] - loss: 0.002463 best_pearson: 0.7130
Batch[1447] - loss: 0.002524 best_pearson: 0.7130
Batch[1448] - loss: 0.003483 best_pearson: 0.7130
Batch[1449] - loss: 0.002245 best_pearson: 0.7130
Batch[1450] - loss: 0.002880 best_pearson: 0.7130
Batch[1451] - loss: 0.002410 best_pearson: 0.7130
Batch[1452] - loss: 0.002015 best_pearson: 0.7130
Batch[1453] - loss: 0.001774 best_pearson: 0.7130
Batch[1454] - loss: 0.002837 best_pearson: 0.7130
Batch[1455] - loss: 0.001574 best_pearson: 0.7130
Batch[1456] - loss: 0.002006 best_pearson: 0.7130
Batch[1457] - loss: 0.004378 best_pearson: 0.7130
Batch[1458] - loss: 0.001352 best_pearson: 0.7130
Batch[1459] - loss: 0.002031 best_pearson: 0.7130
Batch[1460] - loss: 0.002062 best_pearson: 0.7130
Batch[1461] - loss: 0.002102 best_pearson: 0.7130
Batch[1462] - loss: 0.002415 best_pearson: 0.7130
Batch[1463] - loss: 0.003150 best_pearson: 0.7130
Batch[1464] - loss: 0.002671 best_pearson: 0.7130
Batch[1465] - loss: 0.001394 best_pearson: 0.7130
Batch[1466] - loss: 0.001373 best_pearson: 0.7130
Batch[1467] - loss: 0.002268 best_pearson: 0.7130
Batch[1468] - loss: 0.002573 best_pearson: 0.7130
Batch[1469] - loss: 0.001258 best_pearson: 0.7130
Batch[1470] - loss: 0.001736 best_pearson: 0.7130
Batch[1471] - loss: 0.002906 best_pearson: 0.7130
Batch[1472] - loss: 0.001907 best_pearson: 0.7130
Batch[1473] - loss: 0.001576 best_pearson: 0.7130
Batch[1474] - loss: 0.001884 best_pearson: 0.7130
Batch[1475] - loss: 0.001726 best_pearson: 0.7130
Batch[1476] - loss: 0.001979 best_pearson: 0.7130
Batch[1477] - loss: 0.002283 best_pearson: 0.7130
Batch[1478] - loss: 0.002864 best_pearson: 0.7130
Batch[1479] - loss: 0.002844 best_pearson: 0.7130
Batch[1480] - loss: 0.002703 best_pearson: 0.7130
Batch[1481] - loss: 0.002876 best_pearson: 0.7130
Batch[1482] - loss: 0.002604 best_pearson: 0.7130
Batch[1483] - loss: 0.002337 best_pearson: 0.7130
Batch[1484] - loss: 0.002568 best_pearson: 0.7130
Batch[1485] - loss: 0.002271 best_pearson: 0.7130
Batch[1486] - loss: 0.001852 best_pearson: 0.7130
Batch[1487] - loss: 0.002266 best_pearson: 0.7130
Batch[1488] - loss: 0.001870 best_pearson: 0.7130
Batch[1489] - loss: 0.004157 best_pearson: 0.7130
Batch[1490] - loss: 0.001561 best_pearson: 0.7130
Batch[1491] - loss: 0.003093 best_pearson: 0.7130
Batch[1492] - loss: 0.001329 best_pearson: 0.7130
Batch[1493] - loss: 0.003193 best_pearson: 0.7130
Batch[1494] - loss: 0.002871 best_pearson: 0.7130
Batch[1495] - loss: 0.003249 best_pearson: 0.7130
Batch[1496] - loss: 0.003957 best_pearson: 0.7130
Batch[1497] - loss: 0.004332 best_pearson: 0.7130
Batch[1498] - loss: 0.002790 best_pearson: 0.7130
Batch[1499] - loss: 0.002834 best_pearson: 0.7130
Batch[1500] - loss: 0.004465 best_pearson: 0.7130

Evaluation - loss: 0.000047 pearson: 0.7151 

Batch[1501] - loss: 0.002173 best_pearson: 0.7151
Batch[1502] - loss: 0.003851 best_pearson: 0.7151
Batch[1503] - loss: 0.003528 best_pearson: 0.7151
Batch[1504] - loss: 0.003380 best_pearson: 0.7151
Batch[1505] - loss: 0.006283 best_pearson: 0.7151
Batch[1506] - loss: 0.002036 best_pearson: 0.7151
Batch[1507] - loss: 0.001701 best_pearson: 0.7151
Batch[1508] - loss: 0.002318 best_pearson: 0.7151
Batch[1509] - loss: 0.001126 best_pearson: 0.7151
Batch[1510] - loss: 0.002996 best_pearson: 0.7151
Batch[1511] - loss: 0.002921 best_pearson: 0.7151
Batch[1512] - loss: 0.002025 best_pearson: 0.7151
Batch[1513] - loss: 0.002917 best_pearson: 0.7151
Batch[1514] - loss: 0.002667 best_pearson: 0.7151
Batch[1515] - loss: 0.001983 best_pearson: 0.7151
Batch[1516] - loss: 0.002764 best_pearson: 0.7151
Batch[1517] - loss: 0.001142 best_pearson: 0.7151
Batch[1518] - loss: 0.001298 best_pearson: 0.7151
Batch[1519] - loss: 0.001665 best_pearson: 0.7151
Batch[1520] - loss: 0.001301 best_pearson: 0.7151
Batch[1521] - loss: 0.002354 best_pearson: 0.7151
Batch[1522] - loss: 0.001419 best_pearson: 0.7151
Batch[1523] - loss: 0.002853 best_pearson: 0.7151
Batch[1524] - loss: 0.001361 best_pearson: 0.7151
Batch[1525] - loss: 0.001522 best_pearson: 0.7151
Batch[1526] - loss: 0.001563 best_pearson: 0.7151
Batch[1527] - loss: 0.003294 best_pearson: 0.7151
Batch[1528] - loss: 0.001753 best_pearson: 0.7151
Batch[1529] - loss: 0.003248 best_pearson: 0.7151
Batch[1530] - loss: 0.002667 best_pearson: 0.7151
Batch[1531] - loss: 0.002078 best_pearson: 0.7151
Batch[1532] - loss: 0.002585 best_pearson: 0.7151
Batch[1533] - loss: 0.002405 best_pearson: 0.7151
Batch[1534] - loss: 0.002031 best_pearson: 0.7151
Batch[1535] - loss: 0.001853 best_pearson: 0.7151
Batch[1536] - loss: 0.001928 best_pearson: 0.7151
Batch[1537] - loss: 0.002599 best_pearson: 0.7151
Batch[1538] - loss: 0.002516 best_pearson: 0.7151
Batch[1539] - loss: 0.002364 best_pearson: 0.7151
Batch[1540] - loss: 0.002637 best_pearson: 0.7151
Batch[1541] - loss: 0.002699 best_pearson: 0.7151
Batch[1542] - loss: 0.001659 best_pearson: 0.7151
Batch[1543] - loss: 0.002056 best_pearson: 0.7151
Batch[1544] - loss: 0.002119 best_pearson: 0.7151
Batch[1545] - loss: 0.002069 best_pearson: 0.7151
Batch[1546] - loss: 0.002181 best_pearson: 0.7151
Batch[1547] - loss: 0.003753 best_pearson: 0.7151
Batch[1548] - loss: 0.002087 best_pearson: 0.7151
Batch[1549] - loss: 0.001711 best_pearson: 0.7151
Batch[1550] - loss: 0.003233 best_pearson: 0.7151
Batch[1551] - loss: 0.002817 best_pearson: 0.7151
Batch[1552] - loss: 0.003592 best_pearson: 0.7151
Batch[1553] - loss: 0.001423 best_pearson: 0.7151
Batch[1554] - loss: 0.001679 best_pearson: 0.7151
Batch[1555] - loss: 0.002176 best_pearson: 0.7151
Batch[1556] - loss: 0.002590 best_pearson: 0.7151
Batch[1557] - loss: 0.001941 best_pearson: 0.7151
Batch[1558] - loss: 0.002739 best_pearson: 0.7151
Batch[1559] - loss: 0.003390 best_pearson: 0.7151
Batch[1560] - loss: 0.002448 best_pearson: 0.7151
Batch[1561] - loss: 0.003163 best_pearson: 0.7151
Batch[1562] - loss: 0.001856 best_pearson: 0.7151
Batch[1563] - loss: 0.001774 best_pearson: 0.7151
Batch[1564] - loss: 0.003464 best_pearson: 0.7151
Batch[1565] - loss: 0.003223 best_pearson: 0.7151
Batch[1566] - loss: 0.002151 best_pearson: 0.7151
Batch[1567] - loss: 0.004461 best_pearson: 0.7151
Batch[1568] - loss: 0.002855 best_pearson: 0.7151
Batch[1569] - loss: 0.001721 best_pearson: 0.7151
Batch[1570] - loss: 0.002693 best_pearson: 0.7151
Batch[1571] - loss: 0.001781 best_pearson: 0.7151
Batch[1572] - loss: 0.002326 best_pearson: 0.7151
Batch[1573] - loss: 0.002123 best_pearson: 0.7151
Batch[1574] - loss: 0.001645 best_pearson: 0.7151
Batch[1575] - loss: 0.002092 best_pearson: 0.7151
Batch[1576] - loss: 0.003290 best_pearson: 0.7151
Batch[1577] - loss: 0.002535 best_pearson: 0.7151
Batch[1578] - loss: 0.001831 best_pearson: 0.7151
Batch[1579] - loss: 0.001207 best_pearson: 0.7151
Batch[1580] - loss: 0.001515 best_pearson: 0.7151
Batch[1581] - loss: 0.002176 best_pearson: 0.7151
Batch[1582] - loss: 0.002521 best_pearson: 0.7151
Batch[1583] - loss: 0.001215 best_pearson: 0.7151
Batch[1584] - loss: 0.001529 best_pearson: 0.7151
Batch[1585] - loss: 0.002517 best_pearson: 0.7151
Batch[1586] - loss: 0.002238 best_pearson: 0.7151
Batch[1587] - loss: 0.002183 best_pearson: 0.7151
Batch[1588] - loss: 0.002191 best_pearson: 0.7151
Batch[1589] - loss: 0.001475 best_pearson: 0.7151
Batch[1590] - loss: 0.002168 best_pearson: 0.7151
Batch[1591] - loss: 0.002614 best_pearson: 0.7151
Batch[1592] - loss: 0.001332 best_pearson: 0.7151
Batch[1593] - loss: 0.003893 best_pearson: 0.7151
Batch[1594] - loss: 0.001267 best_pearson: 0.7151
Batch[1595] - loss: 0.002384 best_pearson: 0.7151
Batch[1596] - loss: 0.001500 best_pearson: 0.7151
Batch[1597] - loss: 0.001931 best_pearson: 0.7151
Batch[1598] - loss: 0.001545 best_pearson: 0.7151
Batch[1599] - loss: 0.001171 best_pearson: 0.7151
Batch[1600] - loss: 0.002232 best_pearson: 0.7151

Evaluation - loss: 0.000047 pearson: 0.7150 

Batch[1601] - loss: 0.002072 best_pearson: 0.7151
Batch[1602] - loss: 0.002890 best_pearson: 0.7151
Batch[1603] - loss: 0.001921 best_pearson: 0.7151
Batch[1604] - loss: 0.001351 best_pearson: 0.7151
Batch[1605] - loss: 0.002649 best_pearson: 0.7151
Batch[1606] - loss: 0.003805 best_pearson: 0.7151
Batch[1607] - loss: 0.001817 best_pearson: 0.7151
Batch[1608] - loss: 0.002143 best_pearson: 0.7151
Batch[1609] - loss: 0.003522 best_pearson: 0.7151
Batch[1610] - loss: 0.002455 best_pearson: 0.7151
Batch[1611] - loss: 0.001846 best_pearson: 0.7151
Batch[1612] - loss: 0.003340 best_pearson: 0.7151
Batch[1613] - loss: 0.002598 best_pearson: 0.7151
Batch[1614] - loss: 0.002477 best_pearson: 0.7151
Batch[1615] - loss: 0.001938 best_pearson: 0.7151
Batch[1616] - loss: 0.002104 best_pearson: 0.7151
Batch[1617] - loss: 0.002642 best_pearson: 0.7151
Batch[1618] - loss: 0.002040 best_pearson: 0.7151
Batch[1619] - loss: 0.002668 best_pearson: 0.7151
Batch[1620] - loss: 0.003637 best_pearson: 0.7151
Batch[1621] - loss: 0.001220 best_pearson: 0.7151
Batch[1622] - loss: 0.003256 best_pearson: 0.7151
Batch[1623] - loss: 0.001898 best_pearson: 0.7151
Batch[1624] - loss: 0.002043 best_pearson: 0.7151
Batch[1625] - loss: 0.002609 best_pearson: 0.7151
Batch[1626] - loss: 0.005838 best_pearson: 0.7151
Batch[1627] - loss: 0.003419 best_pearson: 0.7151
Batch[1628] - loss: 0.002700 best_pearson: 0.7151
Batch[1629] - loss: 0.001157 best_pearson: 0.7151
Batch[1630] - loss: 0.001622 best_pearson: 0.7151
Batch[1631] - loss: 0.003801 best_pearson: 0.7151
Batch[1632] - loss: 0.002185 best_pearson: 0.7151
Batch[1633] - loss: 0.001747 best_pearson: 0.7151
Batch[1634] - loss: 0.001768 best_pearson: 0.7151
Batch[1635] - loss: 0.001961 best_pearson: 0.7151
Batch[1636] - loss: 0.002834 best_pearson: 0.7151
Batch[1637] - loss: 0.002437 best_pearson: 0.7151
Batch[1638] - loss: 0.002278 best_pearson: 0.7151
Batch[1639] - loss: 0.002817 best_pearson: 0.7151
Batch[1640] - loss: 0.002742 best_pearson: 0.7151
Batch[1641] - loss: 0.002288 best_pearson: 0.7151
Batch[1642] - loss: 0.002716 best_pearson: 0.7151
Batch[1643] - loss: 0.003101 best_pearson: 0.7151
Batch[1644] - loss: 0.001963 best_pearson: 0.7151
Batch[1645] - loss: 0.001612 best_pearson: 0.7151
Batch[1646] - loss: 0.002408 best_pearson: 0.7151
Batch[1647] - loss: 0.002203 best_pearson: 0.7151
Batch[1648] - loss: 0.001385 best_pearson: 0.7151
Batch[1649] - loss: 0.002528 best_pearson: 0.7151
Batch[1650] - loss: 0.001742 best_pearson: 0.7151
Batch[1651] - loss: 0.002045 best_pearson: 0.7151
Batch[1652] - loss: 0.001996 best_pearson: 0.7151
Batch[1653] - loss: 0.002348 best_pearson: 0.7151
Batch[1654] - loss: 0.003686 best_pearson: 0.7151
Batch[1655] - loss: 0.002977 best_pearson: 0.7151
Batch[1656] - loss: 0.001707 best_pearson: 0.7151
Batch[1657] - loss: 0.001432 best_pearson: 0.7151
Batch[1658] - loss: 0.001689 best_pearson: 0.7151
Batch[1659] - loss: 0.001654 best_pearson: 0.7151
Batch[1660] - loss: 0.001585 best_pearson: 0.7151
Batch[1661] - loss: 0.003991 best_pearson: 0.7151
Batch[1662] - loss: 0.001327 best_pearson: 0.7151
Batch[1663] - loss: 0.002996 best_pearson: 0.7151
Batch[1664] - loss: 0.003354 best_pearson: 0.7151
Batch[1665] - loss: 0.002966 best_pearson: 0.7151
Batch[1666] - loss: 0.002567 best_pearson: 0.7151
Batch[1667] - loss: 0.003138 best_pearson: 0.7151
Batch[1668] - loss: 0.002005 best_pearson: 0.7151
Batch[1669] - loss: 0.004231 best_pearson: 0.7151
Batch[1670] - loss: 0.004011 best_pearson: 0.7151
Batch[1671] - loss: 0.001804 best_pearson: 0.7151
Batch[1672] - loss: 0.003513 best_pearson: 0.7151
Batch[1673] - loss: 0.001627 best_pearson: 0.7151
Batch[1674] - loss: 0.001926 best_pearson: 0.7151
Batch[1675] - loss: 0.002491 best_pearson: 0.7151
Batch[1676] - loss: 0.001858 best_pearson: 0.7151
Batch[1677] - loss: 0.003770 best_pearson: 0.7151
Batch[1678] - loss: 0.001709 best_pearson: 0.7151
Batch[1679] - loss: 0.003862 best_pearson: 0.7151
Batch[1680] - loss: 0.002152 best_pearson: 0.7151
Batch[1681] - loss: 0.002481 best_pearson: 0.7151
Batch[1682] - loss: 0.003393 best_pearson: 0.7151
Batch[1683] - loss: 0.001817 best_pearson: 0.7151
Batch[1684] - loss: 0.001870 best_pearson: 0.7151
Batch[1685] - loss: 0.002881 best_pearson: 0.7151
Batch[1686] - loss: 0.002175 best_pearson: 0.7151
Batch[1687] - loss: 0.002173 best_pearson: 0.7151
Batch[1688] - loss: 0.002454 best_pearson: 0.7151
Batch[1689] - loss: 0.001640 best_pearson: 0.7151
Batch[1690] - loss: 0.001243 best_pearson: 0.7151
Batch[1691] - loss: 0.001819 best_pearson: 0.7151
Batch[1692] - loss: 0.002851 best_pearson: 0.7151
Batch[1693] - loss: 0.004209 best_pearson: 0.7151
Batch[1694] - loss: 0.001657 best_pearson: 0.7151
Batch[1695] - loss: 0.001992 best_pearson: 0.7151
Batch[1696] - loss: 0.003098 best_pearson: 0.7151
Batch[1697] - loss: 0.002474 best_pearson: 0.7151
Batch[1698] - loss: 0.002379 best_pearson: 0.7151
Batch[1699] - loss: 0.002593 best_pearson: 0.7151
Batch[1700] - loss: 0.001649 best_pearson: 0.7151

Evaluation - loss: 0.000049 pearson: 0.7083 

Batch[1701] - loss: 0.001623 best_pearson: 0.7151
Batch[1702] - loss: 0.004596 best_pearson: 0.7151
Batch[1703] - loss: 0.002905 best_pearson: 0.7151
Batch[1704] - loss: 0.002735 best_pearson: 0.7151
Batch[1705] - loss: 0.001497 best_pearson: 0.7151
Batch[1706] - loss: 0.001673 best_pearson: 0.7151
Batch[1707] - loss: 0.002883 best_pearson: 0.7151
Batch[1708] - loss: 0.003842 best_pearson: 0.7151
Batch[1709] - loss: 0.003009 best_pearson: 0.7151
Batch[1710] - loss: 0.003487 best_pearson: 0.7151
Batch[1711] - loss: 0.001995 best_pearson: 0.7151
Batch[1712] - loss: 0.001645 best_pearson: 0.7151
Batch[1713] - loss: 0.001293 best_pearson: 0.7151
Batch[1714] - loss: 0.003002 best_pearson: 0.7151
Batch[1715] - loss: 0.002720 best_pearson: 0.7151
Batch[1716] - loss: 0.001844 best_pearson: 0.7151
Batch[1717] - loss: 0.002383 best_pearson: 0.7151
Batch[1718] - loss: 0.001999 best_pearson: 0.7151
Batch[1719] - loss: 0.002057 best_pearson: 0.7151
Batch[1720] - loss: 0.001866 best_pearson: 0.7151
Batch[1721] - loss: 0.002781 best_pearson: 0.7151
Batch[1722] - loss: 0.001298 best_pearson: 0.7151
Batch[1723] - loss: 0.002447 best_pearson: 0.7151
Batch[1724] - loss: 0.002510 best_pearson: 0.7151
Batch[1725] - loss: 0.001939 best_pearson: 0.7151
Batch[1726] - loss: 0.001529 best_pearson: 0.7151
Batch[1727] - loss: 0.001969 best_pearson: 0.7151
Batch[1728] - loss: 0.002597 best_pearson: 0.7151
Batch[1729] - loss: 0.001759 best_pearson: 0.7151
Batch[1730] - loss: 0.001910 best_pearson: 0.7151
Batch[1731] - loss: 0.001985 best_pearson: 0.7151
Batch[1732] - loss: 0.001568 best_pearson: 0.7151
Batch[1733] - loss: 0.002889 best_pearson: 0.7151
Batch[1734] - loss: 0.002905 best_pearson: 0.7151
Batch[1735] - loss: 0.001540 best_pearson: 0.7151
Batch[1736] - loss: 0.002062 best_pearson: 0.7151
Batch[1737] - loss: 0.002015 best_pearson: 0.7151
Batch[1738] - loss: 0.001000 best_pearson: 0.7151
Batch[1739] - loss: 0.002973 best_pearson: 0.7151
Batch[1740] - loss: 0.001753 best_pearson: 0.7151
Batch[1741] - loss: 0.001316 best_pearson: 0.7151
Batch[1742] - loss: 0.002563 best_pearson: 0.7151
Batch[1743] - loss: 0.001221 best_pearson: 0.7151
Batch[1744] - loss: 0.004072 best_pearson: 0.7151
Batch[1745] - loss: 0.001950 best_pearson: 0.7151
Batch[1746] - loss: 0.001731 best_pearson: 0.7151
Batch[1747] - loss: 0.001712 best_pearson: 0.7151
Batch[1748] - loss: 0.001603 best_pearson: 0.7151
Batch[1749] - loss: 0.002141 best_pearson: 0.7151
Batch[1750] - loss: 0.002446 best_pearson: 0.7151
Batch[1751] - loss: 0.001551 best_pearson: 0.7151
Batch[1752] - loss: 0.005813 best_pearson: 0.7151
Batch[1753] - loss: 0.002290 best_pearson: 0.7151
Batch[1754] - loss: 0.002347 best_pearson: 0.7151
Batch[1755] - loss: 0.003789 best_pearson: 0.7151
Batch[1756] - loss: 0.002338 best_pearson: 0.7151
Batch[1757] - loss: 0.001944 best_pearson: 0.7151
Batch[1758] - loss: 0.002055 best_pearson: 0.7151
Batch[1759] - loss: 0.001245 best_pearson: 0.7151
Batch[1760] - loss: 0.002567 best_pearson: 0.7151
Batch[1761] - loss: 0.003205 best_pearson: 0.7151
Batch[1762] - loss: 0.002430 best_pearson: 0.7151
Batch[1763] - loss: 0.002942 best_pearson: 0.7151
Batch[1764] - loss: 0.001650 best_pearson: 0.7151
Batch[1765] - loss: 0.002280 best_pearson: 0.7151
Batch[1766] - loss: 0.001893 best_pearson: 0.7151
Batch[1767] - loss: 0.002880 best_pearson: 0.7151
Batch[1768] - loss: 0.001888 best_pearson: 0.7151
Batch[1769] - loss: 0.002588 best_pearson: 0.7151
Batch[1770] - loss: 0.001705 best_pearson: 0.7151
Batch[1771] - loss: 0.003204 best_pearson: 0.7151
Batch[1772] - loss: 0.001966 best_pearson: 0.7151
Batch[1773] - loss: 0.001850 best_pearson: 0.7151
Batch[1774] - loss: 0.001945 best_pearson: 0.7151
Batch[1775] - loss: 0.001960 best_pearson: 0.7151
Batch[1776] - loss: 0.001778 best_pearson: 0.7151
Batch[1777] - loss: 0.003340 best_pearson: 0.7151
Batch[1778] - loss: 0.002462 best_pearson: 0.7151
Batch[1779] - loss: 0.002237 best_pearson: 0.7151
Batch[1780] - loss: 0.001631 best_pearson: 0.7151
Batch[1781] - loss: 0.001636 best_pearson: 0.7151
Batch[1782] - loss: 0.000994 best_pearson: 0.7151
Batch[1783] - loss: 0.001777 best_pearson: 0.7151
Batch[1784] - loss: 0.002881 best_pearson: 0.7151
Batch[1785] - loss: 0.002997 best_pearson: 0.7151
Batch[1786] - loss: 0.001716 best_pearson: 0.7151
Batch[1787] - loss: 0.001438 best_pearson: 0.7151
Batch[1788] - loss: 0.002138 best_pearson: 0.7151
Batch[1789] - loss: 0.002584 best_pearson: 0.7151
Batch[1790] - loss: 0.001628 best_pearson: 0.7151
Batch[1791] - loss: 0.002806 best_pearson: 0.7151
Batch[1792] - loss: 0.002026 best_pearson: 0.7151
Batch[1793] - loss: 0.001057 best_pearson: 0.7151
Batch[1794] - loss: 0.001983 best_pearson: 0.7151
Batch[1795] - loss: 0.001672 best_pearson: 0.7151
Batch[1796] - loss: 0.000982 best_pearson: 0.7151
Batch[1797] - loss: 0.001483 best_pearson: 0.7151
Batch[1798] - loss: 0.001198 best_pearson: 0.7151
Batch[1799] - loss: 0.001628 best_pearson: 0.7151
Batch[1800] - loss: 0.002141 best_pearson: 0.7151

Evaluation - loss: 0.000046 pearson: 0.7142 

Batch[1801] - loss: 0.002050 best_pearson: 0.7151
Batch[1802] - loss: 0.000995 best_pearson: 0.7151
Batch[1803] - loss: 0.003003 best_pearson: 0.7151
Batch[1804] - loss: 0.002691 best_pearson: 0.7151
Batch[1805] - loss: 0.001997 best_pearson: 0.7151
Batch[1806] - loss: 0.003966 best_pearson: 0.7151
Batch[1807] - loss: 0.002191 best_pearson: 0.7151
Batch[1808] - loss: 0.002414 best_pearson: 0.7151
Batch[1809] - loss: 0.003104 best_pearson: 0.7151
Batch[1810] - loss: 0.001308 best_pearson: 0.7151
Batch[1811] - loss: 0.001864 best_pearson: 0.7151
Batch[1812] - loss: 0.001259 best_pearson: 0.7151
Batch[1813] - loss: 0.002157 best_pearson: 0.7151
Batch[1814] - loss: 0.001538 best_pearson: 0.7151
Batch[1815] - loss: 0.001764 best_pearson: 0.7151
Batch[1816] - loss: 0.002323 best_pearson: 0.7151
Batch[1817] - loss: 0.002365 best_pearson: 0.7151
Batch[1818] - loss: 0.001859 best_pearson: 0.7151
Batch[1819] - loss: 0.002018 best_pearson: 0.7151
Batch[1820] - loss: 0.001505 best_pearson: 0.7151
Batch[1821] - loss: 0.001884 best_pearson: 0.7151
Batch[1822] - loss: 0.001776 best_pearson: 0.7151
Batch[1823] - loss: 0.002138 best_pearson: 0.7151
Batch[1824] - loss: 0.002508 best_pearson: 0.7151
Batch[1825] - loss: 0.002360 best_pearson: 0.7151
Batch[1826] - loss: 0.002323 best_pearson: 0.7151
Batch[1827] - loss: 0.002079 best_pearson: 0.7151
Batch[1828] - loss: 0.002719 best_pearson: 0.7151
Batch[1829] - loss: 0.002055 best_pearson: 0.7151
Batch[1830] - loss: 0.001640 best_pearson: 0.7151
Batch[1831] - loss: 0.002298 best_pearson: 0.7151
Batch[1832] - loss: 0.002244 best_pearson: 0.7151
Batch[1833] - loss: 0.001548 best_pearson: 0.7151
Batch[1834] - loss: 0.001377 best_pearson: 0.7151
Batch[1835] - loss: 0.002303 best_pearson: 0.7151
Batch[1836] - loss: 0.002240 best_pearson: 0.7151
Batch[1837] - loss: 0.001925 best_pearson: 0.7151
Batch[1838] - loss: 0.002304 best_pearson: 0.7151
Batch[1839] - loss: 0.001902 best_pearson: 0.7151
Batch[1840] - loss: 0.001325 best_pearson: 0.7151
Batch[1841] - loss: 0.002048 best_pearson: 0.7151
Batch[1842] - loss: 0.001650 best_pearson: 0.7151
Batch[1843] - loss: 0.001849 best_pearson: 0.7151
Batch[1844] - loss: 0.002569 best_pearson: 0.7151
Batch[1845] - loss: 0.000971 best_pearson: 0.7151
Batch[1846] - loss: 0.001492 best_pearson: 0.7151
Batch[1847] - loss: 0.003754 best_pearson: 0.7151
Batch[1848] - loss: 0.001724 best_pearson: 0.7151
Batch[1849] - loss: 0.001678 best_pearson: 0.7151
Batch[1850] - loss: 0.001404 best_pearson: 0.7151
Batch[1851] - loss: 0.003587 best_pearson: 0.7151
Batch[1852] - loss: 0.002988 best_pearson: 0.7151
Batch[1853] - loss: 0.001198 best_pearson: 0.7151
Batch[1854] - loss: 0.001744 best_pearson: 0.7151
Batch[1855] - loss: 0.002046 best_pearson: 0.7151
Batch[1856] - loss: 0.002190 best_pearson: 0.7151
Batch[1857] - loss: 0.003192 best_pearson: 0.7151
Batch[1858] - loss: 0.002523 best_pearson: 0.7151
Batch[1859] - loss: 0.001371 best_pearson: 0.7151
Batch[1860] - loss: 0.002562 best_pearson: 0.7151
Batch[1861] - loss: 0.001860 best_pearson: 0.7151
Batch[1862] - loss: 0.003596 best_pearson: 0.7151
Batch[1863] - loss: 0.001601 best_pearson: 0.7151
Batch[1864] - loss: 0.001032 best_pearson: 0.7151
Batch[1865] - loss: 0.001226 best_pearson: 0.7151
Batch[1866] - loss: 0.002488 best_pearson: 0.7151
Batch[1867] - loss: 0.001998 best_pearson: 0.7151
Batch[1868] - loss: 0.001927 best_pearson: 0.7151
Batch[1869] - loss: 0.002087 best_pearson: 0.7151
Batch[1870] - loss: 0.001266 best_pearson: 0.7151
Batch[1871] - loss: 0.002344 best_pearson: 0.7151
Batch[1872] - loss: 0.001623 best_pearson: 0.7151
Batch[1873] - loss: 0.001219 best_pearson: 0.7151
Batch[1874] - loss: 0.001106 best_pearson: 0.7151
Batch[1875] - loss: 0.001157 best_pearson: 0.7151
Batch[1876] - loss: 0.001875 best_pearson: 0.7151
Batch[1877] - loss: 0.002415 best_pearson: 0.7151
Batch[1878] - loss: 0.002704 best_pearson: 0.7151
Batch[1879] - loss: 0.002405 best_pearson: 0.7151
Batch[1880] - loss: 0.002213 best_pearson: 0.7151
Batch[1881] - loss: 0.002229 best_pearson: 0.7151
Batch[1882] - loss: 0.002243 best_pearson: 0.7151
Batch[1883] - loss: 0.002488 best_pearson: 0.7151
Batch[1884] - loss: 0.002417 best_pearson: 0.7151
Batch[1885] - loss: 0.003173 best_pearson: 0.7151
Batch[1886] - loss: 0.001751 best_pearson: 0.7151
Batch[1887] - loss: 0.002583 best_pearson: 0.7151
Batch[1888] - loss: 0.001728 best_pearson: 0.7151
Batch[1889] - loss: 0.001576 best_pearson: 0.7151
Batch[1890] - loss: 0.001717 best_pearson: 0.7151
Batch[1891] - loss: 0.002631 best_pearson: 0.7151
Batch[1892] - loss: 0.002007 best_pearson: 0.7151
Batch[1893] - loss: 0.002013 best_pearson: 0.7151
Batch[1894] - loss: 0.002718 best_pearson: 0.7151
Batch[1895] - loss: 0.002563 best_pearson: 0.7151
Batch[1896] - loss: 0.001431 best_pearson: 0.7151
Batch[1897] - loss: 0.005043 best_pearson: 0.7151
Batch[1898] - loss: 0.002778 best_pearson: 0.7151
Batch[1899] - loss: 0.002413 best_pearson: 0.7151
Batch[1900] - loss: 0.001798 best_pearson: 0.7151

Evaluation - loss: 0.000047 pearson: 0.7156 

Batch[1901] - loss: 0.002495 best_pearson: 0.7156
Batch[1902] - loss: 0.002554 best_pearson: 0.7156
Batch[1903] - loss: 0.003103 best_pearson: 0.7156
Batch[1904] - loss: 0.002077 best_pearson: 0.7156
Batch[1905] - loss: 0.002400 best_pearson: 0.7156
Batch[1906] - loss: 0.001660 best_pearson: 0.7156
Batch[1907] - loss: 0.002306 best_pearson: 0.7156
Batch[1908] - loss: 0.001633 best_pearson: 0.7156
Batch[1909] - loss: 0.001212 best_pearson: 0.7156
Batch[1910] - loss: 0.001379 best_pearson: 0.7156
Batch[1911] - loss: 0.001615 best_pearson: 0.7156
Batch[1912] - loss: 0.002655 best_pearson: 0.7156
Batch[1913] - loss: 0.001764 best_pearson: 0.7156
Batch[1914] - loss: 0.001397 best_pearson: 0.7156
Batch[1915] - loss: 0.003528 best_pearson: 0.7156
Batch[1916] - loss: 0.001986 best_pearson: 0.7156
Batch[1917] - loss: 0.000805 best_pearson: 0.7156
Batch[1918] - loss: 0.001940 best_pearson: 0.7156
Batch[1919] - loss: 0.001232 best_pearson: 0.7156
Batch[1920] - loss: 0.001758 best_pearson: 0.7156
Batch[1921] - loss: 0.003533 best_pearson: 0.7156
Batch[1922] - loss: 0.001877 best_pearson: 0.7156
Batch[1923] - loss: 0.001891 best_pearson: 0.7156
Batch[1924] - loss: 0.001587 best_pearson: 0.7156
Batch[1925] - loss: 0.003454 best_pearson: 0.7156
Batch[1926] - loss: 0.002551 best_pearson: 0.7156
Batch[1927] - loss: 0.002482 best_pearson: 0.7156
Batch[1928] - loss: 0.001558 best_pearson: 0.7156
Batch[1929] - loss: 0.001883 best_pearson: 0.7156
Batch[1930] - loss: 0.001403 best_pearson: 0.7156
Batch[1931] - loss: 0.001981 best_pearson: 0.7156
Batch[1932] - loss: 0.002676 best_pearson: 0.7156
Batch[1933] - loss: 0.002434 best_pearson: 0.7156
Batch[1934] - loss: 0.001138 best_pearson: 0.7156
Batch[1935] - loss: 0.001450 best_pearson: 0.7156
Batch[1936] - loss: 0.002454 best_pearson: 0.7156
Batch[1937] - loss: 0.001679 best_pearson: 0.7156
Batch[1938] - loss: 0.001910 best_pearson: 0.7156
Batch[1939] - loss: 0.001624 best_pearson: 0.7156
Batch[1940] - loss: 0.001436 best_pearson: 0.7156
Batch[1941] - loss: 0.002793 best_pearson: 0.7156
Batch[1942] - loss: 0.002849 best_pearson: 0.7156
Batch[1943] - loss: 0.001303 best_pearson: 0.7156
Batch[1944] - loss: 0.003372 best_pearson: 0.7156
Batch[1945] - loss: 0.002353 best_pearson: 0.7156
Batch[1946] - loss: 0.002468 best_pearson: 0.7156
Batch[1947] - loss: 0.003012 best_pearson: 0.7156
Batch[1948] - loss: 0.002871 best_pearson: 0.7156
Batch[1949] - loss: 0.002067 best_pearson: 0.7156
Batch[1950] - loss: 0.002251 best_pearson: 0.7156
Batch[1951] - loss: 0.002081 best_pearson: 0.7156
Batch[1952] - loss: 0.001671 best_pearson: 0.7156
Batch[1953] - loss: 0.001915 best_pearson: 0.7156
Batch[1954] - loss: 0.001682 best_pearson: 0.7156
Batch[1955] - loss: 0.003141 best_pearson: 0.7156
Batch[1956] - loss: 0.002413 best_pearson: 0.7156
Batch[1957] - loss: 0.002096 best_pearson: 0.7156
Batch[1958] - loss: 0.001453 best_pearson: 0.7156
Batch[1959] - loss: 0.002852 best_pearson: 0.7156
Batch[1960] - loss: 0.001926 best_pearson: 0.7156
Batch[1961] - loss: 0.003172 best_pearson: 0.7156
Batch[1962] - loss: 0.001258 best_pearson: 0.7156
Batch[1963] - loss: 0.001914 best_pearson: 0.7156
Batch[1964] - loss: 0.001776 best_pearson: 0.7156
Batch[1965] - loss: 0.001832 best_pearson: 0.7156
Batch[1966] - loss: 0.001138 best_pearson: 0.7156
Batch[1967] - loss: 0.001666 best_pearson: 0.7156
Batch[1968] - loss: 0.002295 best_pearson: 0.7156
Batch[1969] - loss: 0.001884 best_pearson: 0.7156
Batch[1970] - loss: 0.002819 best_pearson: 0.7156
Batch[1971] - loss: 0.002103 best_pearson: 0.7156
Batch[1972] - loss: 0.001588 best_pearson: 0.7156
Batch[1973] - loss: 0.002255 best_pearson: 0.7156
Batch[1974] - loss: 0.001597 best_pearson: 0.7156
Batch[1975] - loss: 0.001396 best_pearson: 0.7156
Batch[1976] - loss: 0.001657 best_pearson: 0.7156
Batch[1977] - loss: 0.002439 best_pearson: 0.7156
Batch[1978] - loss: 0.001786 best_pearson: 0.7156
Batch[1979] - loss: 0.001970 best_pearson: 0.7156
Batch[1980] - loss: 0.001644 best_pearson: 0.7156
Batch[1981] - loss: 0.004232 best_pearson: 0.7156
Batch[1982] - loss: 0.002275 best_pearson: 0.7156
Batch[1983] - loss: 0.002280 best_pearson: 0.7156
Batch[1984] - loss: 0.000935 best_pearson: 0.7156
Batch[1985] - loss: 0.001718 best_pearson: 0.7156
Batch[1986] - loss: 0.001973 best_pearson: 0.7156
Batch[1987] - loss: 0.001707 best_pearson: 0.7156
Batch[1988] - loss: 0.001118 best_pearson: 0.7156
Batch[1989] - loss: 0.002216 best_pearson: 0.7156
Batch[1990] - loss: 0.002520 best_pearson: 0.7156
Batch[1991] - loss: 0.001731 best_pearson: 0.7156
Batch[1992] - loss: 0.002041 best_pearson: 0.7156
Batch[1993] - loss: 0.002004 best_pearson: 0.7156
Batch[1994] - loss: 0.001775 best_pearson: 0.7156
Batch[1995] - loss: 0.001656 best_pearson: 0.7156
Batch[1996] - loss: 0.001987 best_pearson: 0.7156
Batch[1997] - loss: 0.001815 best_pearson: 0.7156
Batch[1998] - loss: 0.002339 best_pearson: 0.7156
Batch[1999] - loss: 0.001690 best_pearson: 0.7156
Batch[2000] - loss: 0.001995 best_pearson: 0.7156

Evaluation - loss: 0.000049 pearson: 0.7140 

Batch[2001] - loss: 0.002941 best_pearson: 0.7156
Batch[2002] - loss: 0.001548 best_pearson: 0.7156
Batch[2003] - loss: 0.002465 best_pearson: 0.7156
Batch[2004] - loss: 0.002154 best_pearson: 0.7156
Batch[2005] - loss: 0.001589 best_pearson: 0.7156
Batch[2006] - loss: 0.001939 best_pearson: 0.7156
Batch[2007] - loss: 0.002041 best_pearson: 0.7156
Batch[2008] - loss: 0.002793 best_pearson: 0.7156
Batch[2009] - loss: 0.001559 best_pearson: 0.7156
Batch[2010] - loss: 0.002096 best_pearson: 0.7156
Batch[2011] - loss: 0.002044 best_pearson: 0.7156
Batch[2012] - loss: 0.001803 best_pearson: 0.7156
Batch[2013] - loss: 0.002241 best_pearson: 0.7156
Batch[2014] - loss: 0.001729 best_pearson: 0.7156
Batch[2015] - loss: 0.002364 best_pearson: 0.7156
Batch[2016] - loss: 0.001519 best_pearson: 0.7156
Batch[2017] - loss: 0.002969 best_pearson: 0.7156
Batch[2018] - loss: 0.003172 best_pearson: 0.7156
Batch[2019] - loss: 0.001567 best_pearson: 0.7156
Batch[2020] - loss: 0.003163 best_pearson: 0.7156
Batch[2021] - loss: 0.001451 best_pearson: 0.7156
Batch[2022] - loss: 0.001269 best_pearson: 0.7156
Batch[2023] - loss: 0.002156 best_pearson: 0.7156
Batch[2024] - loss: 0.001133 best_pearson: 0.7156
Batch[2025] - loss: 0.002008 best_pearson: 0.7156
Batch[2026] - loss: 0.001304 best_pearson: 0.7156
Batch[2027] - loss: 0.002496 best_pearson: 0.7156
Batch[2028] - loss: 0.001646 best_pearson: 0.7156
Batch[2029] - loss: 0.002310 best_pearson: 0.7156
Batch[2030] - loss: 0.001380 best_pearson: 0.7156
Batch[2031] - loss: 0.001446 best_pearson: 0.7156
Batch[2032] - loss: 0.004326 best_pearson: 0.7156
Batch[2033] - loss: 0.001833 best_pearson: 0.7156
Batch[2034] - loss: 0.001412 best_pearson: 0.7156
Batch[2035] - loss: 0.001322 best_pearson: 0.7156
Batch[2036] - loss: 0.001409 best_pearson: 0.7156
Batch[2037] - loss: 0.002451 best_pearson: 0.7156
Batch[2038] - loss: 0.002453 best_pearson: 0.7156
Batch[2039] - loss: 0.003356 best_pearson: 0.7156
Batch[2040] - loss: 0.001960 best_pearson: 0.7156
Batch[2041] - loss: 0.001282 best_pearson: 0.7156
Batch[2042] - loss: 0.001929 best_pearson: 0.7156
Batch[2043] - loss: 0.002526 best_pearson: 0.7156
Batch[2044] - loss: 0.002019 best_pearson: 0.7156
Batch[2045] - loss: 0.001989 best_pearson: 0.7156
Batch[2046] - loss: 0.001330 best_pearson: 0.7156
Batch[2047] - loss: 0.002876 best_pearson: 0.7156
Batch[2048] - loss: 0.001855 best_pearson: 0.7156
Batch[2049] - loss: 0.002173 best_pearson: 0.7156
Batch[2050] - loss: 0.002415 best_pearson: 0.7156
Batch[2051] - loss: 0.002441 best_pearson: 0.7156
Batch[2052] - loss: 0.001705 best_pearson: 0.7156
Batch[2053] - loss: 0.001924 best_pearson: 0.7156
Batch[2054] - loss: 0.002663 best_pearson: 0.7156
Batch[2055] - loss: 0.002729 best_pearson: 0.7156
Batch[2056] - loss: 0.002111 best_pearson: 0.7156
Batch[2057] - loss: 0.001193 best_pearson: 0.7156
Batch[2058] - loss: 0.002264 best_pearson: 0.7156
Batch[2059] - loss: 0.001035 best_pearson: 0.7156
Batch[2060] - loss: 0.001766 best_pearson: 0.7156
Batch[2061] - loss: 0.001816 best_pearson: 0.7156
Batch[2062] - loss: 0.001481 best_pearson: 0.7156
Batch[2063] - loss: 0.001707 best_pearson: 0.7156
Batch[2064] - loss: 0.002417 best_pearson: 0.7156
Batch[2065] - loss: 0.002193 best_pearson: 0.7156
Batch[2066] - loss: 0.001532 best_pearson: 0.7156
Batch[2067] - loss: 0.001940 best_pearson: 0.7156
Batch[2068] - loss: 0.001484 best_pearson: 0.7156
Batch[2069] - loss: 0.001807 best_pearson: 0.7156
Batch[2070] - loss: 0.001123 best_pearson: 0.7156
Batch[2071] - loss: 0.001932 best_pearson: 0.7156
Batch[2072] - loss: 0.001996 best_pearson: 0.7156
Batch[2073] - loss: 0.001276 best_pearson: 0.7156
Batch[2074] - loss: 0.001438 best_pearson: 0.7156
Batch[2075] - loss: 0.001752 best_pearson: 0.7156
Batch[2076] - loss: 0.001412 best_pearson: 0.7156
Batch[2077] - loss: 0.002033 best_pearson: 0.7156
Batch[2078] - loss: 0.002015 best_pearson: 0.7156
Batch[2079] - loss: 0.001047 best_pearson: 0.7156
Batch[2080] - loss: 0.002999 best_pearson: 0.7156
Batch[2081] - loss: 0.001448 best_pearson: 0.7156
Batch[2082] - loss: 0.001817 best_pearson: 0.7156
Batch[2083] - loss: 0.001533 best_pearson: 0.7156
Batch[2084] - loss: 0.001210 best_pearson: 0.7156
Batch[2085] - loss: 0.001297 best_pearson: 0.7156
Batch[2086] - loss: 0.001606 best_pearson: 0.7156
Batch[2087] - loss: 0.002436 best_pearson: 0.7156
Batch[2088] - loss: 0.002249 best_pearson: 0.7156
Batch[2089] - loss: 0.001679 best_pearson: 0.7156
Batch[2090] - loss: 0.002278 best_pearson: 0.7156
Batch[2091] - loss: 0.001466 best_pearson: 0.7156
Batch[2092] - loss: 0.001332 best_pearson: 0.7156
Batch[2093] - loss: 0.002467 best_pearson: 0.7156
Batch[2094] - loss: 0.002058 best_pearson: 0.7156
Batch[2095] - loss: 0.001812 best_pearson: 0.7156
Batch[2096] - loss: 0.002436 best_pearson: 0.7156
Batch[2097] - loss: 0.001831 best_pearson: 0.7156
Batch[2098] - loss: 0.001403 best_pearson: 0.7156
Batch[2099] - loss: 0.001226 best_pearson: 0.7156
Batch[2100] - loss: 0.001432 best_pearson: 0.7156

Evaluation - loss: 0.000047 pearson: 0.7127 

Batch[2101] - loss: 0.001983 best_pearson: 0.7156
Batch[2102] - loss: 0.001835 best_pearson: 0.7156
Batch[2103] - loss: 0.002474 best_pearson: 0.7156
Batch[2104] - loss: 0.002578 best_pearson: 0.7156
Batch[2105] - loss: 0.001627 best_pearson: 0.7156
Batch[2106] - loss: 0.002536 best_pearson: 0.7156
Batch[2107] - loss: 0.000732 best_pearson: 0.7156
Batch[2108] - loss: 0.001625 best_pearson: 0.7156
Batch[2109] - loss: 0.002752 best_pearson: 0.7156
Batch[2110] - loss: 0.002178 best_pearson: 0.7156
Batch[2111] - loss: 0.001517 best_pearson: 0.7156
Batch[2112] - loss: 0.001903 best_pearson: 0.7156
Batch[2113] - loss: 0.001646 best_pearson: 0.7156
Batch[2114] - loss: 0.002011 best_pearson: 0.7156
Batch[2115] - loss: 0.001020 best_pearson: 0.7156
Batch[2116] - loss: 0.001902 best_pearson: 0.7156
Batch[2117] - loss: 0.001336 best_pearson: 0.7156
Batch[2118] - loss: 0.001377 best_pearson: 0.7156
Batch[2119] - loss: 0.003032 best_pearson: 0.7156
Batch[2120] - loss: 0.001437 best_pearson: 0.7156
Batch[2121] - loss: 0.002891 best_pearson: 0.7156
Batch[2122] - loss: 0.002155 best_pearson: 0.7156
Batch[2123] - loss: 0.001315 best_pearson: 0.7156
Batch[2124] - loss: 0.002636 best_pearson: 0.7156
Batch[2125] - loss: 0.002507 best_pearson: 0.7156
Batch[2126] - loss: 0.001651 best_pearson: 0.7156
Batch[2127] - loss: 0.002098 best_pearson: 0.7156
Batch[2128] - loss: 0.001316 best_pearson: 0.7156
Batch[2129] - loss: 0.001784 best_pearson: 0.7156
Batch[2130] - loss: 0.001607 best_pearson: 0.7156
Batch[2131] - loss: 0.001611 best_pearson: 0.7156
Batch[2132] - loss: 0.001736 best_pearson: 0.7156
Batch[2133] - loss: 0.003317 best_pearson: 0.7156
Batch[2134] - loss: 0.001810 best_pearson: 0.7156
Batch[2135] - loss: 0.001061 best_pearson: 0.7156
Batch[2136] - loss: 0.001681 best_pearson: 0.7156
Batch[2137] - loss: 0.002249 best_pearson: 0.7156
Batch[2138] - loss: 0.001430 best_pearson: 0.7156
Batch[2139] - loss: 0.003043 best_pearson: 0.7156
Batch[2140] - loss: 0.001062 best_pearson: 0.7156
Batch[2141] - loss: 0.001868 best_pearson: 0.7156
Batch[2142] - loss: 0.001319 best_pearson: 0.7156
Batch[2143] - loss: 0.001856 best_pearson: 0.7156
Batch[2144] - loss: 0.001826 best_pearson: 0.7156
Batch[2145] - loss: 0.001535 best_pearson: 0.7156
Batch[2146] - loss: 0.001456 best_pearson: 0.7156
Batch[2147] - loss: 0.002754 best_pearson: 0.7156
Batch[2148] - loss: 0.001753 best_pearson: 0.7156
Batch[2149] - loss: 0.002241 best_pearson: 0.7156
Batch[2150] - loss: 0.001730 best_pearson: 0.7156
Batch[2151] - loss: 0.001889 best_pearson: 0.7156
Batch[2152] - loss: 0.002429 best_pearson: 0.7156
Batch[2153] - loss: 0.001971 best_pearson: 0.7156
Batch[2154] - loss: 0.001226 best_pearson: 0.7156
Batch[2155] - loss: 0.001786 best_pearson: 0.7156
Batch[2156] - loss: 0.001902 best_pearson: 0.7156
Batch[2157] - loss: 0.002624 best_pearson: 0.7156
Batch[2158] - loss: 0.001854 best_pearson: 0.7156
Batch[2159] - loss: 0.002450 best_pearson: 0.7156
Batch[2160] - loss: 0.002317 best_pearson: 0.7156
Batch[2161] - loss: 0.002880 best_pearson: 0.7156
Batch[2162] - loss: 0.001685 best_pearson: 0.7156
Batch[2163] - loss: 0.001244 best_pearson: 0.7156
Batch[2164] - loss: 0.001743 best_pearson: 0.7156
Batch[2165] - loss: 0.002001 best_pearson: 0.7156
Batch[2166] - loss: 0.003196 best_pearson: 0.7156
Batch[2167] - loss: 0.001884 best_pearson: 0.7156
Batch[2168] - loss: 0.001433 best_pearson: 0.7156
Batch[2169] - loss: 0.002684 best_pearson: 0.7156
Batch[2170] - loss: 0.001398 best_pearson: 0.7156
Batch[2171] - loss: 0.001562 best_pearson: 0.7156
Batch[2172] - loss: 0.001175 best_pearson: 0.7156
Batch[2173] - loss: 0.000922 best_pearson: 0.7156
Batch[2174] - loss: 0.001774 best_pearson: 0.7156
Batch[2175] - loss: 0.002162 best_pearson: 0.7156
Batch[2176] - loss: 0.001492 best_pearson: 0.7156
Batch[2177] - loss: 0.002182 best_pearson: 0.7156
Batch[2178] - loss: 0.001527 best_pearson: 0.7156
Batch[2179] - loss: 0.002320 best_pearson: 0.7156
Batch[2180] - loss: 0.001667 best_pearson: 0.7156
Batch[2181] - loss: 0.002245 best_pearson: 0.7156
Batch[2182] - loss: 0.001831 best_pearson: 0.7156
Batch[2183] - loss: 0.002288 best_pearson: 0.7156
Batch[2184] - loss: 0.002821 best_pearson: 0.7156
Batch[2185] - loss: 0.001068 best_pearson: 0.7156
Batch[2186] - loss: 0.001388 best_pearson: 0.7156
Batch[2187] - loss: 0.001064 best_pearson: 0.7156
Batch[2188] - loss: 0.002309 best_pearson: 0.7156
Batch[2189] - loss: 0.001797 best_pearson: 0.7156
Batch[2190] - loss: 0.001494 best_pearson: 0.7156
Batch[2191] - loss: 0.001326 best_pearson: 0.7156
Batch[2192] - loss: 0.001866 best_pearson: 0.7156
Batch[2193] - loss: 0.000855 best_pearson: 0.7156
Batch[2194] - loss: 0.001718 best_pearson: 0.7156
Batch[2195] - loss: 0.001992 best_pearson: 0.7156
Batch[2196] - loss: 0.001087 best_pearson: 0.7156
Batch[2197] - loss: 0.001917 best_pearson: 0.7156
Batch[2198] - loss: 0.003603 best_pearson: 0.7156
Batch[2199] - loss: 0.001476 best_pearson: 0.7156
Batch[2200] - loss: 0.002716 best_pearson: 0.7156

Evaluation - loss: 0.000045 pearson: 0.7210 

Batch[2201] - loss: 0.001656 best_pearson: 0.7210
Batch[2202] - loss: 0.002118 best_pearson: 0.7210
Batch[2203] - loss: 0.001933 best_pearson: 0.7210
Batch[2204] - loss: 0.002408 best_pearson: 0.7210
Batch[2205] - loss: 0.002853 best_pearson: 0.7210
Batch[2206] - loss: 0.002925 best_pearson: 0.7210
Batch[2207] - loss: 0.001732 best_pearson: 0.7210
Batch[2208] - loss: 0.002443 best_pearson: 0.7210
Batch[2209] - loss: 0.002327 best_pearson: 0.7210
Batch[2210] - loss: 0.001737 best_pearson: 0.7210
Batch[2211] - loss: 0.001871 best_pearson: 0.7210
Batch[2212] - loss: 0.001316 best_pearson: 0.7210
Batch[2213] - loss: 0.000578 best_pearson: 0.7210
Batch[2214] - loss: 0.001334 best_pearson: 0.7210
Batch[2215] - loss: 0.001395 best_pearson: 0.7210
Batch[2216] - loss: 0.003039 best_pearson: 0.7210
Batch[2217] - loss: 0.001720 best_pearson: 0.7210
Batch[2218] - loss: 0.002234 best_pearson: 0.7210
Batch[2219] - loss: 0.001360 best_pearson: 0.7210
Batch[2220] - loss: 0.001682 best_pearson: 0.7210
Batch[2221] - loss: 0.001222 best_pearson: 0.7210
Batch[2222] - loss: 0.001337 best_pearson: 0.7210
Batch[2223] - loss: 0.001844 best_pearson: 0.7210
Batch[2224] - loss: 0.002499 best_pearson: 0.7210
Batch[2225] - loss: 0.001932 best_pearson: 0.7210
Batch[2226] - loss: 0.002159 best_pearson: 0.7210
Batch[2227] - loss: 0.001418 best_pearson: 0.7210
Batch[2228] - loss: 0.001829 best_pearson: 0.7210
Batch[2229] - loss: 0.002041 best_pearson: 0.7210
Batch[2230] - loss: 0.001410 best_pearson: 0.7210
Batch[2231] - loss: 0.001760 best_pearson: 0.7210
Batch[2232] - loss: 0.002757 best_pearson: 0.7210
Batch[2233] - loss: 0.002833 best_pearson: 0.7210
Batch[2234] - loss: 0.002132 best_pearson: 0.7210
Batch[2235] - loss: 0.002859 best_pearson: 0.7210
Batch[2236] - loss: 0.004146 best_pearson: 0.7210
Batch[2237] - loss: 0.002060 best_pearson: 0.7210
Batch[2238] - loss: 0.002718 best_pearson: 0.7210
Batch[2239] - loss: 0.002958 best_pearson: 0.7210
Batch[2240] - loss: 0.001726 best_pearson: 0.7210
Batch[2241] - loss: 0.001598 best_pearson: 0.7210
Batch[2242] - loss: 0.001623 best_pearson: 0.7210
Batch[2243] - loss: 0.001533 best_pearson: 0.7210
Batch[2244] - loss: 0.003883 best_pearson: 0.7210
Batch[2245] - loss: 0.001768 best_pearson: 0.7210
Batch[2246] - loss: 0.001987 best_pearson: 0.7210
Batch[2247] - loss: 0.003181 best_pearson: 0.7210
Batch[2248] - loss: 0.002900 best_pearson: 0.7210
Batch[2249] - loss: 0.001521 best_pearson: 0.7210
Batch[2250] - loss: 0.001869 best_pearson: 0.7210
Batch[2251] - loss: 0.002806 best_pearson: 0.7210
Batch[2252] - loss: 0.002896 best_pearson: 0.7210
Batch[2253] - loss: 0.001776 best_pearson: 0.7210
Batch[2254] - loss: 0.002221 best_pearson: 0.7210
Batch[2255] - loss: 0.001640 best_pearson: 0.7210
Batch[2256] - loss: 0.002213 best_pearson: 0.7210
Batch[2257] - loss: 0.001635 best_pearson: 0.7210
Batch[2258] - loss: 0.001470 best_pearson: 0.7210
Batch[2259] - loss: 0.002075 best_pearson: 0.7210
Batch[2260] - loss: 0.001553 best_pearson: 0.7210
Batch[2261] - loss: 0.001418 best_pearson: 0.7210
Batch[2262] - loss: 0.001903 best_pearson: 0.7210
Batch[2263] - loss: 0.002868 best_pearson: 0.7210
Batch[2264] - loss: 0.001010 best_pearson: 0.7210
Batch[2265] - loss: 0.001314 best_pearson: 0.7210
Batch[2266] - loss: 0.002377 best_pearson: 0.7210
Batch[2267] - loss: 0.001832 best_pearson: 0.7210
Batch[2268] - loss: 0.003463 best_pearson: 0.7210
Batch[2269] - loss: 0.001818 best_pearson: 0.7210
Batch[2270] - loss: 0.001459 best_pearson: 0.7210
Batch[2271] - loss: 0.002662 best_pearson: 0.7210
Batch[2272] - loss: 0.003759 best_pearson: 0.7210
Batch[2273] - loss: 0.002492 best_pearson: 0.7210
Batch[2274] - loss: 0.001765 best_pearson: 0.7210
Batch[2275] - loss: 0.001642 best_pearson: 0.7210
Batch[2276] - loss: 0.003122 best_pearson: 0.7210
Batch[2277] - loss: 0.002691 best_pearson: 0.7210
Batch[2278] - loss: 0.002329 best_pearson: 0.7210
Batch[2279] - loss: 0.002495 best_pearson: 0.7210
Batch[2280] - loss: 0.001944 best_pearson: 0.7210
Batch[2281] - loss: 0.002224 best_pearson: 0.7210
Batch[2282] - loss: 0.001391 best_pearson: 0.7210
Batch[2283] - loss: 0.001977 best_pearson: 0.7210
Batch[2284] - loss: 0.002212 best_pearson: 0.7210
Batch[2285] - loss: 0.001720 best_pearson: 0.7210
Batch[2286] - loss: 0.001914 best_pearson: 0.7210
Batch[2287] - loss: 0.002703 best_pearson: 0.7210
Batch[2288] - loss: 0.001484 best_pearson: 0.7210
Batch[2289] - loss: 0.001660 best_pearson: 0.7210
Batch[2290] - loss: 0.001989 best_pearson: 0.7210
Batch[2291] - loss: 0.001241 best_pearson: 0.7210
Batch[2292] - loss: 0.002448 best_pearson: 0.7210
Batch[2293] - loss: 0.003950 best_pearson: 0.7210
Batch[2294] - loss: 0.002135 best_pearson: 0.7210
Batch[2295] - loss: 0.001683 best_pearson: 0.7210
Batch[2296] - loss: 0.002165 best_pearson: 0.7210
Batch[2297] - loss: 0.001778 best_pearson: 0.7210
Batch[2298] - loss: 0.001900 best_pearson: 0.7210
Batch[2299] - loss: 0.001634 best_pearson: 0.7210
Batch[2300] - loss: 0.002386 best_pearson: 0.7210

Evaluation - loss: 0.000045 pearson: 0.7211 

Batch[2301] - loss: 0.001748 best_pearson: 0.7211
Batch[2302] - loss: 0.002544 best_pearson: 0.7211
Batch[2303] - loss: 0.001210 best_pearson: 0.7211
Batch[2304] - loss: 0.002533 best_pearson: 0.7211
Batch[2305] - loss: 0.002115 best_pearson: 0.7211
Batch[2306] - loss: 0.001375 best_pearson: 0.7211
Batch[2307] - loss: 0.002170 best_pearson: 0.7211
Batch[2308] - loss: 0.001807 best_pearson: 0.7211
Batch[2309] - loss: 0.002960 best_pearson: 0.7211
Batch[2310] - loss: 0.001624 best_pearson: 0.7211
Batch[2311] - loss: 0.002440 best_pearson: 0.7211
Batch[2312] - loss: 0.001364 best_pearson: 0.7211
Batch[2313] - loss: 0.002823 best_pearson: 0.7211
Batch[2314] - loss: 0.001880 best_pearson: 0.7211
Batch[2315] - loss: 0.002026 best_pearson: 0.7211
Batch[2316] - loss: 0.002723 best_pearson: 0.7211
Batch[2317] - loss: 0.002060 best_pearson: 0.7211
Batch[2318] - loss: 0.001946 best_pearson: 0.7211
Batch[2319] - loss: 0.002003 best_pearson: 0.7211
Batch[2320] - loss: 0.002074 best_pearson: 0.7211
Batch[2321] - loss: 0.003334 best_pearson: 0.7211
Batch[2322] - loss: 0.001563 best_pearson: 0.7211
Batch[2323] - loss: 0.001099 best_pearson: 0.7211
Batch[2324] - loss: 0.001905 best_pearson: 0.7211
Batch[2325] - loss: 0.002730 best_pearson: 0.7211
Batch[2326] - loss: 0.002488 best_pearson: 0.7211
Batch[2327] - loss: 0.000766 best_pearson: 0.7211
Batch[2328] - loss: 0.001836 best_pearson: 0.7211
Batch[2329] - loss: 0.004346 best_pearson: 0.7211
Batch[2330] - loss: 0.004109 best_pearson: 0.7211
Batch[2331] - loss: 0.002182 best_pearson: 0.7211
Batch[2332] - loss: 0.001606 best_pearson: 0.7211
Batch[2333] - loss: 0.003076 best_pearson: 0.7211
Batch[2334] - loss: 0.001304 best_pearson: 0.7211
Batch[2335] - loss: 0.001959 best_pearson: 0.7211
Batch[2336] - loss: 0.002213 best_pearson: 0.7211
Batch[2337] - loss: 0.002777 best_pearson: 0.7211
Batch[2338] - loss: 0.002348 best_pearson: 0.7211
Batch[2339] - loss: 0.002179 best_pearson: 0.7211
Batch[2340] - loss: 0.002035 best_pearson: 0.7211
Batch[2341] - loss: 0.001709 best_pearson: 0.7211
Batch[2342] - loss: 0.002005 best_pearson: 0.7211
Batch[2343] - loss: 0.001655 best_pearson: 0.7211
Batch[2344] - loss: 0.002623 best_pearson: 0.7211
Batch[2345] - loss: 0.002195 best_pearson: 0.7211
Batch[2346] - loss: 0.002926 best_pearson: 0.7211
Batch[2347] - loss: 0.001723 best_pearson: 0.7211
Batch[2348] - loss: 0.001633 best_pearson: 0.7211
Batch[2349] - loss: 0.002410 best_pearson: 0.7211
Batch[2350] - loss: 0.001447 best_pearson: 0.7211
Batch[2351] - loss: 0.000952 best_pearson: 0.7211
Batch[2352] - loss: 0.002136 best_pearson: 0.7211
Batch[2353] - loss: 0.003739 best_pearson: 0.7211
Batch[2354] - loss: 0.001596 best_pearson: 0.7211
Batch[2355] - loss: 0.001773 best_pearson: 0.7211
Batch[2356] - loss: 0.002334 best_pearson: 0.7211
Batch[2357] - loss: 0.001376 best_pearson: 0.7211
Batch[2358] - loss: 0.001353 best_pearson: 0.7211
Batch[2359] - loss: 0.001753 best_pearson: 0.7211
Batch[2360] - loss: 0.001663 best_pearson: 0.7211
Batch[2361] - loss: 0.001856 best_pearson: 0.7211
Batch[2362] - loss: 0.002006 best_pearson: 0.7211
Batch[2363] - loss: 0.002134 best_pearson: 0.7211
Batch[2364] - loss: 0.002669 best_pearson: 0.7211
Batch[2365] - loss: 0.002481 best_pearson: 0.7211
Batch[2366] - loss: 0.001484 best_pearson: 0.7211
Batch[2367] - loss: 0.002577 best_pearson: 0.7211
Batch[2368] - loss: 0.001930 best_pearson: 0.7211
Batch[2369] - loss: 0.002026 best_pearson: 0.7211
Batch[2370] - loss: 0.002131 best_pearson: 0.7211
Batch[2371] - loss: 0.001337 best_pearson: 0.7211
Batch[2372] - loss: 0.002055 best_pearson: 0.7211
Batch[2373] - loss: 0.002273 best_pearson: 0.7211
Batch[2374] - loss: 0.001887 best_pearson: 0.7211
Batch[2375] - loss: 0.001059 best_pearson: 0.7211
Batch[2376] - loss: 0.001293 best_pearson: 0.7211
Batch[2377] - loss: 0.002927 best_pearson: 0.7211
Batch[2378] - loss: 0.001688 best_pearson: 0.7211
Batch[2379] - loss: 0.002370 best_pearson: 0.7211
Batch[2380] - loss: 0.001230 best_pearson: 0.7211
Batch[2381] - loss: 0.002600 best_pearson: 0.7211
Batch[2382] - loss: 0.001083 best_pearson: 0.7211
Batch[2383] - loss: 0.002258 best_pearson: 0.7211
Batch[2384] - loss: 0.001888 best_pearson: 0.7211
Batch[2385] - loss: 0.002730 best_pearson: 0.7211
Batch[2386] - loss: 0.001100 best_pearson: 0.7211
Batch[2387] - loss: 0.001535 best_pearson: 0.7211
Batch[2388] - loss: 0.001917 best_pearson: 0.7211
Batch[2389] - loss: 0.001303 best_pearson: 0.7211
Batch[2390] - loss: 0.002288 best_pearson: 0.7211
Batch[2391] - loss: 0.001316 best_pearson: 0.7211
Batch[2392] - loss: 0.002856 best_pearson: 0.7211
Batch[2393] - loss: 0.001781 best_pearson: 0.7211
Batch[2394] - loss: 0.002051 best_pearson: 0.7211
Batch[2395] - loss: 0.001453 best_pearson: 0.7211
Batch[2396] - loss: 0.002256 best_pearson: 0.7211
Batch[2397] - loss: 0.001537 best_pearson: 0.7211
Batch[2398] - loss: 0.002414 best_pearson: 0.7211
Batch[2399] - loss: 0.001883 best_pearson: 0.7211
Batch[2400] - loss: 0.001594 best_pearson: 0.7211

Evaluation - loss: 0.000048 pearson: 0.7153 

Batch[2401] - loss: 0.002203 best_pearson: 0.7211
Batch[2402] - loss: 0.001639 best_pearson: 0.7211
Batch[2403] - loss: 0.002108 best_pearson: 0.7211
Batch[2404] - loss: 0.001671 best_pearson: 0.7211
Batch[2405] - loss: 0.002381 best_pearson: 0.7211
Batch[2406] - loss: 0.001396 best_pearson: 0.7211
Batch[2407] - loss: 0.002868 best_pearson: 0.7211
Batch[2408] - loss: 0.002166 best_pearson: 0.7211
Batch[2409] - loss: 0.002515 best_pearson: 0.7211
Batch[2410] - loss: 0.001627 best_pearson: 0.7211
Batch[2411] - loss: 0.001961 best_pearson: 0.7211
Batch[2412] - loss: 0.002735 best_pearson: 0.7211
Batch[2413] - loss: 0.001699 best_pearson: 0.7211
Batch[2414] - loss: 0.001713 best_pearson: 0.7211
Batch[2415] - loss: 0.001654 best_pearson: 0.7211
Batch[2416] - loss: 0.001555 best_pearson: 0.7211
Batch[2417] - loss: 0.001812 best_pearson: 0.7211
Batch[2418] - loss: 0.000919 best_pearson: 0.7211
Batch[2419] - loss: 0.001579 best_pearson: 0.7211
Batch[2420] - loss: 0.001580 best_pearson: 0.7211
Batch[2421] - loss: 0.001836 best_pearson: 0.7211
Batch[2422] - loss: 0.001469 best_pearson: 0.7211
Batch[2423] - loss: 0.001352 best_pearson: 0.7211
Batch[2424] - loss: 0.001481 best_pearson: 0.7211
Batch[2425] - loss: 0.000982 best_pearson: 0.7211
Batch[2426] - loss: 0.001935 best_pearson: 0.7211
Batch[2427] - loss: 0.002586 best_pearson: 0.7211
Batch[2428] - loss: 0.001262 best_pearson: 0.7211
Batch[2429] - loss: 0.001202 best_pearson: 0.7211
Batch[2430] - loss: 0.002443 best_pearson: 0.7211
Batch[2431] - loss: 0.001194 best_pearson: 0.7211
Batch[2432] - loss: 0.000877 best_pearson: 0.7211
Batch[2433] - loss: 0.002337 best_pearson: 0.7211
Batch[2434] - loss: 0.002037 best_pearson: 0.7211
Batch[2435] - loss: 0.001141 best_pearson: 0.7211
Batch[2436] - loss: 0.002221 best_pearson: 0.7211
Batch[2437] - loss: 0.001792 best_pearson: 0.7211
Batch[2438] - loss: 0.001410 best_pearson: 0.7211
Batch[2439] - loss: 0.001692 best_pearson: 0.7211
Batch[2440] - loss: 0.001392 best_pearson: 0.7211
Batch[2441] - loss: 0.001776 best_pearson: 0.7211
Batch[2442] - loss: 0.002486 best_pearson: 0.7211
Batch[2443] - loss: 0.001329 best_pearson: 0.7211
Batch[2444] - loss: 0.001202 best_pearson: 0.7211
Batch[2445] - loss: 0.001925 best_pearson: 0.7211
Batch[2446] - loss: 0.001597 best_pearson: 0.7211
Batch[2447] - loss: 0.002396 best_pearson: 0.7211
Batch[2448] - loss: 0.001631 best_pearson: 0.7211
Batch[2449] - loss: 0.001001 best_pearson: 0.7211
Batch[2450] - loss: 0.002016 best_pearson: 0.7211
Batch[2451] - loss: 0.002722 best_pearson: 0.7211
Batch[2452] - loss: 0.001476 best_pearson: 0.7211
Batch[2453] - loss: 0.001679 best_pearson: 0.7211
Batch[2454] - loss: 0.002263 best_pearson: 0.7211
Batch[2455] - loss: 0.001720 best_pearson: 0.7211
Batch[2456] - loss: 0.002040 best_pearson: 0.7211
Batch[2457] - loss: 0.002172 best_pearson: 0.7211
Batch[2458] - loss: 0.001394 best_pearson: 0.7211
Batch[2459] - loss: 0.001623 best_pearson: 0.7211
Batch[2460] - loss: 0.002567 best_pearson: 0.7211
Batch[2461] - loss: 0.002577 best_pearson: 0.7211
Batch[2462] - loss: 0.001314 best_pearson: 0.7211
Batch[2463] - loss: 0.001364 best_pearson: 0.7211
Batch[2464] - loss: 0.001764 best_pearson: 0.7211
Batch[2465] - loss: 0.001356 best_pearson: 0.7211
Batch[2466] - loss: 0.002993 best_pearson: 0.7211
Batch[2467] - loss: 0.001923 best_pearson: 0.7211
Batch[2468] - loss: 0.001810 best_pearson: 0.7211
Batch[2469] - loss: 0.001248 best_pearson: 0.7211
Batch[2470] - loss: 0.002178 best_pearson: 0.7211
Batch[2471] - loss: 0.002045 best_pearson: 0.7211
Batch[2472] - loss: 0.001204 best_pearson: 0.7211
Batch[2473] - loss: 0.001796 best_pearson: 0.7211
Batch[2474] - loss: 0.002042 best_pearson: 0.7211
Batch[2475] - loss: 0.000955 best_pearson: 0.7211
Batch[2476] - loss: 0.001236 best_pearson: 0.7211
Batch[2477] - loss: 0.002490 best_pearson: 0.7211
Batch[2478] - loss: 0.001731 best_pearson: 0.7211
Batch[2479] - loss: 0.001486 best_pearson: 0.7211
Batch[2480] - loss: 0.001661 best_pearson: 0.7211
Batch[2481] - loss: 0.002077 best_pearson: 0.7211
Batch[2482] - loss: 0.000874 best_pearson: 0.7211
Batch[2483] - loss: 0.001602 best_pearson: 0.7211
Batch[2484] - loss: 0.001212 best_pearson: 0.7211
Batch[2485] - loss: 0.001224 best_pearson: 0.7211
Batch[2486] - loss: 0.001184 best_pearson: 0.7211
Batch[2487] - loss: 0.001264 best_pearson: 0.7211
Batch[2488] - loss: 0.001311 best_pearson: 0.7211
Batch[2489] - loss: 0.001082 best_pearson: 0.7211
Batch[2490] - loss: 0.001219 best_pearson: 0.7211
Batch[2491] - loss: 0.001481 best_pearson: 0.7211
Batch[2492] - loss: 0.001178 best_pearson: 0.7211
Batch[2493] - loss: 0.001554 best_pearson: 0.7211
Batch[2494] - loss: 0.002030 best_pearson: 0.7211
Batch[2495] - loss: 0.001295 best_pearson: 0.7211
Batch[2496] - loss: 0.000843 best_pearson: 0.7211
Batch[2497] - loss: 0.001324 best_pearson: 0.7211
Batch[2498] - loss: 0.002488 best_pearson: 0.7211
Batch[2499] - loss: 0.002137 best_pearson: 0.7211
Batch[2500] - loss: 0.001430 best_pearson: 0.7211

Evaluation - loss: 0.000046 pearson: 0.7179 

Batch[2501] - loss: 0.000909 best_pearson: 0.7211
Batch[2502] - loss: 0.000928 best_pearson: 0.7211
Batch[2503] - loss: 0.001522 best_pearson: 0.7211
Batch[2504] - loss: 0.001300 best_pearson: 0.7211
Batch[2505] - loss: 0.002715 best_pearson: 0.7211
Batch[2506] - loss: 0.002124 best_pearson: 0.7211
Batch[2507] - loss: 0.002336 best_pearson: 0.7211
Batch[2508] - loss: 0.001115 best_pearson: 0.7211
Batch[2509] - loss: 0.001542 best_pearson: 0.7211
Batch[2510] - loss: 0.001543 best_pearson: 0.7211
Batch[2511] - loss: 0.001872 best_pearson: 0.7211
Batch[2512] - loss: 0.001659 best_pearson: 0.7211
Batch[2513] - loss: 0.001960 best_pearson: 0.7211
Batch[2514] - loss: 0.001572 best_pearson: 0.7211
Batch[2515] - loss: 0.002265 best_pearson: 0.7211
Batch[2516] - loss: 0.001267 best_pearson: 0.7211
Batch[2517] - loss: 0.001731 best_pearson: 0.7211
Batch[2518] - loss: 0.001667 best_pearson: 0.7211
Batch[2519] - loss: 0.001379 best_pearson: 0.7211
Batch[2520] - loss: 0.002878 best_pearson: 0.7211
Batch[2521] - loss: 0.002626 best_pearson: 0.7211
Batch[2522] - loss: 0.001724 best_pearson: 0.7211
Batch[2523] - loss: 0.001209 best_pearson: 0.7211
Batch[2524] - loss: 0.002148 best_pearson: 0.7211
Batch[2525] - loss: 0.001824 best_pearson: 0.7211
Batch[2526] - loss: 0.001144 best_pearson: 0.7211
Batch[2527] - loss: 0.002489 best_pearson: 0.7211
Batch[2528] - loss: 0.001200 best_pearson: 0.7211
Batch[2529] - loss: 0.002311 best_pearson: 0.7211
Batch[2530] - loss: 0.002005 best_pearson: 0.7211
Batch[2531] - loss: 0.001623 best_pearson: 0.7211
Batch[2532] - loss: 0.001230 best_pearson: 0.7211
Batch[2533] - loss: 0.001640 best_pearson: 0.7211
Batch[2534] - loss: 0.001739 best_pearson: 0.7211
Batch[2535] - loss: 0.001569 best_pearson: 0.7211
Batch[2536] - loss: 0.001119 best_pearson: 0.7211
Batch[2537] - loss: 0.001277 best_pearson: 0.7211
Batch[2538] - loss: 0.001243 best_pearson: 0.7211
Batch[2539] - loss: 0.001680 best_pearson: 0.7211
Batch[2540] - loss: 0.001726 best_pearson: 0.7211
Batch[2541] - loss: 0.002376 best_pearson: 0.7211
Batch[2542] - loss: 0.001444 best_pearson: 0.7211
Batch[2543] - loss: 0.001060 best_pearson: 0.7211
Batch[2544] - loss: 0.001848 best_pearson: 0.7211
Batch[2545] - loss: 0.001600 best_pearson: 0.7211
Batch[2546] - loss: 0.001833 best_pearson: 0.7211
Batch[2547] - loss: 0.001294 best_pearson: 0.7211
Batch[2548] - loss: 0.001280 best_pearson: 0.7211
Batch[2549] - loss: 0.002000 best_pearson: 0.7211
Batch[2550] - loss: 0.002233 best_pearson: 0.7211
Batch[2551] - loss: 0.001247 best_pearson: 0.7211
Batch[2552] - loss: 0.001365 best_pearson: 0.7211
Batch[2553] - loss: 0.001113 best_pearson: 0.7211
Batch[2554] - loss: 0.001273 best_pearson: 0.7211
Batch[2555] - loss: 0.001700 best_pearson: 0.7211
Batch[2556] - loss: 0.001077 best_pearson: 0.7211
Batch[2557] - loss: 0.001351 best_pearson: 0.7211
Batch[2558] - loss: 0.000884 best_pearson: 0.7211
Batch[2559] - loss: 0.003026 best_pearson: 0.7211
Batch[2560] - loss: 0.002267 best_pearson: 0.7211
Batch[2561] - loss: 0.001292 best_pearson: 0.7211
Batch[2562] - loss: 0.001219 best_pearson: 0.7211
Batch[2563] - loss: 0.001029 best_pearson: 0.7211
Batch[2564] - loss: 0.001554 best_pearson: 0.7211
Batch[2565] - loss: 0.001575 best_pearson: 0.7211
Batch[2566] - loss: 0.002539 best_pearson: 0.7211
Batch[2567] - loss: 0.001302 best_pearson: 0.7211
Batch[2568] - loss: 0.001591 best_pearson: 0.7211
Batch[2569] - loss: 0.001659 best_pearson: 0.7211
Batch[2570] - loss: 0.001156 best_pearson: 0.7211
Batch[2571] - loss: 0.001398 best_pearson: 0.7211
Batch[2572] - loss: 0.001290 best_pearson: 0.7211
Batch[2573] - loss: 0.001717 best_pearson: 0.7211
Batch[2574] - loss: 0.001210 best_pearson: 0.7211
Batch[2575] - loss: 0.001312 best_pearson: 0.7211
Batch[2576] - loss: 0.001557 best_pearson: 0.7211
Batch[2577] - loss: 0.001128 best_pearson: 0.7211
Batch[2578] - loss: 0.001279 best_pearson: 0.7211
Batch[2579] - loss: 0.001788 best_pearson: 0.7211
Batch[2580] - loss: 0.001601 best_pearson: 0.7211
Batch[2581] - loss: 0.000997 best_pearson: 0.7211
Batch[2582] - loss: 0.001641 best_pearson: 0.7211
Batch[2583] - loss: 0.001681 best_pearson: 0.7211
Batch[2584] - loss: 0.001920 best_pearson: 0.7211
Batch[2585] - loss: 0.001962 best_pearson: 0.7211
Batch[2586] - loss: 0.001436 best_pearson: 0.7211
Batch[2587] - loss: 0.002587 best_pearson: 0.7211
Batch[2588] - loss: 0.001066 best_pearson: 0.7211
Batch[2589] - loss: 0.002466 best_pearson: 0.7211
Batch[2590] - loss: 0.002053 best_pearson: 0.7211
Batch[2591] - loss: 0.001148 best_pearson: 0.7211
Batch[2592] - loss: 0.001873 best_pearson: 0.7211
Batch[2593] - loss: 0.001417 best_pearson: 0.7211
Batch[2594] - loss: 0.001447 best_pearson: 0.7211
Batch[2595] - loss: 0.001558 best_pearson: 0.7211
Batch[2596] - loss: 0.002446 best_pearson: 0.7211
Batch[2597] - loss: 0.001658 best_pearson: 0.7211
Batch[2598] - loss: 0.001588 best_pearson: 0.7211
Batch[2599] - loss: 0.001726 best_pearson: 0.7211
Batch[2600] - loss: 0.001093 best_pearson: 0.7211

Evaluation - loss: 0.000046 pearson: 0.7191 

Batch[2601] - loss: 0.001848 best_pearson: 0.7211
Batch[2602] - loss: 0.001335 best_pearson: 0.7211
Batch[2603] - loss: 0.001960 best_pearson: 0.7211
Batch[2604] - loss: 0.001296 best_pearson: 0.7211
Batch[2605] - loss: 0.000803 best_pearson: 0.7211
Batch[2606] - loss: 0.001603 best_pearson: 0.7211
Batch[2607] - loss: 0.001117 best_pearson: 0.7211
Batch[2608] - loss: 0.000880 best_pearson: 0.7211
Batch[2609] - loss: 0.001675 best_pearson: 0.7211
Batch[2610] - loss: 0.000820 best_pearson: 0.7211
Batch[2611] - loss: 0.001400 best_pearson: 0.7211
Batch[2612] - loss: 0.001407 best_pearson: 0.7211
Batch[2613] - loss: 0.002475 best_pearson: 0.7211
Batch[2614] - loss: 0.001063 best_pearson: 0.7211
Batch[2615] - loss: 0.001524 best_pearson: 0.7211
Batch[2616] - loss: 0.001871 best_pearson: 0.7211
Batch[2617] - loss: 0.001971 best_pearson: 0.7211
Batch[2618] - loss: 0.000893 best_pearson: 0.7211
Batch[2619] - loss: 0.002806 best_pearson: 0.7211
Batch[2620] - loss: 0.001728 best_pearson: 0.7211
Batch[2621] - loss: 0.001281 best_pearson: 0.7211
Batch[2622] - loss: 0.001339 best_pearson: 0.7211
Batch[2623] - loss: 0.001014 best_pearson: 0.7211
Batch[2624] - loss: 0.001522 best_pearson: 0.7211
Batch[2625] - loss: 0.002106 best_pearson: 0.7211
Batch[2626] - loss: 0.000752 best_pearson: 0.7211
Batch[2627] - loss: 0.002555 best_pearson: 0.7211
Batch[2628] - loss: 0.000974 best_pearson: 0.7211
Batch[2629] - loss: 0.002074 best_pearson: 0.7211
Batch[2630] - loss: 0.001904 best_pearson: 0.7211
Batch[2631] - loss: 0.002360 best_pearson: 0.7211
Batch[2632] - loss: 0.001497 best_pearson: 0.7211
Batch[2633] - loss: 0.001004 best_pearson: 0.7211
Batch[2634] - loss: 0.001944 best_pearson: 0.7211
Batch[2635] - loss: 0.001662 best_pearson: 0.7211
Batch[2636] - loss: 0.001137 best_pearson: 0.7211
Batch[2637] - loss: 0.002197 best_pearson: 0.7211
Batch[2638] - loss: 0.001345 best_pearson: 0.7211
Batch[2639] - loss: 0.001464 best_pearson: 0.7211
Batch[2640] - loss: 0.001139 best_pearson: 0.7211
Batch[2641] - loss: 0.001171 best_pearson: 0.7211
Batch[2642] - loss: 0.000906 best_pearson: 0.7211
Batch[2643] - loss: 0.001432 best_pearson: 0.7211
Batch[2644] - loss: 0.002517 best_pearson: 0.7211
Batch[2645] - loss: 0.003257 best_pearson: 0.7211
Batch[2646] - loss: 0.000989 best_pearson: 0.7211
Batch[2647] - loss: 0.001965 best_pearson: 0.7211
Batch[2648] - loss: 0.001275 best_pearson: 0.7211
Batch[2649] - loss: 0.001429 best_pearson: 0.7211
Batch[2650] - loss: 0.002104 best_pearson: 0.7211
Batch[2651] - loss: 0.001710 best_pearson: 0.7211
Batch[2652] - loss: 0.001379 best_pearson: 0.7211
Batch[2653] - loss: 0.002226 best_pearson: 0.7211
Batch[2654] - loss: 0.001094 best_pearson: 0.7211
Batch[2655] - loss: 0.001796 best_pearson: 0.7211
Batch[2656] - loss: 0.001330 best_pearson: 0.7211
Batch[2657] - loss: 0.001182 best_pearson: 0.7211
Batch[2658] - loss: 0.001247 best_pearson: 0.7211
Batch[2659] - loss: 0.000841 best_pearson: 0.7211
Batch[2660] - loss: 0.002152 best_pearson: 0.7211
Batch[2661] - loss: 0.001719 best_pearson: 0.7211
Batch[2662] - loss: 0.001615 best_pearson: 0.7211
Batch[2663] - loss: 0.001516 best_pearson: 0.7211
Batch[2664] - loss: 0.001917 best_pearson: 0.7211
Batch[2665] - loss: 0.001152 best_pearson: 0.7211
Batch[2666] - loss: 0.001354 best_pearson: 0.7211
Batch[2667] - loss: 0.001143 best_pearson: 0.7211
Batch[2668] - loss: 0.001826 best_pearson: 0.7211
Batch[2669] - loss: 0.002169 best_pearson: 0.7211
Batch[2670] - loss: 0.001802 best_pearson: 0.7211
Batch[2671] - loss: 0.000650 best_pearson: 0.7211
Batch[2672] - loss: 0.001617 best_pearson: 0.7211
Batch[2673] - loss: 0.001421 best_pearson: 0.7211
Batch[2674] - loss: 0.001639 best_pearson: 0.7211
Batch[2675] - loss: 0.001543 best_pearson: 0.7211
Batch[2676] - loss: 0.001158 best_pearson: 0.7211
Batch[2677] - loss: 0.001705 best_pearson: 0.7211
Batch[2678] - loss: 0.001785 best_pearson: 0.7211
Batch[2679] - loss: 0.001726 best_pearson: 0.7211
Batch[2680] - loss: 0.000779 best_pearson: 0.7211
Batch[2681] - loss: 0.000910 best_pearson: 0.7211
Batch[2682] - loss: 0.001119 best_pearson: 0.7211
Batch[2683] - loss: 0.002426 best_pearson: 0.7211
Batch[2684] - loss: 0.002421 best_pearson: 0.7211
Batch[2685] - loss: 0.001609 best_pearson: 0.7211
Batch[2686] - loss: 0.002319 best_pearson: 0.7211
Batch[2687] - loss: 0.001045 best_pearson: 0.7211
Batch[2688] - loss: 0.002433 best_pearson: 0.7211
Batch[2689] - loss: 0.001218 best_pearson: 0.7211
Batch[2690] - loss: 0.001294 best_pearson: 0.7211
Batch[2691] - loss: 0.001633 best_pearson: 0.7211
Batch[2692] - loss: 0.001144 best_pearson: 0.7211
Batch[2693] - loss: 0.001917 best_pearson: 0.7211
Batch[2694] - loss: 0.000802 best_pearson: 0.7211
Batch[2695] - loss: 0.001185 best_pearson: 0.7211
Batch[2696] - loss: 0.001002 best_pearson: 0.7211
Batch[2697] - loss: 0.001147 best_pearson: 0.7211
Batch[2698] - loss: 0.001274 best_pearson: 0.7211
Batch[2699] - loss: 0.001485 best_pearson: 0.7211
Batch[2700] - loss: 0.001390 best_pearson: 0.7211

Evaluation - loss: 0.000047 pearson: 0.7190 

Batch[2701] - loss: 0.001591 best_pearson: 0.7211
Batch[2702] - loss: 0.000858 best_pearson: 0.7211
Batch[2703] - loss: 0.001496 best_pearson: 0.7211
Batch[2704] - loss: 0.001662 best_pearson: 0.7211
Batch[2705] - loss: 0.003048 best_pearson: 0.7211
Batch[2706] - loss: 0.000999 best_pearson: 0.7211
Batch[2707] - loss: 0.001420 best_pearson: 0.7211
Batch[2708] - loss: 0.001839 best_pearson: 0.7211
Batch[2709] - loss: 0.001467 best_pearson: 0.7211
Batch[2710] - loss: 0.002397 best_pearson: 0.7211
Batch[2711] - loss: 0.001125 best_pearson: 0.7211
Batch[2712] - loss: 0.002026 best_pearson: 0.7211
Batch[2713] - loss: 0.002491 best_pearson: 0.7211
Batch[2714] - loss: 0.002106 best_pearson: 0.7211
Batch[2715] - loss: 0.001920 best_pearson: 0.7211
Batch[2716] - loss: 0.001900 best_pearson: 0.7211
Batch[2717] - loss: 0.000781 best_pearson: 0.7211
Batch[2718] - loss: 0.001628 best_pearson: 0.7211
Batch[2719] - loss: 0.001171 best_pearson: 0.7211
Batch[2720] - loss: 0.001931 best_pearson: 0.7211
Batch[2721] - loss: 0.001863 best_pearson: 0.7211
Batch[2722] - loss: 0.001478 best_pearson: 0.7211
Batch[2723] - loss: 0.001398 best_pearson: 0.7211
Batch[2724] - loss: 0.002208 best_pearson: 0.7211
Batch[2725] - loss: 0.001229 best_pearson: 0.7211
Batch[2726] - loss: 0.001310 best_pearson: 0.7211
Batch[2727] - loss: 0.001378 best_pearson: 0.7211
Batch[2728] - loss: 0.001099 best_pearson: 0.7211
Batch[2729] - loss: 0.001024 best_pearson: 0.7211
Batch[2730] - loss: 0.001242 best_pearson: 0.7211
Batch[2731] - loss: 0.001422 best_pearson: 0.7211
Batch[2732] - loss: 0.001318 best_pearson: 0.7211
Batch[2733] - loss: 0.000955 best_pearson: 0.7211
Batch[2734] - loss: 0.001150 best_pearson: 0.7211
Batch[2735] - loss: 0.002309 best_pearson: 0.7211
Batch[2736] - loss: 0.002104 best_pearson: 0.7211
Batch[2737] - loss: 0.001600 best_pearson: 0.7211
Batch[2738] - loss: 0.001416 best_pearson: 0.7211
Batch[2739] - loss: 0.001673 best_pearson: 0.7211
Batch[2740] - loss: 0.003137 best_pearson: 0.7211
Batch[2741] - loss: 0.001890 best_pearson: 0.7211
Batch[2742] - loss: 0.002315 best_pearson: 0.7211
Batch[2743] - loss: 0.000850 best_pearson: 0.7211
Batch[2744] - loss: 0.001703 best_pearson: 0.7211
Batch[2745] - loss: 0.002107 best_pearson: 0.7211
Batch[2746] - loss: 0.002116 best_pearson: 0.7211
Batch[2747] - loss: 0.001403 best_pearson: 0.7211
Batch[2748] - loss: 0.001800 best_pearson: 0.7211
Batch[2749] - loss: 0.001826 best_pearson: 0.7211
Batch[2750] - loss: 0.001989 best_pearson: 0.7211
Batch[2751] - loss: 0.001407 best_pearson: 0.7211
Batch[2752] - loss: 0.000895 best_pearson: 0.7211
Batch[2753] - loss: 0.002132 best_pearson: 0.7211
Batch[2754] - loss: 0.000845 best_pearson: 0.7211
Batch[2755] - loss: 0.001591 best_pearson: 0.7211
Batch[2756] - loss: 0.001482 best_pearson: 0.7211
Batch[2757] - loss: 0.002452 best_pearson: 0.7211
Batch[2758] - loss: 0.001701 best_pearson: 0.7211
Batch[2759] - loss: 0.001157 best_pearson: 0.7211
Batch[2760] - loss: 0.001446 best_pearson: 0.7211
Batch[2761] - loss: 0.001095 best_pearson: 0.7211
Batch[2762] - loss: 0.001754 best_pearson: 0.7211
Batch[2763] - loss: 0.000877 best_pearson: 0.7211
Batch[2764] - loss: 0.000771 best_pearson: 0.7211
Batch[2765] - loss: 0.002764 best_pearson: 0.7211
Batch[2766] - loss: 0.001081 best_pearson: 0.7211
Batch[2767] - loss: 0.001746 best_pearson: 0.7211
Batch[2768] - loss: 0.001308 best_pearson: 0.7211
Batch[2769] - loss: 0.001271 best_pearson: 0.7211
Batch[2770] - loss: 0.001699 best_pearson: 0.7211
Batch[2771] - loss: 0.000660 best_pearson: 0.7211
Batch[2772] - loss: 0.000933 best_pearson: 0.7211
Batch[2773] - loss: 0.001690 best_pearson: 0.7211
Batch[2774] - loss: 0.001080 best_pearson: 0.7211
Batch[2775] - loss: 0.001437 best_pearson: 0.7211
Batch[2776] - loss: 0.001317 best_pearson: 0.7211
Batch[2777] - loss: 0.002042 best_pearson: 0.7211
Batch[2778] - loss: 0.001965 best_pearson: 0.7211
Batch[2779] - loss: 0.001911 best_pearson: 0.7211
Batch[2780] - loss: 0.002743 best_pearson: 0.7211
Batch[2781] - loss: 0.003034 best_pearson: 0.7211
Batch[2782] - loss: 0.001724 best_pearson: 0.7211
Batch[2783] - loss: 0.002666 best_pearson: 0.7211
Batch[2784] - loss: 0.001794 best_pearson: 0.7211
Batch[2785] - loss: 0.003302 best_pearson: 0.7211
Batch[2786] - loss: 0.002729 best_pearson: 0.7211
Batch[2787] - loss: 0.001252 best_pearson: 0.7211
Batch[2788] - loss: 0.005172 best_pearson: 0.7211
Batch[2789] - loss: 0.003460 best_pearson: 0.7211
Batch[2790] - loss: 0.001771 best_pearson: 0.7211
Batch[2791] - loss: 0.001212 best_pearson: 0.7211
Batch[2792] - loss: 0.003874 best_pearson: 0.7211
Batch[2793] - loss: 0.002854 best_pearson: 0.7211
Batch[2794] - loss: 0.001429 best_pearson: 0.7211
Batch[2795] - loss: 0.001031 best_pearson: 0.7211
Batch[2796] - loss: 0.002750 best_pearson: 0.7211
Batch[2797] - loss: 0.001553 best_pearson: 0.7211
Batch[2798] - loss: 0.002339 best_pearson: 0.7211
Batch[2799] - loss: 0.002807 best_pearson: 0.7211
Batch[2800] - loss: 0.002784 best_pearson: 0.7211

Evaluation - loss: 0.000047 pearson: 0.7172 

Batch[2801] - loss: 0.000968 best_pearson: 0.7211
Batch[2802] - loss: 0.001899 best_pearson: 0.7211
Batch[2803] - loss: 0.001480 best_pearson: 0.7211
Batch[2804] - loss: 0.001567 best_pearson: 0.7211
Batch[2805] - loss: 0.001415 best_pearson: 0.7211
Batch[2806] - loss: 0.002018 best_pearson: 0.7211
Batch[2807] - loss: 0.003363 best_pearson: 0.7211
Batch[2808] - loss: 0.001400 best_pearson: 0.7211
Batch[2809] - loss: 0.001778 best_pearson: 0.7211
Batch[2810] - loss: 0.002054 best_pearson: 0.7211
Batch[2811] - loss: 0.002562 best_pearson: 0.7211
Batch[2812] - loss: 0.001640 best_pearson: 0.7211
Batch[2813] - loss: 0.002250 best_pearson: 0.7211
Batch[2814] - loss: 0.001462 best_pearson: 0.7211
Batch[2815] - loss: 0.001450 best_pearson: 0.7211
Batch[2816] - loss: 0.001417 best_pearson: 0.7211
Batch[2817] - loss: 0.001878 best_pearson: 0.7211
Batch[2818] - loss: 0.001167 best_pearson: 0.7211
Batch[2819] - loss: 0.001119 best_pearson: 0.7211
Batch[2820] - loss: 0.002284 best_pearson: 0.7211
Batch[2821] - loss: 0.002147 best_pearson: 0.7211
Batch[2822] - loss: 0.001463 best_pearson: 0.7211
Batch[2823] - loss: 0.001607 best_pearson: 0.7211
Batch[2824] - loss: 0.002162 best_pearson: 0.7211
Batch[2825] - loss: 0.001446 best_pearson: 0.7211
Batch[2826] - loss: 0.001935 best_pearson: 0.7211
Batch[2827] - loss: 0.001303 best_pearson: 0.7211
Batch[2828] - loss: 0.001866 best_pearson: 0.7211
Batch[2829] - loss: 0.001559 best_pearson: 0.7211
Batch[2830] - loss: 0.001420 best_pearson: 0.7211
Batch[2831] - loss: 0.001760 best_pearson: 0.7211
Batch[2832] - loss: 0.001435 best_pearson: 0.7211
Batch[2833] - loss: 0.001817 best_pearson: 0.7211
Batch[2834] - loss: 0.001208 best_pearson: 0.7211
Batch[2835] - loss: 0.001806 best_pearson: 0.7211
Batch[2836] - loss: 0.001254 best_pearson: 0.7211
Batch[2837] - loss: 0.001963 best_pearson: 0.7211
Batch[2838] - loss: 0.001433 best_pearson: 0.7211
Batch[2839] - loss: 0.001218 best_pearson: 0.7211
Batch[2840] - loss: 0.001675 best_pearson: 0.7211
Batch[2841] - loss: 0.001928 best_pearson: 0.7211
Batch[2842] - loss: 0.001889 best_pearson: 0.7211
Batch[2843] - loss: 0.002431 best_pearson: 0.7211
Batch[2844] - loss: 0.002209 best_pearson: 0.7211
Batch[2845] - loss: 0.001573 best_pearson: 0.7211
Batch[2846] - loss: 0.002939 best_pearson: 0.7211
Batch[2847] - loss: 0.002047 best_pearson: 0.7211
Batch[2848] - loss: 0.001816 best_pearson: 0.7211
Batch[2849] - loss: 0.001743 best_pearson: 0.7211
Batch[2850] - loss: 0.001534 best_pearson: 0.7211
Batch[2851] - loss: 0.000926 best_pearson: 0.7211
Batch[2852] - loss: 0.001470 best_pearson: 0.7211
Batch[2853] - loss: 0.002045 best_pearson: 0.7211
Batch[2854] - loss: 0.001805 best_pearson: 0.7211
Batch[2855] - loss: 0.001783 best_pearson: 0.7211
Batch[2856] - loss: 0.002901 best_pearson: 0.7211
Batch[2857] - loss: 0.001873 best_pearson: 0.7211
Batch[2858] - loss: 0.001206 best_pearson: 0.7211
Batch[2859] - loss: 0.003089 best_pearson: 0.7211
Batch[2860] - loss: 0.003214 best_pearson: 0.7211
Batch[2861] - loss: 0.001829 best_pearson: 0.7211
Batch[2862] - loss: 0.002457 best_pearson: 0.7211
Batch[2863] - loss: 0.001491 best_pearson: 0.7211
Batch[2864] - loss: 0.002891 best_pearson: 0.7211
Batch[2865] - loss: 0.001830 best_pearson: 0.7211
Batch[2866] - loss: 0.003733 best_pearson: 0.7211
Batch[2867] - loss: 0.002321 best_pearson: 0.7211
Batch[2868] - loss: 0.002091 best_pearson: 0.7211
Batch[2869] - loss: 0.001980 best_pearson: 0.7211
Batch[2870] - loss: 0.003429 best_pearson: 0.7211
Batch[2871] - loss: 0.002372 best_pearson: 0.7211
Batch[2872] - loss: 0.001237 best_pearson: 0.7211
Batch[2873] - loss: 0.001811 best_pearson: 0.7211
Batch[2874] - loss: 0.001525 best_pearson: 0.7211
Batch[2875] - loss: 0.002213 best_pearson: 0.7211
Batch[2876] - loss: 0.001162 best_pearson: 0.7211
Batch[2877] - loss: 0.002839 best_pearson: 0.7211
Batch[2878] - loss: 0.001928 best_pearson: 0.7211
Batch[2879] - loss: 0.001958 best_pearson: 0.7211
Batch[2880] - loss: 0.001448 best_pearson: 0.7211
Batch[2881] - loss: 0.001981 best_pearson: 0.7211
Batch[2882] - loss: 0.001850 best_pearson: 0.7211
Batch[2883] - loss: 0.002117 best_pearson: 0.7211
Batch[2884] - loss: 0.002131 best_pearson: 0.7211
Batch[2885] - loss: 0.001448 best_pearson: 0.7211
Batch[2886] - loss: 0.001492 best_pearson: 0.7211
Batch[2887] - loss: 0.001479 best_pearson: 0.7211
Batch[2888] - loss: 0.001555 best_pearson: 0.7211
Batch[2889] - loss: 0.001777 best_pearson: 0.7211
Batch[2890] - loss: 0.001810 best_pearson: 0.7211
Batch[2891] - loss: 0.001918 best_pearson: 0.7211
Batch[2892] - loss: 0.001784 best_pearson: 0.7211
Batch[2893] - loss: 0.001955 best_pearson: 0.7211
Batch[2894] - loss: 0.001675 best_pearson: 0.7211
Batch[2895] - loss: 0.001501 best_pearson: 0.7211
Batch[2896] - loss: 0.001911 best_pearson: 0.7211
Batch[2897] - loss: 0.001735 best_pearson: 0.7211
Batch[2898] - loss: 0.001871 best_pearson: 0.7211
Batch[2899] - loss: 0.001318 best_pearson: 0.7211
Batch[2900] - loss: 0.001160 best_pearson: 0.7211

Evaluation - loss: 0.000045 pearson: 0.7243 

Batch[2901] - loss: 0.001139 best_pearson: 0.7243
Batch[2902] - loss: 0.001185 best_pearson: 0.7243
Batch[2903] - loss: 0.001463 best_pearson: 0.7243
Batch[2904] - loss: 0.001521 best_pearson: 0.7243
Batch[2905] - loss: 0.001480 best_pearson: 0.7243
Batch[2906] - loss: 0.001409 best_pearson: 0.7243
Batch[2907] - loss: 0.001067 best_pearson: 0.7243
Batch[2908] - loss: 0.001260 best_pearson: 0.7243
Batch[2909] - loss: 0.002234 best_pearson: 0.7243
Batch[2910] - loss: 0.000907 best_pearson: 0.7243
Batch[2911] - loss: 0.001091 best_pearson: 0.7243
Batch[2912] - loss: 0.001974 best_pearson: 0.7243
Batch[2913] - loss: 0.001403 best_pearson: 0.7243
Batch[2914] - loss: 0.001137 best_pearson: 0.7243
Batch[2915] - loss: 0.001952 best_pearson: 0.7243
Batch[2916] - loss: 0.001931 best_pearson: 0.7243
Batch[2917] - loss: 0.001266 best_pearson: 0.7243
Batch[2918] - loss: 0.001445 best_pearson: 0.7243
Batch[2919] - loss: 0.001096 best_pearson: 0.7243
Batch[2920] - loss: 0.003083 best_pearson: 0.7243
Batch[2921] - loss: 0.001330 best_pearson: 0.7243
Batch[2922] - loss: 0.001223 best_pearson: 0.7243
Batch[2923] - loss: 0.002093 best_pearson: 0.7243
Batch[2924] - loss: 0.001164 best_pearson: 0.7243
Batch[2925] - loss: 0.001565 best_pearson: 0.7243
Batch[2926] - loss: 0.001475 best_pearson: 0.7243
Batch[2927] - loss: 0.001053 best_pearson: 0.7243
Batch[2928] - loss: 0.001640 best_pearson: 0.7243
Batch[2929] - loss: 0.000735 best_pearson: 0.7243
Batch[2930] - loss: 0.001561 best_pearson: 0.7243
Batch[2931] - loss: 0.001244 best_pearson: 0.7243
Batch[2932] - loss: 0.001412 best_pearson: 0.7243
Batch[2933] - loss: 0.002924 best_pearson: 0.7243
Batch[2934] - loss: 0.002839 best_pearson: 0.7243
Batch[2935] - loss: 0.003645 best_pearson: 0.7243
Batch[2936] - loss: 0.001547 best_pearson: 0.7243
Batch[2937] - loss: 0.002005 best_pearson: 0.7243
Batch[2938] - loss: 0.002754 best_pearson: 0.7243
Batch[2939] - loss: 0.003157 best_pearson: 0.7243
Batch[2940] - loss: 0.001581 best_pearson: 0.7243
Batch[2941] - loss: 0.003327 best_pearson: 0.7243
Batch[2942] - loss: 0.002257 best_pearson: 0.7243
Batch[2943] - loss: 0.002157 best_pearson: 0.7243
Batch[2944] - loss: 0.001576 best_pearson: 0.7243
Batch[2945] - loss: 0.002158 best_pearson: 0.7243
Batch[2946] - loss: 0.002109 best_pearson: 0.7243
Batch[2947] - loss: 0.001991 best_pearson: 0.7243
Batch[2948] - loss: 0.002388 best_pearson: 0.7243
Batch[2949] - loss: 0.001603 best_pearson: 0.7243
Batch[2950] - loss: 0.001428 best_pearson: 0.7243
Batch[2951] - loss: 0.002830 best_pearson: 0.7243
Batch[2952] - loss: 0.002159 best_pearson: 0.7243
Batch[2953] - loss: 0.001626 best_pearson: 0.7243
Batch[2954] - loss: 0.001185 best_pearson: 0.7243
Batch[2955] - loss: 0.001735 best_pearson: 0.7243
Batch[2956] - loss: 0.001245 best_pearson: 0.7243
Batch[2957] - loss: 0.001289 best_pearson: 0.7243
Batch[2958] - loss: 0.002722 best_pearson: 0.7243
Batch[2959] - loss: 0.001639 best_pearson: 0.7243
Batch[2960] - loss: 0.001115 best_pearson: 0.7243
Batch[2961] - loss: 0.001774 best_pearson: 0.7243
Batch[2962] - loss: 0.001666 best_pearson: 0.7243
Batch[2963] - loss: 0.001234 best_pearson: 0.7243
Batch[2964] - loss: 0.001224 best_pearson: 0.7243
Batch[2965] - loss: 0.001223 best_pearson: 0.7243
Batch[2966] - loss: 0.001599 best_pearson: 0.7243
Batch[2967] - loss: 0.000891 best_pearson: 0.7243
Batch[2968] - loss: 0.001853 best_pearson: 0.7243
Batch[2969] - loss: 0.002284 best_pearson: 0.7243
Batch[2970] - loss: 0.001870 best_pearson: 0.7243
Batch[2971] - loss: 0.001399 best_pearson: 0.7243
Batch[2972] - loss: 0.001026 best_pearson: 0.7243
Batch[2973] - loss: 0.001349 best_pearson: 0.7243
Batch[2974] - loss: 0.001687 best_pearson: 0.7243
Batch[2975] - loss: 0.001162 best_pearson: 0.7243
Batch[2976] - loss: 0.001249 best_pearson: 0.7243
Batch[2977] - loss: 0.001514 best_pearson: 0.7243
Batch[2978] - loss: 0.001183 best_pearson: 0.7243
Batch[2979] - loss: 0.001374 best_pearson: 0.7243
Batch[2980] - loss: 0.001690 best_pearson: 0.7243
Batch[2981] - loss: 0.001619 best_pearson: 0.7243
Batch[2982] - loss: 0.001365 best_pearson: 0.7243
Batch[2983] - loss: 0.001562 best_pearson: 0.7243
Batch[2984] - loss: 0.001001 best_pearson: 0.7243
Batch[2985] - loss: 0.002009 best_pearson: 0.7243
Batch[2986] - loss: 0.001972 best_pearson: 0.7243
Batch[2987] - loss: 0.002401 best_pearson: 0.7243
Batch[2988] - loss: 0.002436 best_pearson: 0.7243
Batch[2989] - loss: 0.000881 best_pearson: 0.7243
Batch[2990] - loss: 0.001094 best_pearson: 0.7243
Batch[2991] - loss: 0.002094 best_pearson: 0.7243
Batch[2992] - loss: 0.000907 best_pearson: 0.7243
Batch[2993] - loss: 0.001640 best_pearson: 0.7243
Batch[2994] - loss: 0.001042 best_pearson: 0.7243
Batch[2995] - loss: 0.001518 best_pearson: 0.7243
Batch[2996] - loss: 0.001793 best_pearson: 0.7243
Batch[2997] - loss: 0.001329 best_pearson: 0.7243
Batch[2998] - loss: 0.001416 best_pearson: 0.7243
Batch[2999] - loss: 0.002225 best_pearson: 0.7243
Batch[3000] - loss: 0.002497 best_pearson: 0.7243

Evaluation - loss: 0.000046 pearson: 0.7171 

Batch[3001] - loss: 0.001901 best_pearson: 0.7243
Batch[3002] - loss: 0.002328 best_pearson: 0.7243
Batch[3003] - loss: 0.002800 best_pearson: 0.7243
Batch[3004] - loss: 0.001249 best_pearson: 0.7243
Batch[3005] - loss: 0.002097 best_pearson: 0.7243
Batch[3006] - loss: 0.002906 best_pearson: 0.7243
Batch[3007] - loss: 0.001534 best_pearson: 0.7243
Batch[3008] - loss: 0.001622 best_pearson: 0.7243
Batch[3009] - loss: 0.001097 best_pearson: 0.7243
Batch[3010] - loss: 0.003096 best_pearson: 0.7243
Batch[3011] - loss: 0.001117 best_pearson: 0.7243
Batch[3012] - loss: 0.000964 best_pearson: 0.7243
Batch[3013] - loss: 0.001271 best_pearson: 0.7243
Batch[3014] - loss: 0.001411 best_pearson: 0.7243
Batch[3015] - loss: 0.001657 best_pearson: 0.7243
Batch[3016] - loss: 0.001412 best_pearson: 0.7243
Batch[3017] - loss: 0.001161 best_pearson: 0.7243
Batch[3018] - loss: 0.001383 best_pearson: 0.7243
Batch[3019] - loss: 0.001106 best_pearson: 0.7243
Batch[3020] - loss: 0.002446 best_pearson: 0.7243
Batch[3021] - loss: 0.001814 best_pearson: 0.7243
Batch[3022] - loss: 0.001961 best_pearson: 0.7243
Batch[3023] - loss: 0.001633 best_pearson: 0.7243
Batch[3024] - loss: 0.001923 best_pearson: 0.7243
Batch[3025] - loss: 0.001901 best_pearson: 0.7243
Batch[3026] - loss: 0.001244 best_pearson: 0.7243
Batch[3027] - loss: 0.001878 best_pearson: 0.7243
Batch[3028] - loss: 0.001583 best_pearson: 0.7243
Batch[3029] - loss: 0.001220 best_pearson: 0.7243
Batch[3030] - loss: 0.002143 best_pearson: 0.7243
Batch[3031] - loss: 0.001537 best_pearson: 0.7243
Batch[3032] - loss: 0.001406 best_pearson: 0.7243
Batch[3033] - loss: 0.001449 best_pearson: 0.7243
Batch[3034] - loss: 0.001627 best_pearson: 0.7243
Batch[3035] - loss: 0.001853 best_pearson: 0.7243
Batch[3036] - loss: 0.001041 best_pearson: 0.7243
Batch[3037] - loss: 0.001748 best_pearson: 0.7243
Batch[3038] - loss: 0.002341 best_pearson: 0.7243
Batch[3039] - loss: 0.001449 best_pearson: 0.7243
Batch[3040] - loss: 0.001181 best_pearson: 0.7243
Batch[3041] - loss: 0.001745 best_pearson: 0.7243
Batch[3042] - loss: 0.001656 best_pearson: 0.7243
Batch[3043] - loss: 0.001401 best_pearson: 0.7243
Batch[3044] - loss: 0.001838 best_pearson: 0.7243
Batch[3045] - loss: 0.001702 best_pearson: 0.7243
Batch[3046] - loss: 0.001652 best_pearson: 0.7243
Batch[3047] - loss: 0.001480 best_pearson: 0.7243
Batch[3048] - loss: 0.001746 best_pearson: 0.7243
Batch[3049] - loss: 0.001869 best_pearson: 0.7243
Batch[3050] - loss: 0.002008 best_pearson: 0.7243
Batch[3051] - loss: 0.002035 best_pearson: 0.7243
Batch[3052] - loss: 0.001930 best_pearson: 0.7243
Batch[3053] - loss: 0.001292 best_pearson: 0.7243
Batch[3054] - loss: 0.001657 best_pearson: 0.7243
Batch[3055] - loss: 0.001193 best_pearson: 0.7243
Batch[3056] - loss: 0.001276 best_pearson: 0.7243
Batch[3057] - loss: 0.001242 best_pearson: 0.7243
Batch[3058] - loss: 0.001636 best_pearson: 0.7243
Batch[3059] - loss: 0.001644 best_pearson: 0.7243
Batch[3060] - loss: 0.001188 best_pearson: 0.7243
Batch[3061] - loss: 0.001251 best_pearson: 0.7243
Batch[3062] - loss: 0.002418 best_pearson: 0.7243
Batch[3063] - loss: 0.001350 best_pearson: 0.7243
Batch[3064] - loss: 0.001319 best_pearson: 0.7243
Batch[3065] - loss: 0.001039 best_pearson: 0.7243
Batch[3066] - loss: 0.001924 best_pearson: 0.7243
Batch[3067] - loss: 0.001277 best_pearson: 0.7243
Batch[3068] - loss: 0.001929 best_pearson: 0.7243
Batch[3069] - loss: 0.001791 best_pearson: 0.7243
Batch[3070] - loss: 0.000830 best_pearson: 0.7243
Batch[3071] - loss: 0.001842 best_pearson: 0.7243
Batch[3072] - loss: 0.002191 best_pearson: 0.7243
Batch[3073] - loss: 0.002368 best_pearson: 0.7243
Batch[3074] - loss: 0.001602 best_pearson: 0.7243
Batch[3075] - loss: 0.001440 best_pearson: 0.7243
Batch[3076] - loss: 0.002488 best_pearson: 0.7243
Batch[3077] - loss: 0.001075 best_pearson: 0.7243
Batch[3078] - loss: 0.001307 best_pearson: 0.7243
Batch[3079] - loss: 0.002661 best_pearson: 0.7243
Batch[3080] - loss: 0.002437 best_pearson: 0.7243
Batch[3081] - loss: 0.001112 best_pearson: 0.7243
Batch[3082] - loss: 0.001995 best_pearson: 0.7243
Batch[3083] - loss: 0.001873 best_pearson: 0.7243
Batch[3084] - loss: 0.001867 best_pearson: 0.7243
Batch[3085] - loss: 0.001061 best_pearson: 0.7243
Batch[3086] - loss: 0.001529 best_pearson: 0.7243
Batch[3087] - loss: 0.000712 best_pearson: 0.7243
Batch[3088] - loss: 0.002388 best_pearson: 0.7243
Batch[3089] - loss: 0.001985 best_pearson: 0.7243
Batch[3090] - loss: 0.002416 best_pearson: 0.7243
Batch[3091] - loss: 0.001546 best_pearson: 0.7243
Batch[3092] - loss: 0.001239 best_pearson: 0.7243
Batch[3093] - loss: 0.001194 best_pearson: 0.7243
Batch[3094] - loss: 0.002351 best_pearson: 0.7243
Batch[3095] - loss: 0.000739 best_pearson: 0.7243
Batch[3096] - loss: 0.001522 best_pearson: 0.7243
Batch[3097] - loss: 0.000958 best_pearson: 0.7243
Batch[3098] - loss: 0.002299 best_pearson: 0.7243
Batch[3099] - loss: 0.001360 best_pearson: 0.7243
Batch[3100] - loss: 0.001489 best_pearson: 0.7243

Evaluation - loss: 0.000045 pearson: 0.7226 

Batch[3101] - loss: 0.002455 best_pearson: 0.7243
Batch[3102] - loss: 0.001905 best_pearson: 0.7243
Batch[3103] - loss: 0.001237 best_pearson: 0.7243
Batch[3104] - loss: 0.000907 best_pearson: 0.7243
Batch[3105] - loss: 0.000981 best_pearson: 0.7243
Batch[3106] - loss: 0.001248 best_pearson: 0.7243
Batch[3107] - loss: 0.001114 best_pearson: 0.7243
Batch[3108] - loss: 0.001552 best_pearson: 0.7243
Batch[3109] - loss: 0.001380 best_pearson: 0.7243
Batch[3110] - loss: 0.000962 best_pearson: 0.7243
Batch[3111] - loss: 0.001793 best_pearson: 0.7243
Batch[3112] - loss: 0.001626 best_pearson: 0.7243
Batch[3113] - loss: 0.001447 best_pearson: 0.7243
Batch[3114] - loss: 0.001436 best_pearson: 0.7243
Batch[3115] - loss: 0.001150 best_pearson: 0.7243
Batch[3116] - loss: 0.001405 best_pearson: 0.7243
Batch[3117] - loss: 0.001357 best_pearson: 0.7243
Batch[3118] - loss: 0.001957 best_pearson: 0.7243
Batch[3119] - loss: 0.000999 best_pearson: 0.7243
Batch[3120] - loss: 0.002054 best_pearson: 0.7243
Batch[3121] - loss: 0.001817 best_pearson: 0.7243
Batch[3122] - loss: 0.001508 best_pearson: 0.7243
Batch[3123] - loss: 0.001449 best_pearson: 0.7243
Batch[3124] - loss: 0.001178 best_pearson: 0.7243
Batch[3125] - loss: 0.001801 best_pearson: 0.7243
Batch[3126] - loss: 0.001007 best_pearson: 0.7243
Batch[3127] - loss: 0.001601 best_pearson: 0.7243
Batch[3128] - loss: 0.001452 best_pearson: 0.7243
Batch[3129] - loss: 0.000906 best_pearson: 0.7243
Batch[3130] - loss: 0.000935 best_pearson: 0.7243
Batch[3131] - loss: 0.001225 best_pearson: 0.7243
Batch[3132] - loss: 0.001666 best_pearson: 0.7243
Batch[3133] - loss: 0.001262 best_pearson: 0.7243
Batch[3134] - loss: 0.002085 best_pearson: 0.7243
Batch[3135] - loss: 0.001631 best_pearson: 0.7243
Batch[3136] - loss: 0.001270 best_pearson: 0.7243
Batch[3137] - loss: 0.001157 best_pearson: 0.7243
Batch[3138] - loss: 0.002058 best_pearson: 0.7243
Batch[3139] - loss: 0.002464 best_pearson: 0.7243
Batch[3140] - loss: 0.001553 best_pearson: 0.7243
Batch[3141] - loss: 0.001414 best_pearson: 0.7243
Batch[3142] - loss: 0.001483 best_pearson: 0.7243
Batch[3143] - loss: 0.000848 best_pearson: 0.7243
Batch[3144] - loss: 0.000987 best_pearson: 0.7243
Batch[3145] - loss: 0.001635 best_pearson: 0.7243
Batch[3146] - loss: 0.002014 best_pearson: 0.7243
Batch[3147] - loss: 0.001060 best_pearson: 0.7243
Batch[3148] - loss: 0.002201 best_pearson: 0.7243
Batch[3149] - loss: 0.001436 best_pearson: 0.7243
Batch[3150] - loss: 0.001286 best_pearson: 0.7243
Batch[3151] - loss: 0.001099 best_pearson: 0.7243
Batch[3152] - loss: 0.002127 best_pearson: 0.7243
Batch[3153] - loss: 0.002348 best_pearson: 0.7243
Batch[3154] - loss: 0.001219 best_pearson: 0.7243
Batch[3155] - loss: 0.000856 best_pearson: 0.7243
Batch[3156] - loss: 0.001043 best_pearson: 0.7243
Batch[3157] - loss: 0.002125 best_pearson: 0.7243
Batch[3158] - loss: 0.001666 best_pearson: 0.7243
Batch[3159] - loss: 0.000913 best_pearson: 0.7243
Batch[3160] - loss: 0.001348 best_pearson: 0.7243
Batch[3161] - loss: 0.001195 best_pearson: 0.7243
Batch[3162] - loss: 0.001823 best_pearson: 0.7243
Batch[3163] - loss: 0.001096 best_pearson: 0.7243
Batch[3164] - loss: 0.001987 best_pearson: 0.7243
Batch[3165] - loss: 0.001688 best_pearson: 0.7243
Batch[3166] - loss: 0.000710 best_pearson: 0.7243
Batch[3167] - loss: 0.002077 best_pearson: 0.7243
Batch[3168] - loss: 0.001503 best_pearson: 0.7243
Batch[3169] - loss: 0.001150 best_pearson: 0.7243
Batch[3170] - loss: 0.001208 best_pearson: 0.7243
Batch[3171] - loss: 0.001392 best_pearson: 0.7243
Batch[3172] - loss: 0.001036 best_pearson: 0.7243
Batch[3173] - loss: 0.001116 best_pearson: 0.7243
Batch[3174] - loss: 0.002562 best_pearson: 0.7243
Batch[3175] - loss: 0.001149 best_pearson: 0.7243
Batch[3176] - loss: 0.000866 best_pearson: 0.7243
Batch[3177] - loss: 0.001051 best_pearson: 0.7243
Batch[3178] - loss: 0.001906 best_pearson: 0.7243
Batch[3179] - loss: 0.001396 best_pearson: 0.7243
Batch[3180] - loss: 0.000726 best_pearson: 0.7243
Batch[3181] - loss: 0.001317 best_pearson: 0.7243
Batch[3182] - loss: 0.000800 best_pearson: 0.7243
Batch[3183] - loss: 0.001268 best_pearson: 0.7243
Batch[3184] - loss: 0.000948 best_pearson: 0.7243
Batch[3185] - loss: 0.001154 best_pearson: 0.7243
Batch[3186] - loss: 0.001063 best_pearson: 0.7243
Batch[3187] - loss: 0.001087 best_pearson: 0.7243
Batch[3188] - loss: 0.001973 best_pearson: 0.7243
Batch[3189] - loss: 0.001406 best_pearson: 0.7243
Batch[3190] - loss: 0.000956 best_pearson: 0.7243
Batch[3191] - loss: 0.000917 best_pearson: 0.7243
Batch[3192] - loss: 0.001758 best_pearson: 0.7243
Batch[3193] - loss: 0.001246 best_pearson: 0.7243
Batch[3194] - loss: 0.001122 best_pearson: 0.7243
Batch[3195] - loss: 0.002862 best_pearson: 0.7243
Batch[3196] - loss: 0.000945 best_pearson: 0.7243
Batch[3197] - loss: 0.000921 best_pearson: 0.7243
Batch[3198] - loss: 0.001560 best_pearson: 0.7243
Batch[3199] - loss: 0.001282 best_pearson: 0.7243
Batch[3200] - loss: 0.001961 best_pearson: 0.7243

Evaluation - loss: 0.000046 pearson: 0.7203 

Batch[3201] - loss: 0.001180 best_pearson: 0.7243
Batch[3202] - loss: 0.000869 best_pearson: 0.7243
Batch[3203] - loss: 0.001161 best_pearson: 0.7243
Batch[3204] - loss: 0.000758 best_pearson: 0.7243
Batch[3205] - loss: 0.001070 best_pearson: 0.7243
Batch[3206] - loss: 0.001684 best_pearson: 0.7243
Batch[3207] - loss: 0.002115 best_pearson: 0.7243
Batch[3208] - loss: 0.001393 best_pearson: 0.7243
Batch[3209] - loss: 0.001253 best_pearson: 0.7243
Batch[3210] - loss: 0.001311 best_pearson: 0.7243
Batch[3211] - loss: 0.001237 best_pearson: 0.7243
Batch[3212] - loss: 0.002733 best_pearson: 0.7243
Batch[3213] - loss: 0.001574 best_pearson: 0.7243
Batch[3214] - loss: 0.001644 best_pearson: 0.7243
Batch[3215] - loss: 0.003109 best_pearson: 0.7243
Batch[3216] - loss: 0.001338 best_pearson: 0.7243
Batch[3217] - loss: 0.001624 best_pearson: 0.7243
Batch[3218] - loss: 0.001263 best_pearson: 0.7243
Batch[3219] - loss: 0.001941 best_pearson: 0.7243
Batch[3220] - loss: 0.001559 best_pearson: 0.7243
Batch[3221] - loss: 0.001180 best_pearson: 0.7243
Batch[3222] - loss: 0.000901 best_pearson: 0.7243
Batch[3223] - loss: 0.001251 best_pearson: 0.7243
Batch[3224] - loss: 0.001441 best_pearson: 0.7243
Batch[3225] - loss: 0.001139 best_pearson: 0.7243
Batch[3226] - loss: 0.001139 best_pearson: 0.7243
Batch[3227] - loss: 0.000963 best_pearson: 0.7243
Batch[3228] - loss: 0.001136 best_pearson: 0.7243
Batch[3229] - loss: 0.001337 best_pearson: 0.7243
Batch[3230] - loss: 0.001292 best_pearson: 0.7243
Batch[3231] - loss: 0.001130 best_pearson: 0.7243
Batch[3232] - loss: 0.001994 best_pearson: 0.7243
Batch[3233] - loss: 0.001555 best_pearson: 0.7243
Batch[3234] - loss: 0.001336 best_pearson: 0.7243
Batch[3235] - loss: 0.001388 best_pearson: 0.7243
Batch[3236] - loss: 0.001755 best_pearson: 0.7243
Batch[3237] - loss: 0.001174 best_pearson: 0.7243
Batch[3238] - loss: 0.000565 best_pearson: 0.7243
Batch[3239] - loss: 0.002510 best_pearson: 0.7243
Batch[3240] - loss: 0.001061 best_pearson: 0.7243
Batch[3241] - loss: 0.001235 best_pearson: 0.7243
Batch[3242] - loss: 0.002033 best_pearson: 0.7243
Batch[3243] - loss: 0.001651 best_pearson: 0.7243
Batch[3244] - loss: 0.000843 best_pearson: 0.7243
Batch[3245] - loss: 0.000837 best_pearson: 0.7243
Batch[3246] - loss: 0.000821 best_pearson: 0.7243
Batch[3247] - loss: 0.002105 best_pearson: 0.7243
Batch[3248] - loss: 0.001076 best_pearson: 0.7243
Batch[3249] - loss: 0.002622 best_pearson: 0.7243
Batch[3250] - loss: 0.001217 best_pearson: 0.7243
Batch[3251] - loss: 0.001823 best_pearson: 0.7243
Batch[3252] - loss: 0.001480 best_pearson: 0.7243
Batch[3253] - loss: 0.002214 best_pearson: 0.7243
Batch[3254] - loss: 0.001182 best_pearson: 0.7243
Batch[3255] - loss: 0.001484 best_pearson: 0.7243
Batch[3256] - loss: 0.001716 best_pearson: 0.7243
Batch[3257] - loss: 0.001076 best_pearson: 0.7243
Batch[3258] - loss: 0.001708 best_pearson: 0.7243
Batch[3259] - loss: 0.002149 best_pearson: 0.7243
Batch[3260] - loss: 0.001287 best_pearson: 0.7243
Batch[3261] - loss: 0.001314 best_pearson: 0.7243
Batch[3262] - loss: 0.001833 best_pearson: 0.7243
Batch[3263] - loss: 0.001498 best_pearson: 0.7243
Batch[3264] - loss: 0.002075 best_pearson: 0.7243
Batch[3265] - loss: 0.001209 best_pearson: 0.7243
Batch[3266] - loss: 0.001126 best_pearson: 0.7243
Batch[3267] - loss: 0.002678 best_pearson: 0.7243
Batch[3268] - loss: 0.001271 best_pearson: 0.7243
Batch[3269] - loss: 0.000666 best_pearson: 0.7243
Batch[3270] - loss: 0.002007 best_pearson: 0.7243
Batch[3271] - loss: 0.001467 best_pearson: 0.7243
Batch[3272] - loss: 0.001185 best_pearson: 0.7243
Batch[3273] - loss: 0.001819 best_pearson: 0.7243
Batch[3274] - loss: 0.001209 best_pearson: 0.7243
Batch[3275] - loss: 0.002255 best_pearson: 0.7243
Batch[3276] - loss: 0.001451 best_pearson: 0.7243
Batch[3277] - loss: 0.001422 best_pearson: 0.7243
Batch[3278] - loss: 0.001054 best_pearson: 0.7243
Batch[3279] - loss: 0.001581 best_pearson: 0.7243
Batch[3280] - loss: 0.001478 best_pearson: 0.7243
Batch[3281] - loss: 0.000999 best_pearson: 0.7243
Batch[3282] - loss: 0.001981 best_pearson: 0.7243
Batch[3283] - loss: 0.001250 best_pearson: 0.7243
Batch[3284] - loss: 0.001263 best_pearson: 0.7243
Batch[3285] - loss: 0.001399 best_pearson: 0.7243
Batch[3286] - loss: 0.001610 best_pearson: 0.7243
Batch[3287] - loss: 0.000817 best_pearson: 0.7243
Batch[3288] - loss: 0.001270 best_pearson: 0.7243
Batch[3289] - loss: 0.001062 best_pearson: 0.7243
Batch[3290] - loss: 0.001634 best_pearson: 0.7243
Batch[3291] - loss: 0.001068 best_pearson: 0.7243
Batch[3292] - loss: 0.000876 best_pearson: 0.7243
Batch[3293] - loss: 0.001050 best_pearson: 0.7243
Batch[3294] - loss: 0.001663 best_pearson: 0.7243
Batch[3295] - loss: 0.001023 best_pearson: 0.7243
Batch[3296] - loss: 0.001453 best_pearson: 0.7243
Batch[3297] - loss: 0.001032 best_pearson: 0.7243
Batch[3298] - loss: 0.001767 best_pearson: 0.7243
Batch[3299] - loss: 0.000973 best_pearson: 0.7243
Batch[3300] - loss: 0.000865 best_pearson: 0.7243

Evaluation - loss: 0.000047 pearson: 0.7178 

Batch[3301] - loss: 0.001443 best_pearson: 0.7243
Batch[3302] - loss: 0.001129 best_pearson: 0.7243
Batch[3303] - loss: 0.001484 best_pearson: 0.7243
Batch[3304] - loss: 0.000938 best_pearson: 0.7243
Batch[3305] - loss: 0.001071 best_pearson: 0.7243
Batch[3306] - loss: 0.000617 best_pearson: 0.7243
Batch[3307] - loss: 0.000959 best_pearson: 0.7243
Batch[3308] - loss: 0.001394 best_pearson: 0.7243
Batch[3309] - loss: 0.000973 best_pearson: 0.7243
Batch[3310] - loss: 0.001490 best_pearson: 0.7243
Batch[3311] - loss: 0.001395 best_pearson: 0.7243
Batch[3312] - loss: 0.001503 best_pearson: 0.7243
Batch[3313] - loss: 0.000777 best_pearson: 0.7243
Batch[3314] - loss: 0.001714 best_pearson: 0.7243
Batch[3315] - loss: 0.001147 best_pearson: 0.7243
Batch[3316] - loss: 0.000625 best_pearson: 0.7243
Batch[3317] - loss: 0.000978 best_pearson: 0.7243
Batch[3318] - loss: 0.001806 best_pearson: 0.7243
Batch[3319] - loss: 0.001914 best_pearson: 0.7243
Batch[3320] - loss: 0.001702 best_pearson: 0.7243
Batch[3321] - loss: 0.000838 best_pearson: 0.7243
Batch[3322] - loss: 0.001198 best_pearson: 0.7243
Batch[3323] - loss: 0.001229 best_pearson: 0.7243
Batch[3324] - loss: 0.001266 best_pearson: 0.7243
Batch[3325] - loss: 0.001043 best_pearson: 0.7243
Batch[3326] - loss: 0.001204 best_pearson: 0.7243
Batch[3327] - loss: 0.001409 best_pearson: 0.7243
Batch[3328] - loss: 0.001598 best_pearson: 0.7243
Batch[3329] - loss: 0.001787 best_pearson: 0.7243
Batch[3330] - loss: 0.001978 best_pearson: 0.7243
Batch[3331] - loss: 0.001827 best_pearson: 0.7243
Batch[3332] - loss: 0.002265 best_pearson: 0.7243
Batch[3333] - loss: 0.001797 best_pearson: 0.7243
Batch[3334] - loss: 0.001778 best_pearson: 0.7243
Batch[3335] - loss: 0.001512 best_pearson: 0.7243
Batch[3336] - loss: 0.001574 best_pearson: 0.7243
Batch[3337] - loss: 0.003339 best_pearson: 0.7243
Batch[3338] - loss: 0.001495 best_pearson: 0.7243
Batch[3339] - loss: 0.002011 best_pearson: 0.7243
Batch[3340] - loss: 0.002492 best_pearson: 0.7243
Batch[3341] - loss: 0.001389 best_pearson: 0.7243
Batch[3342] - loss: 0.001111 best_pearson: 0.7243
Batch[3343] - loss: 0.001787 best_pearson: 0.7243
Batch[3344] - loss: 0.001891 best_pearson: 0.7243
Batch[3345] - loss: 0.001920 best_pearson: 0.7243
Batch[3346] - loss: 0.001373 best_pearson: 0.7243
Batch[3347] - loss: 0.001726 best_pearson: 0.7243
Batch[3348] - loss: 0.002388 best_pearson: 0.7243
Batch[3349] - loss: 0.002556 best_pearson: 0.7243
Batch[3350] - loss: 0.001428 best_pearson: 0.7243
Batch[3351] - loss: 0.001781 best_pearson: 0.7243
Batch[3352] - loss: 0.000941 best_pearson: 0.7243
Batch[3353] - loss: 0.001881 best_pearson: 0.7243
Batch[3354] - loss: 0.001735 best_pearson: 0.7243
Batch[3355] - loss: 0.001287 best_pearson: 0.7243
Batch[3356] - loss: 0.001684 best_pearson: 0.7243
Batch[3357] - loss: 0.001519 best_pearson: 0.7243
Batch[3358] - loss: 0.001126 best_pearson: 0.7243
Batch[3359] - loss: 0.002025 best_pearson: 0.7243
Batch[3360] - loss: 0.001000 best_pearson: 0.7243
Batch[3361] - loss: 0.001873 best_pearson: 0.7243
Batch[3362] - loss: 0.000820 best_pearson: 0.7243
Batch[3363] - loss: 0.001449 best_pearson: 0.7243
Batch[3364] - loss: 0.001692 best_pearson: 0.7243
Batch[3365] - loss: 0.001697 best_pearson: 0.7243
Batch[3366] - loss: 0.001257 best_pearson: 0.7243
Batch[3367] - loss: 0.000943 best_pearson: 0.7243
Batch[3368] - loss: 0.001107 best_pearson: 0.7243
Batch[3369] - loss: 0.001076 best_pearson: 0.7243
Batch[3370] - loss: 0.001152 best_pearson: 0.7243
Batch[3371] - loss: 0.002070 best_pearson: 0.7243
Batch[3372] - loss: 0.002153 best_pearson: 0.7243
Batch[3373] - loss: 0.001324 best_pearson: 0.7243
Batch[3374] - loss: 0.001178 best_pearson: 0.7243
Batch[3375] - loss: 0.001633 best_pearson: 0.7243
Batch[3376] - loss: 0.002472 best_pearson: 0.7243
Batch[3377] - loss: 0.002184 best_pearson: 0.7243
Batch[3378] - loss: 0.001303 best_pearson: 0.7243
Batch[3379] - loss: 0.001930 best_pearson: 0.7243
Batch[3380] - loss: 0.000948 best_pearson: 0.7243
Batch[3381] - loss: 0.001603 best_pearson: 0.7243
Batch[3382] - loss: 0.002094 best_pearson: 0.7243
Batch[3383] - loss: 0.000888 best_pearson: 0.7243
Batch[3384] - loss: 0.001301 best_pearson: 0.7243
Batch[3385] - loss: 0.001788 best_pearson: 0.7243
Batch[3386] - loss: 0.001529 best_pearson: 0.7243
Batch[3387] - loss: 0.000785 best_pearson: 0.7243
Batch[3388] - loss: 0.000653 best_pearson: 0.7243
Batch[3389] - loss: 0.002948 best_pearson: 0.7243
Batch[3390] - loss: 0.001188 best_pearson: 0.7243
Batch[3391] - loss: 0.001915 best_pearson: 0.7243
Batch[3392] - loss: 0.001783 best_pearson: 0.7243
Batch[3393] - loss: 0.001626 best_pearson: 0.7243
Batch[3394] - loss: 0.002162 best_pearson: 0.7243
Batch[3395] - loss: 0.001946 best_pearson: 0.7243
Batch[3396] - loss: 0.001246 best_pearson: 0.7243
Batch[3397] - loss: 0.001339 best_pearson: 0.7243
Batch[3398] - loss: 0.001600 best_pearson: 0.7243
Batch[3399] - loss: 0.001625 best_pearson: 0.7243
Batch[3400] - loss: 0.001552 best_pearson: 0.7243

Evaluation - loss: 0.000046 pearson: 0.7208 

Batch[3401] - loss: 0.001997 best_pearson: 0.7243
Batch[3402] - loss: 0.002791 best_pearson: 0.7243
Batch[3403] - loss: 0.001561 best_pearson: 0.7243
Batch[3404] - loss: 0.001231 best_pearson: 0.7243
Batch[3405] - loss: 0.003077 best_pearson: 0.7243
Batch[3406] - loss: 0.001352 best_pearson: 0.7243
Batch[3407] - loss: 0.001938 best_pearson: 0.7243
Batch[3408] - loss: 0.001811 best_pearson: 0.7243
Batch[3409] - loss: 0.002181 best_pearson: 0.7243
Batch[3410] - loss: 0.001193 best_pearson: 0.7243
Batch[3411] - loss: 0.001677 best_pearson: 0.7243
Batch[3412] - loss: 0.001930 best_pearson: 0.7243
Batch[3413] - loss: 0.002205 best_pearson: 0.7243
Batch[3414] - loss: 0.001516 best_pearson: 0.7243
Batch[3415] - loss: 0.001989 best_pearson: 0.7243
Batch[3416] - loss: 0.001091 best_pearson: 0.7243
Batch[3417] - loss: 0.000911 best_pearson: 0.7243
Batch[3418] - loss: 0.002627 best_pearson: 0.7243
Batch[3419] - loss: 0.002142 best_pearson: 0.7243
Batch[3420] - loss: 0.001599 best_pearson: 0.7243
Batch[3421] - loss: 0.001983 best_pearson: 0.7243
Batch[3422] - loss: 0.001661 best_pearson: 0.7243
Batch[3423] - loss: 0.001866 best_pearson: 0.7243
Batch[3424] - loss: 0.001969 best_pearson: 0.7243
Batch[3425] - loss: 0.002542 best_pearson: 0.7243
Batch[3426] - loss: 0.002369 best_pearson: 0.7243
Batch[3427] - loss: 0.001462 best_pearson: 0.7243
Batch[3428] - loss: 0.002409 best_pearson: 0.7243
Batch[3429] - loss: 0.002095 best_pearson: 0.7243
Batch[3430] - loss: 0.002029 best_pearson: 0.7243
Batch[3431] - loss: 0.001605 best_pearson: 0.7243
Batch[3432] - loss: 0.003552 best_pearson: 0.7243
Batch[3433] - loss: 0.000962 best_pearson: 0.7243
Batch[3434] - loss: 0.000780 best_pearson: 0.7243
Batch[3435] - loss: 0.001208 best_pearson: 0.7243
Batch[3436] - loss: 0.000943 best_pearson: 0.7243
Batch[3437] - loss: 0.001740 best_pearson: 0.7243
Batch[3438] - loss: 0.001622 best_pearson: 0.7243
Batch[3439] - loss: 0.001522 best_pearson: 0.7243
Batch[3440] - loss: 0.000979 best_pearson: 0.7243
Batch[3441] - loss: 0.001914 best_pearson: 0.7243
Batch[3442] - loss: 0.002157 best_pearson: 0.7243
Batch[3443] - loss: 0.001205 best_pearson: 0.7243
Batch[3444] - loss: 0.002131 best_pearson: 0.7243
Batch[3445] - loss: 0.001865 best_pearson: 0.7243
Batch[3446] - loss: 0.000758 best_pearson: 0.7243
Batch[3447] - loss: 0.001556 best_pearson: 0.7243
Batch[3448] - loss: 0.001180 best_pearson: 0.7243
Batch[3449] - loss: 0.001585 best_pearson: 0.7243
Batch[3450] - loss: 0.000951 best_pearson: 0.7243
Batch[3451] - loss: 0.001428 best_pearson: 0.7243
Batch[3452] - loss: 0.001694 best_pearson: 0.7243
Batch[3453] - loss: 0.001447 best_pearson: 0.7243
Batch[3454] - loss: 0.000883 best_pearson: 0.7243
Batch[3455] - loss: 0.001224 best_pearson: 0.7243
Batch[3456] - loss: 0.002223 best_pearson: 0.7243
Batch[3457] - loss: 0.001539 best_pearson: 0.7243
Batch[3458] - loss: 0.000915 best_pearson: 0.7243
Batch[3459] - loss: 0.001179 best_pearson: 0.7243
Batch[3460] - loss: 0.001034 best_pearson: 0.7243
Batch[3461] - loss: 0.002190 best_pearson: 0.7243
Batch[3462] - loss: 0.001602 best_pearson: 0.7243
Batch[3463] - loss: 0.001204 best_pearson: 0.7243
Batch[3464] - loss: 0.001476 best_pearson: 0.7243
Batch[3465] - loss: 0.001450 best_pearson: 0.7243
Batch[3466] - loss: 0.002594 best_pearson: 0.7243
Batch[3467] - loss: 0.000810 best_pearson: 0.7243
Batch[3468] - loss: 0.001757 best_pearson: 0.7243
Batch[3469] - loss: 0.002386 best_pearson: 0.7243
Batch[3470] - loss: 0.001179 best_pearson: 0.7243
Batch[3471] - loss: 0.001451 best_pearson: 0.7243
Batch[3472] - loss: 0.001801 best_pearson: 0.7243
Batch[3473] - loss: 0.002344 best_pearson: 0.7243
Batch[3474] - loss: 0.001512 best_pearson: 0.7243
Batch[3475] - loss: 0.000932 best_pearson: 0.7243
Batch[3476] - loss: 0.001063 best_pearson: 0.7243
Batch[3477] - loss: 0.000925 best_pearson: 0.7243
Batch[3478] - loss: 0.001656 best_pearson: 0.7243
Batch[3479] - loss: 0.001027 best_pearson: 0.7243
Batch[3480] - loss: 0.000925 best_pearson: 0.7243
Batch[3481] - loss: 0.001557 best_pearson: 0.7243
Batch[3482] - loss: 0.001426 best_pearson: 0.7243
Batch[3483] - loss: 0.002167 best_pearson: 0.7243
Batch[3484] - loss: 0.001153 best_pearson: 0.7243
Batch[3485] - loss: 0.001399 best_pearson: 0.7243
Batch[3486] - loss: 0.001570 best_pearson: 0.7243
Batch[3487] - loss: 0.001129 best_pearson: 0.7243
Batch[3488] - loss: 0.001285 best_pearson: 0.7243
Batch[3489] - loss: 0.001462 best_pearson: 0.7243
Batch[3490] - loss: 0.001879 best_pearson: 0.7243
Batch[3491] - loss: 0.001395 best_pearson: 0.7243
Batch[3492] - loss: 0.001112 best_pearson: 0.7243
Batch[3493] - loss: 0.001293 best_pearson: 0.7243
Batch[3494] - loss: 0.002220 best_pearson: 0.7243
Batch[3495] - loss: 0.001014 best_pearson: 0.7243
Batch[3496] - loss: 0.001380 best_pearson: 0.7243
Batch[3497] - loss: 0.001001 best_pearson: 0.7243
Batch[3498] - loss: 0.001762 best_pearson: 0.7243
Batch[3499] - loss: 0.001806 best_pearson: 0.7243
Batch[3500] - loss: 0.000966 best_pearson: 0.7243

Evaluation - loss: 0.000048 pearson: 0.7166 

Batch[3501] - loss: 0.003126 best_pearson: 0.7243
Batch[3502] - loss: 0.001945 best_pearson: 0.7243
Batch[3503] - loss: 0.002241 best_pearson: 0.7243
Batch[3504] - loss: 0.001269 best_pearson: 0.7243
Batch[3505] - loss: 0.001851 best_pearson: 0.7243
Batch[3506] - loss: 0.001314 best_pearson: 0.7243
Batch[3507] - loss: 0.002083 best_pearson: 0.7243
Batch[3508] - loss: 0.002044 best_pearson: 0.7243
Batch[3509] - loss: 0.001416 best_pearson: 0.7243
Batch[3510] - loss: 0.001105 best_pearson: 0.7243
Batch[3511] - loss: 0.002371 best_pearson: 0.7243
Batch[3512] - loss: 0.002388 best_pearson: 0.7243
Batch[3513] - loss: 0.001193 best_pearson: 0.7243
Batch[3514] - loss: 0.001443 best_pearson: 0.7243
Batch[3515] - loss: 0.002632 best_pearson: 0.7243
Batch[3516] - loss: 0.001986 best_pearson: 0.7243
Batch[3517] - loss: 0.001814 best_pearson: 0.7243
Batch[3518] - loss: 0.000916 best_pearson: 0.7243
Batch[3519] - loss: 0.002131 best_pearson: 0.7243
Batch[3520] - loss: 0.001283 best_pearson: 0.7243
Batch[3521] - loss: 0.001031 best_pearson: 0.7243
Batch[3522] - loss: 0.001828 best_pearson: 0.7243
Batch[3523] - loss: 0.002259 best_pearson: 0.7243
Batch[3524] - loss: 0.001013 best_pearson: 0.7243
Batch[3525] - loss: 0.002114 best_pearson: 0.7243
Batch[3526] - loss: 0.000892 best_pearson: 0.7243
Batch[3527] - loss: 0.001476 best_pearson: 0.7243
Batch[3528] - loss: 0.001311 best_pearson: 0.7243
Batch[3529] - loss: 0.001770 best_pearson: 0.7243
Batch[3530] - loss: 0.001421 best_pearson: 0.7243
Batch[3531] - loss: 0.000718 best_pearson: 0.7243
Batch[3532] - loss: 0.002339 best_pearson: 0.7243
Batch[3533] - loss: 0.002374 best_pearson: 0.7243
Batch[3534] - loss: 0.001688 best_pearson: 0.7243
Batch[3535] - loss: 0.001365 best_pearson: 0.7243
Batch[3536] - loss: 0.001433 best_pearson: 0.7243
Batch[3537] - loss: 0.001567 best_pearson: 0.7243
Batch[3538] - loss: 0.002080 best_pearson: 0.7243
Batch[3539] - loss: 0.001106 best_pearson: 0.7243
Batch[3540] - loss: 0.001409 best_pearson: 0.7243
Batch[3541] - loss: 0.001631 best_pearson: 0.7243
Batch[3542] - loss: 0.002221 best_pearson: 0.7243
Batch[3543] - loss: 0.001576 best_pearson: 0.7243
Batch[3544] - loss: 0.001520 best_pearson: 0.7243
Batch[3545] - loss: 0.003229 best_pearson: 0.7243
Batch[3546] - loss: 0.002370 best_pearson: 0.7243
Batch[3547] - loss: 0.002185 best_pearson: 0.7243
Batch[3548] - loss: 0.002458 best_pearson: 0.7243
Batch[3549] - loss: 0.002112 best_pearson: 0.7243
Batch[3550] - loss: 0.002157 best_pearson: 0.7243
Batch[3551] - loss: 0.002502 best_pearson: 0.7243
Batch[3552] - loss: 0.001337 best_pearson: 0.7243
Batch[3553] - loss: 0.002633 best_pearson: 0.7243
Batch[3554] - loss: 0.002566 best_pearson: 0.7243
Batch[3555] - loss: 0.001760 best_pearson: 0.7243
Batch[3556] - loss: 0.002115 best_pearson: 0.7243
Batch[3557] - loss: 0.001967 best_pearson: 0.7243
Batch[3558] - loss: 0.002268 best_pearson: 0.7243
Batch[3559] - loss: 0.001273 best_pearson: 0.7243
Batch[3560] - loss: 0.001394 best_pearson: 0.7243
Batch[3561] - loss: 0.001625 best_pearson: 0.7243
Batch[3562] - loss: 0.001416 best_pearson: 0.7243
Batch[3563] - loss: 0.001458 best_pearson: 0.7243
Batch[3564] - loss: 0.001407 best_pearson: 0.7243
Batch[3565] - loss: 0.000886 best_pearson: 0.7243
Batch[3566] - loss: 0.001567 best_pearson: 0.7243
Batch[3567] - loss: 0.001177 best_pearson: 0.7243
Batch[3568] - loss: 0.001324 best_pearson: 0.7243
Batch[3569] - loss: 0.000978 best_pearson: 0.7243
Batch[3570] - loss: 0.001709 best_pearson: 0.7243
Batch[3571] - loss: 0.001918 best_pearson: 0.7243
Batch[3572] - loss: 0.001448 best_pearson: 0.7243
Batch[3573] - loss: 0.001353 best_pearson: 0.7243
Batch[3574] - loss: 0.000991 best_pearson: 0.7243
Batch[3575] - loss: 0.001214 best_pearson: 0.7243
Batch[3576] - loss: 0.001158 best_pearson: 0.7243
Batch[3577] - loss: 0.002323 best_pearson: 0.7243
Batch[3578] - loss: 0.001340 best_pearson: 0.7243
Batch[3579] - loss: 0.001557 best_pearson: 0.7243
Batch[3580] - loss: 0.001494 best_pearson: 0.7243
Batch[3581] - loss: 0.001198 best_pearson: 0.7243
Batch[3582] - loss: 0.001276 best_pearson: 0.7243
Batch[3583] - loss: 0.001392 best_pearson: 0.7243
Batch[3584] - loss: 0.001478 best_pearson: 0.7243
Batch[3585] - loss: 0.001489 best_pearson: 0.7243
Batch[3586] - loss: 0.001469 best_pearson: 0.7243
Batch[3587] - loss: 0.001760 best_pearson: 0.7243
Batch[3588] - loss: 0.001505 best_pearson: 0.7243
Batch[3589] - loss: 0.001074 best_pearson: 0.7243
Batch[3590] - loss: 0.001274 best_pearson: 0.7243
Batch[3591] - loss: 0.001853 best_pearson: 0.7243
Batch[3592] - loss: 0.002124 best_pearson: 0.7243
Batch[3593] - loss: 0.001471 best_pearson: 0.7243
Batch[3594] - loss: 0.001759 best_pearson: 0.7243
Batch[3595] - loss: 0.002217 best_pearson: 0.7243
Batch[3596] - loss: 0.001382 best_pearson: 0.7243
Batch[3597] - loss: 0.001049 best_pearson: 0.7243
Batch[3598] - loss: 0.001373 best_pearson: 0.7243
Batch[3599] - loss: 0.001560 best_pearson: 0.7243
Batch[3600] - loss: 0.001764 best_pearson: 0.7243

Evaluation - loss: 0.000045 pearson: 0.7219 

Batch[3601] - loss: 0.002179 best_pearson: 0.7243
Batch[3602] - loss: 0.001621 best_pearson: 0.7243
Batch[3603] - loss: 0.002034 best_pearson: 0.7243
Batch[3604] - loss: 0.001505 best_pearson: 0.7243
Batch[3605] - loss: 0.001468 best_pearson: 0.7243
Batch[3606] - loss: 0.001480 best_pearson: 0.7243
Batch[3607] - loss: 0.001608 best_pearson: 0.7243
Batch[3608] - loss: 0.001445 best_pearson: 0.7243
Batch[3609] - loss: 0.000908 best_pearson: 0.7243
Batch[3610] - loss: 0.001533 best_pearson: 0.7243
Batch[3611] - loss: 0.001185 best_pearson: 0.7243
Batch[3612] - loss: 0.001374 best_pearson: 0.7243
Batch[3613] - loss: 0.001962 best_pearson: 0.7243
Batch[3614] - loss: 0.001482 best_pearson: 0.7243
Batch[3615] - loss: 0.001648 best_pearson: 0.7243
Batch[3616] - loss: 0.001226 best_pearson: 0.7243
Batch[3617] - loss: 0.002216 best_pearson: 0.7243
Batch[3618] - loss: 0.003465 best_pearson: 0.7243
Batch[3619] - loss: 0.000847 best_pearson: 0.7243
Batch[3620] - loss: 0.000940 best_pearson: 0.7243
Batch[3621] - loss: 0.001438 best_pearson: 0.7243
Batch[3622] - loss: 0.001376 best_pearson: 0.7243
Batch[3623] - loss: 0.001866 best_pearson: 0.7243
Batch[3624] - loss: 0.000995 best_pearson: 0.7243
Batch[3625] - loss: 0.000958 best_pearson: 0.7243
Batch[3626] - loss: 0.001800 best_pearson: 0.7243
Batch[3627] - loss: 0.001658 best_pearson: 0.7243
Batch[3628] - loss: 0.001424 best_pearson: 0.7243
Batch[3629] - loss: 0.001963 best_pearson: 0.7243
Batch[3630] - loss: 0.001341 best_pearson: 0.7243
Batch[3631] - loss: 0.001465 best_pearson: 0.7243
Batch[3632] - loss: 0.001249 best_pearson: 0.7243
Batch[3633] - loss: 0.002029 best_pearson: 0.7243
Batch[3634] - loss: 0.001690 best_pearson: 0.7243
Batch[3635] - loss: 0.001815 best_pearson: 0.7243
Batch[3636] - loss: 0.001465 best_pearson: 0.7243
Batch[3637] - loss: 0.001984 best_pearson: 0.7243
Batch[3638] - loss: 0.002233 best_pearson: 0.7243
Batch[3639] - loss: 0.002196 best_pearson: 0.7243
Batch[3640] - loss: 0.001141 best_pearson: 0.7243
Batch[3641] - loss: 0.000767 best_pearson: 0.7243
Batch[3642] - loss: 0.001635 best_pearson: 0.7243
Batch[3643] - loss: 0.001286 best_pearson: 0.7243
Batch[3644] - loss: 0.002829 best_pearson: 0.7243
Batch[3645] - loss: 0.001163 best_pearson: 0.7243
Batch[3646] - loss: 0.001134 best_pearson: 0.7243
Batch[3647] - loss: 0.001356 best_pearson: 0.7243
Batch[3648] - loss: 0.002071 best_pearson: 0.7243
Batch[3649] - loss: 0.000965 best_pearson: 0.7243
Batch[3650] - loss: 0.001033 best_pearson: 0.7243
Batch[3651] - loss: 0.001096 best_pearson: 0.7243
Batch[3652] - loss: 0.001944 best_pearson: 0.7243
Batch[3653] - loss: 0.000728 best_pearson: 0.7243
Batch[3654] - loss: 0.001650 best_pearson: 0.7243
Batch[3655] - loss: 0.002066 best_pearson: 0.7243
Batch[3656] - loss: 0.001434 best_pearson: 0.7243
Batch[3657] - loss: 0.001281 best_pearson: 0.7243
Batch[3658] - loss: 0.001100 best_pearson: 0.7243
Batch[3659] - loss: 0.000555 best_pearson: 0.7243
Batch[3660] - loss: 0.001084 best_pearson: 0.7243
Batch[3661] - loss: 0.000830 best_pearson: 0.7243
Batch[3662] - loss: 0.000916 best_pearson: 0.7243
Batch[3663] - loss: 0.001540 best_pearson: 0.7243
Batch[3664] - loss: 0.001485 best_pearson: 0.7243
Batch[3665] - loss: 0.002378 best_pearson: 0.7243
Batch[3666] - loss: 0.000729 best_pearson: 0.7243
Batch[3667] - loss: 0.002361 best_pearson: 0.7243
Batch[3668] - loss: 0.000921 best_pearson: 0.7243
Batch[3669] - loss: 0.000957 best_pearson: 0.7243
Batch[3670] - loss: 0.001017 best_pearson: 0.7243
Batch[3671] - loss: 0.001330 best_pearson: 0.7243
Batch[3672] - loss: 0.000794 best_pearson: 0.7243
Batch[3673] - loss: 0.001289 best_pearson: 0.7243
Batch[3674] - loss: 0.002115 best_pearson: 0.7243
Batch[3675] - loss: 0.001333 best_pearson: 0.7243
Batch[3676] - loss: 0.001443 best_pearson: 0.7243
Batch[3677] - loss: 0.001249 best_pearson: 0.7243
Batch[3678] - loss: 0.001112 best_pearson: 0.7243
Batch[3679] - loss: 0.000827 best_pearson: 0.7243
Batch[3680] - loss: 0.001207 best_pearson: 0.7243
Batch[3681] - loss: 0.001461 best_pearson: 0.7243
Batch[3682] - loss: 0.000998 best_pearson: 0.7243
Batch[3683] - loss: 0.001037 best_pearson: 0.7243
Batch[3684] - loss: 0.001028 best_pearson: 0.7243
Batch[3685] - loss: 0.001406 best_pearson: 0.7243
Batch[3686] - loss: 0.000929 best_pearson: 0.7243
Batch[3687] - loss: 0.000908 best_pearson: 0.7243
Batch[3688] - loss: 0.001132 best_pearson: 0.7243
Batch[3689] - loss: 0.001317 best_pearson: 0.7243
Batch[3690] - loss: 0.000897 best_pearson: 0.7243
Batch[3691] - loss: 0.001348 best_pearson: 0.7243
Batch[3692] - loss: 0.000872 best_pearson: 0.7243
Batch[3693] - loss: 0.001209 best_pearson: 0.7243
Batch[3694] - loss: 0.001406 best_pearson: 0.7243
Batch[3695] - loss: 0.000860 best_pearson: 0.7243
Batch[3696] - loss: 0.000886 best_pearson: 0.7243
Batch[3697] - loss: 0.001612 best_pearson: 0.7243
Batch[3698] - loss: 0.000993 best_pearson: 0.7243
Batch[3699] - loss: 0.001130 best_pearson: 0.7243
Batch[3700] - loss: 0.002764 best_pearson: 0.7243

Evaluation - loss: 0.000046 pearson: 0.7205 

Batch[3701] - loss: 0.000883 best_pearson: 0.7243
Batch[3702] - loss: 0.002369 best_pearson: 0.7243
Batch[3703] - loss: 0.000708 best_pearson: 0.7243
Batch[3704] - loss: 0.001620 best_pearson: 0.7243
Batch[3705] - loss: 0.000669 best_pearson: 0.7243
Batch[3706] - loss: 0.001079 best_pearson: 0.7243
Batch[3707] - loss: 0.002199 best_pearson: 0.7243
Batch[3708] - loss: 0.002079 best_pearson: 0.7243
Batch[3709] - loss: 0.000822 best_pearson: 0.7243
Batch[3710] - loss: 0.001125 best_pearson: 0.7243
Batch[3711] - loss: 0.001710 best_pearson: 0.7243
Batch[3712] - loss: 0.002285 best_pearson: 0.7243
Batch[3713] - loss: 0.000808 best_pearson: 0.7243
Batch[3714] - loss: 0.001985 best_pearson: 0.7243
Batch[3715] - loss: 0.001046 best_pearson: 0.7243
Batch[3716] - loss: 0.000949 best_pearson: 0.7243
Batch[3717] - loss: 0.001700 best_pearson: 0.7243
Batch[3718] - loss: 0.001188 best_pearson: 0.7243
Batch[3719] - loss: 0.000980 best_pearson: 0.7243
Batch[3720] - loss: 0.001259 best_pearson: 0.7243
Batch[3721] - loss: 0.001150 best_pearson: 0.7243
Batch[3722] - loss: 0.002206 best_pearson: 0.7243
Batch[3723] - loss: 0.001203 best_pearson: 0.7243
Batch[3724] - loss: 0.001493 best_pearson: 0.7243
Batch[3725] - loss: 0.001418 best_pearson: 0.7243
Batch[3726] - loss: 0.000470 best_pearson: 0.7243
Batch[3727] - loss: 0.001206 best_pearson: 0.7243
Batch[3728] - loss: 0.002214 best_pearson: 0.7243
Batch[3729] - loss: 0.001035 best_pearson: 0.7243
Batch[3730] - loss: 0.001104 best_pearson: 0.7243
Batch[3731] - loss: 0.001193 best_pearson: 0.7243
Batch[3732] - loss: 0.001557 best_pearson: 0.7243
Batch[3733] - loss: 0.001735 best_pearson: 0.7243
Batch[3734] - loss: 0.002261 best_pearson: 0.7243
Batch[3735] - loss: 0.000967 best_pearson: 0.7243
Batch[3736] - loss: 0.001032 best_pearson: 0.7243
Batch[3737] - loss: 0.001247 best_pearson: 0.7243
Batch[3738] - loss: 0.001608 best_pearson: 0.7243
Batch[3739] - loss: 0.001221 best_pearson: 0.7243
Batch[3740] - loss: 0.001904 best_pearson: 0.7243
Batch[3741] - loss: 0.001816 best_pearson: 0.7243
Batch[3742] - loss: 0.000902 best_pearson: 0.7243
Batch[3743] - loss: 0.001366 best_pearson: 0.7243
Batch[3744] - loss: 0.002015 best_pearson: 0.7243
Batch[3745] - loss: 0.000838 best_pearson: 0.7243
Batch[3746] - loss: 0.001135 best_pearson: 0.7243
Batch[3747] - loss: 0.000949 best_pearson: 0.7243
Batch[3748] - loss: 0.000748 best_pearson: 0.7243
Batch[3749] - loss: 0.002047 best_pearson: 0.7243
Batch[3750] - loss: 0.001511 best_pearson: 0.7243
Batch[3751] - loss: 0.001414 best_pearson: 0.7243
Batch[3752] - loss: 0.001023 best_pearson: 0.7243
Batch[3753] - loss: 0.001320 best_pearson: 0.7243
Batch[3754] - loss: 0.000830 best_pearson: 0.7243
Batch[3755] - loss: 0.001786 best_pearson: 0.7243
Batch[3756] - loss: 0.001141 best_pearson: 0.7243
Batch[3757] - loss: 0.002159 best_pearson: 0.7243
Batch[3758] - loss: 0.001263 best_pearson: 0.7243
Batch[3759] - loss: 0.000614 best_pearson: 0.7243
Batch[3760] - loss: 0.000684 best_pearson: 0.7243
Batch[3761] - loss: 0.000952 best_pearson: 0.7243
Batch[3762] - loss: 0.001263 best_pearson: 0.7243
Batch[3763] - loss: 0.000924 best_pearson: 0.7243
Batch[3764] - loss: 0.001116 best_pearson: 0.7243
Batch[3765] - loss: 0.001340 best_pearson: 0.7243
Batch[3766] - loss: 0.001019 best_pearson: 0.7243
Batch[3767] - loss: 0.001096 best_pearson: 0.7243
Batch[3768] - loss: 0.001381 best_pearson: 0.7243
Batch[3769] - loss: 0.001857 best_pearson: 0.7243
Batch[3770] - loss: 0.000887 best_pearson: 0.7243
Batch[3771] - loss: 0.001371 best_pearson: 0.7243
Batch[3772] - loss: 0.001142 best_pearson: 0.7243
Batch[3773] - loss: 0.001748 best_pearson: 0.7243
Batch[3774] - loss: 0.001749 best_pearson: 0.7243
Batch[3775] - loss: 0.001196 best_pearson: 0.7243
Batch[3776] - loss: 0.001548 best_pearson: 0.7243
Batch[3777] - loss: 0.001939 best_pearson: 0.7243
Batch[3778] - loss: 0.001154 best_pearson: 0.7243
Batch[3779] - loss: 0.000890 best_pearson: 0.7243
Batch[3780] - loss: 0.001315 best_pearson: 0.7243
Batch[3781] - loss: 0.001754 best_pearson: 0.7243
Batch[3782] - loss: 0.001328 best_pearson: 0.7243
Batch[3783] - loss: 0.001317 best_pearson: 0.7243
Batch[3784] - loss: 0.001273 best_pearson: 0.7243
Batch[3785] - loss: 0.000885 best_pearson: 0.7243
Batch[3786] - loss: 0.001874 best_pearson: 0.7243
Batch[3787] - loss: 0.001258 best_pearson: 0.7243
Batch[3788] - loss: 0.000983 best_pearson: 0.7243
Batch[3789] - loss: 0.000946 best_pearson: 0.7243
Batch[3790] - loss: 0.000753 best_pearson: 0.7243
Batch[3791] - loss: 0.001545 best_pearson: 0.7243
Batch[3792] - loss: 0.001135 best_pearson: 0.7243
Batch[3793] - loss: 0.000901 best_pearson: 0.7243
Batch[3794] - loss: 0.001377 best_pearson: 0.7243
Batch[3795] - loss: 0.001021 best_pearson: 0.7243
Batch[3796] - loss: 0.001014 best_pearson: 0.7243
Batch[3797] - loss: 0.001015 best_pearson: 0.7243
Batch[3798] - loss: 0.001980 best_pearson: 0.7243
Batch[3799] - loss: 0.001135 best_pearson: 0.7243
Batch[3800] - loss: 0.001578 best_pearson: 0.7243

Evaluation - loss: 0.000046 pearson: 0.7221 

Batch[3801] - loss: 0.000576 best_pearson: 0.7243
Batch[3802] - loss: 0.001705 best_pearson: 0.7243
Batch[3803] - loss: 0.000528 best_pearson: 0.7243
Batch[3804] - loss: 0.002056 best_pearson: 0.7243
Batch[3805] - loss: 0.001152 best_pearson: 0.7243
Batch[3806] - loss: 0.001294 best_pearson: 0.7243
Batch[3807] - loss: 0.002548 best_pearson: 0.7243
Batch[3808] - loss: 0.001588 best_pearson: 0.7243
Batch[3809] - loss: 0.001458 best_pearson: 0.7243
Batch[3810] - loss: 0.001812 best_pearson: 0.7243
Batch[3811] - loss: 0.001463 best_pearson: 0.7243
Batch[3812] - loss: 0.001156 best_pearson: 0.7243
Batch[3813] - loss: 0.000663 best_pearson: 0.7243
Batch[3814] - loss: 0.001468 best_pearson: 0.7243
Batch[3815] - loss: 0.001419 best_pearson: 0.7243
Batch[3816] - loss: 0.001189 best_pearson: 0.7243
Batch[3817] - loss: 0.001284 best_pearson: 0.7243
Batch[3818] - loss: 0.001321 best_pearson: 0.7243
Batch[3819] - loss: 0.001145 best_pearson: 0.7243
Batch[3820] - loss: 0.000965 best_pearson: 0.7243
Batch[3821] - loss: 0.001619 best_pearson: 0.7243
Batch[3822] - loss: 0.001193 best_pearson: 0.7243
Batch[3823] - loss: 0.000934 best_pearson: 0.7243
Batch[3824] - loss: 0.001180 best_pearson: 0.7243
Batch[3825] - loss: 0.001453 best_pearson: 0.7243
Batch[3826] - loss: 0.001531 best_pearson: 0.7243
Batch[3827] - loss: 0.001419 best_pearson: 0.7243
Batch[3828] - loss: 0.001168 best_pearson: 0.7243
Batch[3829] - loss: 0.001451 best_pearson: 0.7243
Batch[3830] - loss: 0.000689 best_pearson: 0.7243
Batch[3831] - loss: 0.001576 best_pearson: 0.7243
Batch[3832] - loss: 0.001263 best_pearson: 0.7243
Batch[3833] - loss: 0.001367 best_pearson: 0.7243
Batch[3834] - loss: 0.001205 best_pearson: 0.7243
Batch[3835] - loss: 0.001502 best_pearson: 0.7243
Batch[3836] - loss: 0.001052 best_pearson: 0.7243
Batch[3837] - loss: 0.001259 best_pearson: 0.7243
Batch[3838] - loss: 0.001245 best_pearson: 0.7243
Batch[3839] - loss: 0.000841 best_pearson: 0.7243
Batch[3840] - loss: 0.002340 best_pearson: 0.7243
Batch[3841] - loss: 0.000917 best_pearson: 0.7243
Batch[3842] - loss: 0.001149 best_pearson: 0.7243
Batch[3843] - loss: 0.001045 best_pearson: 0.7243
Batch[3844] - loss: 0.002218 best_pearson: 0.7243
Batch[3845] - loss: 0.001597 best_pearson: 0.7243
Batch[3846] - loss: 0.000944 best_pearson: 0.7243
Batch[3847] - loss: 0.001270 best_pearson: 0.7243
Batch[3848] - loss: 0.001162 best_pearson: 0.7243
Batch[3849] - loss: 0.001731 best_pearson: 0.7243
Batch[3850] - loss: 0.000821 best_pearson: 0.7243
Batch[3851] - loss: 0.001890 best_pearson: 0.7243
Batch[3852] - loss: 0.001017 best_pearson: 0.7243
Batch[3853] - loss: 0.001251 best_pearson: 0.7243
Batch[3854] - loss: 0.000880 best_pearson: 0.7243
Batch[3855] - loss: 0.000948 best_pearson: 0.7243
Batch[3856] - loss: 0.001725 best_pearson: 0.7243
Batch[3857] - loss: 0.001871 best_pearson: 0.7243
Batch[3858] - loss: 0.001311 best_pearson: 0.7243
Batch[3859] - loss: 0.001421 best_pearson: 0.7243
Batch[3860] - loss: 0.001173 best_pearson: 0.7243
Batch[3861] - loss: 0.001187 best_pearson: 0.7243
Batch[3862] - loss: 0.000878 best_pearson: 0.7243
Batch[3863] - loss: 0.000770 best_pearson: 0.7243
Batch[3864] - loss: 0.000352 best_pearson: 0.7243
Batch[3865] - loss: 0.001235 best_pearson: 0.7243
Batch[3866] - loss: 0.001213 best_pearson: 0.7243
Batch[3867] - loss: 0.000785 best_pearson: 0.7243
Batch[3868] - loss: 0.000807 best_pearson: 0.7243
Batch[3869] - loss: 0.002063 best_pearson: 0.7243
Batch[3870] - loss: 0.000784 best_pearson: 0.7243
Batch[3871] - loss: 0.000902 best_pearson: 0.7243
Batch[3872] - loss: 0.000737 best_pearson: 0.7243
Batch[3873] - loss: 0.000962 best_pearson: 0.7243
Batch[3874] - loss: 0.000686 best_pearson: 0.7243
Batch[3875] - loss: 0.001671 best_pearson: 0.7243
Batch[3876] - loss: 0.001032 best_pearson: 0.7243
Batch[3877] - loss: 0.000745 best_pearson: 0.7243
Batch[3878] - loss: 0.001074 best_pearson: 0.7243
Batch[3879] - loss: 0.001619 best_pearson: 0.7243
Batch[3880] - loss: 0.001715 best_pearson: 0.7243
Batch[3881] - loss: 0.000811 best_pearson: 0.7243
Batch[3882] - loss: 0.001179 best_pearson: 0.7243
Batch[3883] - loss: 0.000973 best_pearson: 0.7243
Batch[3884] - loss: 0.001013 best_pearson: 0.7243
Batch[3885] - loss: 0.001230 best_pearson: 0.7243
Batch[3886] - loss: 0.001605 best_pearson: 0.7243
Batch[3887] - loss: 0.001548 best_pearson: 0.7243
Batch[3888] - loss: 0.001716 best_pearson: 0.7243
Batch[3889] - loss: 0.000986 best_pearson: 0.7243
Batch[3890] - loss: 0.001174 best_pearson: 0.7243
Batch[3891] - loss: 0.001166 best_pearson: 0.7243
Batch[3892] - loss: 0.001768 best_pearson: 0.7243
Batch[3893] - loss: 0.001114 best_pearson: 0.7243
Batch[3894] - loss: 0.000835 best_pearson: 0.7243
Batch[3895] - loss: 0.002007 best_pearson: 0.7243
Batch[3896] - loss: 0.001367 best_pearson: 0.7243
Batch[3897] - loss: 0.000997 best_pearson: 0.7243
Batch[3898] - loss: 0.000945 best_pearson: 0.7243
Batch[3899] - loss: 0.001148 best_pearson: 0.7243
Batch[3900] - loss: 0.001284 best_pearson: 0.7243

Evaluation - loss: 0.000046 pearson: 0.7195 

Batch[3901] - loss: 0.001454 best_pearson: 0.7243
Batch[3902] - loss: 0.000882 best_pearson: 0.7243
Batch[3903] - loss: 0.001279 best_pearson: 0.7243
Batch[3904] - loss: 0.001017 best_pearson: 0.7243
Batch[3905] - loss: 0.001242 best_pearson: 0.7243
Batch[3906] - loss: 0.000857 best_pearson: 0.7243
Batch[3907] - loss: 0.000773 best_pearson: 0.7243
Batch[3908] - loss: 0.002179 best_pearson: 0.7243
Batch[3909] - loss: 0.001073 best_pearson: 0.7243
Batch[3910] - loss: 0.000962 best_pearson: 0.7243
Batch[3911] - loss: 0.001699 best_pearson: 0.7243
Batch[3912] - loss: 0.001838 best_pearson: 0.7243
Batch[3913] - loss: 0.001648 best_pearson: 0.7243
Batch[3914] - loss: 0.001027 best_pearson: 0.7243
Batch[3915] - loss: 0.000814 best_pearson: 0.7243
Batch[3916] - loss: 0.001910 best_pearson: 0.7243
Batch[3917] - loss: 0.001167 best_pearson: 0.7243
Batch[3918] - loss: 0.001644 best_pearson: 0.7243
Batch[3919] - loss: 0.001643 best_pearson: 0.7243
Batch[3920] - loss: 0.001438 best_pearson: 0.7243
Batch[3921] - loss: 0.001059 best_pearson: 0.7243
Batch[3922] - loss: 0.001707 best_pearson: 0.7243
Batch[3923] - loss: 0.000995 best_pearson: 0.7243
Batch[3924] - loss: 0.001147 best_pearson: 0.7243
Batch[3925] - loss: 0.000789 best_pearson: 0.7243
Batch[3926] - loss: 0.001159 best_pearson: 0.7243
Batch[3927] - loss: 0.000732 best_pearson: 0.7243
Batch[3928] - loss: 0.000912 best_pearson: 0.7243
Batch[3929] - loss: 0.001033 best_pearson: 0.7243
Batch[3930] - loss: 0.001336 best_pearson: 0.7243
Batch[3931] - loss: 0.001700 best_pearson: 0.7243
Batch[3932] - loss: 0.000862 best_pearson: 0.7243
Batch[3933] - loss: 0.000710 best_pearson: 0.7243
Batch[3934] - loss: 0.000843 best_pearson: 0.7243
Batch[3935] - loss: 0.001176 best_pearson: 0.7243
Batch[3936] - loss: 0.000642 best_pearson: 0.7243
Batch[3937] - loss: 0.001434 best_pearson: 0.7243
Batch[3938] - loss: 0.001702 best_pearson: 0.7243
Batch[3939] - loss: 0.001160 best_pearson: 0.7243
Batch[3940] - loss: 0.001486 best_pearson: 0.7243
Batch[3941] - loss: 0.001338 best_pearson: 0.7243
Batch[3942] - loss: 0.000790 best_pearson: 0.7243
Batch[3943] - loss: 0.001698 best_pearson: 0.7243
Batch[3944] - loss: 0.001449 best_pearson: 0.7243
Batch[3945] - loss: 0.000958 best_pearson: 0.7243
Batch[3946] - loss: 0.002676 best_pearson: 0.7243
Batch[3947] - loss: 0.000980 best_pearson: 0.7243
Batch[3948] - loss: 0.001525 best_pearson: 0.7243
Batch[3949] - loss: 0.001380 best_pearson: 0.7243
Batch[3950] - loss: 0.001192 best_pearson: 0.7243
Batch[3951] - loss: 0.001218 best_pearson: 0.7243
Batch[3952] - loss: 0.000629 best_pearson: 0.7243
Batch[3953] - loss: 0.001329 best_pearson: 0.7243
Batch[3954] - loss: 0.001570 best_pearson: 0.7243
Batch[3955] - loss: 0.000981 best_pearson: 0.7243
Batch[3956] - loss: 0.000832 best_pearson: 0.7243
Batch[3957] - loss: 0.001411 best_pearson: 0.7243
Batch[3958] - loss: 0.001121 best_pearson: 0.7243
Batch[3959] - loss: 0.001369 best_pearson: 0.7243
Batch[3960] - loss: 0.000676 best_pearson: 0.7243
Batch[3961] - loss: 0.000927 best_pearson: 0.7243
Batch[3962] - loss: 0.001617 best_pearson: 0.7243
Batch[3963] - loss: 0.001751 best_pearson: 0.7243
Batch[3964] - loss: 0.000834 best_pearson: 0.7243
Batch[3965] - loss: 0.002127 best_pearson: 0.7243
Batch[3966] - loss: 0.000968 best_pearson: 0.7243
Batch[3967] - loss: 0.001028 best_pearson: 0.7243
Batch[3968] - loss: 0.001095 best_pearson: 0.7243
Batch[3969] - loss: 0.001086 best_pearson: 0.7243
Batch[3970] - loss: 0.000916 best_pearson: 0.7243
Batch[3971] - loss: 0.001550 best_pearson: 0.7243
Batch[3972] - loss: 0.001529 best_pearson: 0.7243
Batch[3973] - loss: 0.001013 best_pearson: 0.7243
Batch[3974] - loss: 0.001517 best_pearson: 0.7243
Batch[3975] - loss: 0.001454 best_pearson: 0.7243
Batch[3976] - loss: 0.001918 best_pearson: 0.7243
Batch[3977] - loss: 0.001303 best_pearson: 0.7243
Batch[3978] - loss: 0.002079 best_pearson: 0.7243
Batch[3979] - loss: 0.000557 best_pearson: 0.7243
Batch[3980] - loss: 0.001066 best_pearson: 0.7243
Batch[3981] - loss: 0.001453 best_pearson: 0.7243
Batch[3982] - loss: 0.001199 best_pearson: 0.7243
Batch[3983] - loss: 0.001142 best_pearson: 0.7243
Batch[3984] - loss: 0.001901 best_pearson: 0.7243
Batch[3985] - loss: 0.000653 best_pearson: 0.7243
Batch[3986] - loss: 0.001709 best_pearson: 0.7243
Batch[3987] - loss: 0.001567 best_pearson: 0.7243
Batch[3988] - loss: 0.001201 best_pearson: 0.7243
Batch[3989] - loss: 0.001568 best_pearson: 0.7243
Batch[3990] - loss: 0.000619 best_pearson: 0.7243
Batch[3991] - loss: 0.001030 best_pearson: 0.7243
Batch[3992] - loss: 0.000974 best_pearson: 0.7243
Batch[3993] - loss: 0.001611 best_pearson: 0.7243
Batch[3994] - loss: 0.001790 best_pearson: 0.7243
Batch[3995] - loss: 0.001330 best_pearson: 0.7243
Batch[3996] - loss: 0.001651 best_pearson: 0.7243
Batch[3997] - loss: 0.001306 best_pearson: 0.7243
Batch[3998] - loss: 0.001008 best_pearson: 0.7243
Batch[3999] - loss: 0.001209 best_pearson: 0.7243
Batch[4000] - loss: 0.000995 best_pearson: 0.7243

Evaluation - loss: 0.000046 pearson: 0.7199 

Batch[4001] - loss: 0.001432 best_pearson: 0.7243
Batch[4002] - loss: 0.003267 best_pearson: 0.7243
Batch[4003] - loss: 0.001186 best_pearson: 0.7243
Batch[4004] - loss: 0.000718 best_pearson: 0.7243
Batch[4005] - loss: 0.000788 best_pearson: 0.7243
Batch[4006] - loss: 0.000651 best_pearson: 0.7243
Batch[4007] - loss: 0.001376 best_pearson: 0.7243
Batch[4008] - loss: 0.001714 best_pearson: 0.7243
Batch[4009] - loss: 0.001136 best_pearson: 0.7243
Batch[4010] - loss: 0.002211 best_pearson: 0.7243
Batch[4011] - loss: 0.001197 best_pearson: 0.7243
Batch[4012] - loss: 0.001073 best_pearson: 0.7243
Batch[4013] - loss: 0.001744 best_pearson: 0.7243
Batch[4014] - loss: 0.002680 best_pearson: 0.7243
Batch[4015] - loss: 0.001451 best_pearson: 0.7243
Batch[4016] - loss: 0.000812 best_pearson: 0.7243
Batch[4017] - loss: 0.000926 best_pearson: 0.7243
Batch[4018] - loss: 0.000749 best_pearson: 0.7243
Batch[4019] - loss: 0.000844 best_pearson: 0.7243
Batch[4020] - loss: 0.002175 best_pearson: 0.7243
Batch[4021] - loss: 0.001323 best_pearson: 0.7243
Batch[4022] - loss: 0.000768 best_pearson: 0.7243
Batch[4023] - loss: 0.001047 best_pearson: 0.7243
Batch[4024] - loss: 0.001480 best_pearson: 0.7243
Batch[4025] - loss: 0.001303 best_pearson: 0.7243
Batch[4026] - loss: 0.000886 best_pearson: 0.7243
Batch[4027] - loss: 0.000923 best_pearson: 0.7243
Batch[4028] - loss: 0.001243 best_pearson: 0.7243
Batch[4029] - loss: 0.001461 best_pearson: 0.7243
Batch[4030] - loss: 0.001235 best_pearson: 0.7243
Batch[4031] - loss: 0.001381 best_pearson: 0.7243
Batch[4032] - loss: 0.001369 best_pearson: 0.7243
Batch[4033] - loss: 0.001482 best_pearson: 0.7243
Batch[4034] - loss: 0.002088 best_pearson: 0.7243
Batch[4035] - loss: 0.000915 best_pearson: 0.7243
Batch[4036] - loss: 0.001724 best_pearson: 0.7243
Batch[4037] - loss: 0.001179 best_pearson: 0.7243
Batch[4038] - loss: 0.001055 best_pearson: 0.7243
Batch[4039] - loss: 0.001881 best_pearson: 0.7243
Batch[4040] - loss: 0.000794 best_pearson: 0.7243
Batch[4041] - loss: 0.001664 best_pearson: 0.7243
Batch[4042] - loss: 0.000870 best_pearson: 0.7243
Batch[4043] - loss: 0.001723 best_pearson: 0.7243
Batch[4044] - loss: 0.001576 best_pearson: 0.7243
Batch[4045] - loss: 0.001556 best_pearson: 0.7243
Batch[4046] - loss: 0.001252 best_pearson: 0.7243
Batch[4047] - loss: 0.001085 best_pearson: 0.7243
Batch[4048] - loss: 0.002180 best_pearson: 0.7243
Batch[4049] - loss: 0.001534 best_pearson: 0.7243
Batch[4050] - loss: 0.001307 best_pearson: 0.7243
Batch[4051] - loss: 0.000834 best_pearson: 0.7243
Batch[4052] - loss: 0.001149 best_pearson: 0.7243
Batch[4053] - loss: 0.001479 best_pearson: 0.7243
Batch[4054] - loss: 0.000933 best_pearson: 0.7243
Batch[4055] - loss: 0.000866 best_pearson: 0.7243
Batch[4056] - loss: 0.001187 best_pearson: 0.7243
Batch[4057] - loss: 0.001309 best_pearson: 0.7243
Batch[4058] - loss: 0.001402 best_pearson: 0.7243
Batch[4059] - loss: 0.000745 best_pearson: 0.7243
Batch[4060] - loss: 0.001135 best_pearson: 0.7243
Batch[4061] - loss: 0.001017 best_pearson: 0.7243
Batch[4062] - loss: 0.001265 best_pearson: 0.7243
Batch[4063] - loss: 0.001364 best_pearson: 0.7243
Batch[4064] - loss: 0.000855 best_pearson: 0.7243
Batch[4065] - loss: 0.001389 best_pearson: 0.7243
Batch[4066] - loss: 0.001882 best_pearson: 0.7243
Batch[4067] - loss: 0.001144 best_pearson: 0.7243
Batch[4068] - loss: 0.003270 best_pearson: 0.7243
Batch[4069] - loss: 0.001618 best_pearson: 0.7243
Batch[4070] - loss: 0.001561 best_pearson: 0.7243
Batch[4071] - loss: 0.000868 best_pearson: 0.7243
Batch[4072] - loss: 0.001003 best_pearson: 0.7243
Batch[4073] - loss: 0.001372 best_pearson: 0.7243
Batch[4074] - loss: 0.001210 best_pearson: 0.7243
Batch[4075] - loss: 0.000893 best_pearson: 0.7243
Batch[4076] - loss: 0.000906 best_pearson: 0.7243
Batch[4077] - loss: 0.001042 best_pearson: 0.7243
Batch[4078] - loss: 0.001404 best_pearson: 0.7243
Batch[4079] - loss: 0.001130 best_pearson: 0.7243
Batch[4080] - loss: 0.000732 best_pearson: 0.7243
Batch[4081] - loss: 0.000924 best_pearson: 0.7243
Batch[4082] - loss: 0.001089 best_pearson: 0.7243
Batch[4083] - loss: 0.000790 best_pearson: 0.7243
Batch[4084] - loss: 0.000751 best_pearson: 0.7243
Batch[4085] - loss: 0.001463 best_pearson: 0.7243
Batch[4086] - loss: 0.000742 best_pearson: 0.7243
Batch[4087] - loss: 0.000945 best_pearson: 0.7243
Batch[4088] - loss: 0.001264 best_pearson: 0.7243
Batch[4089] - loss: 0.001493 best_pearson: 0.7243
Batch[4090] - loss: 0.001453 best_pearson: 0.7243
Batch[4091] - loss: 0.001176 best_pearson: 0.7243
Batch[4092] - loss: 0.000917 best_pearson: 0.7243
Batch[4093] - loss: 0.001078 best_pearson: 0.7243
Batch[4094] - loss: 0.001712 best_pearson: 0.7243
Batch[4095] - loss: 0.001661 best_pearson: 0.7243
Batch[4096] - loss: 0.000991 best_pearson: 0.7243
Batch[4097] - loss: 0.000895 best_pearson: 0.7243
Batch[4098] - loss: 0.001823 best_pearson: 0.7243
Batch[4099] - loss: 0.001185 best_pearson: 0.7243
Batch[4100] - loss: 0.001056 best_pearson: 0.7243

Evaluation - loss: 0.000046 pearson: 0.7208 

Batch[4101] - loss: 0.002066 best_pearson: 0.7243
Batch[4102] - loss: 0.000860 best_pearson: 0.7243
Batch[4103] - loss: 0.001363 best_pearson: 0.7243
Batch[4104] - loss: 0.001234 best_pearson: 0.7243
Batch[4105] - loss: 0.002096 best_pearson: 0.7243
Batch[4106] - loss: 0.001103 best_pearson: 0.7243
Batch[4107] - loss: 0.001332 best_pearson: 0.7243
Batch[4108] - loss: 0.000858 best_pearson: 0.7243
Batch[4109] - loss: 0.001499 best_pearson: 0.7243
Batch[4110] - loss: 0.002320 best_pearson: 0.7243
Batch[4111] - loss: 0.000929 best_pearson: 0.7243
Batch[4112] - loss: 0.001424 best_pearson: 0.7243
Batch[4113] - loss: 0.001282 best_pearson: 0.7243
Batch[4114] - loss: 0.000842 best_pearson: 0.7243
Batch[4115] - loss: 0.000882 best_pearson: 0.7243
Batch[4116] - loss: 0.001240 best_pearson: 0.7243
Batch[4117] - loss: 0.000934 best_pearson: 0.7243
Batch[4118] - loss: 0.001107 best_pearson: 0.7243
Batch[4119] - loss: 0.001738 best_pearson: 0.7243
Batch[4120] - loss: 0.001243 best_pearson: 0.7243
Batch[4121] - loss: 0.001071 best_pearson: 0.7243
Batch[4122] - loss: 0.001530 best_pearson: 0.7243
Batch[4123] - loss: 0.001615 best_pearson: 0.7243
Batch[4124] - loss: 0.001458 best_pearson: 0.7243
Batch[4125] - loss: 0.000767 best_pearson: 0.7243
Batch[4126] - loss: 0.000735 best_pearson: 0.7243
Batch[4127] - loss: 0.001067 best_pearson: 0.7243
Batch[4128] - loss: 0.001027 best_pearson: 0.7243
Batch[4129] - loss: 0.002423 best_pearson: 0.7243
Batch[4130] - loss: 0.001077 best_pearson: 0.7243
Batch[4131] - loss: 0.001477 best_pearson: 0.7243
Batch[4132] - loss: 0.001019 best_pearson: 0.7243
Batch[4133] - loss: 0.001995 best_pearson: 0.7243
Batch[4134] - loss: 0.000887 best_pearson: 0.7243
Batch[4135] - loss: 0.000920 best_pearson: 0.7243
Batch[4136] - loss: 0.001853 best_pearson: 0.7243
Batch[4137] - loss: 0.001122 best_pearson: 0.7243
Batch[4138] - loss: 0.001078 best_pearson: 0.7243
Batch[4139] - loss: 0.001210 best_pearson: 0.7243
Batch[4140] - loss: 0.001928 best_pearson: 0.7243
Batch[4141] - loss: 0.001354 best_pearson: 0.7243
Batch[4142] - loss: 0.001419 best_pearson: 0.7243
Batch[4143] - loss: 0.001302 best_pearson: 0.7243
Batch[4144] - loss: 0.000847 best_pearson: 0.7243
Batch[4145] - loss: 0.001108 best_pearson: 0.7243
Batch[4146] - loss: 0.001425 best_pearson: 0.7243
Batch[4147] - loss: 0.000834 best_pearson: 0.7243
Batch[4148] - loss: 0.001430 best_pearson: 0.7243
Batch[4149] - loss: 0.001407 best_pearson: 0.7243
Batch[4150] - loss: 0.001893 best_pearson: 0.7243
Batch[4151] - loss: 0.001031 best_pearson: 0.7243
Batch[4152] - loss: 0.000972 best_pearson: 0.7243
Batch[4153] - loss: 0.001582 best_pearson: 0.7243
Batch[4154] - loss: 0.001494 best_pearson: 0.7243
Batch[4155] - loss: 0.000714 best_pearson: 0.7243
Batch[4156] - loss: 0.000834 best_pearson: 0.7243
Batch[4157] - loss: 0.000779 best_pearson: 0.7243
Batch[4158] - loss: 0.001038 best_pearson: 0.7243
Batch[4159] - loss: 0.001303 best_pearson: 0.7243
Batch[4160] - loss: 0.000950 best_pearson: 0.7243
Batch[4161] - loss: 0.001187 best_pearson: 0.7243
Batch[4162] - loss: 0.001362 best_pearson: 0.7243
Batch[4163] - loss: 0.001069 best_pearson: 0.7243
Batch[4164] - loss: 0.001030 best_pearson: 0.7243
Batch[4165] - loss: 0.001627 best_pearson: 0.7243
Batch[4166] - loss: 0.001207 best_pearson: 0.7243
Batch[4167] - loss: 0.001819 best_pearson: 0.7243
Batch[4168] - loss: 0.001245 best_pearson: 0.7243
Batch[4169] - loss: 0.001134 best_pearson: 0.7243
Batch[4170] - loss: 0.001502 best_pearson: 0.7243
Batch[4171] - loss: 0.002400 best_pearson: 0.7243
Batch[4172] - loss: 0.001335 best_pearson: 0.7243
Batch[4173] - loss: 0.001928 best_pearson: 0.7243
Batch[4174] - loss: 0.001347 best_pearson: 0.7243
Batch[4175] - loss: 0.000660 best_pearson: 0.7243
Batch[4176] - loss: 0.001643 best_pearson: 0.7243
Batch[4177] - loss: 0.001590 best_pearson: 0.7243
Batch[4178] - loss: 0.001143 best_pearson: 0.7243
Batch[4179] - loss: 0.000638 best_pearson: 0.7243
Batch[4180] - loss: 0.001317 best_pearson: 0.7243
Batch[4181] - loss: 0.001586 best_pearson: 0.7243
Batch[4182] - loss: 0.001279 best_pearson: 0.7243
Batch[4183] - loss: 0.000798 best_pearson: 0.7243
Batch[4184] - loss: 0.000980 best_pearson: 0.7243
Batch[4185] - loss: 0.001485 best_pearson: 0.7243
Batch[4186] - loss: 0.001169 best_pearson: 0.7243
Batch[4187] - loss: 0.002402 best_pearson: 0.7243
Batch[4188] - loss: 0.001051 best_pearson: 0.7243
Batch[4189] - loss: 0.001096 best_pearson: 0.7243
Batch[4190] - loss: 0.002180 best_pearson: 0.7243
Batch[4191] - loss: 0.001185 best_pearson: 0.7243
Batch[4192] - loss: 0.001156 best_pearson: 0.7243
Batch[4193] - loss: 0.001163 best_pearson: 0.7243
Batch[4194] - loss: 0.001118 best_pearson: 0.7243
Batch[4195] - loss: 0.001285 best_pearson: 0.7243
Batch[4196] - loss: 0.001037 best_pearson: 0.7243
Batch[4197] - loss: 0.002105 best_pearson: 0.7243
Batch[4198] - loss: 0.000735 best_pearson: 0.7243
Batch[4199] - loss: 0.001126 best_pearson: 0.7243
Batch[4200] - loss: 0.001388 best_pearson: 0.7243

Evaluation - loss: 0.000046 pearson: 0.7206 

Batch[4201] - loss: 0.000886 best_pearson: 0.7243
Batch[4202] - loss: 0.000816 best_pearson: 0.7243
Batch[4203] - loss: 0.001020 best_pearson: 0.7243
Batch[4204] - loss: 0.001200 best_pearson: 0.7243
Batch[4205] - loss: 0.000599 best_pearson: 0.7243
Batch[4206] - loss: 0.001010 best_pearson: 0.7243
Batch[4207] - loss: 0.001119 best_pearson: 0.7243
Batch[4208] - loss: 0.001557 best_pearson: 0.7243
Batch[4209] - loss: 0.001089 best_pearson: 0.7243
Batch[4210] - loss: 0.000971 best_pearson: 0.7243
Batch[4211] - loss: 0.001181 best_pearson: 0.7243
Batch[4212] - loss: 0.001888 best_pearson: 0.7243
Batch[4213] - loss: 0.001121 best_pearson: 0.7243
Batch[4214] - loss: 0.001678 best_pearson: 0.7243
Batch[4215] - loss: 0.000602 best_pearson: 0.7243
Batch[4216] - loss: 0.000415 best_pearson: 0.7243
Batch[4217] - loss: 0.001693 best_pearson: 0.7243
Batch[4218] - loss: 0.001099 best_pearson: 0.7243
Batch[4219] - loss: 0.001381 best_pearson: 0.7243
Batch[4220] - loss: 0.000823 best_pearson: 0.7243
Batch[4221] - loss: 0.000941 best_pearson: 0.7243
Batch[4222] - loss: 0.001111 best_pearson: 0.7243
Batch[4223] - loss: 0.000757 best_pearson: 0.7243
Batch[4224] - loss: 0.001498 best_pearson: 0.7243
Batch[4225] - loss: 0.001320 best_pearson: 0.7243
Batch[4226] - loss: 0.001225 best_pearson: 0.7243
Batch[4227] - loss: 0.000924 best_pearson: 0.7243
Batch[4228] - loss: 0.000796 best_pearson: 0.7243
Batch[4229] - loss: 0.001397 best_pearson: 0.7243
Batch[4230] - loss: 0.000666 best_pearson: 0.7243
Batch[4231] - loss: 0.001704 best_pearson: 0.7243
Batch[4232] - loss: 0.001690 best_pearson: 0.7243
Batch[4233] - loss: 0.000974 best_pearson: 0.7243
Batch[4234] - loss: 0.000467 best_pearson: 0.7243
Batch[4235] - loss: 0.000983 best_pearson: 0.7243
Batch[4236] - loss: 0.001378 best_pearson: 0.7243
Batch[4237] - loss: 0.001291 best_pearson: 0.7243
Batch[4238] - loss: 0.001447 best_pearson: 0.7243
Batch[4239] - loss: 0.001618 best_pearson: 0.7243
Batch[4240] - loss: 0.000978 best_pearson: 0.7243
Batch[4241] - loss: 0.000559 best_pearson: 0.7243
Batch[4242] - loss: 0.001152 best_pearson: 0.7243
Batch[4243] - loss: 0.000668 best_pearson: 0.7243
Batch[4244] - loss: 0.001107 best_pearson: 0.7243
Batch[4245] - loss: 0.002147 best_pearson: 0.7243
Batch[4246] - loss: 0.001428 best_pearson: 0.7243
Batch[4247] - loss: 0.001955 best_pearson: 0.7243
Batch[4248] - loss: 0.001004 best_pearson: 0.7243
Batch[4249] - loss: 0.001932 best_pearson: 0.7243
Batch[4250] - loss: 0.001980 best_pearson: 0.7243
Batch[4251] - loss: 0.001249 best_pearson: 0.7243
Batch[4252] - loss: 0.002780 best_pearson: 0.7243
Batch[4253] - loss: 0.001071 best_pearson: 0.7243
Batch[4254] - loss: 0.001182 best_pearson: 0.7243
Batch[4255] - loss: 0.002431 best_pearson: 0.7243
Batch[4256] - loss: 0.002247 best_pearson: 0.7243
Batch[4257] - loss: 0.001114 best_pearson: 0.7243
Batch[4258] - loss: 0.000743 best_pearson: 0.7243
Batch[4259] - loss: 0.000673 best_pearson: 0.7243
Batch[4260] - loss: 0.002460 best_pearson: 0.7243
Batch[4261] - loss: 0.001588 best_pearson: 0.7243
Batch[4262] - loss: 0.000999 best_pearson: 0.7243
Batch[4263] - loss: 0.001736 best_pearson: 0.7243
Batch[4264] - loss: 0.001336 best_pearson: 0.7243
Batch[4265] - loss: 0.000723 best_pearson: 0.7243
Batch[4266] - loss: 0.001191 best_pearson: 0.7243
Batch[4267] - loss: 0.000893 best_pearson: 0.7243
Batch[4268] - loss: 0.001544 best_pearson: 0.7243
Batch[4269] - loss: 0.002460 best_pearson: 0.7243
Batch[4270] - loss: 0.000937 best_pearson: 0.7243
Batch[4271] - loss: 0.001743 best_pearson: 0.7243
Batch[4272] - loss: 0.001669 best_pearson: 0.7243
Batch[4273] - loss: 0.001793 best_pearson: 0.7243
Batch[4274] - loss: 0.000763 best_pearson: 0.7243
Batch[4275] - loss: 0.001122 best_pearson: 0.7243
Batch[4276] - loss: 0.001300 best_pearson: 0.7243
Batch[4277] - loss: 0.000955 best_pearson: 0.7243
Batch[4278] - loss: 0.001173 best_pearson: 0.7243
Batch[4279] - loss: 0.000815 best_pearson: 0.7243
Batch[4280] - loss: 0.000938 best_pearson: 0.7243
Batch[4281] - loss: 0.001189 best_pearson: 0.7243
Batch[4282] - loss: 0.002013 best_pearson: 0.7243
Batch[4283] - loss: 0.001263 best_pearson: 0.7243
Batch[4284] - loss: 0.001124 best_pearson: 0.7243
Batch[4285] - loss: 0.001502 best_pearson: 0.7243
Batch[4286] - loss: 0.001533 best_pearson: 0.7243
Batch[4287] - loss: 0.001132 best_pearson: 0.7243
Batch[4288] - loss: 0.000819 best_pearson: 0.7243
Batch[4289] - loss: 0.001579 best_pearson: 0.7243
Batch[4290] - loss: 0.000646 best_pearson: 0.7243
Batch[4291] - loss: 0.001702 best_pearson: 0.7243
Batch[4292] - loss: 0.001441 best_pearson: 0.7243
Batch[4293] - loss: 0.001297 best_pearson: 0.7243
Batch[4294] - loss: 0.001355 best_pearson: 0.7243
Batch[4295] - loss: 0.000762 best_pearson: 0.7243
Batch[4296] - loss: 0.002233 best_pearson: 0.7243
Batch[4297] - loss: 0.002175 best_pearson: 0.7243
Batch[4298] - loss: 0.002176 best_pearson: 0.7243
Batch[4299] - loss: 0.000960 best_pearson: 0.7243
Batch[4300] - loss: 0.001255 best_pearson: 0.7243

Evaluation - loss: 0.000046 pearson: 0.7223 

Batch[4301] - loss: 0.001082 best_pearson: 0.7243
Batch[4302] - loss: 0.000851 best_pearson: 0.7243
Batch[4303] - loss: 0.002064 best_pearson: 0.7243
Batch[4304] - loss: 0.000863 best_pearson: 0.7243
Batch[4305] - loss: 0.000977 best_pearson: 0.7243
Batch[4306] - loss: 0.000608 best_pearson: 0.7243
Batch[4307] - loss: 0.001051 best_pearson: 0.7243
Batch[4308] - loss: 0.001386 best_pearson: 0.7243
Batch[4309] - loss: 0.001712 best_pearson: 0.7243
Batch[4310] - loss: 0.001065 best_pearson: 0.7243
Batch[4311] - loss: 0.000866 best_pearson: 0.7243
Batch[4312] - loss: 0.001048 best_pearson: 0.7243
Batch[4313] - loss: 0.001018 best_pearson: 0.7243
Batch[4314] - loss: 0.001212 best_pearson: 0.7243
Batch[4315] - loss: 0.002584 best_pearson: 0.7243
Batch[4316] - loss: 0.001463 best_pearson: 0.7243
Batch[4317] - loss: 0.000962 best_pearson: 0.7243
Batch[4318] - loss: 0.002215 best_pearson: 0.7243
Batch[4319] - loss: 0.001359 best_pearson: 0.7243
Batch[4320] - loss: 0.001071 best_pearson: 0.7243
Batch[4321] - loss: 0.000970 best_pearson: 0.7243
Batch[4322] - loss: 0.001754 best_pearson: 0.7243
Batch[4323] - loss: 0.001267 best_pearson: 0.7243
Batch[4324] - loss: 0.001389 best_pearson: 0.7243
Batch[4325] - loss: 0.001301 best_pearson: 0.7243
Batch[4326] - loss: 0.001080 best_pearson: 0.7243
Batch[4327] - loss: 0.001612 best_pearson: 0.7243
Batch[4328] - loss: 0.001267 best_pearson: 0.7243
Batch[4329] - loss: 0.001201 best_pearson: 0.7243
Batch[4330] - loss: 0.000836 best_pearson: 0.7243
Batch[4331] - loss: 0.001636 best_pearson: 0.7243
Batch[4332] - loss: 0.003350 best_pearson: 0.7243
Batch[4333] - loss: 0.001107 best_pearson: 0.7243
Batch[4334] - loss: 0.001708 best_pearson: 0.7243
Batch[4335] - loss: 0.001770 best_pearson: 0.7243
Batch[4336] - loss: 0.001950 best_pearson: 0.7243
Batch[4337] - loss: 0.000958 best_pearson: 0.7243
Batch[4338] - loss: 0.002525 best_pearson: 0.7243
Batch[4339] - loss: 0.001239 best_pearson: 0.7243
Batch[4340] - loss: 0.001155 best_pearson: 0.7243
Batch[4341] - loss: 0.001351 best_pearson: 0.7243
Batch[4342] - loss: 0.001027 best_pearson: 0.7243
Batch[4343] - loss: 0.001115 best_pearson: 0.7243
Batch[4344] - loss: 0.001513 best_pearson: 0.7243
Batch[4345] - loss: 0.001133 best_pearson: 0.7243
Batch[4346] - loss: 0.001189 best_pearson: 0.7243
Batch[4347] - loss: 0.000841 best_pearson: 0.7243
Batch[4348] - loss: 0.001912 best_pearson: 0.7243
Batch[4349] - loss: 0.001243 best_pearson: 0.7243
Batch[4350] - loss: 0.000835 best_pearson: 0.7243
Batch[4351] - loss: 0.001266 best_pearson: 0.7243
Batch[4352] - loss: 0.001433 best_pearson: 0.7243
Batch[4353] - loss: 0.001320 best_pearson: 0.7243
Batch[4354] - loss: 0.000845 best_pearson: 0.7243
Batch[4355] - loss: 0.000748 best_pearson: 0.7243
Batch[4356] - loss: 0.001674 best_pearson: 0.7243
Batch[4357] - loss: 0.000807 best_pearson: 0.7243
Batch[4358] - loss: 0.001061 best_pearson: 0.7243
Batch[4359] - loss: 0.001173 best_pearson: 0.7243
Batch[4360] - loss: 0.001260 best_pearson: 0.7243
Batch[4361] - loss: 0.000897 best_pearson: 0.7243
Batch[4362] - loss: 0.001281 best_pearson: 0.7243
Batch[4363] - loss: 0.001531 best_pearson: 0.7243
Batch[4364] - loss: 0.001045 best_pearson: 0.7243
Batch[4365] - loss: 0.002010 best_pearson: 0.7243
Batch[4366] - loss: 0.001044 best_pearson: 0.7243
Batch[4367] - loss: 0.001856 best_pearson: 0.7243
Batch[4368] - loss: 0.001047 best_pearson: 0.7243
Batch[4369] - loss: 0.000952 best_pearson: 0.7243
Batch[4370] - loss: 0.000897 best_pearson: 0.7243
Batch[4371] - loss: 0.001620 best_pearson: 0.7243
Batch[4372] - loss: 0.001674 best_pearson: 0.7243
Batch[4373] - loss: 0.000797 best_pearson: 0.7243
Batch[4374] - loss: 0.001302 best_pearson: 0.7243
Batch[4375] - loss: 0.001744 best_pearson: 0.7243
Batch[4376] - loss: 0.001122 best_pearson: 0.7243
Batch[4377] - loss: 0.000563 best_pearson: 0.7243
Batch[4378] - loss: 0.001837 best_pearson: 0.7243
Batch[4379] - loss: 0.001255 best_pearson: 0.7243
Batch[4380] - loss: 0.001192 best_pearson: 0.7243
Batch[4381] - loss: 0.000798 best_pearson: 0.7243
Batch[4382] - loss: 0.000856 best_pearson: 0.7243
Batch[4383] - loss: 0.001654 best_pearson: 0.7243
Batch[4384] - loss: 0.002086 best_pearson: 0.7243
Batch[4385] - loss: 0.001933 best_pearson: 0.7243
Batch[4386] - loss: 0.001307 best_pearson: 0.7243
Batch[4387] - loss: 0.001402 best_pearson: 0.7243
Batch[4388] - loss: 0.000824 best_pearson: 0.7243
Batch[4389] - loss: 0.001085 best_pearson: 0.7243
Batch[4390] - loss: 0.000897 best_pearson: 0.7243
Batch[4391] - loss: 0.000989 best_pearson: 0.7243
Batch[4392] - loss: 0.001467 best_pearson: 0.7243
Batch[4393] - loss: 0.000759 best_pearson: 0.7243
Batch[4394] - loss: 0.000899 best_pearson: 0.7243
Batch[4395] - loss: 0.000589 best_pearson: 0.7243
Batch[4396] - loss: 0.001181 best_pearson: 0.7243
Batch[4397] - loss: 0.000847 best_pearson: 0.7243
Batch[4398] - loss: 0.001548 best_pearson: 0.7243
Batch[4399] - loss: 0.001722 best_pearson: 0.7243
Batch[4400] - loss: 0.000672 best_pearson: 0.7243

Evaluation - loss: 0.000045 pearson: 0.7236 

early stop by 1500 steps.
Batch[4401] - loss: 0.000824 best_pearson: 0.7243
Batch[4402] - loss: 0.001144 best_pearson: 0.7243
Batch[4403] - loss: 0.001584 best_pearson: 0.7243
Batch[4404] - loss: 0.001571 best_pearson: 0.7243
Batch[4405] - loss: 0.001661 best_pearson: 0.7243
Batch[4406] - loss: 0.001829 best_pearson: 0.7243
Batch[4407] - loss: 0.001099 best_pearson: 0.7243
Batch[4408] - loss: 0.000882 best_pearson: 0.7243
Batch[4409] - loss: 0.001504 best_pearson: 0.7243
Batch[4410] - loss: 0.001062 best_pearson: 0.7243
Batch[4411] - loss: 0.001093 best_pearson: 0.7243
Batch[4412] - loss: 0.000819 best_pearson: 0.7243
Batch[4413] - loss: 0.002426 best_pearson: 0.7243
Batch[4414] - loss: 0.001286 best_pearson: 0.7243
Batch[4415] - loss: 0.000927 best_pearson: 0.7243
Batch[4416] - loss: 0.002470 best_pearson: 0.7243
Batch[4417] - loss: 0.001417 best_pearson: 0.7243
Batch[4418] - loss: 0.000981 best_pearson: 0.7243
Batch[4419] - loss: 0.001178 best_pearson: 0.7243
Batch[4420] - loss: 0.000740 best_pearson: 0.7243
Batch[4421] - loss: 0.001151 best_pearson: 0.7243
Batch[4422] - loss: 0.000932 best_pearson: 0.7243
Batch[4423] - loss: 0.000847 best_pearson: 0.7243
Batch[4424] - loss: 0.000761 best_pearson: 0.7243
Batch[4425] - loss: 0.001187 best_pearson: 0.7243
Batch[4426] - loss: 0.001351 best_pearson: 0.7243
Batch[4427] - loss: 0.001211 best_pearson: 0.7243
Batch[4428] - loss: 0.000977 best_pearson: 0.7243
Batch[4429] - loss: 0.000554 best_pearson: 0.7243
Batch[4430] - loss: 0.000505 best_pearson: 0.7243
Batch[4431] - loss: 0.001515 best_pearson: 0.7243
Batch[4432] - loss: 0.000677 best_pearson: 0.7243
Batch[4433] - loss: 0.001655 best_pearson: 0.7243
Batch[4434] - loss: 0.001230 best_pearson: 0.7243
Batch[4435] - loss: 0.000588 best_pearson: 0.7243
Batch[4436] - loss: 0.001250 best_pearson: 0.7243
Batch[4437] - loss: 0.001705 best_pearson: 0.7243
Batch[4438] - loss: 0.002080 best_pearson: 0.7243
Batch[4439] - loss: 0.000968 best_pearson: 0.7243
Batch[4440] - loss: 0.000991 best_pearson: 0.7243
Batch[4441] - loss: 0.002019 best_pearson: 0.7243
Batch[4442] - loss: 0.000831 best_pearson: 0.7243
Batch[4443] - loss: 0.002453 best_pearson: 0.7243
Batch[4444] - loss: 0.001496 best_pearson: 0.7243
Batch[4445] - loss: 0.001200 best_pearson: 0.7243
Batch[4446] - loss: 0.001364 best_pearson: 0.7243
Batch[4447] - loss: 0.000909 best_pearson: 0.7243
Batch[4448] - loss: 0.001233 best_pearson: 0.7243
Batch[4449] - loss: 0.001331 best_pearson: 0.7243
Batch[4450] - loss: 0.001663 best_pearson: 0.7243
Batch[4451] - loss: 0.000992 best_pearson: 0.7243
Batch[4452] - loss: 0.001399 best_pearson: 0.7243
Batch[4453] - loss: 0.002292 best_pearson: 0.7243
Batch[4454] - loss: 0.001222 best_pearson: 0.7243
Batch[4455] - loss: 0.000979 best_pearson: 0.7243
Batch[4456] - loss: 0.001615 best_pearson: 0.7243
Batch[4457] - loss: 0.001097 best_pearson: 0.7243
Batch[4458] - loss: 0.002354 best_pearson: 0.7243
Batch[4459] - loss: 0.001412 best_pearson: 0.7243
Batch[4460] - loss: 0.001027 best_pearson: 0.7243
Batch[4461] - loss: 0.001124 best_pearson: 0.7243
Batch[4462] - loss: 0.002292 best_pearson: 0.7243
Batch[4463] - loss: 0.001083 best_pearson: 0.7243
Batch[4464] - loss: 0.001182 best_pearson: 0.7243
Batch[4465] - loss: 0.001587 best_pearson: 0.7243
Batch[4466] - loss: 0.001336 best_pearson: 0.7243
Batch[4467] - loss: 0.001933 best_pearson: 0.7243
Batch[4468] - loss: 0.001577 best_pearson: 0.7243
Batch[4469] - loss: 0.001564 best_pearson: 0.7243
Batch[4470] - loss: 0.002089 best_pearson: 0.7243
Batch[4471] - loss: 0.001064 best_pearson: 0.7243
Batch[4472] - loss: 0.001631 best_pearson: 0.7243
Batch[4473] - loss: 0.001076 best_pearson: 0.7243
Batch[4474] - loss: 0.001160 best_pearson: 0.7243
Batch[4475] - loss: 0.001550 best_pearson: 0.7243
Batch[4476] - loss: 0.000848 best_pearson: 0.7243
Batch[4477] - loss: 0.001622 best_pearson: 0.7243
Batch[4478] - loss: 0.001797 best_pearson: 0.7243
Batch[4479] - loss: 0.000886 best_pearson: 0.7243
Batch[4480] - loss: 0.001046 best_pearson: 0.7243
Batch[4481] - loss: 0.001698 best_pearson: 0.7243
Batch[4482] - loss: 0.000907 best_pearson: 0.7243
Batch[4483] - loss: 0.001419 best_pearson: 0.7243
Batch[4484] - loss: 0.001564 best_pearson: 0.7243
Batch[4485] - loss: 0.002055 best_pearson: 0.7243
Batch[4486] - loss: 0.000614 best_pearson: 0.7243
Batch[4487] - loss: 0.001451 best_pearson: 0.7243
Batch[4488] - loss: 0.000768 best_pearson: 0.7243
Batch[4489] - loss: 0.001537 best_pearson: 0.7243
Batch[4490] - loss: 0.000799 best_pearson: 0.7243
Batch[4491] - loss: 0.001127 best_pearson: 0.7243
Batch[4492] - loss: 0.001142 best_pearson: 0.7243
Batch[4493] - loss: 0.001251 best_pearson: 0.7243
Batch[4494] - loss: 0.001160 best_pearson: 0.7243
Batch[4495] - loss: 0.001392 best_pearson: 0.7243
Batch[4496] - loss: 0.001652 best_pearson: 0.7243
Batch[4497] - loss: 0.001258 best_pearson: 0.7243
Batch[4498] - loss: 0.001262 best_pearson: 0.7243
Batch[4499] - loss: 0.001077 best_pearson: 0.7243
Batch[4500] - loss: 0.001017 best_pearson: 0.7243

Evaluation - loss: 0.000045 pearson: 0.7240 

early stop by 1500 steps.
Batch[4501] - loss: 0.001487 best_pearson: 0.7243
Batch[4502] - loss: 0.001400 best_pearson: 0.7243
Batch[4503] - loss: 0.001184 best_pearson: 0.7243
Batch[4504] - loss: 0.000915 best_pearson: 0.7243
Batch[4505] - loss: 0.000616 best_pearson: 0.7243
Batch[4506] - loss: 0.001069 best_pearson: 0.7243
Batch[4507] - loss: 0.000861 best_pearson: 0.7243
Batch[4508] - loss: 0.001034 best_pearson: 0.7243
Batch[4509] - loss: 0.001133 best_pearson: 0.7243
Batch[4510] - loss: 0.001106 best_pearson: 0.7243
Batch[4511] - loss: 0.002379 best_pearson: 0.7243
Batch[4512] - loss: 0.001884 best_pearson: 0.7243
Batch[4513] - loss: 0.000779 best_pearson: 0.7243
Batch[4514] - loss: 0.001600 best_pearson: 0.7243
Batch[4515] - loss: 0.001950 best_pearson: 0.7243
Batch[4516] - loss: 0.000898 best_pearson: 0.7243
Batch[4517] - loss: 0.001198 best_pearson: 0.7243
Batch[4518] - loss: 0.001643 best_pearson: 0.7243
Batch[4519] - loss: 0.001664 best_pearson: 0.7243
Batch[4520] - loss: 0.001472 best_pearson: 0.7243
Batch[4521] - loss: 0.001238 best_pearson: 0.7243
Batch[4522] - loss: 0.002180 best_pearson: 0.7243
Batch[4523] - loss: 0.000700 best_pearson: 0.7243
Batch[4524] - loss: 0.000937 best_pearson: 0.7243
Batch[4525] - loss: 0.001220 best_pearson: 0.7243
Batch[4526] - loss: 0.001471 best_pearson: 0.7243
Batch[4527] - loss: 0.001480 best_pearson: 0.7243
Batch[4528] - loss: 0.002262 best_pearson: 0.7243
Batch[4529] - loss: 0.000872 best_pearson: 0.7243
Batch[4530] - loss: 0.002602 best_pearson: 0.7243
Batch[4531] - loss: 0.001631 best_pearson: 0.7243
Batch[4532] - loss: 0.001203 best_pearson: 0.7243
Batch[4533] - loss: 0.001774 best_pearson: 0.7243
Batch[4534] - loss: 0.000914 best_pearson: 0.7243
Batch[4535] - loss: 0.001375 best_pearson: 0.7243
Batch[4536] - loss: 0.001141 best_pearson: 0.7243
Batch[4537] - loss: 0.001227 best_pearson: 0.7243
Batch[4538] - loss: 0.000744 best_pearson: 0.7243
Batch[4539] - loss: 0.002425 best_pearson: 0.7243
Batch[4540] - loss: 0.000996 best_pearson: 0.7243
Batch[4541] - loss: 0.002182 best_pearson: 0.7243
Batch[4542] - loss: 0.000953 best_pearson: 0.7243
Batch[4543] - loss: 0.001522 best_pearson: 0.7243
Batch[4544] - loss: 0.000954 best_pearson: 0.7243
Batch[4545] - loss: 0.001264 best_pearson: 0.7243
Batch[4546] - loss: 0.001309 best_pearson: 0.7243
Batch[4547] - loss: 0.000804 best_pearson: 0.7243
Batch[4548] - loss: 0.001935 best_pearson: 0.7243
Batch[4549] - loss: 0.000919 best_pearson: 0.7243
Batch[4550] - loss: 0.000948 best_pearson: 0.7243
Batch[4551] - loss: 0.000866 best_pearson: 0.7243
Batch[4552] - loss: 0.001055 best_pearson: 0.7243
Batch[4553] - loss: 0.001318 best_pearson: 0.7243
Batch[4554] - loss: 0.001535 best_pearson: 0.7243
Batch[4555] - loss: 0.000682 best_pearson: 0.7243
Batch[4556] - loss: 0.001087 best_pearson: 0.7243
Batch[4557] - loss: 0.001060 best_pearson: 0.7243
Batch[4558] - loss: 0.000820 best_pearson: 0.7243
Batch[4559] - loss: 0.001168 best_pearson: 0.7243
Batch[4560] - loss: 0.000905 best_pearson: 0.7243
Batch[4561] - loss: 0.001862 best_pearson: 0.7243
Batch[4562] - loss: 0.000951 best_pearson: 0.7243
Batch[4563] - loss: 0.001520 best_pearson: 0.7243
Batch[4564] - loss: 0.000893 best_pearson: 0.7243
Batch[4565] - loss: 0.000792 best_pearson: 0.7243
Batch[4566] - loss: 0.000814 best_pearson: 0.7243
Batch[4567] - loss: 0.001330 best_pearson: 0.7243
Batch[4568] - loss: 0.001216 best_pearson: 0.7243
Batch[4569] - loss: 0.000992 best_pearson: 0.7243
Batch[4570] - loss: 0.000982 best_pearson: 0.7243
Batch[4571] - loss: 0.001733 best_pearson: 0.7243
Batch[4572] - loss: 0.002090 best_pearson: 0.7243
Batch[4573] - loss: 0.001143 best_pearson: 0.7243
Batch[4574] - loss: 0.000696 best_pearson: 0.7243
Batch[4575] - loss: 0.001252 best_pearson: 0.7243
Batch[4576] - loss: 0.001511 best_pearson: 0.7243
Batch[4577] - loss: 0.002002 best_pearson: 0.7243
Batch[4578] - loss: 0.001501 best_pearson: 0.7243
Batch[4579] - loss: 0.001376 best_pearson: 0.7243
Batch[4580] - loss: 0.000599 best_pearson: 0.7243
Batch[4581] - loss: 0.000889 best_pearson: 0.7243
Batch[4582] - loss: 0.000662 best_pearson: 0.7243
Batch[4583] - loss: 0.001041 best_pearson: 0.7243
Batch[4584] - loss: 0.000865 best_pearson: 0.7243
Batch[4585] - loss: 0.001492 best_pearson: 0.7243
Batch[4586] - loss: 0.000867 best_pearson: 0.7243
Batch[4587] - loss: 0.000686 best_pearson: 0.7243
Batch[4588] - loss: 0.000769 best_pearson: 0.7243
Batch[4589] - loss: 0.001370 best_pearson: 0.7243
Batch[4590] - loss: 0.001748 best_pearson: 0.7243
Batch[4591] - loss: 0.001759 best_pearson: 0.7243
Batch[4592] - loss: 0.001078 best_pearson: 0.7243
Batch[4593] - loss: 0.001220 best_pearson: 0.7243
Batch[4594] - loss: 0.001268 best_pearson: 0.7243
Batch[4595] - loss: 0.000977 best_pearson: 0.7243
Batch[4596] - loss: 0.001085 best_pearson: 0.7243
Batch[4597] - loss: 0.001439 best_pearson: 0.7243
Batch[4598] - loss: 0.001183 best_pearson: 0.7243
Batch[4599] - loss: 0.001304 best_pearson: 0.7243
Batch[4600] - loss: 0.001728 best_pearson: 0.7243

Evaluation - loss: 0.000047 pearson: 0.7229 

early stop by 1500 steps.
Batch[4601] - loss: 0.001041 best_pearson: 0.7243
Batch[4602] - loss: 0.002165 best_pearson: 0.7243
Batch[4603] - loss: 0.001195 best_pearson: 0.7243
Batch[4604] - loss: 0.001187 best_pearson: 0.7243
Batch[4605] - loss: 0.001414 best_pearson: 0.7243
Batch[4606] - loss: 0.001038 best_pearson: 0.7243
Batch[4607] - loss: 0.001482 best_pearson: 0.7243
Batch[4608] - loss: 0.000779 best_pearson: 0.7243
Batch[4609] - loss: 0.001496 best_pearson: 0.7243
Batch[4610] - loss: 0.001199 best_pearson: 0.7243
Batch[4611] - loss: 0.001187 best_pearson: 0.7243
Batch[4612] - loss: 0.001479 best_pearson: 0.7243
Batch[4613] - loss: 0.000521 best_pearson: 0.7243
Batch[4614] - loss: 0.001136 best_pearson: 0.7243
Batch[4615] - loss: 0.001255 best_pearson: 0.7243
Batch[4616] - loss: 0.001179 best_pearson: 0.7243
Batch[4617] - loss: 0.000779 best_pearson: 0.7243
Batch[4618] - loss: 0.001263 best_pearson: 0.7243
Batch[4619] - loss: 0.001010 best_pearson: 0.7243
Batch[4620] - loss: 0.000864 best_pearson: 0.7243
Batch[4621] - loss: 0.001066 best_pearson: 0.7243
Batch[4622] - loss: 0.001945 best_pearson: 0.7243
Batch[4623] - loss: 0.001278 best_pearson: 0.7243
Batch[4624] - loss: 0.000519 best_pearson: 0.7243
Batch[4625] - loss: 0.001268 best_pearson: 0.7243
Batch[4626] - loss: 0.001033 best_pearson: 0.7243
Batch[4627] - loss: 0.001136 best_pearson: 0.7243
Batch[4628] - loss: 0.000773 best_pearson: 0.7243
Batch[4629] - loss: 0.001219 best_pearson: 0.7243
Batch[4630] - loss: 0.001101 best_pearson: 0.7243
Batch[4631] - loss: 0.000835 best_pearson: 0.7243
Batch[4632] - loss: 0.001223 best_pearson: 0.7243
Batch[4633] - loss: 0.000832 best_pearson: 0.7243
Batch[4634] - loss: 0.001402 best_pearson: 0.7243
Batch[4635] - loss: 0.001127 best_pearson: 0.7243
Batch[4636] - loss: 0.001463 best_pearson: 0.7243
Batch[4637] - loss: 0.000783 best_pearson: 0.7243
Batch[4638] - loss: 0.001358 best_pearson: 0.7243
Batch[4639] - loss: 0.000694 best_pearson: 0.7243
Batch[4640] - loss: 0.000643 best_pearson: 0.7243
Batch[4641] - loss: 0.001428 best_pearson: 0.7243
Batch[4642] - loss: 0.000670 best_pearson: 0.7243
Batch[4643] - loss: 0.000971 best_pearson: 0.7243
Batch[4644] - loss: 0.001137 best_pearson: 0.7243
Batch[4645] - loss: 0.001444 best_pearson: 0.7243
Batch[4646] - loss: 0.001351 best_pearson: 0.7243
Batch[4647] - loss: 0.000814 best_pearson: 0.7243
Batch[4648] - loss: 0.001529 best_pearson: 0.7243
Batch[4649] - loss: 0.001054 best_pearson: 0.7243
Batch[4650] - loss: 0.000929 best_pearson: 0.7243
Batch[4651] - loss: 0.001723 best_pearson: 0.7243
Batch[4652] - loss: 0.001303 best_pearson: 0.7243
Batch[4653] - loss: 0.000942 best_pearson: 0.7243
Batch[4654] - loss: 0.001381 best_pearson: 0.7243
Batch[4655] - loss: 0.001251 best_pearson: 0.7243
Batch[4656] - loss: 0.001011 best_pearson: 0.7243
Batch[4657] - loss: 0.001325 best_pearson: 0.7243
Batch[4658] - loss: 0.001169 best_pearson: 0.7243
Batch[4659] - loss: 0.001104 best_pearson: 0.7243
Batch[4660] - loss: 0.001145 best_pearson: 0.7243
Batch[4661] - loss: 0.000978 best_pearson: 0.7243
Batch[4662] - loss: 0.001122 best_pearson: 0.7243
Batch[4663] - loss: 0.000762 best_pearson: 0.7243
Batch[4664] - loss: 0.002062 best_pearson: 0.7243
Batch[4665] - loss: 0.000867 best_pearson: 0.7243
Batch[4666] - loss: 0.000732 best_pearson: 0.7243
Batch[4667] - loss: 0.001268 best_pearson: 0.7243
Batch[4668] - loss: 0.000750 best_pearson: 0.7243
Batch[4669] - loss: 0.001023 best_pearson: 0.7243
Batch[4670] - loss: 0.001847 best_pearson: 0.7243
Batch[4671] - loss: 0.001056 best_pearson: 0.7243
Batch[4672] - loss: 0.000734 best_pearson: 0.7243
Batch[4673] - loss: 0.001148 best_pearson: 0.7243
Batch[4674] - loss: 0.001211 best_pearson: 0.7243
Batch[4675] - loss: 0.000730 best_pearson: 0.7243
Batch[4676] - loss: 0.000925 best_pearson: 0.7243
Batch[4677] - loss: 0.001059 best_pearson: 0.7243
Batch[4678] - loss: 0.000786 best_pearson: 0.7243
Batch[4679] - loss: 0.001204 best_pearson: 0.7243
Batch[4680] - loss: 0.001128 best_pearson: 0.7243
Batch[4681] - loss: 0.000810 best_pearson: 0.7243
Batch[4682] - loss: 0.001392 best_pearson: 0.7243
Batch[4683] - loss: 0.001054 best_pearson: 0.7243
Batch[4684] - loss: 0.000916 best_pearson: 0.7243
Batch[4685] - loss: 0.001189 best_pearson: 0.7243
Batch[4686] - loss: 0.002089 best_pearson: 0.7243
Batch[4687] - loss: 0.001002 best_pearson: 0.7243
Batch[4688] - loss: 0.001211 best_pearson: 0.7243
Batch[4689] - loss: 0.001170 best_pearson: 0.7243
Batch[4690] - loss: 0.001265 best_pearson: 0.7243
Batch[4691] - loss: 0.001613 best_pearson: 0.7243
Batch[4692] - loss: 0.001359 best_pearson: 0.7243
Batch[4693] - loss: 0.000863 best_pearson: 0.7243
Batch[4694] - loss: 0.000994 best_pearson: 0.7243
Batch[4695] - loss: 0.000862 best_pearson: 0.7243
Batch[4696] - loss: 0.001399 best_pearson: 0.7243
Batch[4697] - loss: 0.001250 best_pearson: 0.7243
Batch[4698] - loss: 0.001299 best_pearson: 0.7243
Batch[4699] - loss: 0.000946 best_pearson: 0.7243
Batch[4700] - loss: 0.000902 best_pearson: 0.7243

Evaluation - loss: 0.000046 pearson: 0.7236 

early stop by 1500 steps.
Batch[4701] - loss: 0.001103 best_pearson: 0.7243
Batch[4702] - loss: 0.001073 best_pearson: 0.7243
Batch[4703] - loss: 0.001248 best_pearson: 0.7243
Batch[4704] - loss: 0.000804 best_pearson: 0.7243
Batch[4705] - loss: 0.002212 best_pearson: 0.7243
Batch[4706] - loss: 0.000928 best_pearson: 0.7243
Batch[4707] - loss: 0.000924 best_pearson: 0.7243
Batch[4708] - loss: 0.000861 best_pearson: 0.7243
Batch[4709] - loss: 0.001225 best_pearson: 0.7243
Batch[4710] - loss: 0.000999 best_pearson: 0.7243
Batch[4711] - loss: 0.000880 best_pearson: 0.7243
Batch[4712] - loss: 0.001283 best_pearson: 0.7243
Batch[4713] - loss: 0.001166 best_pearson: 0.7243
Batch[4714] - loss: 0.001132 best_pearson: 0.7243
Batch[4715] - loss: 0.000754 best_pearson: 0.7243
Batch[4716] - loss: 0.001363 best_pearson: 0.7243
Batch[4717] - loss: 0.000916 best_pearson: 0.7243
Batch[4718] - loss: 0.000994 best_pearson: 0.7243
Batch[4719] - loss: 0.001517 best_pearson: 0.7243
Batch[4720] - loss: 0.001574 best_pearson: 0.7243
Batch[4721] - loss: 0.002022 best_pearson: 0.7243
Batch[4722] - loss: 0.001409 best_pearson: 0.7243
Batch[4723] - loss: 0.000676 best_pearson: 0.7243
Batch[4724] - loss: 0.001314 best_pearson: 0.7243
Batch[4725] - loss: 0.001303 best_pearson: 0.7243
Batch[4726] - loss: 0.001617 best_pearson: 0.7243
Batch[4727] - loss: 0.000705 best_pearson: 0.7243
Batch[4728] - loss: 0.001336 best_pearson: 0.7243
Batch[4729] - loss: 0.000828 best_pearson: 0.7243
Batch[4730] - loss: 0.001369 best_pearson: 0.7243
Batch[4731] - loss: 0.001779 best_pearson: 0.7243
Batch[4732] - loss: 0.002055 best_pearson: 0.7243
Batch[4733] - loss: 0.000700 best_pearson: 0.7243
Batch[4734] - loss: 0.001696 best_pearson: 0.7243
Batch[4735] - loss: 0.000998 best_pearson: 0.7243
Batch[4736] - loss: 0.000873 best_pearson: 0.7243
Batch[4737] - loss: 0.001321 best_pearson: 0.7243
Batch[4738] - loss: 0.001435 best_pearson: 0.7243
Batch[4739] - loss: 0.000973 best_pearson: 0.7243
Batch[4740] - loss: 0.001571 best_pearson: 0.7243
Batch[4741] - loss: 0.000700 best_pearson: 0.7243
Batch[4742] - loss: 0.002689 best_pearson: 0.7243
Batch[4743] - loss: 0.000759 best_pearson: 0.7243
Batch[4744] - loss: 0.001029 best_pearson: 0.7243
Batch[4745] - loss: 0.001386 best_pearson: 0.7243
Batch[4746] - loss: 0.001601 best_pearson: 0.7243
Batch[4747] - loss: 0.001056 best_pearson: 0.7243
Batch[4748] - loss: 0.000923 best_pearson: 0.7243
Batch[4749] - loss: 0.001507 best_pearson: 0.7243
Batch[4750] - loss: 0.001204 best_pearson: 0.7243
Batch[4751] - loss: 0.001025 best_pearson: 0.7243
Batch[4752] - loss: 0.000998 best_pearson: 0.7243
Batch[4753] - loss: 0.001228 best_pearson: 0.7243
Batch[4754] - loss: 0.001570 best_pearson: 0.7243
Batch[4755] - loss: 0.001220 best_pearson: 0.7243
Batch[4756] - loss: 0.000702 best_pearson: 0.7243
Batch[4757] - loss: 0.001251 best_pearson: 0.7243
Batch[4758] - loss: 0.000966 best_pearson: 0.7243
Batch[4759] - loss: 0.000773 best_pearson: 0.7243
Batch[4760] - loss: 0.001540 best_pearson: 0.7243
Batch[4761] - loss: 0.000976 best_pearson: 0.7243
Batch[4762] - loss: 0.001007 best_pearson: 0.7243
Batch[4763] - loss: 0.001162 best_pearson: 0.7243
Batch[4764] - loss: 0.001818 best_pearson: 0.7243
Batch[4765] - loss: 0.001156 best_pearson: 0.7243
Batch[4766] - loss: 0.001803 best_pearson: 0.7243
Batch[4767] - loss: 0.000794 best_pearson: 0.7243
Batch[4768] - loss: 0.001129 best_pearson: 0.7243
Batch[4769] - loss: 0.000913 best_pearson: 0.7243
Batch[4770] - loss: 0.001249 best_pearson: 0.7243
Batch[4771] - loss: 0.001025 best_pearson: 0.7243
Batch[4772] - loss: 0.001120 best_pearson: 0.7243
Batch[4773] - loss: 0.001615 best_pearson: 0.7243
Batch[4774] - loss: 0.001150 best_pearson: 0.7243
Batch[4775] - loss: 0.001412 best_pearson: 0.7243
Batch[4776] - loss: 0.000741 best_pearson: 0.7243
Batch[4777] - loss: 0.001511 best_pearson: 0.7243
Batch[4778] - loss: 0.001340 best_pearson: 0.7243
Batch[4779] - loss: 0.001066 best_pearson: 0.7243
Batch[4780] - loss: 0.001016 best_pearson: 0.7243
Batch[4781] - loss: 0.000557 best_pearson: 0.7243
Batch[4782] - loss: 0.000883 best_pearson: 0.7243
Batch[4783] - loss: 0.001522 best_pearson: 0.7243
Batch[4784] - loss: 0.001080 best_pearson: 0.7243
Batch[4785] - loss: 0.000667 best_pearson: 0.7243
Batch[4786] - loss: 0.000990 best_pearson: 0.7243
Batch[4787] - loss: 0.000981 best_pearson: 0.7243
Batch[4788] - loss: 0.000953 best_pearson: 0.7243
Batch[4789] - loss: 0.001021 best_pearson: 0.7243
Batch[4790] - loss: 0.001385 best_pearson: 0.7243
Batch[4791] - loss: 0.001755 best_pearson: 0.7243
Batch[4792] - loss: 0.001460 best_pearson: 0.7243
Batch[4793] - loss: 0.000910 best_pearson: 0.7243
Batch[4794] - loss: 0.000801 best_pearson: 0.7243
Batch[4795] - loss: 0.001197 best_pearson: 0.7243
Batch[4796] - loss: 0.001373 best_pearson: 0.7243
Batch[4797] - loss: 0.000837 best_pearson: 0.7243
Batch[4798] - loss: 0.001636 best_pearson: 0.7243
Batch[4799] - loss: 0.001379 best_pearson: 0.7243
Batch[4800] - loss: 0.001860 best_pearson: 0.7243

Evaluation - loss: 0.000047 pearson: 0.7221 

early stop by 1500 steps.
Batch[4801] - loss: 0.001729 best_pearson: 0.7243
Batch[4802] - loss: 0.002060 best_pearson: 0.7243
Batch[4803] - loss: 0.000728 best_pearson: 0.7243
Batch[4804] - loss: 0.001324 best_pearson: 0.7243
Batch[4805] - loss: 0.001073 best_pearson: 0.7243
Batch[4806] - loss: 0.001201 best_pearson: 0.7243
Batch[4807] - loss: 0.001232 best_pearson: 0.7243
Batch[4808] - loss: 0.001307 best_pearson: 0.7243
Batch[4809] - loss: 0.001140 best_pearson: 0.7243
Batch[4810] - loss: 0.001432 best_pearson: 0.7243
Batch[4811] - loss: 0.001445 best_pearson: 0.7243
Batch[4812] - loss: 0.001142 best_pearson: 0.7243
Batch[4813] - loss: 0.001234 best_pearson: 0.7243
Batch[4814] - loss: 0.001298 best_pearson: 0.7243
Batch[4815] - loss: 0.001421 best_pearson: 0.7243
Batch[4816] - loss: 0.001430 best_pearson: 0.7243
Batch[4817] - loss: 0.001144 best_pearson: 0.7243
Batch[4818] - loss: 0.001181 best_pearson: 0.7243
Batch[4819] - loss: 0.001609 best_pearson: 0.7243
Batch[4820] - loss: 0.000924 best_pearson: 0.7243
Batch[4821] - loss: 0.001417 best_pearson: 0.7243
Batch[4822] - loss: 0.001404 best_pearson: 0.7243
Batch[4823] - loss: 0.000828 best_pearson: 0.7243
Batch[4824] - loss: 0.001283 best_pearson: 0.7243
Batch[4825] - loss: 0.000748 best_pearson: 0.7243
Batch[4826] - loss: 0.001200 best_pearson: 0.7243
Batch[4827] - loss: 0.001610 best_pearson: 0.7243
Batch[4828] - loss: 0.001085 best_pearson: 0.7243
Batch[4829] - loss: 0.000915 best_pearson: 0.7243
Batch[4830] - loss: 0.000627 best_pearson: 0.7243
Batch[4831] - loss: 0.000763 best_pearson: 0.7243
Batch[4832] - loss: 0.000809 best_pearson: 0.7243
Batch[4833] - loss: 0.000781 best_pearson: 0.7243
Batch[4834] - loss: 0.000938 best_pearson: 0.7243
Batch[4835] - loss: 0.001238 best_pearson: 0.7243
Batch[4836] - loss: 0.000984 best_pearson: 0.7243
Batch[4837] - loss: 0.001449 best_pearson: 0.7243
Batch[4838] - loss: 0.000985 best_pearson: 0.7243
Batch[4839] - loss: 0.000656 best_pearson: 0.7243
Batch[4840] - loss: 0.001364 best_pearson: 0.7243
Batch[4841] - loss: 0.001008 best_pearson: 0.7243
Batch[4842] - loss: 0.000979 best_pearson: 0.7243
Batch[4843] - loss: 0.001263 best_pearson: 0.7243
Batch[4844] - loss: 0.001175 best_pearson: 0.7243
Batch[4845] - loss: 0.000930 best_pearson: 0.7243
Batch[4846] - loss: 0.000845 best_pearson: 0.7243
Batch[4847] - loss: 0.000900 best_pearson: 0.7243
Batch[4848] - loss: 0.001289 best_pearson: 0.7243
Batch[4849] - loss: 0.001006 best_pearson: 0.7243
Batch[4850] - loss: 0.000948 best_pearson: 0.7243
Batch[4851] - loss: 0.001562 best_pearson: 0.7243
Batch[4852] - loss: 0.000872 best_pearson: 0.7243
Batch[4853] - loss: 0.001195 best_pearson: 0.7243
Batch[4854] - loss: 0.001363 best_pearson: 0.7243
Batch[4855] - loss: 0.001419 best_pearson: 0.7243
Batch[4856] - loss: 0.001304 best_pearson: 0.7243
Batch[4857] - loss: 0.000680 best_pearson: 0.7243
Batch[4858] - loss: 0.001198 best_pearson: 0.7243
Batch[4859] - loss: 0.001157 best_pearson: 0.7243
Batch[4860] - loss: 0.000660 best_pearson: 0.7243
Batch[4861] - loss: 0.001007 best_pearson: 0.7243
Batch[4862] - loss: 0.000920 best_pearson: 0.7243
Batch[4863] - loss: 0.001124 best_pearson: 0.7243
Batch[4864] - loss: 0.001497 best_pearson: 0.7243
Batch[4865] - loss: 0.001346 best_pearson: 0.7243
Batch[4866] - loss: 0.001402 best_pearson: 0.7243
Batch[4867] - loss: 0.001300 best_pearson: 0.7243
Batch[4868] - loss: 0.002310 best_pearson: 0.7243
Batch[4869] - loss: 0.001375 best_pearson: 0.7243
Batch[4870] - loss: 0.000648 best_pearson: 0.7243
Batch[4871] - loss: 0.001621 best_pearson: 0.7243
Batch[4872] - loss: 0.001083 best_pearson: 0.7243
Batch[4873] - loss: 0.001167 best_pearson: 0.7243
Batch[4874] - loss: 0.001144 best_pearson: 0.7243
Batch[4875] - loss: 0.001565 best_pearson: 0.7243
Batch[4876] - loss: 0.000937 best_pearson: 0.7243
Batch[4877] - loss: 0.001424 best_pearson: 0.7243
Batch[4878] - loss: 0.000827 best_pearson: 0.7243
Batch[4879] - loss: 0.000880 best_pearson: 0.7243
Batch[4880] - loss: 0.001137 best_pearson: 0.7243
Batch[4881] - loss: 0.001302 best_pearson: 0.7243
Batch[4882] - loss: 0.000891 best_pearson: 0.7243
Batch[4883] - loss: 0.000777 best_pearson: 0.7243
Batch[4884] - loss: 0.001069 best_pearson: 0.7243
Batch[4885] - loss: 0.000787 best_pearson: 0.7243
Batch[4886] - loss: 0.001443 best_pearson: 0.7243
Batch[4887] - loss: 0.001073 best_pearson: 0.7243
Batch[4888] - loss: 0.001678 best_pearson: 0.7243
Batch[4889] - loss: 0.000888 best_pearson: 0.7243
Batch[4890] - loss: 0.002471 best_pearson: 0.7243
Batch[4891] - loss: 0.000695 best_pearson: 0.7243
Batch[4892] - loss: 0.001195 best_pearson: 0.7243
Batch[4893] - loss: 0.001002 best_pearson: 0.7243
Batch[4894] - loss: 0.001417 best_pearson: 0.7243
Batch[4895] - loss: 0.001101 best_pearson: 0.7243
Batch[4896] - loss: 0.001816 best_pearson: 0.7243
Batch[4897] - loss: 0.001179 best_pearson: 0.7243
Batch[4898] - loss: 0.001011 best_pearson: 0.7243
Batch[4899] - loss: 0.000992 best_pearson: 0.7243
Batch[4900] - loss: 0.000827 best_pearson: 0.7243

Evaluation - loss: 0.000046 pearson: 0.7230 

early stop by 1500 steps.
Batch[4901] - loss: 0.000785 best_pearson: 0.7243
Batch[4902] - loss: 0.000861 best_pearson: 0.7243
Batch[4903] - loss: 0.000584 best_pearson: 0.7243
Batch[4904] - loss: 0.000972 best_pearson: 0.7243
Batch[4905] - loss: 0.000564 best_pearson: 0.7243
Batch[4906] - loss: 0.000350 best_pearson: 0.7243
Batch[4907] - loss: 0.000754 best_pearson: 0.7243
Batch[4908] - loss: 0.001170 best_pearson: 0.7243
Batch[4909] - loss: 0.000843 best_pearson: 0.7243
Batch[4910] - loss: 0.001118 best_pearson: 0.7243
Batch[4911] - loss: 0.000886 best_pearson: 0.7243
Batch[4912] - loss: 0.001652 best_pearson: 0.7243
Batch[4913] - loss: 0.000580 best_pearson: 0.7243
Batch[4914] - loss: 0.001234 best_pearson: 0.7243
Batch[4915] - loss: 0.000977 best_pearson: 0.7243
Batch[4916] - loss: 0.001757 best_pearson: 0.7243
Batch[4917] - loss: 0.001393 best_pearson: 0.7243
Batch[4918] - loss: 0.000780 best_pearson: 0.7243
Batch[4919] - loss: 0.001361 best_pearson: 0.7243
Batch[4920] - loss: 0.001288 best_pearson: 0.7243
Batch[4921] - loss: 0.001130 best_pearson: 0.7243
Batch[4922] - loss: 0.000851 best_pearson: 0.7243
Batch[4923] - loss: 0.001099 best_pearson: 0.7243
Batch[4924] - loss: 0.000998 best_pearson: 0.7243
Batch[4925] - loss: 0.000875 best_pearson: 0.7243
Batch[4926] - loss: 0.001105 best_pearson: 0.7243
Batch[4927] - loss: 0.001023 best_pearson: 0.7243
Batch[4928] - loss: 0.001009 best_pearson: 0.7243
Batch[4929] - loss: 0.001601 best_pearson: 0.7243
Batch[4930] - loss: 0.001429 best_pearson: 0.7243
Batch[4931] - loss: 0.001404 best_pearson: 0.7243
Batch[4932] - loss: 0.001345 best_pearson: 0.7243
Batch[4933] - loss: 0.000795 best_pearson: 0.7243
Batch[4934] - loss: 0.000983 best_pearson: 0.7243
Batch[4935] - loss: 0.002174 best_pearson: 0.7243
Batch[4936] - loss: 0.001973 best_pearson: 0.7243
Batch[4937] - loss: 0.000907 best_pearson: 0.7243
Batch[4938] - loss: 0.001251 best_pearson: 0.7243
Batch[4939] - loss: 0.001100 best_pearson: 0.7243
Batch[4940] - loss: 0.001362 best_pearson: 0.7243
Batch[4941] - loss: 0.000496 best_pearson: 0.7243
Batch[4942] - loss: 0.000717 best_pearson: 0.7243
Batch[4943] - loss: 0.001529 best_pearson: 0.7243
Batch[4944] - loss: 0.001560 best_pearson: 0.7243
Batch[4945] - loss: 0.001229 best_pearson: 0.7243
Batch[4946] - loss: 0.001131 best_pearson: 0.7243
Batch[4947] - loss: 0.000941 best_pearson: 0.7243
Batch[4948] - loss: 0.001596 best_pearson: 0.7243
Batch[4949] - loss: 0.000822 best_pearson: 0.7243
Batch[4950] - loss: 0.000915 best_pearson: 0.7243
Batch[4951] - loss: 0.001091 best_pearson: 0.7243
Batch[4952] - loss: 0.000625 best_pearson: 0.7243
Batch[4953] - loss: 0.001356 best_pearson: 0.7243
Batch[4954] - loss: 0.001381 best_pearson: 0.7243
Batch[4955] - loss: 0.001325 best_pearson: 0.7243
Batch[4956] - loss: 0.000822 best_pearson: 0.7243
Batch[4957] - loss: 0.000879 best_pearson: 0.7243
Batch[4958] - loss: 0.000789 best_pearson: 0.7243
Batch[4959] - loss: 0.000858 best_pearson: 0.7243
Batch[4960] - loss: 0.001099 best_pearson: 0.7243
Batch[4961] - loss: 0.001458 best_pearson: 0.7243
Batch[4962] - loss: 0.000943 best_pearson: 0.7243
Batch[4963] - loss: 0.000832 best_pearson: 0.7243
Batch[4964] - loss: 0.000851 best_pearson: 0.7243
Batch[4965] - loss: 0.001049 best_pearson: 0.7243
Batch[4966] - loss: 0.000882 best_pearson: 0.7243
Batch[4967] - loss: 0.000504 best_pearson: 0.7243
Batch[4968] - loss: 0.000730 best_pearson: 0.7243
Batch[4969] - loss: 0.001740 best_pearson: 0.7243
Batch[4970] - loss: 0.001275 best_pearson: 0.7243
Batch[4971] - loss: 0.000676 best_pearson: 0.7243
Batch[4972] - loss: 0.001214 best_pearson: 0.7243
Batch[4973] - loss: 0.001924 best_pearson: 0.7243
Batch[4974] - loss: 0.001579 best_pearson: 0.7243
Batch[4975] - loss: 0.000698 best_pearson: 0.7243
Batch[4976] - loss: 0.000558 best_pearson: 0.7243
Batch[4977] - loss: 0.000703 best_pearson: 0.7243
Batch[4978] - loss: 0.000661 best_pearson: 0.7243
Batch[4979] - loss: 0.001226 best_pearson: 0.7243
Batch[4980] - loss: 0.001170 best_pearson: 0.7243
Batch[4981] - loss: 0.001443 best_pearson: 0.7243
Batch[4982] - loss: 0.001370 best_pearson: 0.7243
Batch[4983] - loss: 0.000831 best_pearson: 0.7243
Batch[4984] - loss: 0.001178 best_pearson: 0.7243
Batch[4985] - loss: 0.001465 best_pearson: 0.7243
Batch[4986] - loss: 0.000714 best_pearson: 0.7243
Batch[4987] - loss: 0.001646 best_pearson: 0.7243
Batch[4988] - loss: 0.001762 best_pearson: 0.7243
Batch[4989] - loss: 0.000736 best_pearson: 0.7243
Batch[4990] - loss: 0.000777 best_pearson: 0.7243
Batch[4991] - loss: 0.000700 best_pearson: 0.7243
Batch[4992] - loss: 0.001017 best_pearson: 0.7243
Batch[4993] - loss: 0.001221 best_pearson: 0.7243
Batch[4994] - loss: 0.001177 best_pearson: 0.7243
Batch[4995] - loss: 0.000925 best_pearson: 0.7243
Batch[4996] - loss: 0.000857 best_pearson: 0.7243
Batch[4997] - loss: 0.001032 best_pearson: 0.7243
Batch[4998] - loss: 0.001105 best_pearson: 0.7243
Batch[4999] - loss: 0.000651 best_pearson: 0.7243
Batch[5000] - loss: 0.000867 best_pearson: 0.7243

Evaluation - loss: 0.000046 pearson: 0.7248 

Batch[5001] - loss: 0.000826 best_pearson: 0.7248
Batch[5002] - loss: 0.000669 best_pearson: 0.7248
Batch[5003] - loss: 0.000757 best_pearson: 0.7248
Batch[5004] - loss: 0.002087 best_pearson: 0.7248
Batch[5005] - loss: 0.001652 best_pearson: 0.7248
Batch[5006] - loss: 0.001130 best_pearson: 0.7248
Batch[5007] - loss: 0.000774 best_pearson: 0.7248
Batch[5008] - loss: 0.000865 best_pearson: 0.7248
Batch[5009] - loss: 0.000895 best_pearson: 0.7248
Batch[5010] - loss: 0.001508 best_pearson: 0.7248
Batch[5011] - loss: 0.001284 best_pearson: 0.7248
Batch[5012] - loss: 0.001438 best_pearson: 0.7248
Batch[5013] - loss: 0.001174 best_pearson: 0.7248
Batch[5014] - loss: 0.001500 best_pearson: 0.7248
Batch[5015] - loss: 0.001883 best_pearson: 0.7248
Batch[5016] - loss: 0.000665 best_pearson: 0.7248
Batch[5017] - loss: 0.000932 best_pearson: 0.7248
Batch[5018] - loss: 0.001316 best_pearson: 0.7248
Batch[5019] - loss: 0.001291 best_pearson: 0.7248
Batch[5020] - loss: 0.001486 best_pearson: 0.7248
Batch[5021] - loss: 0.000789 best_pearson: 0.7248
Batch[5022] - loss: 0.001092 best_pearson: 0.7248
Batch[5023] - loss: 0.000557 best_pearson: 0.7248
Batch[5024] - loss: 0.000971 best_pearson: 0.7248
Batch[5025] - loss: 0.000566 best_pearson: 0.7248
Batch[5026] - loss: 0.001028 best_pearson: 0.7248
Batch[5027] - loss: 0.001202 best_pearson: 0.7248
Batch[5028] - loss: 0.001393 best_pearson: 0.7248
Batch[5029] - loss: 0.000899 best_pearson: 0.7248
Batch[5030] - loss: 0.001316 best_pearson: 0.7248
Batch[5031] - loss: 0.000621 best_pearson: 0.7248
Batch[5032] - loss: 0.001488 best_pearson: 0.7248
Batch[5033] - loss: 0.000784 best_pearson: 0.7248
Batch[5034] - loss: 0.000799 best_pearson: 0.7248
Batch[5035] - loss: 0.001433 best_pearson: 0.7248
Batch[5036] - loss: 0.000956 best_pearson: 0.7248
Batch[5037] - loss: 0.000833 best_pearson: 0.7248
Batch[5038] - loss: 0.001496 best_pearson: 0.7248
Batch[5039] - loss: 0.001433 best_pearson: 0.7248
Batch[5040] - loss: 0.001458 best_pearson: 0.7248
Batch[5041] - loss: 0.001094 best_pearson: 0.7248
Batch[5042] - loss: 0.001075 best_pearson: 0.7248
Batch[5043] - loss: 0.000974 best_pearson: 0.7248
Batch[5044] - loss: 0.000870 best_pearson: 0.7248
Batch[5045] - loss: 0.001242 best_pearson: 0.7248
Batch[5046] - loss: 0.000964 best_pearson: 0.7248
Batch[5047] - loss: 0.000719 best_pearson: 0.7248
Batch[5048] - loss: 0.000815 best_pearson: 0.7248
Batch[5049] - loss: 0.000919 best_pearson: 0.7248
Batch[5050] - loss: 0.001583 best_pearson: 0.7248
Batch[5051] - loss: 0.001700 best_pearson: 0.7248
Batch[5052] - loss: 0.001322 best_pearson: 0.7248
Batch[5053] - loss: 0.001018 best_pearson: 0.7248
Batch[5054] - loss: 0.000886 best_pearson: 0.7248
Batch[5055] - loss: 0.000595 best_pearson: 0.7248
Batch[5056] - loss: 0.001096 best_pearson: 0.7248
Batch[5057] - loss: 0.001226 best_pearson: 0.7248
Batch[5058] - loss: 0.001262 best_pearson: 0.7248
Batch[5059] - loss: 0.001429 best_pearson: 0.7248
Batch[5060] - loss: 0.000636 best_pearson: 0.7248
Batch[5061] - loss: 0.000773 best_pearson: 0.7248
Batch[5062] - loss: 0.001247 best_pearson: 0.7248
Batch[5063] - loss: 0.000766 best_pearson: 0.7248
Batch[5064] - loss: 0.000821 best_pearson: 0.7248
Batch[5065] - loss: 0.000958 best_pearson: 0.7248
Batch[5066] - loss: 0.001200 best_pearson: 0.7248
Batch[5067] - loss: 0.000764 best_pearson: 0.7248
Batch[5068] - loss: 0.001205 best_pearson: 0.7248
Batch[5069] - loss: 0.000824 best_pearson: 0.7248
Batch[5070] - loss: 0.001008 best_pearson: 0.7248
Batch[5071] - loss: 0.001076 best_pearson: 0.7248
Batch[5072] - loss: 0.001013 best_pearson: 0.7248
Batch[5073] - loss: 0.000814 best_pearson: 0.7248
Batch[5074] - loss: 0.001193 best_pearson: 0.7248
Batch[5075] - loss: 0.001160 best_pearson: 0.7248
Batch[5076] - loss: 0.000912 best_pearson: 0.7248
Batch[5077] - loss: 0.001108 best_pearson: 0.7248
Batch[5078] - loss: 0.000731 best_pearson: 0.7248
Batch[5079] - loss: 0.000854 best_pearson: 0.7248
Batch[5080] - loss: 0.000624 best_pearson: 0.7248
Batch[5081] - loss: 0.000971 best_pearson: 0.7248
Batch[5082] - loss: 0.000669 best_pearson: 0.7248
Batch[5083] - loss: 0.000566 best_pearson: 0.7248
Batch[5084] - loss: 0.001759 best_pearson: 0.7248
Batch[5085] - loss: 0.001491 best_pearson: 0.7248
Batch[5086] - loss: 0.001015 best_pearson: 0.7248
Batch[5087] - loss: 0.000588 best_pearson: 0.7248
Batch[5088] - loss: 0.000698 best_pearson: 0.7248
Batch[5089] - loss: 0.001108 best_pearson: 0.7248
Batch[5090] - loss: 0.000854 best_pearson: 0.7248
Batch[5091] - loss: 0.000728 best_pearson: 0.7248
Batch[5092] - loss: 0.001414 best_pearson: 0.7248
Batch[5093] - loss: 0.000967 best_pearson: 0.7248
Batch[5094] - loss: 0.000789 best_pearson: 0.7248
Batch[5095] - loss: 0.001305 best_pearson: 0.7248
Batch[5096] - loss: 0.001106 best_pearson: 0.7248
Batch[5097] - loss: 0.000690 best_pearson: 0.7248
Batch[5098] - loss: 0.000816 best_pearson: 0.7248
Batch[5099] - loss: 0.000794 best_pearson: 0.7248
Batch[5100] - loss: 0.001334 best_pearson: 0.7248

Evaluation - loss: 0.000046 pearson: 0.7225 

Batch[5101] - loss: 0.000680 best_pearson: 0.7248
Batch[5102] - loss: 0.001131 best_pearson: 0.7248
Batch[5103] - loss: 0.001839 best_pearson: 0.7248
Batch[5104] - loss: 0.000864 best_pearson: 0.7248
Batch[5105] - loss: 0.001305 best_pearson: 0.7248
Batch[5106] - loss: 0.001044 best_pearson: 0.7248
Batch[5107] - loss: 0.001448 best_pearson: 0.7248
Batch[5108] - loss: 0.000999 best_pearson: 0.7248
Batch[5109] - loss: 0.000596 best_pearson: 0.7248
Batch[5110] - loss: 0.000881 best_pearson: 0.7248
Batch[5111] - loss: 0.000628 best_pearson: 0.7248
Batch[5112] - loss: 0.001290 best_pearson: 0.7248
Batch[5113] - loss: 0.000839 best_pearson: 0.7248
Batch[5114] - loss: 0.000817 best_pearson: 0.7248
Batch[5115] - loss: 0.001012 best_pearson: 0.7248
Batch[5116] - loss: 0.001003 best_pearson: 0.7248
Batch[5117] - loss: 0.001073 best_pearson: 0.7248
Batch[5118] - loss: 0.000871 best_pearson: 0.7248
Batch[5119] - loss: 0.001595 best_pearson: 0.7248
Batch[5120] - loss: 0.000883 best_pearson: 0.7248
Batch[5121] - loss: 0.001503 best_pearson: 0.7248
Batch[5122] - loss: 0.001129 best_pearson: 0.7248
Batch[5123] - loss: 0.001514 best_pearson: 0.7248
Batch[5124] - loss: 0.000815 best_pearson: 0.7248
Batch[5125] - loss: 0.000794 best_pearson: 0.7248
Batch[5126] - loss: 0.000931 best_pearson: 0.7248
Batch[5127] - loss: 0.001020 best_pearson: 0.7248
Batch[5128] - loss: 0.002128 best_pearson: 0.7248
Batch[5129] - loss: 0.001030 best_pearson: 0.7248
Batch[5130] - loss: 0.001356 best_pearson: 0.7248
Batch[5131] - loss: 0.000897 best_pearson: 0.7248
Batch[5132] - loss: 0.000804 best_pearson: 0.7248
Batch[5133] - loss: 0.000801 best_pearson: 0.7248
Batch[5134] - loss: 0.001393 best_pearson: 0.7248
Batch[5135] - loss: 0.002506 best_pearson: 0.7248
Batch[5136] - loss: 0.002168 best_pearson: 0.7248
Batch[5137] - loss: 0.000753 best_pearson: 0.7248
Batch[5138] - loss: 0.001229 best_pearson: 0.7248
Batch[5139] - loss: 0.000817 best_pearson: 0.7248
Batch[5140] - loss: 0.001381 best_pearson: 0.7248
Batch[5141] - loss: 0.000657 best_pearson: 0.7248
Batch[5142] - loss: 0.001048 best_pearson: 0.7248
Batch[5143] - loss: 0.001094 best_pearson: 0.7248
Batch[5144] - loss: 0.001184 best_pearson: 0.7248
Batch[5145] - loss: 0.000830 best_pearson: 0.7248
Batch[5146] - loss: 0.000815 best_pearson: 0.7248
Batch[5147] - loss: 0.001101 best_pearson: 0.7248
Batch[5148] - loss: 0.000822 best_pearson: 0.7248
Batch[5149] - loss: 0.000822 best_pearson: 0.7248
Batch[5150] - loss: 0.000594 best_pearson: 0.7248
Batch[5151] - loss: 0.001555 best_pearson: 0.7248
Batch[5152] - loss: 0.001347 best_pearson: 0.7248
Batch[5153] - loss: 0.001015 best_pearson: 0.7248
Batch[5154] - loss: 0.000588 best_pearson: 0.7248
Batch[5155] - loss: 0.000510 best_pearson: 0.7248
Batch[5156] - loss: 0.000827 best_pearson: 0.7248
Batch[5157] - loss: 0.001304 best_pearson: 0.7248
Batch[5158] - loss: 0.001120 best_pearson: 0.7248
Batch[5159] - loss: 0.000996 best_pearson: 0.7248
Batch[5160] - loss: 0.000937 best_pearson: 0.7248
Batch[5161] - loss: 0.000443 best_pearson: 0.7248
Batch[5162] - loss: 0.000950 best_pearson: 0.7248
Batch[5163] - loss: 0.001142 best_pearson: 0.7248
Batch[5164] - loss: 0.001776 best_pearson: 0.7248
Batch[5165] - loss: 0.000720 best_pearson: 0.7248
Batch[5166] - loss: 0.001220 best_pearson: 0.7248
Batch[5167] - loss: 0.001019 best_pearson: 0.7248
Batch[5168] - loss: 0.001319 best_pearson: 0.7248
Batch[5169] - loss: 0.000900 best_pearson: 0.7248
Batch[5170] - loss: 0.001563 best_pearson: 0.7248
Batch[5171] - loss: 0.001486 best_pearson: 0.7248
Batch[5172] - loss: 0.001466 best_pearson: 0.7248
Batch[5173] - loss: 0.001334 best_pearson: 0.7248
Batch[5174] - loss: 0.003089 best_pearson: 0.7248
Batch[5175] - loss: 0.001444 best_pearson: 0.7248
Batch[5176] - loss: 0.001280 best_pearson: 0.7248
Batch[5177] - loss: 0.001070 best_pearson: 0.7248
Batch[5178] - loss: 0.001564 best_pearson: 0.7248
Batch[5179] - loss: 0.001487 best_pearson: 0.7248
Batch[5180] - loss: 0.001078 best_pearson: 0.7248
Batch[5181] - loss: 0.000824 best_pearson: 0.7248
Batch[5182] - loss: 0.001163 best_pearson: 0.7248
Batch[5183] - loss: 0.001981 best_pearson: 0.7248
Batch[5184] - loss: 0.000604 best_pearson: 0.7248
Batch[5185] - loss: 0.000865 best_pearson: 0.7248
Batch[5186] - loss: 0.001380 best_pearson: 0.7248
Batch[5187] - loss: 0.001615 best_pearson: 0.7248
Batch[5188] - loss: 0.001253 best_pearson: 0.7248
Batch[5189] - loss: 0.001358 best_pearson: 0.7248
Batch[5190] - loss: 0.001342 best_pearson: 0.7248
Batch[5191] - loss: 0.001315 best_pearson: 0.7248
Batch[5192] - loss: 0.000972 best_pearson: 0.7248
Batch[5193] - loss: 0.000896 best_pearson: 0.7248
Batch[5194] - loss: 0.001507 best_pearson: 0.7248
Batch[5195] - loss: 0.001125 best_pearson: 0.7248
Batch[5196] - loss: 0.001121 best_pearson: 0.7248
Batch[5197] - loss: 0.001982 best_pearson: 0.7248
Batch[5198] - loss: 0.001187 best_pearson: 0.7248
Batch[5199] - loss: 0.001132 best_pearson: 0.7248
Batch[5200] - loss: 0.001062 best_pearson: 0.7248

Evaluation - loss: 0.000046 pearson: 0.7218 

Batch[5201] - loss: 0.001832 best_pearson: 0.7248
Batch[5202] - loss: 0.002009 best_pearson: 0.7248
Batch[5203] - loss: 0.001716 best_pearson: 0.7248
Batch[5204] - loss: 0.000969 best_pearson: 0.7248
Batch[5205] - loss: 0.001560 best_pearson: 0.7248
Batch[5206] - loss: 0.001184 best_pearson: 0.7248
Batch[5207] - loss: 0.001163 best_pearson: 0.7248
Batch[5208] - loss: 0.001116 best_pearson: 0.7248
Batch[5209] - loss: 0.000783 best_pearson: 0.7248
Batch[5210] - loss: 0.000931 best_pearson: 0.7248
Batch[5211] - loss: 0.001924 best_pearson: 0.7248
Batch[5212] - loss: 0.000862 best_pearson: 0.7248
Batch[5213] - loss: 0.001373 best_pearson: 0.7248
Batch[5214] - loss: 0.001182 best_pearson: 0.7248
Batch[5215] - loss: 0.001214 best_pearson: 0.7248
Batch[5216] - loss: 0.001076 best_pearson: 0.7248
Batch[5217] - loss: 0.001100 best_pearson: 0.7248
Batch[5218] - loss: 0.000950 best_pearson: 0.7248
Batch[5219] - loss: 0.001215 best_pearson: 0.7248
Batch[5220] - loss: 0.000937 best_pearson: 0.7248
Batch[5221] - loss: 0.001266 best_pearson: 0.7248
Batch[5222] - loss: 0.001120 best_pearson: 0.7248
Batch[5223] - loss: 0.000922 best_pearson: 0.7248
Batch[5224] - loss: 0.001579 best_pearson: 0.7248
Batch[5225] - loss: 0.001065 best_pearson: 0.7248
Batch[5226] - loss: 0.000647 best_pearson: 0.7248
Batch[5227] - loss: 0.001288 best_pearson: 0.7248
Batch[5228] - loss: 0.002093 best_pearson: 0.7248
Batch[5229] - loss: 0.001823 best_pearson: 0.7248
Batch[5230] - loss: 0.000895 best_pearson: 0.7248
Batch[5231] - loss: 0.002046 best_pearson: 0.7248
Batch[5232] - loss: 0.000825 best_pearson: 0.7248
Batch[5233] - loss: 0.001587 best_pearson: 0.7248
Batch[5234] - loss: 0.001082 best_pearson: 0.7248
Batch[5235] - loss: 0.001039 best_pearson: 0.7248
Batch[5236] - loss: 0.001467 best_pearson: 0.7248
Batch[5237] - loss: 0.001603 best_pearson: 0.7248
Batch[5238] - loss: 0.000757 best_pearson: 0.7248
Batch[5239] - loss: 0.001503 best_pearson: 0.7248
Batch[5240] - loss: 0.001421 best_pearson: 0.7248
Batch[5241] - loss: 0.001257 best_pearson: 0.7248
Batch[5242] - loss: 0.001470 best_pearson: 0.7248
Batch[5243] - loss: 0.000984 best_pearson: 0.7248
Batch[5244] - loss: 0.000782 best_pearson: 0.7248
Batch[5245] - loss: 0.000815 best_pearson: 0.7248
Batch[5246] - loss: 0.000520 best_pearson: 0.7248
Batch[5247] - loss: 0.000761 best_pearson: 0.7248
Batch[5248] - loss: 0.001001 best_pearson: 0.7248
Batch[5249] - loss: 0.001014 best_pearson: 0.7248
Batch[5250] - loss: 0.000709 best_pearson: 0.7248
Batch[5251] - loss: 0.000891 best_pearson: 0.7248
Batch[5252] - loss: 0.001278 best_pearson: 0.7248
Batch[5253] - loss: 0.000770 best_pearson: 0.7248
Batch[5254] - loss: 0.000946 best_pearson: 0.7248
Batch[5255] - loss: 0.000959 best_pearson: 0.7248
Batch[5256] - loss: 0.001357 best_pearson: 0.7248
Batch[5257] - loss: 0.001420 best_pearson: 0.7248
Batch[5258] - loss: 0.002669 best_pearson: 0.7248
Batch[5259] - loss: 0.000974 best_pearson: 0.7248
Batch[5260] - loss: 0.000714 best_pearson: 0.7248
Batch[5261] - loss: 0.001891 best_pearson: 0.7248
Batch[5262] - loss: 0.000876 best_pearson: 0.7248
Batch[5263] - loss: 0.001222 best_pearson: 0.7248
Batch[5264] - loss: 0.001974 best_pearson: 0.7248
Batch[5265] - loss: 0.001724 best_pearson: 0.7248
Batch[5266] - loss: 0.001486 best_pearson: 0.7248
Batch[5267] - loss: 0.001303 best_pearson: 0.7248
Batch[5268] - loss: 0.001129 best_pearson: 0.7248
Batch[5269] - loss: 0.001459 best_pearson: 0.7248
Batch[5270] - loss: 0.000941 best_pearson: 0.7248
Batch[5271] - loss: 0.001590 best_pearson: 0.7248
Batch[5272] - loss: 0.001525 best_pearson: 0.7248
Batch[5273] - loss: 0.001048 best_pearson: 0.7248
Batch[5274] - loss: 0.000813 best_pearson: 0.7248
Batch[5275] - loss: 0.001358 best_pearson: 0.7248
Batch[5276] - loss: 0.001890 best_pearson: 0.7248
Batch[5277] - loss: 0.001359 best_pearson: 0.7248
Batch[5278] - loss: 0.002164 best_pearson: 0.7248
Batch[5279] - loss: 0.001409 best_pearson: 0.7248
Batch[5280] - loss: 0.001267 best_pearson: 0.7248
Batch[5281] - loss: 0.001433 best_pearson: 0.7248
Batch[5282] - loss: 0.001086 best_pearson: 0.7248
Batch[5283] - loss: 0.001086 best_pearson: 0.7248
Batch[5284] - loss: 0.001047 best_pearson: 0.7248
Batch[5285] - loss: 0.001197 best_pearson: 0.7248
Batch[5286] - loss: 0.001187 best_pearson: 0.7248
Batch[5287] - loss: 0.001575 best_pearson: 0.7248
Batch[5288] - loss: 0.001529 best_pearson: 0.7248
Batch[5289] - loss: 0.001067 best_pearson: 0.7248
Batch[5290] - loss: 0.001094 best_pearson: 0.7248
Batch[5291] - loss: 0.001348 best_pearson: 0.7248
Batch[5292] - loss: 0.001397 best_pearson: 0.7248
Batch[5293] - loss: 0.000979 best_pearson: 0.7248
Batch[5294] - loss: 0.001727 best_pearson: 0.7248
Batch[5295] - loss: 0.001203 best_pearson: 0.7248
Batch[5296] - loss: 0.001885 best_pearson: 0.7248
Batch[5297] - loss: 0.000727 best_pearson: 0.7248
Batch[5298] - loss: 0.001234 best_pearson: 0.7248
Batch[5299] - loss: 0.001511 best_pearson: 0.7248
Batch[5300] - loss: 0.000879 best_pearson: 0.7248

Evaluation - loss: 0.000046 pearson: 0.7217 

Batch[5301] - loss: 0.001209 best_pearson: 0.7248
Batch[5302] - loss: 0.000768 best_pearson: 0.7248
Batch[5303] - loss: 0.000801 best_pearson: 0.7248
Batch[5304] - loss: 0.000836 best_pearson: 0.7248
Batch[5305] - loss: 0.001127 best_pearson: 0.7248
Batch[5306] - loss: 0.001182 best_pearson: 0.7248
Batch[5307] - loss: 0.001226 best_pearson: 0.7248
Batch[5308] - loss: 0.001086 best_pearson: 0.7248
Batch[5309] - loss: 0.001514 best_pearson: 0.7248
Batch[5310] - loss: 0.001369 best_pearson: 0.7248
Batch[5311] - loss: 0.000737 best_pearson: 0.7248
Batch[5312] - loss: 0.001219 best_pearson: 0.7248
Batch[5313] - loss: 0.002644 best_pearson: 0.7248
Batch[5314] - loss: 0.001025 best_pearson: 0.7248
Batch[5315] - loss: 0.000655 best_pearson: 0.7248
Batch[5316] - loss: 0.000827 best_pearson: 0.7248
Batch[5317] - loss: 0.000958 best_pearson: 0.7248
Batch[5318] - loss: 0.001223 best_pearson: 0.7248
Batch[5319] - loss: 0.001365 best_pearson: 0.7248
Batch[5320] - loss: 0.001414 best_pearson: 0.7248
Batch[5321] - loss: 0.000881 best_pearson: 0.7248
Batch[5322] - loss: 0.001040 best_pearson: 0.7248
Batch[5323] - loss: 0.001267 best_pearson: 0.7248
Batch[5324] - loss: 0.001966 best_pearson: 0.7248
Batch[5325] - loss: 0.001529 best_pearson: 0.7248
Batch[5326] - loss: 0.000981 best_pearson: 0.7248
Batch[5327] - loss: 0.001531 best_pearson: 0.7248
Batch[5328] - loss: 0.000816 best_pearson: 0.7248
Batch[5329] - loss: 0.000531 best_pearson: 0.7248
Batch[5330] - loss: 0.001105 best_pearson: 0.7248
Batch[5331] - loss: 0.000828 best_pearson: 0.7248
Batch[5332] - loss: 0.001121 best_pearson: 0.7248
Batch[5333] - loss: 0.001302 best_pearson: 0.7248
Batch[5334] - loss: 0.000894 best_pearson: 0.7248
Batch[5335] - loss: 0.000863 best_pearson: 0.7248
Batch[5336] - loss: 0.001114 best_pearson: 0.7248
Batch[5337] - loss: 0.002064 best_pearson: 0.7248
Batch[5338] - loss: 0.001180 best_pearson: 0.7248
Batch[5339] - loss: 0.001044 best_pearson: 0.7248
Batch[5340] - loss: 0.000867 best_pearson: 0.7248
Batch[5341] - loss: 0.001107 best_pearson: 0.7248
Batch[5342] - loss: 0.001013 best_pearson: 0.7248
Batch[5343] - loss: 0.000930 best_pearson: 0.7248
Batch[5344] - loss: 0.000781 best_pearson: 0.7248
Batch[5345] - loss: 0.000896 best_pearson: 0.7248
Batch[5346] - loss: 0.001406 best_pearson: 0.7248
Batch[5347] - loss: 0.002176 best_pearson: 0.7248
Batch[5348] - loss: 0.000951 best_pearson: 0.7248
Batch[5349] - loss: 0.001156 best_pearson: 0.7248
Batch[5350] - loss: 0.001575 best_pearson: 0.7248
Batch[5351] - loss: 0.000914 best_pearson: 0.7248
Batch[5352] - loss: 0.000840 best_pearson: 0.7248
Batch[5353] - loss: 0.000887 best_pearson: 0.7248
Batch[5354] - loss: 0.001513 best_pearson: 0.7248
Batch[5355] - loss: 0.000842 best_pearson: 0.7248
Batch[5356] - loss: 0.001002 best_pearson: 0.7248
Batch[5357] - loss: 0.001285 best_pearson: 0.7248
Batch[5358] - loss: 0.001182 best_pearson: 0.7248
Batch[5359] - loss: 0.001427 best_pearson: 0.7248
Batch[5360] - loss: 0.000763 best_pearson: 0.7248
Batch[5361] - loss: 0.000499 best_pearson: 0.7248
Batch[5362] - loss: 0.000723 best_pearson: 0.7248
Batch[5363] - loss: 0.001396 best_pearson: 0.7248
Batch[5364] - loss: 0.000785 best_pearson: 0.7248
Batch[5365] - loss: 0.000940 best_pearson: 0.7248
Batch[5366] - loss: 0.001332 best_pearson: 0.7248
Batch[5367] - loss: 0.001272 best_pearson: 0.7248
Batch[5368] - loss: 0.002040 best_pearson: 0.7248
Batch[5369] - loss: 0.001435 best_pearson: 0.7248
Batch[5370] - loss: 0.000776 best_pearson: 0.7248
Batch[5371] - loss: 0.001123 best_pearson: 0.7248
Batch[5372] - loss: 0.000889 best_pearson: 0.7248
Batch[5373] - loss: 0.001256 best_pearson: 0.7248
Batch[5374] - loss: 0.001354 best_pearson: 0.7248
Batch[5375] - loss: 0.001356 best_pearson: 0.7248
Batch[5376] - loss: 0.001050 best_pearson: 0.7248
Batch[5377] - loss: 0.001008 best_pearson: 0.7248
Batch[5378] - loss: 0.001284 best_pearson: 0.7248
Batch[5379] - loss: 0.001137 best_pearson: 0.7248
Batch[5380] - loss: 0.000925 best_pearson: 0.7248
Batch[5381] - loss: 0.000797 best_pearson: 0.7248
Batch[5382] - loss: 0.000634 best_pearson: 0.7248
Batch[5383] - loss: 0.000664 best_pearson: 0.7248
Batch[5384] - loss: 0.001238 best_pearson: 0.7248
Batch[5385] - loss: 0.000495 best_pearson: 0.7248
Batch[5386] - loss: 0.001173 best_pearson: 0.7248
Batch[5387] - loss: 0.000650 best_pearson: 0.7248
Batch[5388] - loss: 0.001082 best_pearson: 0.7248
Batch[5389] - loss: 0.000690 best_pearson: 0.7248
Batch[5390] - loss: 0.001082 best_pearson: 0.7248
Batch[5391] - loss: 0.001036 best_pearson: 0.7248
Batch[5392] - loss: 0.000666 best_pearson: 0.7248
Batch[5393] - loss: 0.001202 best_pearson: 0.7248
Batch[5394] - loss: 0.000957 best_pearson: 0.7248
Batch[5395] - loss: 0.000963 best_pearson: 0.7248
Batch[5396] - loss: 0.000664 best_pearson: 0.7248
Batch[5397] - loss: 0.000689 best_pearson: 0.7248
Batch[5398] - loss: 0.001171 best_pearson: 0.7248
Batch[5399] - loss: 0.000995 best_pearson: 0.7248
Batch[5400] - loss: 0.001067 best_pearson: 0.7248

Evaluation - loss: 0.000046 pearson: 0.7221 

Batch[5401] - loss: 0.000976 best_pearson: 0.7248
Batch[5402] - loss: 0.001547 best_pearson: 0.7248
Batch[5403] - loss: 0.000691 best_pearson: 0.7248
Batch[5404] - loss: 0.000811 best_pearson: 0.7248
Batch[5405] - loss: 0.000934 best_pearson: 0.7248
Batch[5406] - loss: 0.001022 best_pearson: 0.7248
Batch[5407] - loss: 0.000808 best_pearson: 0.7248
Batch[5408] - loss: 0.001055 best_pearson: 0.7248
Batch[5409] - loss: 0.001609 best_pearson: 0.7248
Batch[5410] - loss: 0.001206 best_pearson: 0.7248
Batch[5411] - loss: 0.001414 best_pearson: 0.7248
Batch[5412] - loss: 0.001117 best_pearson: 0.7248
Batch[5413] - loss: 0.001221 best_pearson: 0.7248
Batch[5414] - loss: 0.000994 best_pearson: 0.7248
Batch[5415] - loss: 0.001056 best_pearson: 0.7248
Batch[5416] - loss: 0.000972 best_pearson: 0.7248
Batch[5417] - loss: 0.001760 best_pearson: 0.7248
Batch[5418] - loss: 0.001011 best_pearson: 0.7248
Batch[5419] - loss: 0.000676 best_pearson: 0.7248
Batch[5420] - loss: 0.000726 best_pearson: 0.7248
Batch[5421] - loss: 0.000927 best_pearson: 0.7248
Batch[5422] - loss: 0.000898 best_pearson: 0.7248
Batch[5423] - loss: 0.001152 best_pearson: 0.7248
Batch[5424] - loss: 0.001379 best_pearson: 0.7248
Batch[5425] - loss: 0.000852 best_pearson: 0.7248
Batch[5426] - loss: 0.001041 best_pearson: 0.7248
Batch[5427] - loss: 0.001451 best_pearson: 0.7248
Batch[5428] - loss: 0.000660 best_pearson: 0.7248
Batch[5429] - loss: 0.001043 best_pearson: 0.7248
Batch[5430] - loss: 0.001121 best_pearson: 0.7248
Batch[5431] - loss: 0.000931 best_pearson: 0.7248
Batch[5432] - loss: 0.000955 best_pearson: 0.7248
Batch[5433] - loss: 0.000981 best_pearson: 0.7248
Batch[5434] - loss: 0.001350 best_pearson: 0.7248
Batch[5435] - loss: 0.000684 best_pearson: 0.7248
Batch[5436] - loss: 0.000706 best_pearson: 0.7248
Batch[5437] - loss: 0.000823 best_pearson: 0.7248
Batch[5438] - loss: 0.000774 best_pearson: 0.7248
Batch[5439] - loss: 0.000897 best_pearson: 0.7248
Batch[5440] - loss: 0.000787 best_pearson: 0.7248
Batch[5441] - loss: 0.000793 best_pearson: 0.7248
Batch[5442] - loss: 0.000917 best_pearson: 0.7248
Batch[5443] - loss: 0.001420 best_pearson: 0.7248
Batch[5444] - loss: 0.000916 best_pearson: 0.7248
Batch[5445] - loss: 0.000740 best_pearson: 0.7248
Batch[5446] - loss: 0.000974 best_pearson: 0.7248
Batch[5447] - loss: 0.000689 best_pearson: 0.7248
Batch[5448] - loss: 0.000571 best_pearson: 0.7248
Batch[5449] - loss: 0.000983 best_pearson: 0.7248
Batch[5450] - loss: 0.001201 best_pearson: 0.7248
Batch[5451] - loss: 0.000547 best_pearson: 0.7248
Batch[5452] - loss: 0.000948 best_pearson: 0.7248
Batch[5453] - loss: 0.001096 best_pearson: 0.7248
Batch[5454] - loss: 0.000766 best_pearson: 0.7248
Batch[5455] - loss: 0.001098 best_pearson: 0.7248
Batch[5456] - loss: 0.000589 best_pearson: 0.7248
Batch[5457] - loss: 0.000614 best_pearson: 0.7248
Batch[5458] - loss: 0.001258 best_pearson: 0.7248
Batch[5459] - loss: 0.000999 best_pearson: 0.7248
Batch[5460] - loss: 0.000592 best_pearson: 0.7248
Batch[5461] - loss: 0.000956 best_pearson: 0.7248
Batch[5462] - loss: 0.000922 best_pearson: 0.7248
Batch[5463] - loss: 0.000851 best_pearson: 0.7248
Batch[5464] - loss: 0.001148 best_pearson: 0.7248
Batch[5465] - loss: 0.000931 best_pearson: 0.7248
Batch[5466] - loss: 0.000580 best_pearson: 0.7248
Batch[5467] - loss: 0.000748 best_pearson: 0.7248
Batch[5468] - loss: 0.000557 best_pearson: 0.7248
Batch[5469] - loss: 0.001231 best_pearson: 0.7248
Batch[5470] - loss: 0.000916 best_pearson: 0.7248
Batch[5471] - loss: 0.001001 best_pearson: 0.7248
Batch[5472] - loss: 0.000552 best_pearson: 0.7248
Batch[5473] - loss: 0.001372 best_pearson: 0.7248
Batch[5474] - loss: 0.000889 best_pearson: 0.7248
Batch[5475] - loss: 0.000604 best_pearson: 0.7248
Batch[5476] - loss: 0.000889 best_pearson: 0.7248
Batch[5477] - loss: 0.001024 best_pearson: 0.7248
Batch[5478] - loss: 0.000986 best_pearson: 0.7248
Batch[5479] - loss: 0.000487 best_pearson: 0.7248
Batch[5480] - loss: 0.001779 best_pearson: 0.7248
Batch[5481] - loss: 0.000669 best_pearson: 0.7248
Batch[5482] - loss: 0.000980 best_pearson: 0.7248
Batch[5483] - loss: 0.000569 best_pearson: 0.7248
Batch[5484] - loss: 0.001187 best_pearson: 0.7248
Batch[5485] - loss: 0.000947 best_pearson: 0.7248
Batch[5486] - loss: 0.000844 best_pearson: 0.7248
Batch[5487] - loss: 0.001074 best_pearson: 0.7248
Batch[5488] - loss: 0.000818 best_pearson: 0.7248
Batch[5489] - loss: 0.001084 best_pearson: 0.7248
Batch[5490] - loss: 0.001148 best_pearson: 0.7248
Batch[5491] - loss: 0.000847 best_pearson: 0.7248
Batch[5492] - loss: 0.000727 best_pearson: 0.7248
Batch[5493] - loss: 0.001124 best_pearson: 0.7248
Batch[5494] - loss: 0.000806 best_pearson: 0.7248
Batch[5495] - loss: 0.000485 best_pearson: 0.7248
Batch[5496] - loss: 0.001264 best_pearson: 0.7248
Batch[5497] - loss: 0.000745 best_pearson: 0.7248
Batch[5498] - loss: 0.001590 best_pearson: 0.7248
Batch[5499] - loss: 0.001051 best_pearson: 0.7248
Batch[5500] - loss: 0.001697 best_pearson: 0.7248

Evaluation - loss: 0.000046 pearson: 0.7216 

Batch[5501] - loss: 0.000722 best_pearson: 0.7248
Batch[5502] - loss: 0.000925 best_pearson: 0.7248
Batch[5503] - loss: 0.000745 best_pearson: 0.7248
Batch[5504] - loss: 0.001041 best_pearson: 0.7248
Batch[5505] - loss: 0.000832 best_pearson: 0.7248
Batch[5506] - loss: 0.000967 best_pearson: 0.7248
Batch[5507] - loss: 0.000837 best_pearson: 0.7248
Batch[5508] - loss: 0.000610 best_pearson: 0.7248
Batch[5509] - loss: 0.001330 best_pearson: 0.7248
Batch[5510] - loss: 0.000648 best_pearson: 0.7248
Batch[5511] - loss: 0.001156 best_pearson: 0.7248
Batch[5512] - loss: 0.001086 best_pearson: 0.7248
Batch[5513] - loss: 0.000495 best_pearson: 0.7248
Batch[5514] - loss: 0.001278 best_pearson: 0.7248
Batch[5515] - loss: 0.001082 best_pearson: 0.7248
Batch[5516] - loss: 0.000929 best_pearson: 0.7248
Batch[5517] - loss: 0.001477 best_pearson: 0.7248
Batch[5518] - loss: 0.001452 best_pearson: 0.7248
Batch[5519] - loss: 0.001154 best_pearson: 0.7248
Batch[5520] - loss: 0.002009 best_pearson: 0.7248
Batch[5521] - loss: 0.000724 best_pearson: 0.7248
Batch[5522] - loss: 0.000594 best_pearson: 0.7248
Batch[5523] - loss: 0.001388 best_pearson: 0.7248
Batch[5524] - loss: 0.000888 best_pearson: 0.7248
Batch[5525] - loss: 0.000586 best_pearson: 0.7248
Batch[5526] - loss: 0.001499 best_pearson: 0.7248
Batch[5527] - loss: 0.000516 best_pearson: 0.7248
Batch[5528] - loss: 0.000598 best_pearson: 0.7248
Batch[5529] - loss: 0.001009 best_pearson: 0.7248
Batch[5530] - loss: 0.000786 best_pearson: 0.7248
Batch[5531] - loss: 0.001812 best_pearson: 0.7248
Batch[5532] - loss: 0.000775 best_pearson: 0.7248
Batch[5533] - loss: 0.000688 best_pearson: 0.7248
Batch[5534] - loss: 0.001142 best_pearson: 0.7248
Batch[5535] - loss: 0.000484 best_pearson: 0.7248
Batch[5536] - loss: 0.000989 best_pearson: 0.7248
Batch[5537] - loss: 0.000409 best_pearson: 0.7248
Batch[5538] - loss: 0.001077 best_pearson: 0.7248
Batch[5539] - loss: 0.001334 best_pearson: 0.7248
Batch[5540] - loss: 0.000818 best_pearson: 0.7248
Batch[5541] - loss: 0.000666 best_pearson: 0.7248
Batch[5542] - loss: 0.000883 best_pearson: 0.7248
Batch[5543] - loss: 0.001410 best_pearson: 0.7248
Batch[5544] - loss: 0.000992 best_pearson: 0.7248
Batch[5545] - loss: 0.001037 best_pearson: 0.7248
Batch[5546] - loss: 0.001293 best_pearson: 0.7248
Batch[5547] - loss: 0.001272 best_pearson: 0.7248
Batch[5548] - loss: 0.001964 best_pearson: 0.7248
Batch[5549] - loss: 0.000652 best_pearson: 0.7248
Batch[5550] - loss: 0.000939 best_pearson: 0.7248
Batch[5551] - loss: 0.000926 best_pearson: 0.7248
Batch[5552] - loss: 0.001213 best_pearson: 0.7248
Batch[5553] - loss: 0.001103 best_pearson: 0.7248
Batch[5554] - loss: 0.000780 best_pearson: 0.7248
Batch[5555] - loss: 0.001088 best_pearson: 0.7248
Batch[5556] - loss: 0.000897 best_pearson: 0.7248
Batch[5557] - loss: 0.000957 best_pearson: 0.7248
Batch[5558] - loss: 0.001535 best_pearson: 0.7248
Batch[5559] - loss: 0.000826 best_pearson: 0.7248
Batch[5560] - loss: 0.001327 best_pearson: 0.7248
Batch[5561] - loss: 0.000733 best_pearson: 0.7248
Batch[5562] - loss: 0.000405 best_pearson: 0.7248
Batch[5563] - loss: 0.001029 best_pearson: 0.7248
Batch[5564] - loss: 0.000831 best_pearson: 0.7248
Batch[5565] - loss: 0.001453 best_pearson: 0.7248
Batch[5566] - loss: 0.000761 best_pearson: 0.7248
Batch[5567] - loss: 0.001221 best_pearson: 0.7248
Batch[5568] - loss: 0.001646 best_pearson: 0.7248
Batch[5569] - loss: 0.001094 best_pearson: 0.7248
Batch[5570] - loss: 0.002057 best_pearson: 0.7248
Batch[5571] - loss: 0.002537 best_pearson: 0.7248
Batch[5572] - loss: 0.001210 best_pearson: 0.7248
Batch[5573] - loss: 0.001002 best_pearson: 0.7248
Batch[5574] - loss: 0.001242 best_pearson: 0.7248
Batch[5575] - loss: 0.002137 best_pearson: 0.7248
Batch[5576] - loss: 0.001172 best_pearson: 0.7248
Batch[5577] - loss: 0.000700 best_pearson: 0.7248
Batch[5578] - loss: 0.001297 best_pearson: 0.7248
Batch[5579] - loss: 0.001641 best_pearson: 0.7248
Batch[5580] - loss: 0.000697 best_pearson: 0.7248
Batch[5581] - loss: 0.000487 best_pearson: 0.7248
Batch[5582] - loss: 0.001136 best_pearson: 0.7248
Batch[5583] - loss: 0.000836 best_pearson: 0.7248
Batch[5584] - loss: 0.000637 best_pearson: 0.7248
Batch[5585] - loss: 0.000783 best_pearson: 0.7248
Batch[5586] - loss: 0.000480 best_pearson: 0.7248
Batch[5587] - loss: 0.001447 best_pearson: 0.7248
Batch[5588] - loss: 0.001170 best_pearson: 0.7248
Batch[5589] - loss: 0.001178 best_pearson: 0.7248
Batch[5590] - loss: 0.000870 best_pearson: 0.7248
Batch[5591] - loss: 0.002039 best_pearson: 0.7248
Batch[5592] - loss: 0.001384 best_pearson: 0.7248
Batch[5593] - loss: 0.001412 best_pearson: 0.7248
Batch[5594] - loss: 0.001637 best_pearson: 0.7248
Batch[5595] - loss: 0.001476 best_pearson: 0.7248
Batch[5596] - loss: 0.001047 best_pearson: 0.7248
Batch[5597] - loss: 0.000956 best_pearson: 0.7248
Batch[5598] - loss: 0.000604 best_pearson: 0.7248
Batch[5599] - loss: 0.000988 best_pearson: 0.7248
Batch[5600] - loss: 0.000796 best_pearson: 0.7248

Evaluation - loss: 0.000046 pearson: 0.7224 

Batch[5601] - loss: 0.000899 best_pearson: 0.7248
Batch[5602] - loss: 0.000951 best_pearson: 0.7248
Batch[5603] - loss: 0.001879 best_pearson: 0.7248
Batch[5604] - loss: 0.001087 best_pearson: 0.7248
Batch[5605] - loss: 0.000870 best_pearson: 0.7248
Batch[5606] - loss: 0.000848 best_pearson: 0.7248
Batch[5607] - loss: 0.001095 best_pearson: 0.7248
Batch[5608] - loss: 0.001092 best_pearson: 0.7248
Batch[5609] - loss: 0.001160 best_pearson: 0.7248
Batch[5610] - loss: 0.001243 best_pearson: 0.7248
Batch[5611] - loss: 0.001045 best_pearson: 0.7248
Batch[5612] - loss: 0.000854 best_pearson: 0.7248
Batch[5613] - loss: 0.000748 best_pearson: 0.7248
Batch[5614] - loss: 0.000981 best_pearson: 0.7248
Batch[5615] - loss: 0.000955 best_pearson: 0.7248
Batch[5616] - loss: 0.001111 best_pearson: 0.7248
Batch[5617] - loss: 0.001070 best_pearson: 0.7248
Batch[5618] - loss: 0.000894 best_pearson: 0.7248
Batch[5619] - loss: 0.001041 best_pearson: 0.7248
Batch[5620] - loss: 0.000668 best_pearson: 0.7248
Batch[5621] - loss: 0.000981 best_pearson: 0.7248
Batch[5622] - loss: 0.000598 best_pearson: 0.7248
Batch[5623] - loss: 0.000943 best_pearson: 0.7248
Batch[5624] - loss: 0.000819 best_pearson: 0.7248
Batch[5625] - loss: 0.001770 best_pearson: 0.7248
Batch[5626] - loss: 0.001199 best_pearson: 0.7248
Batch[5627] - loss: 0.001166 best_pearson: 0.7248
Batch[5628] - loss: 0.000923 best_pearson: 0.7248
Batch[5629] - loss: 0.000966 best_pearson: 0.7248
Batch[5630] - loss: 0.000501 best_pearson: 0.7248
Batch[5631] - loss: 0.001701 best_pearson: 0.7248
Batch[5632] - loss: 0.001633 best_pearson: 0.7248
Batch[5633] - loss: 0.001113 best_pearson: 0.7248
Batch[5634] - loss: 0.001991 best_pearson: 0.7248
Batch[5635] - loss: 0.000855 best_pearson: 0.7248
Batch[5636] - loss: 0.001080 best_pearson: 0.7248
Batch[5637] - loss: 0.000818 best_pearson: 0.7248
Batch[5638] - loss: 0.000799 best_pearson: 0.7248
Batch[5639] - loss: 0.001451 best_pearson: 0.7248
Batch[5640] - loss: 0.000550 best_pearson: 0.7248
Batch[5641] - loss: 0.000684 best_pearson: 0.7248
Batch[5642] - loss: 0.000502 best_pearson: 0.7248
Batch[5643] - loss: 0.001081 best_pearson: 0.7248
Batch[5644] - loss: 0.000921 best_pearson: 0.7248
Batch[5645] - loss: 0.001220 best_pearson: 0.7248
Batch[5646] - loss: 0.000913 best_pearson: 0.7248
Batch[5647] - loss: 0.001278 best_pearson: 0.7248
Batch[5648] - loss: 0.001070 best_pearson: 0.7248
Batch[5649] - loss: 0.000891 best_pearson: 0.7248
Batch[5650] - loss: 0.000733 best_pearson: 0.7248
Batch[5651] - loss: 0.000527 best_pearson: 0.7248
Batch[5652] - loss: 0.000929 best_pearson: 0.7248
Batch[5653] - loss: 0.001465 best_pearson: 0.7248
Batch[5654] - loss: 0.001096 best_pearson: 0.7248
Batch[5655] - loss: 0.001587 best_pearson: 0.7248
Batch[5656] - loss: 0.001110 best_pearson: 0.7248
Batch[5657] - loss: 0.000826 best_pearson: 0.7248
Batch[5658] - loss: 0.000595 best_pearson: 0.7248
Batch[5659] - loss: 0.000680 best_pearson: 0.7248
Batch[5660] - loss: 0.001100 best_pearson: 0.7248
Batch[5661] - loss: 0.000920 best_pearson: 0.7248
Batch[5662] - loss: 0.000903 best_pearson: 0.7248
Batch[5663] - loss: 0.000784 best_pearson: 0.7248
Batch[5664] - loss: 0.001234 best_pearson: 0.7248
Batch[5665] - loss: 0.001438 best_pearson: 0.7248
Batch[5666] - loss: 0.000864 best_pearson: 0.7248
Batch[5667] - loss: 0.000641 best_pearson: 0.7248
Batch[5668] - loss: 0.000978 best_pearson: 0.7248
Batch[5669] - loss: 0.000678 best_pearson: 0.7248
Batch[5670] - loss: 0.001081 best_pearson: 0.7248
Batch[5671] - loss: 0.000950 best_pearson: 0.7248
Batch[5672] - loss: 0.000768 best_pearson: 0.7248
Batch[5673] - loss: 0.002031 best_pearson: 0.7248
Batch[5674] - loss: 0.000922 best_pearson: 0.7248
Batch[5675] - loss: 0.000702 best_pearson: 0.7248
Batch[5676] - loss: 0.000640 best_pearson: 0.7248
Batch[5677] - loss: 0.001634 best_pearson: 0.7248
Batch[5678] - loss: 0.001443 best_pearson: 0.7248
Batch[5679] - loss: 0.001078 best_pearson: 0.7248
Batch[5680] - loss: 0.000766 best_pearson: 0.7248
Batch[5681] - loss: 0.000946 best_pearson: 0.7248
Batch[5682] - loss: 0.001010 best_pearson: 0.7248
Batch[5683] - loss: 0.001049 best_pearson: 0.7248
Batch[5684] - loss: 0.001159 best_pearson: 0.7248
Batch[5685] - loss: 0.001326 best_pearson: 0.7248
Batch[5686] - loss: 0.000966 best_pearson: 0.7248
Batch[5687] - loss: 0.000622 best_pearson: 0.7248
Batch[5688] - loss: 0.001110 best_pearson: 0.7248
Batch[5689] - loss: 0.000854 best_pearson: 0.7248
Batch[5690] - loss: 0.001194 best_pearson: 0.7248
Batch[5691] - loss: 0.000491 best_pearson: 0.7248
Batch[5692] - loss: 0.001156 best_pearson: 0.7248
Batch[5693] - loss: 0.000575 best_pearson: 0.7248
Batch[5694] - loss: 0.001343 best_pearson: 0.7248
Batch[5695] - loss: 0.000638 best_pearson: 0.7248
Batch[5696] - loss: 0.001208 best_pearson: 0.7248
Batch[5697] - loss: 0.000636 best_pearson: 0.7248
Batch[5698] - loss: 0.000650 best_pearson: 0.7248
Batch[5699] - loss: 0.002069 best_pearson: 0.7248
Batch[5700] - loss: 0.000549 best_pearson: 0.7248

Evaluation - loss: 0.000047 pearson: 0.7169 

Batch[5701] - loss: 0.001586 best_pearson: 0.7248
Batch[5702] - loss: 0.000792 best_pearson: 0.7248
Batch[5703] - loss: 0.000676 best_pearson: 0.7248
Batch[5704] - loss: 0.000590 best_pearson: 0.7248
Batch[5705] - loss: 0.000782 best_pearson: 0.7248
Batch[5706] - loss: 0.000783 best_pearson: 0.7248
Batch[5707] - loss: 0.000829 best_pearson: 0.7248
Batch[5708] - loss: 0.000752 best_pearson: 0.7248
Batch[5709] - loss: 0.001088 best_pearson: 0.7248
Batch[5710] - loss: 0.000966 best_pearson: 0.7248
Batch[5711] - loss: 0.000695 best_pearson: 0.7248
Batch[5712] - loss: 0.001029 best_pearson: 0.7248
Batch[5713] - loss: 0.001099 best_pearson: 0.7248
Batch[5714] - loss: 0.001190 best_pearson: 0.7248
Batch[5715] - loss: 0.000783 best_pearson: 0.7248
Batch[5716] - loss: 0.001019 best_pearson: 0.7248
Batch[5717] - loss: 0.000958 best_pearson: 0.7248
Batch[5718] - loss: 0.000877 best_pearson: 0.7248
Batch[5719] - loss: 0.001328 best_pearson: 0.7248
Batch[5720] - loss: 0.000965 best_pearson: 0.7248
Batch[5721] - loss: 0.001002 best_pearson: 0.7248
Batch[5722] - loss: 0.001428 best_pearson: 0.7248
Batch[5723] - loss: 0.000641 best_pearson: 0.7248
Batch[5724] - loss: 0.000676 best_pearson: 0.7248
Batch[5725] - loss: 0.001184 best_pearson: 0.7248
Batch[5726] - loss: 0.000580 best_pearson: 0.7248
Batch[5727] - loss: 0.000981 best_pearson: 0.7248
Batch[5728] - loss: 0.001156 best_pearson: 0.7248
Batch[5729] - loss: 0.000764 best_pearson: 0.7248
Batch[5730] - loss: 0.000713 best_pearson: 0.7248
Batch[5731] - loss: 0.000990 best_pearson: 0.7248
Batch[5732] - loss: 0.000673 best_pearson: 0.7248
Batch[5733] - loss: 0.000902 best_pearson: 0.7248
Batch[5734] - loss: 0.000548 best_pearson: 0.7248
Batch[5735] - loss: 0.001105 best_pearson: 0.7248
Batch[5736] - loss: 0.000756 best_pearson: 0.7248
Batch[5737] - loss: 0.000983 best_pearson: 0.7248
Batch[5738] - loss: 0.001152 best_pearson: 0.7248
Batch[5739] - loss: 0.001239 best_pearson: 0.7248
Batch[5740] - loss: 0.001139 best_pearson: 0.7248
Batch[5741] - loss: 0.000642 best_pearson: 0.7248
Batch[5742] - loss: 0.000410 best_pearson: 0.7248
Batch[5743] - loss: 0.001349 best_pearson: 0.7248
Batch[5744] - loss: 0.000726 best_pearson: 0.7248
Batch[5745] - loss: 0.001275 best_pearson: 0.7248
Batch[5746] - loss: 0.000652 best_pearson: 0.7248
Batch[5747] - loss: 0.000986 best_pearson: 0.7248
Batch[5748] - loss: 0.000606 best_pearson: 0.7248
Batch[5749] - loss: 0.000864 best_pearson: 0.7248
Batch[5750] - loss: 0.000963 best_pearson: 0.7248
Batch[5751] - loss: 0.001193 best_pearson: 0.7248
Batch[5752] - loss: 0.000568 best_pearson: 0.7248
Batch[5753] - loss: 0.000656 best_pearson: 0.7248
Batch[5754] - loss: 0.000891 best_pearson: 0.7248
Batch[5755] - loss: 0.001271 best_pearson: 0.7248
Batch[5756] - loss: 0.000889 best_pearson: 0.7248
Batch[5757] - loss: 0.000998 best_pearson: 0.7248
Batch[5758] - loss: 0.001143 best_pearson: 0.7248
Batch[5759] - loss: 0.001668 best_pearson: 0.7248
Batch[5760] - loss: 0.001938 best_pearson: 0.7248
Batch[5761] - loss: 0.001018 best_pearson: 0.7248
Batch[5762] - loss: 0.000857 best_pearson: 0.7248
Batch[5763] - loss: 0.000689 best_pearson: 0.7248
Batch[5764] - loss: 0.001494 best_pearson: 0.7248
Batch[5765] - loss: 0.000674 best_pearson: 0.7248
Batch[5766] - loss: 0.000703 best_pearson: 0.7248
Batch[5767] - loss: 0.000888 best_pearson: 0.7248
Batch[5768] - loss: 0.000912 best_pearson: 0.7248
Batch[5769] - loss: 0.000762 best_pearson: 0.7248
Batch[5770] - loss: 0.000512 best_pearson: 0.7248
Batch[5771] - loss: 0.000931 best_pearson: 0.7248
Batch[5772] - loss: 0.000906 best_pearson: 0.7248
Batch[5773] - loss: 0.000799 best_pearson: 0.7248
Batch[5774] - loss: 0.001605 best_pearson: 0.7248
Batch[5775] - loss: 0.000622 best_pearson: 0.7248
Batch[5776] - loss: 0.001563 best_pearson: 0.7248
Batch[5777] - loss: 0.000782 best_pearson: 0.7248
Batch[5778] - loss: 0.000751 best_pearson: 0.7248
Batch[5779] - loss: 0.000886 best_pearson: 0.7248
Batch[5780] - loss: 0.000652 best_pearson: 0.7248
Batch[5781] - loss: 0.000953 best_pearson: 0.7248
Batch[5782] - loss: 0.001071 best_pearson: 0.7248
Batch[5783] - loss: 0.000514 best_pearson: 0.7248
Batch[5784] - loss: 0.000570 best_pearson: 0.7248
Batch[5785] - loss: 0.000920 best_pearson: 0.7248
Batch[5786] - loss: 0.000700 best_pearson: 0.7248
Batch[5787] - loss: 0.000860 best_pearson: 0.7248
Batch[5788] - loss: 0.000903 best_pearson: 0.7248
Batch[5789] - loss: 0.000825 best_pearson: 0.7248
Batch[5790] - loss: 0.001225 best_pearson: 0.7248
Batch[5791] - loss: 0.000722 best_pearson: 0.7248
Batch[5792] - loss: 0.000857 best_pearson: 0.7248
Batch[5793] - loss: 0.000957 best_pearson: 0.7248
Batch[5794] - loss: 0.000729 best_pearson: 0.7248
Batch[5795] - loss: 0.000787 best_pearson: 0.7248
Batch[5796] - loss: 0.003651 best_pearson: 0.7248
Batch[5797] - loss: 0.000916 best_pearson: 0.7248
Batch[5798] - loss: 0.000950 best_pearson: 0.7248
Batch[5799] - loss: 0.001065 best_pearson: 0.7248
Batch[5800] - loss: 0.000917 best_pearson: 0.7248

Evaluation - loss: 0.000046 pearson: 0.7187 

Batch[5801] - loss: 0.000476 best_pearson: 0.7248
Batch[5802] - loss: 0.001138 best_pearson: 0.7248
Batch[5803] - loss: 0.000662 best_pearson: 0.7248
Batch[5804] - loss: 0.001229 best_pearson: 0.7248
Batch[5805] - loss: 0.001146 best_pearson: 0.7248
Batch[5806] - loss: 0.001045 best_pearson: 0.7248
Batch[5807] - loss: 0.001005 best_pearson: 0.7248
Batch[5808] - loss: 0.000387 best_pearson: 0.7248
Batch[5809] - loss: 0.001336 best_pearson: 0.7248
Batch[5810] - loss: 0.000614 best_pearson: 0.7248
Batch[5811] - loss: 0.000677 best_pearson: 0.7248
Batch[5812] - loss: 0.000982 best_pearson: 0.7248
Batch[5813] - loss: 0.001112 best_pearson: 0.7248
Batch[5814] - loss: 0.000926 best_pearson: 0.7248
Batch[5815] - loss: 0.000868 best_pearson: 0.7248
Batch[5816] - loss: 0.000499 best_pearson: 0.7248
Batch[5817] - loss: 0.000710 best_pearson: 0.7248
Batch[5818] - loss: 0.001241 best_pearson: 0.7248
Batch[5819] - loss: 0.001415 best_pearson: 0.7248
Batch[5820] - loss: 0.000932 best_pearson: 0.7248
Batch[5821] - loss: 0.000643 best_pearson: 0.7248
Batch[5822] - loss: 0.001075 best_pearson: 0.7248
Batch[5823] - loss: 0.000715 best_pearson: 0.7248
Batch[5824] - loss: 0.001025 best_pearson: 0.7248
Batch[5825] - loss: 0.001305 best_pearson: 0.7248
Batch[5826] - loss: 0.000949 best_pearson: 0.7248
Batch[5827] - loss: 0.000840 best_pearson: 0.7248
Batch[5828] - loss: 0.000817 best_pearson: 0.7248
Batch[5829] - loss: 0.000624 best_pearson: 0.7248
Batch[5830] - loss: 0.000926 best_pearson: 0.7248
Batch[5831] - loss: 0.000866 best_pearson: 0.7248
Batch[5832] - loss: 0.001122 best_pearson: 0.7248
Batch[5833] - loss: 0.000698 best_pearson: 0.7248
Batch[5834] - loss: 0.000788 best_pearson: 0.7248
Batch[5835] - loss: 0.000485 best_pearson: 0.7248
Batch[5836] - loss: 0.000618 best_pearson: 0.7248
Batch[5837] - loss: 0.000810 best_pearson: 0.7248
Batch[5838] - loss: 0.000807 best_pearson: 0.7248
Batch[5839] - loss: 0.000808 best_pearson: 0.7248
Batch[5840] - loss: 0.000865 best_pearson: 0.7248
Batch[5841] - loss: 0.001292 best_pearson: 0.7248
Batch[5842] - loss: 0.000666 best_pearson: 0.7248
Batch[5843] - loss: 0.001449 best_pearson: 0.7248
Batch[5844] - loss: 0.001422 best_pearson: 0.7248
Batch[5845] - loss: 0.001933 best_pearson: 0.7248
Batch[5846] - loss: 0.000737 best_pearson: 0.7248
Batch[5847] - loss: 0.000533 best_pearson: 0.7248
Batch[5848] - loss: 0.000748 best_pearson: 0.7248
Batch[5849] - loss: 0.001299 best_pearson: 0.7248
Batch[5850] - loss: 0.001593 best_pearson: 0.7248
Batch[5851] - loss: 0.000801 best_pearson: 0.7248
Batch[5852] - loss: 0.000974 best_pearson: 0.7248
Batch[5853] - loss: 0.002462 best_pearson: 0.7248
Batch[5854] - loss: 0.000853 best_pearson: 0.7248
Batch[5855] - loss: 0.000946 best_pearson: 0.7248
Batch[5856] - loss: 0.000628 best_pearson: 0.7248
Batch[5857] - loss: 0.000994 best_pearson: 0.7248
Batch[5858] - loss: 0.001699 best_pearson: 0.7248
Batch[5859] - loss: 0.001449 best_pearson: 0.7248
Batch[5860] - loss: 0.000630 best_pearson: 0.7248
Batch[5861] - loss: 0.000952 best_pearson: 0.7248
Batch[5862] - loss: 0.001984 best_pearson: 0.7248
Batch[5863] - loss: 0.000667 best_pearson: 0.7248
Batch[5864] - loss: 0.000646 best_pearson: 0.7248
Batch[5865] - loss: 0.000374 best_pearson: 0.7248
Batch[5866] - loss: 0.000713 best_pearson: 0.7248
Batch[5867] - loss: 0.001697 best_pearson: 0.7248
Batch[5868] - loss: 0.000607 best_pearson: 0.7248
Batch[5869] - loss: 0.001560 best_pearson: 0.7248
Batch[5870] - loss: 0.000969 best_pearson: 0.7248
Batch[5871] - loss: 0.000711 best_pearson: 0.7248
Batch[5872] - loss: 0.001233 best_pearson: 0.7248
Batch[5873] - loss: 0.000770 best_pearson: 0.7248
Batch[5874] - loss: 0.000717 best_pearson: 0.7248
Batch[5875] - loss: 0.000415 best_pearson: 0.7248
Batch[5876] - loss: 0.000527 best_pearson: 0.7248
Batch[5877] - loss: 0.000529 best_pearson: 0.7248
Batch[5878] - loss: 0.000838 best_pearson: 0.7248
Batch[5879] - loss: 0.000743 best_pearson: 0.7248
Batch[5880] - loss: 0.001555 best_pearson: 0.7248
Batch[5881] - loss: 0.000823 best_pearson: 0.7248
Batch[5882] - loss: 0.000461 best_pearson: 0.7248
Batch[5883] - loss: 0.000436 best_pearson: 0.7248
Batch[5884] - loss: 0.000599 best_pearson: 0.7248
Batch[5885] - loss: 0.000872 best_pearson: 0.7248
Batch[5886] - loss: 0.001101 best_pearson: 0.7248
Batch[5887] - loss: 0.000757 best_pearson: 0.7248
Batch[5888] - loss: 0.001094 best_pearson: 0.7248
Batch[5889] - loss: 0.001272 best_pearson: 0.7248
Batch[5890] - loss: 0.001113 best_pearson: 0.7248
Batch[5891] - loss: 0.000743 best_pearson: 0.7248
Batch[5892] - loss: 0.000805 best_pearson: 0.7248
Batch[5893] - loss: 0.000614 best_pearson: 0.7248
Batch[5894] - loss: 0.000847 best_pearson: 0.7248
Batch[5895] - loss: 0.000613 best_pearson: 0.7248
Batch[5896] - loss: 0.001008 best_pearson: 0.7248
Batch[5897] - loss: 0.000520 best_pearson: 0.7248
Batch[5898] - loss: 0.000892 best_pearson: 0.7248
Batch[5899] - loss: 0.000702 best_pearson: 0.7248
Batch[5900] - loss: 0.000871 best_pearson: 0.7248

Evaluation - loss: 0.000046 pearson: 0.7191 

Batch[5901] - loss: 0.000976 best_pearson: 0.7248
Batch[5902] - loss: 0.001040 best_pearson: 0.7248
Batch[5903] - loss: 0.000979 best_pearson: 0.7248
Batch[5904] - loss: 0.001577 best_pearson: 0.7248
Batch[5905] - loss: 0.000678 best_pearson: 0.7248
Batch[5906] - loss: 0.001237 best_pearson: 0.7248
Batch[5907] - loss: 0.001082 best_pearson: 0.7248
Batch[5908] - loss: 0.000834 best_pearson: 0.7248
Batch[5909] - loss: 0.001007 best_pearson: 0.7248
Batch[5910] - loss: 0.001330 best_pearson: 0.7248
Batch[5911] - loss: 0.001011 best_pearson: 0.7248
Batch[5912] - loss: 0.000959 best_pearson: 0.7248
Batch[5913] - loss: 0.001482 best_pearson: 0.7248
Batch[5914] - loss: 0.001203 best_pearson: 0.7248
Batch[5915] - loss: 0.000579 best_pearson: 0.7248
Batch[5916] - loss: 0.001848 best_pearson: 0.7248
Batch[5917] - loss: 0.001770 best_pearson: 0.7248
Batch[5918] - loss: 0.001486 best_pearson: 0.7248
Batch[5919] - loss: 0.001907 best_pearson: 0.7248
Batch[5920] - loss: 0.001453 best_pearson: 0.7248
Batch[5921] - loss: 0.001385 best_pearson: 0.7248
Batch[5922] - loss: 0.000855 best_pearson: 0.7248
Batch[5923] - loss: 0.001033 best_pearson: 0.7248
Batch[5924] - loss: 0.002010 best_pearson: 0.7248
Batch[5925] - loss: 0.001159 best_pearson: 0.7248
Batch[5926] - loss: 0.000732 best_pearson: 0.7248
Batch[5927] - loss: 0.001526 best_pearson: 0.7248
Batch[5928] - loss: 0.001572 best_pearson: 0.7248
Batch[5929] - loss: 0.000886 best_pearson: 0.7248
Batch[5930] - loss: 0.001405 best_pearson: 0.7248
Batch[5931] - loss: 0.001031 best_pearson: 0.7248
Batch[5932] - loss: 0.001311 best_pearson: 0.7248
Batch[5933] - loss: 0.001001 best_pearson: 0.7248
Batch[5934] - loss: 0.001363 best_pearson: 0.7248
Batch[5935] - loss: 0.001247 best_pearson: 0.7248
Batch[5936] - loss: 0.001392 best_pearson: 0.7248
Batch[5937] - loss: 0.001018 best_pearson: 0.7248
Batch[5938] - loss: 0.002347 best_pearson: 0.7248
Batch[5939] - loss: 0.001483 best_pearson: 0.7248
Batch[5940] - loss: 0.001157 best_pearson: 0.7248
Batch[5941] - loss: 0.001049 best_pearson: 0.7248
Batch[5942] - loss: 0.000970 best_pearson: 0.7248
Batch[5943] - loss: 0.000818 best_pearson: 0.7248
Batch[5944] - loss: 0.001105 best_pearson: 0.7248
Batch[5945] - loss: 0.000730 best_pearson: 0.7248
Batch[5946] - loss: 0.001100 best_pearson: 0.7248
Batch[5947] - loss: 0.000946 best_pearson: 0.7248
Batch[5948] - loss: 0.001620 best_pearson: 0.7248
Batch[5949] - loss: 0.000949 best_pearson: 0.7248
Batch[5950] - loss: 0.001277 best_pearson: 0.7248
Batch[5951] - loss: 0.001761 best_pearson: 0.7248
Batch[5952] - loss: 0.001235 best_pearson: 0.7248
Batch[5953] - loss: 0.001437 best_pearson: 0.7248
Batch[5954] - loss: 0.001393 best_pearson: 0.7248
Batch[5955] - loss: 0.000942 best_pearson: 0.7248
Batch[5956] - loss: 0.000957 best_pearson: 0.7248
Batch[5957] - loss: 0.001475 best_pearson: 0.7248
Batch[5958] - loss: 0.001052 best_pearson: 0.7248
Batch[5959] - loss: 0.001123 best_pearson: 0.7248
Batch[5960] - loss: 0.001368 best_pearson: 0.7248
Batch[5961] - loss: 0.001203 best_pearson: 0.7248
Batch[5962] - loss: 0.000783 best_pearson: 0.7248
Batch[5963] - loss: 0.001100 best_pearson: 0.7248
Batch[5964] - loss: 0.000751 best_pearson: 0.7248
Batch[5965] - loss: 0.001183 best_pearson: 0.7248
Batch[5966] - loss: 0.001297 best_pearson: 0.7248
Batch[5967] - loss: 0.001520 best_pearson: 0.7248
Batch[5968] - loss: 0.001033 best_pearson: 0.7248
Batch[5969] - loss: 0.001208 best_pearson: 0.7248
Batch[5970] - loss: 0.000629 best_pearson: 0.7248
Batch[5971] - loss: 0.001309 best_pearson: 0.7248
Batch[5972] - loss: 0.001746 best_pearson: 0.7248
Batch[5973] - loss: 0.000968 best_pearson: 0.7248
Batch[5974] - loss: 0.001067 best_pearson: 0.7248
Batch[5975] - loss: 0.001150 best_pearson: 0.7248
Batch[5976] - loss: 0.001229 best_pearson: 0.7248
Batch[5977] - loss: 0.001366 best_pearson: 0.7248
Batch[5978] - loss: 0.001038 best_pearson: 0.7248
Batch[5979] - loss: 0.002050 best_pearson: 0.7248
Batch[5980] - loss: 0.001479 best_pearson: 0.7248
Batch[5981] - loss: 0.002006 best_pearson: 0.7248
Batch[5982] - loss: 0.001395 best_pearson: 0.7248
Batch[5983] - loss: 0.001017 best_pearson: 0.7248
Batch[5984] - loss: 0.001750 best_pearson: 0.7248
Batch[5985] - loss: 0.000772 best_pearson: 0.7248
Batch[5986] - loss: 0.002587 best_pearson: 0.7248
Batch[5987] - loss: 0.001648 best_pearson: 0.7248
Batch[5988] - loss: 0.000688 best_pearson: 0.7248
Batch[5989] - loss: 0.001444 best_pearson: 0.7248
Batch[5990] - loss: 0.001285 best_pearson: 0.7248
Batch[5991] - loss: 0.001481 best_pearson: 0.7248
Batch[5992] - loss: 0.000966 best_pearson: 0.7248
Batch[5993] - loss: 0.001310 best_pearson: 0.7248
Batch[5994] - loss: 0.001308 best_pearson: 0.7248
Batch[5995] - loss: 0.001591 best_pearson: 0.7248
Batch[5996] - loss: 0.001592 best_pearson: 0.7248
Batch[5997] - loss: 0.000679 best_pearson: 0.7248
Batch[5998] - loss: 0.001360 best_pearson: 0.7248
Batch[5999] - loss: 0.001071 best_pearson: 0.7248
Batch[6000] - loss: 0.000847 best_pearson: 0.7248

Evaluation - loss: 0.000046 pearson: 0.7190 

Batch[6001] - loss: 0.000998 best_pearson: 0.7248
Batch[6002] - loss: 0.000825 best_pearson: 0.7248
Batch[6003] - loss: 0.000480 best_pearson: 0.7248
Batch[6004] - loss: 0.000873 best_pearson: 0.7248
Batch[6005] - loss: 0.000849 best_pearson: 0.7248
Batch[6006] - loss: 0.000905 best_pearson: 0.7248
Batch[6007] - loss: 0.000948 best_pearson: 0.7248
Batch[6008] - loss: 0.000953 best_pearson: 0.7248
Batch[6009] - loss: 0.001515 best_pearson: 0.7248
Batch[6010] - loss: 0.000953 best_pearson: 0.7248
Batch[6011] - loss: 0.001810 best_pearson: 0.7248
Batch[6012] - loss: 0.000837 best_pearson: 0.7248
Batch[6013] - loss: 0.000833 best_pearson: 0.7248
Batch[6014] - loss: 0.001890 best_pearson: 0.7248
Batch[6015] - loss: 0.001641 best_pearson: 0.7248
Batch[6016] - loss: 0.001268 best_pearson: 0.7248
Batch[6017] - loss: 0.001349 best_pearson: 0.7248
Batch[6018] - loss: 0.000766 best_pearson: 0.7248
Batch[6019] - loss: 0.000840 best_pearson: 0.7248
Batch[6020] - loss: 0.001723 best_pearson: 0.7248
Batch[6021] - loss: 0.001185 best_pearson: 0.7248
Batch[6022] - loss: 0.000677 best_pearson: 0.7248
Batch[6023] - loss: 0.001138 best_pearson: 0.7248
Batch[6024] - loss: 0.001484 best_pearson: 0.7248
Batch[6025] - loss: 0.000573 best_pearson: 0.7248
Batch[6026] - loss: 0.001407 best_pearson: 0.7248
Batch[6027] - loss: 0.000949 best_pearson: 0.7248
Batch[6028] - loss: 0.001062 best_pearson: 0.7248
Batch[6029] - loss: 0.001319 best_pearson: 0.7248
Batch[6030] - loss: 0.001389 best_pearson: 0.7248
Batch[6031] - loss: 0.000692 best_pearson: 0.7248
Batch[6032] - loss: 0.001133 best_pearson: 0.7248
Batch[6033] - loss: 0.001019 best_pearson: 0.7248
Batch[6034] - loss: 0.001925 best_pearson: 0.7248
Batch[6035] - loss: 0.000903 best_pearson: 0.7248
Batch[6036] - loss: 0.001316 best_pearson: 0.7248
Batch[6037] - loss: 0.001906 best_pearson: 0.7248
Batch[6038] - loss: 0.000768 best_pearson: 0.7248
Batch[6039] - loss: 0.000869 best_pearson: 0.7248
Batch[6040] - loss: 0.001999 best_pearson: 0.7248
Batch[6041] - loss: 0.001437 best_pearson: 0.7248
Batch[6042] - loss: 0.001020 best_pearson: 0.7248
Batch[6043] - loss: 0.000821 best_pearson: 0.7248
Batch[6044] - loss: 0.001488 best_pearson: 0.7248
Batch[6045] - loss: 0.001562 best_pearson: 0.7248
Batch[6046] - loss: 0.000962 best_pearson: 0.7248
Batch[6047] - loss: 0.001372 best_pearson: 0.7248
Batch[6048] - loss: 0.001560 best_pearson: 0.7248
Batch[6049] - loss: 0.001798 best_pearson: 0.7248
Batch[6050] - loss: 0.001473 best_pearson: 0.7248
Batch[6051] - loss: 0.001756 best_pearson: 0.7248
Batch[6052] - loss: 0.000847 best_pearson: 0.7248
Batch[6053] - loss: 0.001847 best_pearson: 0.7248
Batch[6054] - loss: 0.000825 best_pearson: 0.7248
Batch[6055] - loss: 0.001038 best_pearson: 0.7248
Batch[6056] - loss: 0.001217 best_pearson: 0.7248
Batch[6057] - loss: 0.001085 best_pearson: 0.7248
Batch[6058] - loss: 0.001081 best_pearson: 0.7248
Batch[6059] - loss: 0.001451 best_pearson: 0.7248
Batch[6060] - loss: 0.000827 best_pearson: 0.7248
Batch[6061] - loss: 0.001437 best_pearson: 0.7248
Batch[6062] - loss: 0.000791 best_pearson: 0.7248
Batch[6063] - loss: 0.001071 best_pearson: 0.7248
Batch[6064] - loss: 0.000799 best_pearson: 0.7248
Batch[6065] - loss: 0.001236 best_pearson: 0.7248
Batch[6066] - loss: 0.000932 best_pearson: 0.7248
Batch[6067] - loss: 0.001636 best_pearson: 0.7248
Batch[6068] - loss: 0.001345 best_pearson: 0.7248
Batch[6069] - loss: 0.001355 best_pearson: 0.7248
Batch[6070] - loss: 0.002183 best_pearson: 0.7248
Batch[6071] - loss: 0.001372 best_pearson: 0.7248
Batch[6072] - loss: 0.002099 best_pearson: 0.7248
Batch[6073] - loss: 0.000993 best_pearson: 0.7248
Batch[6074] - loss: 0.000854 best_pearson: 0.7248
Batch[6075] - loss: 0.000800 best_pearson: 0.7248
Batch[6076] - loss: 0.001002 best_pearson: 0.7248
Batch[6077] - loss: 0.000995 best_pearson: 0.7248
Batch[6078] - loss: 0.001286 best_pearson: 0.7248
Batch[6079] - loss: 0.000680 best_pearson: 0.7248
Batch[6080] - loss: 0.000612 best_pearson: 0.7248
Batch[6081] - loss: 0.000745 best_pearson: 0.7248
Batch[6082] - loss: 0.001715 best_pearson: 0.7248
Batch[6083] - loss: 0.000471 best_pearson: 0.7248
Batch[6084] - loss: 0.001319 best_pearson: 0.7248
Batch[6085] - loss: 0.001030 best_pearson: 0.7248
Batch[6086] - loss: 0.000991 best_pearson: 0.7248
Batch[6087] - loss: 0.001383 best_pearson: 0.7248
Batch[6088] - loss: 0.000741 best_pearson: 0.7248
Batch[6089] - loss: 0.000945 best_pearson: 0.7248
Batch[6090] - loss: 0.001179 best_pearson: 0.7248
Batch[6091] - loss: 0.000723 best_pearson: 0.7248
Batch[6092] - loss: 0.001931 best_pearson: 0.7248
Batch[6093] - loss: 0.000814 best_pearson: 0.7248
Batch[6094] - loss: 0.000853 best_pearson: 0.7248
Batch[6095] - loss: 0.001018 best_pearson: 0.7248
Batch[6096] - loss: 0.001141 best_pearson: 0.7248
Batch[6097] - loss: 0.001312 best_pearson: 0.7248
Batch[6098] - loss: 0.000833 best_pearson: 0.7248
Batch[6099] - loss: 0.001732 best_pearson: 0.7248
Batch[6100] - loss: 0.001604 best_pearson: 0.7248

Evaluation - loss: 0.000047 pearson: 0.7141 

Batch[6101] - loss: 0.001131 best_pearson: 0.7248
Batch[6102] - loss: 0.000788 best_pearson: 0.7248
Batch[6103] - loss: 0.001019 best_pearson: 0.7248
Batch[6104] - loss: 0.001046 best_pearson: 0.7248
Batch[6105] - loss: 0.001053 best_pearson: 0.7248
Batch[6106] - loss: 0.000912 best_pearson: 0.7248
Batch[6107] - loss: 0.001165 best_pearson: 0.7248
Batch[6108] - loss: 0.000873 best_pearson: 0.7248
Batch[6109] - loss: 0.000736 best_pearson: 0.7248
Batch[6110] - loss: 0.001447 best_pearson: 0.7248
Batch[6111] - loss: 0.001460 best_pearson: 0.7248
Batch[6112] - loss: 0.001085 best_pearson: 0.7248
Batch[6113] - loss: 0.001307 best_pearson: 0.7248
Batch[6114] - loss: 0.000788 best_pearson: 0.7248
Batch[6115] - loss: 0.000603 best_pearson: 0.7248
Batch[6116] - loss: 0.000791 best_pearson: 0.7248
Batch[6117] - loss: 0.001072 best_pearson: 0.7248
Batch[6118] - loss: 0.001141 best_pearson: 0.7248
Batch[6119] - loss: 0.001121 best_pearson: 0.7248
Batch[6120] - loss: 0.000974 best_pearson: 0.7248
Batch[6121] - loss: 0.001591 best_pearson: 0.7248
Batch[6122] - loss: 0.001912 best_pearson: 0.7248
Batch[6123] - loss: 0.001468 best_pearson: 0.7248
Batch[6124] - loss: 0.001156 best_pearson: 0.7248
Batch[6125] - loss: 0.001078 best_pearson: 0.7248
Batch[6126] - loss: 0.000705 best_pearson: 0.7248
Batch[6127] - loss: 0.001068 best_pearson: 0.7248
Batch[6128] - loss: 0.001088 best_pearson: 0.7248
Batch[6129] - loss: 0.000765 best_pearson: 0.7248
Batch[6130] - loss: 0.001185 best_pearson: 0.7248
Batch[6131] - loss: 0.001200 best_pearson: 0.7248
Batch[6132] - loss: 0.000993 best_pearson: 0.7248
Batch[6133] - loss: 0.001026 best_pearson: 0.7248
Batch[6134] - loss: 0.001196 best_pearson: 0.7248
Batch[6135] - loss: 0.000782 best_pearson: 0.7248
Batch[6136] - loss: 0.001527 best_pearson: 0.7248
Batch[6137] - loss: 0.001324 best_pearson: 0.7248
Batch[6138] - loss: 0.001277 best_pearson: 0.7248
Batch[6139] - loss: 0.000821 best_pearson: 0.7248
Batch[6140] - loss: 0.000669 best_pearson: 0.7248
Batch[6141] - loss: 0.000499 best_pearson: 0.7248
Batch[6142] - loss: 0.001033 best_pearson: 0.7248
Batch[6143] - loss: 0.000829 best_pearson: 0.7248
Batch[6144] - loss: 0.000668 best_pearson: 0.7248
Batch[6145] - loss: 0.000567 best_pearson: 0.7248
Batch[6146] - loss: 0.000973 best_pearson: 0.7248
Batch[6147] - loss: 0.000526 best_pearson: 0.7248
Batch[6148] - loss: 0.000863 best_pearson: 0.7248
Batch[6149] - loss: 0.001833 best_pearson: 0.7248
Batch[6150] - loss: 0.000755 best_pearson: 0.7248
Batch[6151] - loss: 0.001006 best_pearson: 0.7248
Batch[6152] - loss: 0.000976 best_pearson: 0.7248
Batch[6153] - loss: 0.001153 best_pearson: 0.7248
Batch[6154] - loss: 0.000693 best_pearson: 0.7248
Batch[6155] - loss: 0.000685 best_pearson: 0.7248
Batch[6156] - loss: 0.000564 best_pearson: 0.7248
Batch[6157] - loss: 0.001168 best_pearson: 0.7248
Batch[6158] - loss: 0.001013 best_pearson: 0.7248
Batch[6159] - loss: 0.001133 best_pearson: 0.7248
Batch[6160] - loss: 0.001108 best_pearson: 0.7248
Batch[6161] - loss: 0.000713 best_pearson: 0.7248
Batch[6162] - loss: 0.001717 best_pearson: 0.7248
Batch[6163] - loss: 0.000654 best_pearson: 0.7248
Batch[6164] - loss: 0.001100 best_pearson: 0.7248
Batch[6165] - loss: 0.000916 best_pearson: 0.7248
Batch[6166] - loss: 0.000949 best_pearson: 0.7248
Batch[6167] - loss: 0.000917 best_pearson: 0.7248
Batch[6168] - loss: 0.001033 best_pearson: 0.7248
Batch[6169] - loss: 0.000698 best_pearson: 0.7248
Batch[6170] - loss: 0.001353 best_pearson: 0.7248
Batch[6171] - loss: 0.000887 best_pearson: 0.7248
Batch[6172] - loss: 0.000814 best_pearson: 0.7248
Batch[6173] - loss: 0.000935 best_pearson: 0.7248
Batch[6174] - loss: 0.000663 best_pearson: 0.7248
Batch[6175] - loss: 0.000871 best_pearson: 0.7248
Batch[6176] - loss: 0.000985 best_pearson: 0.7248
Batch[6177] - loss: 0.001148 best_pearson: 0.7248
Batch[6178] - loss: 0.001542 best_pearson: 0.7248
Batch[6179] - loss: 0.001191 best_pearson: 0.7248
Batch[6180] - loss: 0.000804 best_pearson: 0.7248
Batch[6181] - loss: 0.000694 best_pearson: 0.7248
Batch[6182] - loss: 0.000703 best_pearson: 0.7248
Batch[6183] - loss: 0.000741 best_pearson: 0.7248
Batch[6184] - loss: 0.000507 best_pearson: 0.7248
Batch[6185] - loss: 0.000887 best_pearson: 0.7248
Batch[6186] - loss: 0.000943 best_pearson: 0.7248
Batch[6187] - loss: 0.000773 best_pearson: 0.7248
Batch[6188] - loss: 0.001018 best_pearson: 0.7248
Batch[6189] - loss: 0.001267 best_pearson: 0.7248
Batch[6190] - loss: 0.000682 best_pearson: 0.7248
Batch[6191] - loss: 0.000821 best_pearson: 0.7248
Batch[6192] - loss: 0.000734 best_pearson: 0.7248
Batch[6193] - loss: 0.000424 best_pearson: 0.7248
Batch[6194] - loss: 0.000622 best_pearson: 0.7248
Batch[6195] - loss: 0.000782 best_pearson: 0.7248
Batch[6196] - loss: 0.001475 best_pearson: 0.7248
Batch[6197] - loss: 0.000720 best_pearson: 0.7248
Batch[6198] - loss: 0.000654 best_pearson: 0.7248
Batch[6199] - loss: 0.000905 best_pearson: 0.7248
Batch[6200] - loss: 0.001747 best_pearson: 0.7248

Evaluation - loss: 0.000046 pearson: 0.7175 

Batch[6201] - loss: 0.000560 best_pearson: 0.7248
Batch[6202] - loss: 0.001125 best_pearson: 0.7248
Batch[6203] - loss: 0.001214 best_pearson: 0.7248
Batch[6204] - loss: 0.001144 best_pearson: 0.7248
Batch[6205] - loss: 0.000625 best_pearson: 0.7248
Batch[6206] - loss: 0.000844 best_pearson: 0.7248
Batch[6207] - loss: 0.000691 best_pearson: 0.7248
Batch[6208] - loss: 0.001029 best_pearson: 0.7248
Batch[6209] - loss: 0.000994 best_pearson: 0.7248
Batch[6210] - loss: 0.000954 best_pearson: 0.7248
Batch[6211] - loss: 0.001493 best_pearson: 0.7248
Batch[6212] - loss: 0.000426 best_pearson: 0.7248
Batch[6213] - loss: 0.000622 best_pearson: 0.7248
Batch[6214] - loss: 0.000519 best_pearson: 0.7248
Batch[6215] - loss: 0.000543 best_pearson: 0.7248
Batch[6216] - loss: 0.001171 best_pearson: 0.7248
Batch[6217] - loss: 0.000577 best_pearson: 0.7248
Batch[6218] - loss: 0.000795 best_pearson: 0.7248
Batch[6219] - loss: 0.000802 best_pearson: 0.7248
Batch[6220] - loss: 0.000965 best_pearson: 0.7248
Batch[6221] - loss: 0.000572 best_pearson: 0.7248
Batch[6222] - loss: 0.000800 best_pearson: 0.7248
Batch[6223] - loss: 0.001403 best_pearson: 0.7248
Batch[6224] - loss: 0.001030 best_pearson: 0.7248
Batch[6225] - loss: 0.001068 best_pearson: 0.7248
Batch[6226] - loss: 0.001722 best_pearson: 0.7248
Batch[6227] - loss: 0.000623 best_pearson: 0.7248
Batch[6228] - loss: 0.000920 best_pearson: 0.7248
Batch[6229] - loss: 0.000791 best_pearson: 0.7248
Batch[6230] - loss: 0.000864 best_pearson: 0.7248
Batch[6231] - loss: 0.000729 best_pearson: 0.7248
Batch[6232] - loss: 0.000848 best_pearson: 0.7248
Batch[6233] - loss: 0.000769 best_pearson: 0.7248
Batch[6234] - loss: 0.000517 best_pearson: 0.7248
Batch[6235] - loss: 0.000816 best_pearson: 0.7248
Batch[6236] - loss: 0.001060 best_pearson: 0.7248
Batch[6237] - loss: 0.001156 best_pearson: 0.7248
Batch[6238] - loss: 0.000678 best_pearson: 0.7248
Batch[6239] - loss: 0.000473 best_pearson: 0.7248
Batch[6240] - loss: 0.001506 best_pearson: 0.7248
Batch[6241] - loss: 0.001271 best_pearson: 0.7248
Batch[6242] - loss: 0.000760 best_pearson: 0.7248
Batch[6243] - loss: 0.001203 best_pearson: 0.7248
Batch[6244] - loss: 0.000682 best_pearson: 0.7248
Batch[6245] - loss: 0.000937 best_pearson: 0.7248
Batch[6246] - loss: 0.001069 best_pearson: 0.7248
Batch[6247] - loss: 0.001770 best_pearson: 0.7248
Batch[6248] - loss: 0.000620 best_pearson: 0.7248
Batch[6249] - loss: 0.001109 best_pearson: 0.7248
Batch[6250] - loss: 0.001036 best_pearson: 0.7248
Batch[6251] - loss: 0.001284 best_pearson: 0.7248
Batch[6252] - loss: 0.000630 best_pearson: 0.7248
Batch[6253] - loss: 0.000871 best_pearson: 0.7248
Batch[6254] - loss: 0.001057 best_pearson: 0.7248
Batch[6255] - loss: 0.001417 best_pearson: 0.7248
Batch[6256] - loss: 0.000719 best_pearson: 0.7248
Batch[6257] - loss: 0.000632 best_pearson: 0.7248
Batch[6258] - loss: 0.000853 best_pearson: 0.7248
Batch[6259] - loss: 0.001417 best_pearson: 0.7248
Batch[6260] - loss: 0.000999 best_pearson: 0.7248
Batch[6261] - loss: 0.001004 best_pearson: 0.7248
Batch[6262] - loss: 0.000623 best_pearson: 0.7248
Batch[6263] - loss: 0.000689 best_pearson: 0.7248
Batch[6264] - loss: 0.000736 best_pearson: 0.7248
Batch[6265] - loss: 0.000752 best_pearson: 0.7248
Batch[6266] - loss: 0.001371 best_pearson: 0.7248
Batch[6267] - loss: 0.000997 best_pearson: 0.7248
Batch[6268] - loss: 0.000543 best_pearson: 0.7248
Batch[6269] - loss: 0.001408 best_pearson: 0.7248
Batch[6270] - loss: 0.000671 best_pearson: 0.7248
Batch[6271] - loss: 0.000521 best_pearson: 0.7248
Batch[6272] - loss: 0.001210 best_pearson: 0.7248
Batch[6273] - loss: 0.000901 best_pearson: 0.7248
Batch[6274] - loss: 0.000890 best_pearson: 0.7248
Batch[6275] - loss: 0.000765 best_pearson: 0.7248
Batch[6276] - loss: 0.000599 best_pearson: 0.7248
Batch[6277] - loss: 0.000992 best_pearson: 0.7248
Batch[6278] - loss: 0.001043 best_pearson: 0.7248
Batch[6279] - loss: 0.001158 best_pearson: 0.7248
Batch[6280] - loss: 0.000391 best_pearson: 0.7248
Batch[6281] - loss: 0.000560 best_pearson: 0.7248
Batch[6282] - loss: 0.000981 best_pearson: 0.7248
Batch[6283] - loss: 0.000964 best_pearson: 0.7248
Batch[6284] - loss: 0.000514 best_pearson: 0.7248
Batch[6285] - loss: 0.000817 best_pearson: 0.7248
Batch[6286] - loss: 0.000731 best_pearson: 0.7248
Batch[6287] - loss: 0.000914 best_pearson: 0.7248
Batch[6288] - loss: 0.000716 best_pearson: 0.7248
Batch[6289] - loss: 0.000843 best_pearson: 0.7248
Batch[6290] - loss: 0.000906 best_pearson: 0.7248
Batch[6291] - loss: 0.001192 best_pearson: 0.7248
Batch[6292] - loss: 0.000827 best_pearson: 0.7248
Batch[6293] - loss: 0.001378 best_pearson: 0.7248
Batch[6294] - loss: 0.000579 best_pearson: 0.7248
Batch[6295] - loss: 0.000738 best_pearson: 0.7248
Batch[6296] - loss: 0.000435 best_pearson: 0.7248
Batch[6297] - loss: 0.000651 best_pearson: 0.7248
Batch[6298] - loss: 0.001559 best_pearson: 0.7248
Batch[6299] - loss: 0.001014 best_pearson: 0.7248
Batch[6300] - loss: 0.000787 best_pearson: 0.7248

Evaluation - loss: 0.000047 pearson: 0.7161 

Batch[6301] - loss: 0.000702 best_pearson: 0.7248
Batch[6302] - loss: 0.000612 best_pearson: 0.7248
Batch[6303] - loss: 0.000403 best_pearson: 0.7248
Batch[6304] - loss: 0.000606 best_pearson: 0.7248
Batch[6305] - loss: 0.000621 best_pearson: 0.7248
Batch[6306] - loss: 0.001100 best_pearson: 0.7248
Batch[6307] - loss: 0.001242 best_pearson: 0.7248
Batch[6308] - loss: 0.001473 best_pearson: 0.7248
Batch[6309] - loss: 0.000645 best_pearson: 0.7248
Batch[6310] - loss: 0.001631 best_pearson: 0.7248
Batch[6311] - loss: 0.000909 best_pearson: 0.7248
Batch[6312] - loss: 0.000751 best_pearson: 0.7248
Batch[6313] - loss: 0.001796 best_pearson: 0.7248
Batch[6314] - loss: 0.000946 best_pearson: 0.7248
Batch[6315] - loss: 0.000793 best_pearson: 0.7248
Batch[6316] - loss: 0.000730 best_pearson: 0.7248
Batch[6317] - loss: 0.001940 best_pearson: 0.7248
Batch[6318] - loss: 0.000573 best_pearson: 0.7248
Batch[6319] - loss: 0.000632 best_pearson: 0.7248
Batch[6320] - loss: 0.000869 best_pearson: 0.7248
Batch[6321] - loss: 0.001319 best_pearson: 0.7248
Batch[6322] - loss: 0.000701 best_pearson: 0.7248
Batch[6323] - loss: 0.000440 best_pearson: 0.7248
Batch[6324] - loss: 0.000804 best_pearson: 0.7248
Batch[6325] - loss: 0.000492 best_pearson: 0.7248
Batch[6326] - loss: 0.000478 best_pearson: 0.7248
Batch[6327] - loss: 0.000751 best_pearson: 0.7248
Batch[6328] - loss: 0.000624 best_pearson: 0.7248
Batch[6329] - loss: 0.001274 best_pearson: 0.7248
Batch[6330] - loss: 0.000569 best_pearson: 0.7248
Batch[6331] - loss: 0.001141 best_pearson: 0.7248
Batch[6332] - loss: 0.001001 best_pearson: 0.7248
Batch[6333] - loss: 0.001102 best_pearson: 0.7248
Batch[6334] - loss: 0.001147 best_pearson: 0.7248
Batch[6335] - loss: 0.001262 best_pearson: 0.7248
Batch[6336] - loss: 0.000931 best_pearson: 0.7248
Batch[6337] - loss: 0.001407 best_pearson: 0.7248
Batch[6338] - loss: 0.000760 best_pearson: 0.7248
Batch[6339] - loss: 0.000744 best_pearson: 0.7248
Batch[6340] - loss: 0.000908 best_pearson: 0.7248
Batch[6341] - loss: 0.000616 best_pearson: 0.7248
Batch[6342] - loss: 0.000556 best_pearson: 0.7248
Batch[6343] - loss: 0.000975 best_pearson: 0.7248
Batch[6344] - loss: 0.000803 best_pearson: 0.7248
Batch[6345] - loss: 0.000539 best_pearson: 0.7248
Batch[6346] - loss: 0.000661 best_pearson: 0.7248
Batch[6347] - loss: 0.000562 best_pearson: 0.7248
Batch[6348] - loss: 0.000889 best_pearson: 0.7248
Batch[6349] - loss: 0.000952 best_pearson: 0.7248
Batch[6350] - loss: 0.000689 best_pearson: 0.7248
Batch[6351] - loss: 0.001040 best_pearson: 0.7248
Batch[6352] - loss: 0.000875 best_pearson: 0.7248
Batch[6353] - loss: 0.000549 best_pearson: 0.7248
Batch[6354] - loss: 0.000501 best_pearson: 0.7248
Batch[6355] - loss: 0.000684 best_pearson: 0.7248
Batch[6356] - loss: 0.000993 best_pearson: 0.7248
Batch[6357] - loss: 0.000954 best_pearson: 0.7248
Batch[6358] - loss: 0.000860 best_pearson: 0.7248
Batch[6359] - loss: 0.001124 best_pearson: 0.7248
Batch[6360] - loss: 0.000696 best_pearson: 0.7248
Batch[6361] - loss: 0.001202 best_pearson: 0.7248
Batch[6362] - loss: 0.000775 best_pearson: 0.7248
Batch[6363] - loss: 0.000625 best_pearson: 0.7248
Batch[6364] - loss: 0.000719 best_pearson: 0.7248
Batch[6365] - loss: 0.000784 best_pearson: 0.7248
Batch[6366] - loss: 0.000543 best_pearson: 0.7248
Batch[6367] - loss: 0.000926 best_pearson: 0.7248
Batch[6368] - loss: 0.000942 best_pearson: 0.7248
Batch[6369] - loss: 0.000927 best_pearson: 0.7248
Batch[6370] - loss: 0.000987 best_pearson: 0.7248
Batch[6371] - loss: 0.001263 best_pearson: 0.7248
Batch[6372] - loss: 0.002064 best_pearson: 0.7248
Batch[6373] - loss: 0.000637 best_pearson: 0.7248
Batch[6374] - loss: 0.000716 best_pearson: 0.7248
Batch[6375] - loss: 0.000780 best_pearson: 0.7248
Batch[6376] - loss: 0.000732 best_pearson: 0.7248
Batch[6377] - loss: 0.000723 best_pearson: 0.7248
Batch[6378] - loss: 0.000655 best_pearson: 0.7248
Batch[6379] - loss: 0.001096 best_pearson: 0.7248
Batch[6380] - loss: 0.000676 best_pearson: 0.7248
Batch[6381] - loss: 0.001119 best_pearson: 0.7248
Batch[6382] - loss: 0.000939 best_pearson: 0.7248
Batch[6383] - loss: 0.001246 best_pearson: 0.7248
Batch[6384] - loss: 0.000683 best_pearson: 0.7248
Batch[6385] - loss: 0.000557 best_pearson: 0.7248
Batch[6386] - loss: 0.001428 best_pearson: 0.7248
Batch[6387] - loss: 0.000845 best_pearson: 0.7248
Batch[6388] - loss: 0.000976 best_pearson: 0.7248
Batch[6389] - loss: 0.001288 best_pearson: 0.7248
Batch[6390] - loss: 0.000770 best_pearson: 0.7248
Batch[6391] - loss: 0.000788 best_pearson: 0.7248
Batch[6392] - loss: 0.000634 best_pearson: 0.7248
Batch[6393] - loss: 0.000526 best_pearson: 0.7248
Batch[6394] - loss: 0.000654 best_pearson: 0.7248
Batch[6395] - loss: 0.001010 best_pearson: 0.7248
Batch[6396] - loss: 0.000847 best_pearson: 0.7248
Batch[6397] - loss: 0.000541 best_pearson: 0.7248
Batch[6398] - loss: 0.000698 best_pearson: 0.7248
Batch[6399] - loss: 0.001156 best_pearson: 0.7248
Batch[6400] - loss: 0.000680 best_pearson: 0.7248

Evaluation - loss: 0.000046 pearson: 0.7199 

Batch[6401] - loss: 0.000646 best_pearson: 0.7248
Batch[6402] - loss: 0.000562 best_pearson: 0.7248
Batch[6403] - loss: 0.001355 best_pearson: 0.7248
Batch[6404] - loss: 0.001357 best_pearson: 0.7248
Batch[6405] - loss: 0.001724 best_pearson: 0.7248
Batch[6406] - loss: 0.000988 best_pearson: 0.7248
Batch[6407] - loss: 0.000736 best_pearson: 0.7248
Batch[6408] - loss: 0.001113 best_pearson: 0.7248
Batch[6409] - loss: 0.001959 best_pearson: 0.7248
Batch[6410] - loss: 0.001001 best_pearson: 0.7248
Batch[6411] - loss: 0.000811 best_pearson: 0.7248
Batch[6412] - loss: 0.001966 best_pearson: 0.7248
Batch[6413] - loss: 0.001436 best_pearson: 0.7248
Batch[6414] - loss: 0.001310 best_pearson: 0.7248
Batch[6415] - loss: 0.001581 best_pearson: 0.7248
Batch[6416] - loss: 0.001458 best_pearson: 0.7248
Batch[6417] - loss: 0.002987 best_pearson: 0.7248
Batch[6418] - loss: 0.000457 best_pearson: 0.7248
Batch[6419] - loss: 0.001052 best_pearson: 0.7248
Batch[6420] - loss: 0.001940 best_pearson: 0.7248
Batch[6421] - loss: 0.001982 best_pearson: 0.7248
Batch[6422] - loss: 0.001006 best_pearson: 0.7248
Batch[6423] - loss: 0.001176 best_pearson: 0.7248
Batch[6424] - loss: 0.002685 best_pearson: 0.7248
Batch[6425] - loss: 0.001331 best_pearson: 0.7248
Batch[6426] - loss: 0.001334 best_pearson: 0.7248
Batch[6427] - loss: 0.000832 best_pearson: 0.7248
Batch[6428] - loss: 0.001343 best_pearson: 0.7248
Batch[6429] - loss: 0.002544 best_pearson: 0.7248
Batch[6430] - loss: 0.000889 best_pearson: 0.7248
Batch[6431] - loss: 0.000732 best_pearson: 0.7248
Batch[6432] - loss: 0.001715 best_pearson: 0.7248
Batch[6433] - loss: 0.002603 best_pearson: 0.7248
Batch[6434] - loss: 0.001139 best_pearson: 0.7248
Batch[6435] - loss: 0.001005 best_pearson: 0.7248
Batch[6436] - loss: 0.000927 best_pearson: 0.7248
Batch[6437] - loss: 0.001538 best_pearson: 0.7248
Batch[6438] - loss: 0.001102 best_pearson: 0.7248
Batch[6439] - loss: 0.000644 best_pearson: 0.7248
Batch[6440] - loss: 0.000553 best_pearson: 0.7248
Batch[6441] - loss: 0.002027 best_pearson: 0.7248
Batch[6442] - loss: 0.001890 best_pearson: 0.7248
Batch[6443] - loss: 0.001129 best_pearson: 0.7248
Batch[6444] - loss: 0.000964 best_pearson: 0.7248
Batch[6445] - loss: 0.000969 best_pearson: 0.7248
Batch[6446] - loss: 0.002136 best_pearson: 0.7248
Batch[6447] - loss: 0.001141 best_pearson: 0.7248
Batch[6448] - loss: 0.001096 best_pearson: 0.7248
Batch[6449] - loss: 0.001190 best_pearson: 0.7248
Batch[6450] - loss: 0.001467 best_pearson: 0.7248
Batch[6451] - loss: 0.000499 best_pearson: 0.7248
Batch[6452] - loss: 0.001121 best_pearson: 0.7248
Batch[6453] - loss: 0.001261 best_pearson: 0.7248
Batch[6454] - loss: 0.000869 best_pearson: 0.7248
Batch[6455] - loss: 0.000911 best_pearson: 0.7248
Batch[6456] - loss: 0.000966 best_pearson: 0.7248
Batch[6457] - loss: 0.002046 best_pearson: 0.7248
Batch[6458] - loss: 0.000855 best_pearson: 0.7248
Batch[6459] - loss: 0.001046 best_pearson: 0.7248
Batch[6460] - loss: 0.001197 best_pearson: 0.7248
Batch[6461] - loss: 0.001125 best_pearson: 0.7248
Batch[6462] - loss: 0.000789 best_pearson: 0.7248
Batch[6463] - loss: 0.000987 best_pearson: 0.7248
Batch[6464] - loss: 0.001075 best_pearson: 0.7248
Batch[6465] - loss: 0.001282 best_pearson: 0.7248
Batch[6466] - loss: 0.001807 best_pearson: 0.7248
Batch[6467] - loss: 0.001485 best_pearson: 0.7248
Batch[6468] - loss: 0.000838 best_pearson: 0.7248
Batch[6469] - loss: 0.001331 best_pearson: 0.7248
Batch[6470] - loss: 0.001382 best_pearson: 0.7248
Batch[6471] - loss: 0.000988 best_pearson: 0.7248
Batch[6472] - loss: 0.001247 best_pearson: 0.7248
Batch[6473] - loss: 0.001164 best_pearson: 0.7248
Batch[6474] - loss: 0.001089 best_pearson: 0.7248
Batch[6475] - loss: 0.001083 best_pearson: 0.7248
Batch[6476] - loss: 0.001157 best_pearson: 0.7248
Batch[6477] - loss: 0.002061 best_pearson: 0.7248
Batch[6478] - loss: 0.001641 best_pearson: 0.7248
Batch[6479] - loss: 0.001155 best_pearson: 0.7248
Batch[6480] - loss: 0.001823 best_pearson: 0.7248
Batch[6481] - loss: 0.001052 best_pearson: 0.7248
Batch[6482] - loss: 0.000586 best_pearson: 0.7248
Batch[6483] - loss: 0.001076 best_pearson: 0.7248
Batch[6484] - loss: 0.000728 best_pearson: 0.7248
Batch[6485] - loss: 0.001405 best_pearson: 0.7248
Batch[6486] - loss: 0.000573 best_pearson: 0.7248
Batch[6487] - loss: 0.000740 best_pearson: 0.7248
Batch[6488] - loss: 0.000806 best_pearson: 0.7248
Batch[6489] - loss: 0.001397 best_pearson: 0.7248
Batch[6490] - loss: 0.000768 best_pearson: 0.7248
Batch[6491] - loss: 0.001009 best_pearson: 0.7248
Batch[6492] - loss: 0.001662 best_pearson: 0.7248
Batch[6493] - loss: 0.000974 best_pearson: 0.7248
Batch[6494] - loss: 0.001098 best_pearson: 0.7248
Batch[6495] - loss: 0.001907 best_pearson: 0.7248
Batch[6496] - loss: 0.001509 best_pearson: 0.7248
Batch[6497] - loss: 0.001367 best_pearson: 0.7248
Batch[6498] - loss: 0.001718 best_pearson: 0.7248
Batch[6499] - loss: 0.001256 best_pearson: 0.7248
Batch[6500] - loss: 0.000851 best_pearson: 0.7248

Evaluation - loss: 0.000046 pearson: 0.7191 

early stop by 1500 steps.
Batch[6501] - loss: 0.001281 best_pearson: 0.7248
Batch[6502] - loss: 0.000842 best_pearson: 0.7248
Batch[6503] - loss: 0.000934 best_pearson: 0.7248
Batch[6504] - loss: 0.001438 best_pearson: 0.7248
Batch[6505] - loss: 0.001823 best_pearson: 0.7248
Batch[6506] - loss: 0.001532 best_pearson: 0.7248
Batch[6507] - loss: 0.001205 best_pearson: 0.7248
Batch[6508] - loss: 0.001635 best_pearson: 0.7248
Batch[6509] - loss: 0.000960 best_pearson: 0.7248
Batch[6510] - loss: 0.002631 best_pearson: 0.7248
Batch[6511] - loss: 0.001659 best_pearson: 0.7248
Batch[6512] - loss: 0.001231 best_pearson: 0.7248
Batch[6513] - loss: 0.001363 best_pearson: 0.7248
Batch[6514] - loss: 0.001657 best_pearson: 0.7248
Batch[6515] - loss: 0.000649 best_pearson: 0.7248
Batch[6516] - loss: 0.001273 best_pearson: 0.7248
Batch[6517] - loss: 0.002253 best_pearson: 0.7248
Batch[6518] - loss: 0.002231 best_pearson: 0.7248
Batch[6519] - loss: 0.001823 best_pearson: 0.7248
Batch[6520] - loss: 0.001584 best_pearson: 0.7248
Batch[6521] - loss: 0.001112 best_pearson: 0.7248
Batch[6522] - loss: 0.000860 best_pearson: 0.7248
Batch[6523] - loss: 0.001420 best_pearson: 0.7248
Batch[6524] - loss: 0.000821 best_pearson: 0.7248
Batch[6525] - loss: 0.001361 best_pearson: 0.7248
Batch[6526] - loss: 0.001666 best_pearson: 0.7248
Batch[6527] - loss: 0.001609 best_pearson: 0.7248
Batch[6528] - loss: 0.001419 best_pearson: 0.7248
Batch[6529] - loss: 0.001232 best_pearson: 0.7248
Batch[6530] - loss: 0.001450 best_pearson: 0.7248
Batch[6531] - loss: 0.001363 best_pearson: 0.7248
Batch[6532] - loss: 0.000935 best_pearson: 0.7248
Batch[6533] - loss: 0.000845 best_pearson: 0.7248
Batch[6534] - loss: 0.001218 best_pearson: 0.7248
Batch[6535] - loss: 0.001594 best_pearson: 0.7248
Batch[6536] - loss: 0.001329 best_pearson: 0.7248
Batch[6537] - loss: 0.001088 best_pearson: 0.7248
Batch[6538] - loss: 0.001436 best_pearson: 0.7248
Batch[6539] - loss: 0.001283 best_pearson: 0.7248
Batch[6540] - loss: 0.001242 best_pearson: 0.7248
Batch[6541] - loss: 0.000707 best_pearson: 0.7248
Batch[6542] - loss: 0.001794 best_pearson: 0.7248
Batch[6543] - loss: 0.001597 best_pearson: 0.7248
Batch[6544] - loss: 0.001030 best_pearson: 0.7248
Batch[6545] - loss: 0.001397 best_pearson: 0.7248
Batch[6546] - loss: 0.001258 best_pearson: 0.7248
Batch[6547] - loss: 0.001729 best_pearson: 0.7248
Batch[6548] - loss: 0.001449 best_pearson: 0.7248
Batch[6549] - loss: 0.001375 best_pearson: 0.7248
Batch[6550] - loss: 0.001770 best_pearson: 0.7248
Batch[6551] - loss: 0.001376 best_pearson: 0.7248
Batch[6552] - loss: 0.001129 best_pearson: 0.7248
Batch[6553] - loss: 0.001178 best_pearson: 0.7248
Batch[6554] - loss: 0.001364 best_pearson: 0.7248
Batch[6555] - loss: 0.001172 best_pearson: 0.7248
Batch[6556] - loss: 0.001245 best_pearson: 0.7248
Batch[6557] - loss: 0.001030 best_pearson: 0.7248
Batch[6558] - loss: 0.000895 best_pearson: 0.7248
Batch[6559] - loss: 0.001055 best_pearson: 0.7248
Batch[6560] - loss: 0.000977 best_pearson: 0.7248
Batch[6561] - loss: 0.001003 best_pearson: 0.7248
Batch[6562] - loss: 0.000759 best_pearson: 0.7248
Batch[6563] - loss: 0.000972 best_pearson: 0.7248
Batch[6564] - loss: 0.000853 best_pearson: 0.7248
Batch[6565] - loss: 0.002015 best_pearson: 0.7248
Batch[6566] - loss: 0.001254 best_pearson: 0.7248
Batch[6567] - loss: 0.000737 best_pearson: 0.7248
Batch[6568] - loss: 0.000556 best_pearson: 0.7248
Batch[6569] - loss: 0.001119 best_pearson: 0.7248
Batch[6570] - loss: 0.001404 best_pearson: 0.7248
Batch[6571] - loss: 0.000521 best_pearson: 0.7248
Batch[6572] - loss: 0.001739 best_pearson: 0.7248
Batch[6573] - loss: 0.001218 best_pearson: 0.7248
Batch[6574] - loss: 0.000769 best_pearson: 0.7248
Batch[6575] - loss: 0.000799 best_pearson: 0.7248
Batch[6576] - loss: 0.000769 best_pearson: 0.7248
Batch[6577] - loss: 0.000941 best_pearson: 0.7248
Batch[6578] - loss: 0.000614 best_pearson: 0.7248
Batch[6579] - loss: 0.001137 best_pearson: 0.7248
Batch[6580] - loss: 0.000803 best_pearson: 0.7248
Batch[6581] - loss: 0.001521 best_pearson: 0.7248
Batch[6582] - loss: 0.000946 best_pearson: 0.7248
Batch[6583] - loss: 0.000764 best_pearson: 0.7248
Batch[6584] - loss: 0.001399 best_pearson: 0.7248
Batch[6585] - loss: 0.001241 best_pearson: 0.7248
Batch[6586] - loss: 0.001559 best_pearson: 0.7248
Batch[6587] - loss: 0.000812 best_pearson: 0.7248
Batch[6588] - loss: 0.001278 best_pearson: 0.7248
Batch[6589] - loss: 0.000772 best_pearson: 0.7248
Batch[6590] - loss: 0.001403 best_pearson: 0.7248
Batch[6591] - loss: 0.001162 best_pearson: 0.7248
Batch[6592] - loss: 0.000962 best_pearson: 0.7248
Batch[6593] - loss: 0.000831 best_pearson: 0.7248
Batch[6594] - loss: 0.001198 best_pearson: 0.7248
Batch[6595] - loss: 0.000873 best_pearson: 0.7248
Batch[6596] - loss: 0.001734 best_pearson: 0.7248
Batch[6597] - loss: 0.000681 best_pearson: 0.7248
Batch[6598] - loss: 0.000896 best_pearson: 0.7248
Batch[6599] - loss: 0.000947 best_pearson: 0.7248
Batch[6600] - loss: 0.001015 best_pearson: 0.7248

Evaluation - loss: 0.000048 pearson: 0.7158 

early stop by 1500 steps.
Batch[6601] - loss: 0.000953 best_pearson: 0.7248
Batch[6602] - loss: 0.001135 best_pearson: 0.7248
Batch[6603] - loss: 0.000647 best_pearson: 0.7248
Batch[6604] - loss: 0.000832 best_pearson: 0.7248
Batch[6605] - loss: 0.000916 best_pearson: 0.7248
Batch[6606] - loss: 0.000987 best_pearson: 0.7248
Batch[6607] - loss: 0.001220 best_pearson: 0.7248
Batch[6608] - loss: 0.000928 best_pearson: 0.7248
Batch[6609] - loss: 0.000872 best_pearson: 0.7248
Batch[6610] - loss: 0.001491 best_pearson: 0.7248
Batch[6611] - loss: 0.001061 best_pearson: 0.7248
Batch[6612] - loss: 0.000692 best_pearson: 0.7248
Batch[6613] - loss: 0.000766 best_pearson: 0.7248
Batch[6614] - loss: 0.000848 best_pearson: 0.7248
Batch[6615] - loss: 0.000789 best_pearson: 0.7248
Batch[6616] - loss: 0.000728 best_pearson: 0.7248
Batch[6617] - loss: 0.001007 best_pearson: 0.7248
Batch[6618] - loss: 0.001371 best_pearson: 0.7248
Batch[6619] - loss: 0.000913 best_pearson: 0.7248
Batch[6620] - loss: 0.000972 best_pearson: 0.7248
Batch[6621] - loss: 0.000835 best_pearson: 0.7248
Batch[6622] - loss: 0.000879 best_pearson: 0.7248
Batch[6623] - loss: 0.000764 best_pearson: 0.7248
Batch[6624] - loss: 0.001044 best_pearson: 0.7248
Batch[6625] - loss: 0.000982 best_pearson: 0.7248
Batch[6626] - loss: 0.000927 best_pearson: 0.7248
Batch[6627] - loss: 0.000822 best_pearson: 0.7248
Batch[6628] - loss: 0.000320 best_pearson: 0.7248
Batch[6629] - loss: 0.000489 best_pearson: 0.7248
Batch[6630] - loss: 0.000633 best_pearson: 0.7248
Batch[6631] - loss: 0.000649 best_pearson: 0.7248
Batch[6632] - loss: 0.000859 best_pearson: 0.7248
Batch[6633] - loss: 0.001025 best_pearson: 0.7248
Batch[6634] - loss: 0.000797 best_pearson: 0.7248
Batch[6635] - loss: 0.000674 best_pearson: 0.7248
Batch[6636] - loss: 0.000695 best_pearson: 0.7248
Batch[6637] - loss: 0.000612 best_pearson: 0.7248
Batch[6638] - loss: 0.000818 best_pearson: 0.7248
Batch[6639] - loss: 0.000802 best_pearson: 0.7248
Batch[6640] - loss: 0.000897 best_pearson: 0.7248
Batch[6641] - loss: 0.000570 best_pearson: 0.7248
Batch[6642] - loss: 0.000452 best_pearson: 0.7248
Batch[6643] - loss: 0.000724 best_pearson: 0.7248
Batch[6644] - loss: 0.000681 best_pearson: 0.7248
Batch[6645] - loss: 0.000580 best_pearson: 0.7248
Batch[6646] - loss: 0.001093 best_pearson: 0.7248
Batch[6647] - loss: 0.001463 best_pearson: 0.7248
Batch[6648] - loss: 0.000839 best_pearson: 0.7248
Batch[6649] - loss: 0.001299 best_pearson: 0.7248
Batch[6650] - loss: 0.000924 best_pearson: 0.7248
Batch[6651] - loss: 0.001558 best_pearson: 0.7248
Batch[6652] - loss: 0.000903 best_pearson: 0.7248
Batch[6653] - loss: 0.001008 best_pearson: 0.7248
Batch[6654] - loss: 0.000873 best_pearson: 0.7248
Batch[6655] - loss: 0.000829 best_pearson: 0.7248
Batch[6656] - loss: 0.000761 best_pearson: 0.7248
Batch[6657] - loss: 0.000882 best_pearson: 0.7248
Batch[6658] - loss: 0.000698 best_pearson: 0.7248
Batch[6659] - loss: 0.000752 best_pearson: 0.7248
Batch[6660] - loss: 0.000810 best_pearson: 0.7248
Batch[6661] - loss: 0.000955 best_pearson: 0.7248
Batch[6662] - loss: 0.001091 best_pearson: 0.7248
Batch[6663] - loss: 0.000940 best_pearson: 0.7248
Batch[6664] - loss: 0.001302 best_pearson: 0.7248
Batch[6665] - loss: 0.000828 best_pearson: 0.7248
Batch[6666] - loss: 0.001542 best_pearson: 0.7248
Batch[6667] - loss: 0.001021 best_pearson: 0.7248
Batch[6668] - loss: 0.000685 best_pearson: 0.7248
Batch[6669] - loss: 0.000462 best_pearson: 0.7248
Batch[6670] - loss: 0.000852 best_pearson: 0.7248
Batch[6671] - loss: 0.000722 best_pearson: 0.7248
Batch[6672] - loss: 0.000689 best_pearson: 0.7248
Batch[6673] - loss: 0.000683 best_pearson: 0.7248
Batch[6674] - loss: 0.000698 best_pearson: 0.7248
Batch[6675] - loss: 0.001102 best_pearson: 0.7248
Batch[6676] - loss: 0.000791 best_pearson: 0.7248
Batch[6677] - loss: 0.000705 best_pearson: 0.7248
Batch[6678] - loss: 0.001051 best_pearson: 0.7248
Batch[6679] - loss: 0.000966 best_pearson: 0.7248
Batch[6680] - loss: 0.001220 best_pearson: 0.7248
Batch[6681] - loss: 0.000900 best_pearson: 0.7248
Batch[6682] - loss: 0.001077 best_pearson: 0.7248
Batch[6683] - loss: 0.000650 best_pearson: 0.7248
Batch[6684] - loss: 0.000604 best_pearson: 0.7248
Batch[6685] - loss: 0.000816 best_pearson: 0.7248
Batch[6686] - loss: 0.000734 best_pearson: 0.7248
Batch[6687] - loss: 0.000843 best_pearson: 0.7248
Batch[6688] - loss: 0.000916 best_pearson: 0.7248
Batch[6689] - loss: 0.000752 best_pearson: 0.7248
Batch[6690] - loss: 0.000555 best_pearson: 0.7248
Batch[6691] - loss: 0.000641 best_pearson: 0.7248
Batch[6692] - loss: 0.000983 best_pearson: 0.7248
Batch[6693] - loss: 0.000453 best_pearson: 0.7248
Batch[6694] - loss: 0.000616 best_pearson: 0.7248
Batch[6695] - loss: 0.000835 best_pearson: 0.7248
Batch[6696] - loss: 0.000421 best_pearson: 0.7248
Batch[6697] - loss: 0.000528 best_pearson: 0.7248
Batch[6698] - loss: 0.000381 best_pearson: 0.7248
Batch[6699] - loss: 0.000575 best_pearson: 0.7248
Batch[6700] - loss: 0.000487 best_pearson: 0.7248

Evaluation - loss: 0.000046 pearson: 0.7162 

early stop by 1500 steps.
Batch[6701] - loss: 0.000930 best_pearson: 0.7248
Batch[6702] - loss: 0.000665 best_pearson: 0.7248
Batch[6703] - loss: 0.000735 best_pearson: 0.7248
Batch[6704] - loss: 0.000683 best_pearson: 0.7248
Batch[6705] - loss: 0.000815 best_pearson: 0.7248
Batch[6706] - loss: 0.001004 best_pearson: 0.7248
Batch[6707] - loss: 0.000784 best_pearson: 0.7248
Batch[6708] - loss: 0.000691 best_pearson: 0.7248
Batch[6709] - loss: 0.000427 best_pearson: 0.7248
Batch[6710] - loss: 0.000976 best_pearson: 0.7248
Batch[6711] - loss: 0.000579 best_pearson: 0.7248
Batch[6712] - loss: 0.000888 best_pearson: 0.7248
Batch[6713] - loss: 0.000966 best_pearson: 0.7248
Batch[6714] - loss: 0.000820 best_pearson: 0.7248
Batch[6715] - loss: 0.001044 best_pearson: 0.7248
Batch[6716] - loss: 0.000849 best_pearson: 0.7248
Batch[6717] - loss: 0.000870 best_pearson: 0.7248
Batch[6718] - loss: 0.000733 best_pearson: 0.7248
Batch[6719] - loss: 0.000754 best_pearson: 0.7248
Batch[6720] - loss: 0.000721 best_pearson: 0.7248
Batch[6721] - loss: 0.000642 best_pearson: 0.7248
Batch[6722] - loss: 0.000536 best_pearson: 0.7248
Batch[6723] - loss: 0.000674 best_pearson: 0.7248
Batch[6724] - loss: 0.000713 best_pearson: 0.7248
Batch[6725] - loss: 0.000467 best_pearson: 0.7248
Batch[6726] - loss: 0.000600 best_pearson: 0.7248
Batch[6727] - loss: 0.000662 best_pearson: 0.7248
Batch[6728] - loss: 0.000974 best_pearson: 0.7248
Batch[6729] - loss: 0.000739 best_pearson: 0.7248
Batch[6730] - loss: 0.001753 best_pearson: 0.7248
Batch[6731] - loss: 0.001249 best_pearson: 0.7248
Batch[6732] - loss: 0.000599 best_pearson: 0.7248
Batch[6733] - loss: 0.001388 best_pearson: 0.7248
Batch[6734] - loss: 0.000626 best_pearson: 0.7248
Batch[6735] - loss: 0.001221 best_pearson: 0.7248
Batch[6736] - loss: 0.001148 best_pearson: 0.7248
Batch[6737] - loss: 0.000629 best_pearson: 0.7248
Batch[6738] - loss: 0.000779 best_pearson: 0.7248
Batch[6739] - loss: 0.000550 best_pearson: 0.7248
Batch[6740] - loss: 0.000631 best_pearson: 0.7248
Batch[6741] - loss: 0.001012 best_pearson: 0.7248
Batch[6742] - loss: 0.000899 best_pearson: 0.7248
Batch[6743] - loss: 0.000907 best_pearson: 0.7248
Batch[6744] - loss: 0.000711 best_pearson: 0.7248
Batch[6745] - loss: 0.000709 best_pearson: 0.7248
Batch[6746] - loss: 0.000545 best_pearson: 0.7248
Batch[6747] - loss: 0.000838 best_pearson: 0.7248
Batch[6748] - loss: 0.000636 best_pearson: 0.7248
Batch[6749] - loss: 0.000563 best_pearson: 0.7248
Batch[6750] - loss: 0.000672 best_pearson: 0.7248
Batch[6751] - loss: 0.000967 best_pearson: 0.7248
Batch[6752] - loss: 0.001043 best_pearson: 0.7248
Batch[6753] - loss: 0.000747 best_pearson: 0.7248
Batch[6754] - loss: 0.000418 best_pearson: 0.7248
Batch[6755] - loss: 0.000935 best_pearson: 0.7248
Batch[6756] - loss: 0.001484 best_pearson: 0.7248
Batch[6757] - loss: 0.000719 best_pearson: 0.7248
Batch[6758] - loss: 0.000869 best_pearson: 0.7248
Batch[6759] - loss: 0.000904 best_pearson: 0.7248
Batch[6760] - loss: 0.000580 best_pearson: 0.7248
Batch[6761] - loss: 0.001237 best_pearson: 0.7248
Batch[6762] - loss: 0.001153 best_pearson: 0.7248
Batch[6763] - loss: 0.000422 best_pearson: 0.7248
Batch[6764] - loss: 0.000825 best_pearson: 0.7248
Batch[6765] - loss: 0.000862 best_pearson: 0.7248
Batch[6766] - loss: 0.000540 best_pearson: 0.7248
Batch[6767] - loss: 0.000660 best_pearson: 0.7248
Batch[6768] - loss: 0.001067 best_pearson: 0.7248
Batch[6769] - loss: 0.000688 best_pearson: 0.7248
Batch[6770] - loss: 0.000950 best_pearson: 0.7248
Batch[6771] - loss: 0.001289 best_pearson: 0.7248
Batch[6772] - loss: 0.000710 best_pearson: 0.7248
Batch[6773] - loss: 0.000751 best_pearson: 0.7248
Batch[6774] - loss: 0.000485 best_pearson: 0.7248
Batch[6775] - loss: 0.000806 best_pearson: 0.7248
Batch[6776] - loss: 0.000886 best_pearson: 0.7248
Batch[6777] - loss: 0.000624 best_pearson: 0.7248
Batch[6778] - loss: 0.001131 best_pearson: 0.7248
Batch[6779] - loss: 0.001328 best_pearson: 0.7248
Batch[6780] - loss: 0.000719 best_pearson: 0.7248
Batch[6781] - loss: 0.000607 best_pearson: 0.7248
Batch[6782] - loss: 0.000296 best_pearson: 0.7248
Batch[6783] - loss: 0.001026 best_pearson: 0.7248
Batch[6784] - loss: 0.000508 best_pearson: 0.7248
Batch[6785] - loss: 0.000649 best_pearson: 0.7248
Batch[6786] - loss: 0.000613 best_pearson: 0.7248
Batch[6787] - loss: 0.000580 best_pearson: 0.7248
Batch[6788] - loss: 0.000483 best_pearson: 0.7248
Batch[6789] - loss: 0.001171 best_pearson: 0.7248
Batch[6790] - loss: 0.000555 best_pearson: 0.7248
Batch[6791] - loss: 0.001008 best_pearson: 0.7248
Batch[6792] - loss: 0.000769 best_pearson: 0.7248
Batch[6793] - loss: 0.000916 best_pearson: 0.7248
Batch[6794] - loss: 0.000803 best_pearson: 0.7248
Batch[6795] - loss: 0.001047 best_pearson: 0.7248
Batch[6796] - loss: 0.000890 best_pearson: 0.7248
Batch[6797] - loss: 0.001030 best_pearson: 0.7248
Batch[6798] - loss: 0.000433 best_pearson: 0.7248
Batch[6799] - loss: 0.000546 best_pearson: 0.7248
Batch[6800] - loss: 0.000954 best_pearson: 0.7248

Evaluation - loss: 0.000048 pearson: 0.7161 

early stop by 1500 steps.
Batch[6801] - loss: 0.000630 best_pearson: 0.7248
Batch[6802] - loss: 0.000619 best_pearson: 0.7248
Batch[6803] - loss: 0.001154 best_pearson: 0.7248
Batch[6804] - loss: 0.000838 best_pearson: 0.7248
Batch[6805] - loss: 0.001331 best_pearson: 0.7248
Batch[6806] - loss: 0.001145 best_pearson: 0.7248
Batch[6807] - loss: 0.001577 best_pearson: 0.7248
Batch[6808] - loss: 0.000379 best_pearson: 0.7248
Batch[6809] - loss: 0.001182 best_pearson: 0.7248
Batch[6810] - loss: 0.001191 best_pearson: 0.7248
Batch[6811] - loss: 0.000763 best_pearson: 0.7248
Batch[6812] - loss: 0.000519 best_pearson: 0.7248
Batch[6813] - loss: 0.000814 best_pearson: 0.7248
Batch[6814] - loss: 0.000633 best_pearson: 0.7248
Batch[6815] - loss: 0.000634 best_pearson: 0.7248
Batch[6816] - loss: 0.001318 best_pearson: 0.7248
Batch[6817] - loss: 0.000746 best_pearson: 0.7248
Batch[6818] - loss: 0.000667 best_pearson: 0.7248
Batch[6819] - loss: 0.000672 best_pearson: 0.7248
Batch[6820] - loss: 0.000441 best_pearson: 0.7248
Batch[6821] - loss: 0.001450 best_pearson: 0.7248
Batch[6822] - loss: 0.000717 best_pearson: 0.7248
Batch[6823] - loss: 0.000626 best_pearson: 0.7248
Batch[6824] - loss: 0.001532 best_pearson: 0.7248
Batch[6825] - loss: 0.000693 best_pearson: 0.7248
Batch[6826] - loss: 0.001090 best_pearson: 0.7248
Batch[6827] - loss: 0.000811 best_pearson: 0.7248
Batch[6828] - loss: 0.000806 best_pearson: 0.7248
Batch[6829] - loss: 0.000978 best_pearson: 0.7248
Batch[6830] - loss: 0.000777 best_pearson: 0.7248
Batch[6831] - loss: 0.000678 best_pearson: 0.7248
Batch[6832] - loss: 0.001085 best_pearson: 0.7248
Batch[6833] - loss: 0.000673 best_pearson: 0.7248
Batch[6834] - loss: 0.000682 best_pearson: 0.7248
Batch[6835] - loss: 0.000683 best_pearson: 0.7248
Batch[6836] - loss: 0.000668 best_pearson: 0.7248
Batch[6837] - loss: 0.000737 best_pearson: 0.7248
Batch[6838] - loss: 0.001235 best_pearson: 0.7248
Batch[6839] - loss: 0.000828 best_pearson: 0.7248
Batch[6840] - loss: 0.001291 best_pearson: 0.7248
Batch[6841] - loss: 0.001066 best_pearson: 0.7248
Batch[6842] - loss: 0.000828 best_pearson: 0.7248
Batch[6843] - loss: 0.000904 best_pearson: 0.7248
Batch[6844] - loss: 0.001302 best_pearson: 0.7248
Batch[6845] - loss: 0.001398 best_pearson: 0.7248
Batch[6846] - loss: 0.000825 best_pearson: 0.7248
Batch[6847] - loss: 0.000714 best_pearson: 0.7248
Batch[6848] - loss: 0.000948 best_pearson: 0.7248
Batch[6849] - loss: 0.000981 best_pearson: 0.7248
Batch[6850] - loss: 0.001277 best_pearson: 0.7248
Batch[6851] - loss: 0.000814 best_pearson: 0.7248
Batch[6852] - loss: 0.000817 best_pearson: 0.7248
Batch[6853] - loss: 0.000848 best_pearson: 0.7248
Batch[6854] - loss: 0.001064 best_pearson: 0.7248
Batch[6855] - loss: 0.001152 best_pearson: 0.7248
Batch[6856] - loss: 0.001133 best_pearson: 0.7248
Batch[6857] - loss: 0.000685 best_pearson: 0.7248
Batch[6858] - loss: 0.000614 best_pearson: 0.7248
Batch[6859] - loss: 0.000972 best_pearson: 0.7248
Batch[6860] - loss: 0.000736 best_pearson: 0.7248
Batch[6861] - loss: 0.000487 best_pearson: 0.7248
Batch[6862] - loss: 0.000872 best_pearson: 0.7248
Batch[6863] - loss: 0.001235 best_pearson: 0.7248
Batch[6864] - loss: 0.000394 best_pearson: 0.7248
Batch[6865] - loss: 0.000551 best_pearson: 0.7248
Batch[6866] - loss: 0.001147 best_pearson: 0.7248
Batch[6867] - loss: 0.000342 best_pearson: 0.7248
Batch[6868] - loss: 0.000594 best_pearson: 0.7248
Batch[6869] - loss: 0.001131 best_pearson: 0.7248
Batch[6870] - loss: 0.000803 best_pearson: 0.7248
Batch[6871] - loss: 0.000987 best_pearson: 0.7248
Batch[6872] - loss: 0.000815 best_pearson: 0.7248
Batch[6873] - loss: 0.000739 best_pearson: 0.7248
Batch[6874] - loss: 0.000956 best_pearson: 0.7248
Batch[6875] - loss: 0.000713 best_pearson: 0.7248
Batch[6876] - loss: 0.000496 best_pearson: 0.7248
Batch[6877] - loss: 0.001028 best_pearson: 0.7248
Batch[6878] - loss: 0.000830 best_pearson: 0.7248
Batch[6879] - loss: 0.000607 best_pearson: 0.7248
Batch[6880] - loss: 0.001094 best_pearson: 0.7248
Batch[6881] - loss: 0.001023 best_pearson: 0.7248
Batch[6882] - loss: 0.000648 best_pearson: 0.7248
Batch[6883] - loss: 0.000885 best_pearson: 0.7248
Batch[6884] - loss: 0.001084 best_pearson: 0.7248
Batch[6885] - loss: 0.000678 best_pearson: 0.7248
Batch[6886] - loss: 0.000865 best_pearson: 0.7248
Batch[6887] - loss: 0.000734 best_pearson: 0.7248
Batch[6888] - loss: 0.000887 best_pearson: 0.7248
Batch[6889] - loss: 0.000721 best_pearson: 0.7248
Batch[6890] - loss: 0.000433 best_pearson: 0.7248
Batch[6891] - loss: 0.000712 best_pearson: 0.7248
Batch[6892] - loss: 0.000666 best_pearson: 0.7248
Batch[6893] - loss: 0.000790 best_pearson: 0.7248
Batch[6894] - loss: 0.000755 best_pearson: 0.7248
Batch[6895] - loss: 0.000640 best_pearson: 0.7248
Batch[6896] - loss: 0.000756 best_pearson: 0.7248
Batch[6897] - loss: 0.000756 best_pearson: 0.7248
Batch[6898] - loss: 0.000781 best_pearson: 0.7248
Batch[6899] - loss: 0.000907 best_pearson: 0.7248
Batch[6900] - loss: 0.001832 best_pearson: 0.7248

Evaluation - loss: 0.000047 pearson: 0.7168 

early stop by 1500 steps.
Batch[6901] - loss: 0.000803 best_pearson: 0.7248
Batch[6902] - loss: 0.000470 best_pearson: 0.7248
Batch[6903] - loss: 0.000902 best_pearson: 0.7248
Batch[6904] - loss: 0.000706 best_pearson: 0.7248
Batch[6905] - loss: 0.000518 best_pearson: 0.7248
Batch[6906] - loss: 0.000694 best_pearson: 0.7248
Batch[6907] - loss: 0.000693 best_pearson: 0.7248
Batch[6908] - loss: 0.000787 best_pearson: 0.7248
Batch[6909] - loss: 0.001155 best_pearson: 0.7248
Batch[6910] - loss: 0.001125 best_pearson: 0.7248
Batch[6911] - loss: 0.001262 best_pearson: 0.7248
Batch[6912] - loss: 0.000440 best_pearson: 0.7248
Batch[6913] - loss: 0.000742 best_pearson: 0.7248
Batch[6914] - loss: 0.000765 best_pearson: 0.7248
Batch[6915] - loss: 0.000791 best_pearson: 0.7248
Batch[6916] - loss: 0.000788 best_pearson: 0.7248
Batch[6917] - loss: 0.001179 best_pearson: 0.7248
Batch[6918] - loss: 0.000803 best_pearson: 0.7248
Batch[6919] - loss: 0.002054 best_pearson: 0.7248
Batch[6920] - loss: 0.000847 best_pearson: 0.7248
Batch[6921] - loss: 0.000940 best_pearson: 0.7248
Batch[6922] - loss: 0.000974 best_pearson: 0.7248
Batch[6923] - loss: 0.001898 best_pearson: 0.7248
Batch[6924] - loss: 0.001242 best_pearson: 0.7248
Batch[6925] - loss: 0.001257 best_pearson: 0.7248
Batch[6926] - loss: 0.000788 best_pearson: 0.7248
Batch[6927] - loss: 0.000759 best_pearson: 0.7248
Batch[6928] - loss: 0.000916 best_pearson: 0.7248
Batch[6929] - loss: 0.000745 best_pearson: 0.7248
Batch[6930] - loss: 0.000594 best_pearson: 0.7248
Batch[6931] - loss: 0.001100 best_pearson: 0.7248
Batch[6932] - loss: 0.001069 best_pearson: 0.7248
Batch[6933] - loss: 0.000579 best_pearson: 0.7248
Batch[6934] - loss: 0.000951 best_pearson: 0.7248
Batch[6935] - loss: 0.000772 best_pearson: 0.7248
Batch[6936] - loss: 0.000929 best_pearson: 0.7248
Batch[6937] - loss: 0.001007 best_pearson: 0.7248
Batch[6938] - loss: 0.000852 best_pearson: 0.7248
Batch[6939] - loss: 0.001027 best_pearson: 0.7248
Batch[6940] - loss: 0.001323 best_pearson: 0.7248
Batch[6941] - loss: 0.000512 best_pearson: 0.7248
Batch[6942] - loss: 0.000855 best_pearson: 0.7248
Batch[6943] - loss: 0.000581 best_pearson: 0.7248
Batch[6944] - loss: 0.000717 best_pearson: 0.7248
Batch[6945] - loss: 0.000831 best_pearson: 0.7248
Batch[6946] - loss: 0.001066 best_pearson: 0.7248
Batch[6947] - loss: 0.001075 best_pearson: 0.7248
Batch[6948] - loss: 0.000521 best_pearson: 0.7248
Batch[6949] - loss: 0.000839 best_pearson: 0.7248
Batch[6950] - loss: 0.000824 best_pearson: 0.7248
Batch[6951] - loss: 0.000833 best_pearson: 0.7248
Batch[6952] - loss: 0.001076 best_pearson: 0.7248
Batch[6953] - loss: 0.001243 best_pearson: 0.7248
Batch[6954] - loss: 0.001111 best_pearson: 0.7248
Batch[6955] - loss: 0.001243 best_pearson: 0.7248
Batch[6956] - loss: 0.001177 best_pearson: 0.7248
Batch[6957] - loss: 0.000700 best_pearson: 0.7248
Batch[6958] - loss: 0.000580 best_pearson: 0.7248
Batch[6959] - loss: 0.000627 best_pearson: 0.7248
Batch[6960] - loss: 0.000454 best_pearson: 0.7248
Batch[6961] - loss: 0.000431 best_pearson: 0.7248
Batch[6962] - loss: 0.000806 best_pearson: 0.7248
Batch[6963] - loss: 0.000780 best_pearson: 0.7248
Batch[6964] - loss: 0.000737 best_pearson: 0.7248
Batch[6965] - loss: 0.001126 best_pearson: 0.7248
Batch[6966] - loss: 0.000798 best_pearson: 0.7248
Batch[6967] - loss: 0.001075 best_pearson: 0.7248
Batch[6968] - loss: 0.000596 best_pearson: 0.7248
Batch[6969] - loss: 0.001308 best_pearson: 0.7248
Batch[6970] - loss: 0.001315 best_pearson: 0.7248
Batch[6971] - loss: 0.000701 best_pearson: 0.7248
Batch[6972] - loss: 0.001523 best_pearson: 0.7248
Batch[6973] - loss: 0.000862 best_pearson: 0.7248
Batch[6974] - loss: 0.000450 best_pearson: 0.7248
Batch[6975] - loss: 0.000537 best_pearson: 0.7248
Batch[6976] - loss: 0.001007 best_pearson: 0.7248
Batch[6977] - loss: 0.000860 best_pearson: 0.7248
Batch[6978] - loss: 0.000871 best_pearson: 0.7248
Batch[6979] - loss: 0.001417 best_pearson: 0.7248
Batch[6980] - loss: 0.000577 best_pearson: 0.7248
Batch[6981] - loss: 0.000722 best_pearson: 0.7248
Batch[6982] - loss: 0.000948 best_pearson: 0.7248
Batch[6983] - loss: 0.001015 best_pearson: 0.7248
Batch[6984] - loss: 0.000977 best_pearson: 0.7248
Batch[6985] - loss: 0.000639 best_pearson: 0.7248
Batch[6986] - loss: 0.000911 best_pearson: 0.7248
Batch[6987] - loss: 0.001205 best_pearson: 0.7248
Batch[6988] - loss: 0.000771 best_pearson: 0.7248
Batch[6989] - loss: 0.000633 best_pearson: 0.7248
Batch[6990] - loss: 0.000737 best_pearson: 0.7248
Batch[6991] - loss: 0.000696 best_pearson: 0.7248
Batch[6992] - loss: 0.001075 best_pearson: 0.7248
Batch[6993] - loss: 0.001050 best_pearson: 0.7248
Batch[6994] - loss: 0.001009 best_pearson: 0.7248
Batch[6995] - loss: 0.000694 best_pearson: 0.7248
Batch[6996] - loss: 0.001387 best_pearson: 0.7248
Batch[6997] - loss: 0.001479 best_pearson: 0.7248
Batch[6998] - loss: 0.000665 best_pearson: 0.7248
Batch[6999] - loss: 0.000715 best_pearson: 0.7248
Batch[7000] - loss: 0.001576 best_pearson: 0.7248

Evaluation - loss: 0.000047 pearson: 0.7173 

early stop by 1500 steps.
Batch[7001] - loss: 0.000964 best_pearson: 0.7248
Batch[7002] - loss: 0.001103 best_pearson: 0.7248
Batch[7003] - loss: 0.000912 best_pearson: 0.7248
Batch[7004] - loss: 0.000843 best_pearson: 0.7248
Batch[7005] - loss: 0.000618 best_pearson: 0.7248
Batch[7006] - loss: 0.000687 best_pearson: 0.7248
Batch[7007] - loss: 0.000848 best_pearson: 0.7248
Batch[7008] - loss: 0.001171 best_pearson: 0.7248
Batch[7009] - loss: 0.001140 best_pearson: 0.7248
Batch[7010] - loss: 0.000918 best_pearson: 0.7248
Batch[7011] - loss: 0.000653 best_pearson: 0.7248
Batch[7012] - loss: 0.000528 best_pearson: 0.7248
Batch[7013] - loss: 0.000696 best_pearson: 0.7248
Batch[7014] - loss: 0.001680 best_pearson: 0.7248
Batch[7015] - loss: 0.000946 best_pearson: 0.7248
Batch[7016] - loss: 0.001105 best_pearson: 0.7248
Batch[7017] - loss: 0.001096 best_pearson: 0.7248
Batch[7018] - loss: 0.000648 best_pearson: 0.7248
Batch[7019] - loss: 0.000842 best_pearson: 0.7248
Batch[7020] - loss: 0.000714 best_pearson: 0.7248
Batch[7021] - loss: 0.000846 best_pearson: 0.7248
Batch[7022] - loss: 0.000568 best_pearson: 0.7248
Batch[7023] - loss: 0.000642 best_pearson: 0.7248
Batch[7024] - loss: 0.000589 best_pearson: 0.7248
Batch[7025] - loss: 0.000794 best_pearson: 0.7248
Batch[7026] - loss: 0.001129 best_pearson: 0.7248
Batch[7027] - loss: 0.001241 best_pearson: 0.7248
Batch[7028] - loss: 0.000967 best_pearson: 0.7248
Batch[7029] - loss: 0.001152 best_pearson: 0.7248
Batch[7030] - loss: 0.000808 best_pearson: 0.7248
Batch[7031] - loss: 0.001022 best_pearson: 0.7248
Batch[7032] - loss: 0.001380 best_pearson: 0.7248
Batch[7033] - loss: 0.000645 best_pearson: 0.7248
Batch[7034] - loss: 0.001326 best_pearson: 0.7248
Batch[7035] - loss: 0.000820 best_pearson: 0.7248
Batch[7036] - loss: 0.000580 best_pearson: 0.7248
Batch[7037] - loss: 0.000624 best_pearson: 0.7248
Batch[7038] - loss: 0.001150 best_pearson: 0.7248
Batch[7039] - loss: 0.000574 best_pearson: 0.7248
Batch[7040] - loss: 0.000941 best_pearson: 0.7248
Batch[7041] - loss: 0.000482 best_pearson: 0.7248
Batch[7042] - loss: 0.000751 best_pearson: 0.7248
Batch[7043] - loss: 0.001080 best_pearson: 0.7248
Batch[7044] - loss: 0.000531 best_pearson: 0.7248
Batch[7045] - loss: 0.000634 best_pearson: 0.7248
Batch[7046] - loss: 0.000755 best_pearson: 0.7248
Batch[7047] - loss: 0.000781 best_pearson: 0.7248
Batch[7048] - loss: 0.000580 best_pearson: 0.7248
Batch[7049] - loss: 0.000700 best_pearson: 0.7248
Batch[7050] - loss: 0.000973 best_pearson: 0.7248
Batch[7051] - loss: 0.000908 best_pearson: 0.7248
Batch[7052] - loss: 0.000931 best_pearson: 0.7248
Batch[7053] - loss: 0.001034 best_pearson: 0.7248
Batch[7054] - loss: 0.000910 best_pearson: 0.7248
Batch[7055] - loss: 0.000880 best_pearson: 0.7248
Batch[7056] - loss: 0.001089 best_pearson: 0.7248
Batch[7057] - loss: 0.000683 best_pearson: 0.7248
Batch[7058] - loss: 0.000990 best_pearson: 0.7248
Batch[7059] - loss: 0.001040 best_pearson: 0.7248
Batch[7060] - loss: 0.001287 best_pearson: 0.7248
Batch[7061] - loss: 0.000972 best_pearson: 0.7248
Batch[7062] - loss: 0.000881 best_pearson: 0.7248
Batch[7063] - loss: 0.000924 best_pearson: 0.7248
Batch[7064] - loss: 0.000586 best_pearson: 0.7248
Batch[7065] - loss: 0.001066 best_pearson: 0.7248
Batch[7066] - loss: 0.001054 best_pearson: 0.7248
Batch[7067] - loss: 0.000807 best_pearson: 0.7248
Batch[7068] - loss: 0.001077 best_pearson: 0.7248
Batch[7069] - loss: 0.000882 best_pearson: 0.7248
Batch[7070] - loss: 0.001035 best_pearson: 0.7248
Batch[7071] - loss: 0.001569 best_pearson: 0.7248
Batch[7072] - loss: 0.000562 best_pearson: 0.7248
Batch[7073] - loss: 0.000758 best_pearson: 0.7248
Batch[7074] - loss: 0.000874 best_pearson: 0.7248
Batch[7075] - loss: 0.001084 best_pearson: 0.7248
Batch[7076] - loss: 0.000648 best_pearson: 0.7248
Batch[7077] - loss: 0.001126 best_pearson: 0.7248
Batch[7078] - loss: 0.001069 best_pearson: 0.7248
Batch[7079] - loss: 0.001178 best_pearson: 0.7248
Batch[7080] - loss: 0.000873 best_pearson: 0.7248
Batch[7081] - loss: 0.000917 best_pearson: 0.7248
Batch[7082] - loss: 0.000760 best_pearson: 0.7248
Batch[7083] - loss: 0.000370 best_pearson: 0.7248
Batch[7084] - loss: 0.001085 best_pearson: 0.7248
Batch[7085] - loss: 0.000765 best_pearson: 0.7248
Batch[7086] - loss: 0.000557 best_pearson: 0.7248
Batch[7087] - loss: 0.000580 best_pearson: 0.7248
Batch[7088] - loss: 0.000606 best_pearson: 0.7248
Batch[7089] - loss: 0.000834 best_pearson: 0.7248
Batch[7090] - loss: 0.001066 best_pearson: 0.7248
Batch[7091] - loss: 0.000624 best_pearson: 0.7248
Batch[7092] - loss: 0.000955 best_pearson: 0.7248
Batch[7093] - loss: 0.001023 best_pearson: 0.7248
Batch[7094] - loss: 0.000843 best_pearson: 0.7248
Batch[7095] - loss: 0.000846 best_pearson: 0.7248
Batch[7096] - loss: 0.000689 best_pearson: 0.7248
Batch[7097] - loss: 0.000947 best_pearson: 0.7248
Batch[7098] - loss: 0.000703 best_pearson: 0.7248
Batch[7099] - loss: 0.000920 best_pearson: 0.7248
Batch[7100] - loss: 0.000848 best_pearson: 0.7248

Evaluation - loss: 0.000047 pearson: 0.7154 

early stop by 1500 steps.
Batch[7101] - loss: 0.000998 best_pearson: 0.7248
Batch[7102] - loss: 0.000990 best_pearson: 0.7248
Batch[7103] - loss: 0.001004 best_pearson: 0.7248
Batch[7104] - loss: 0.000520 best_pearson: 0.7248
Batch[7105] - loss: 0.000563 best_pearson: 0.7248
Batch[7106] - loss: 0.000740 best_pearson: 0.7248
Batch[7107] - loss: 0.001009 best_pearson: 0.7248
Batch[7108] - loss: 0.000450 best_pearson: 0.7248
Batch[7109] - loss: 0.001140 best_pearson: 0.7248
Batch[7110] - loss: 0.001016 best_pearson: 0.7248
Batch[7111] - loss: 0.000908 best_pearson: 0.7248
Batch[7112] - loss: 0.000920 best_pearson: 0.7248
Batch[7113] - loss: 0.001074 best_pearson: 0.7248
Batch[7114] - loss: 0.000774 best_pearson: 0.7248
Batch[7115] - loss: 0.000713 best_pearson: 0.7248
Batch[7116] - loss: 0.001216 best_pearson: 0.7248
Batch[7117] - loss: 0.000535 best_pearson: 0.7248
Batch[7118] - loss: 0.000593 best_pearson: 0.7248
Batch[7119] - loss: 0.000608 best_pearson: 0.7248
Batch[7120] - loss: 0.000690 best_pearson: 0.7248
Batch[7121] - loss: 0.000746 best_pearson: 0.7248
Batch[7122] - loss: 0.001409 best_pearson: 0.7248
Batch[7123] - loss: 0.000934 best_pearson: 0.7248
Batch[7124] - loss: 0.001240 best_pearson: 0.7248
Batch[7125] - loss: 0.001314 best_pearson: 0.7248
Batch[7126] - loss: 0.000676 best_pearson: 0.7248
Batch[7127] - loss: 0.000835 best_pearson: 0.7248
Batch[7128] - loss: 0.001213 best_pearson: 0.7248
Batch[7129] - loss: 0.000613 best_pearson: 0.7248
Batch[7130] - loss: 0.001292 best_pearson: 0.7248
Batch[7131] - loss: 0.001363 best_pearson: 0.7248
Batch[7132] - loss: 0.000777 best_pearson: 0.7248
Batch[7133] - loss: 0.001012 best_pearson: 0.7248
Batch[7134] - loss: 0.001138 best_pearson: 0.7248
Batch[7135] - loss: 0.001078 best_pearson: 0.7248
Batch[7136] - loss: 0.001002 best_pearson: 0.7248
Batch[7137] - loss: 0.000959 best_pearson: 0.7248
Batch[7138] - loss: 0.000996 best_pearson: 0.7248
Batch[7139] - loss: 0.001067 best_pearson: 0.7248
Batch[7140] - loss: 0.001063 best_pearson: 0.7248
Batch[7141] - loss: 0.000744 best_pearson: 0.7248
Batch[7142] - loss: 0.000741 best_pearson: 0.7248
Batch[7143] - loss: 0.000867 best_pearson: 0.7248
Batch[7144] - loss: 0.000510 best_pearson: 0.7248
Batch[7145] - loss: 0.000661 best_pearson: 0.7248
Batch[7146] - loss: 0.001520 best_pearson: 0.7248
Batch[7147] - loss: 0.000675 best_pearson: 0.7248
Batch[7148] - loss: 0.000904 best_pearson: 0.7248
Batch[7149] - loss: 0.000729 best_pearson: 0.7248
Batch[7150] - loss: 0.000934 best_pearson: 0.7248
Batch[7151] - loss: 0.000624 best_pearson: 0.7248
Batch[7152] - loss: 0.000892 best_pearson: 0.7248
Batch[7153] - loss: 0.000660 best_pearson: 0.7248
Batch[7154] - loss: 0.000559 best_pearson: 0.7248
Batch[7155] - loss: 0.001534 best_pearson: 0.7248
Batch[7156] - loss: 0.000537 best_pearson: 0.7248
Batch[7157] - loss: 0.000535 best_pearson: 0.7248
Batch[7158] - loss: 0.001868 best_pearson: 0.7248
Batch[7159] - loss: 0.000956 best_pearson: 0.7248
Batch[7160] - loss: 0.000657 best_pearson: 0.7248
Batch[7161] - loss: 0.000904 best_pearson: 0.7248
Batch[7162] - loss: 0.000850 best_pearson: 0.7248
Batch[7163] - loss: 0.000534 best_pearson: 0.7248
Batch[7164] - loss: 0.000812 best_pearson: 0.7248
Batch[7165] - loss: 0.000709 best_pearson: 0.7248
Batch[7166] - loss: 0.000630 best_pearson: 0.7248
Batch[7167] - loss: 0.000711 best_pearson: 0.7248
Batch[7168] - loss: 0.001291 best_pearson: 0.7248
Batch[7169] - loss: 0.000843 best_pearson: 0.7248
Batch[7170] - loss: 0.001151 best_pearson: 0.7248
Batch[7171] - loss: 0.000790 best_pearson: 0.7248
Batch[7172] - loss: 0.000927 best_pearson: 0.7248
Batch[7173] - loss: 0.000631 best_pearson: 0.7248
Batch[7174] - loss: 0.001056 best_pearson: 0.7248
Batch[7175] - loss: 0.000603 best_pearson: 0.7248
Batch[7176] - loss: 0.000817 best_pearson: 0.7248
Batch[7177] - loss: 0.000690 best_pearson: 0.7248
Batch[7178] - loss: 0.000984 best_pearson: 0.7248
Batch[7179] - loss: 0.000458 best_pearson: 0.7248
Batch[7180] - loss: 0.000532 best_pearson: 0.7248
Batch[7181] - loss: 0.000381 best_pearson: 0.7248
Batch[7182] - loss: 0.000688 best_pearson: 0.7248
Batch[7183] - loss: 0.000621 best_pearson: 0.7248
Batch[7184] - loss: 0.000565 best_pearson: 0.7248
Batch[7185] - loss: 0.001298 best_pearson: 0.7248
Batch[7186] - loss: 0.000623 best_pearson: 0.7248
Batch[7187] - loss: 0.000886 best_pearson: 0.7248
Batch[7188] - loss: 0.001259 best_pearson: 0.7248
Batch[7189] - loss: 0.000414 best_pearson: 0.7248
Batch[7190] - loss: 0.000904 best_pearson: 0.7248
Batch[7191] - loss: 0.000995 best_pearson: 0.7248
Batch[7192] - loss: 0.001153 best_pearson: 0.7248
Batch[7193] - loss: 0.000837 best_pearson: 0.7248
Batch[7194] - loss: 0.000570 best_pearson: 0.7248
Batch[7195] - loss: 0.000818 best_pearson: 0.7248
Batch[7196] - loss: 0.000534 best_pearson: 0.7248
Batch[7197] - loss: 0.000845 best_pearson: 0.7248
Batch[7198] - loss: 0.001496 best_pearson: 0.7248
Batch[7199] - loss: 0.000833 best_pearson: 0.7248
Batch[7200] - loss: 0.000827 best_pearson: 0.7248

Evaluation - loss: 0.000048 pearson: 0.7139 

early stop by 1500 steps.
Batch[7201] - loss: 0.001054 best_pearson: 0.7248
Batch[7202] - loss: 0.000631 best_pearson: 0.7248
Batch[7203] - loss: 0.000841 best_pearson: 0.7248
Batch[7204] - loss: 0.000943 best_pearson: 0.7248
Batch[7205] - loss: 0.001203 best_pearson: 0.7248
Batch[7206] - loss: 0.001107 best_pearson: 0.7248
Batch[7207] - loss: 0.001471 best_pearson: 0.7248
Batch[7208] - loss: 0.000671 best_pearson: 0.7248
Batch[7209] - loss: 0.000775 best_pearson: 0.7248
Batch[7210] - loss: 0.001060 best_pearson: 0.7248
Batch[7211] - loss: 0.000934 best_pearson: 0.7248
Batch[7212] - loss: 0.000722 best_pearson: 0.7248
Batch[7213] - loss: 0.000838 best_pearson: 0.7248
Batch[7214] - loss: 0.000750 best_pearson: 0.7248
Batch[7215] - loss: 0.000698 best_pearson: 0.7248
Batch[7216] - loss: 0.001048 best_pearson: 0.7248
Batch[7217] - loss: 0.001333 best_pearson: 0.7248
Batch[7218] - loss: 0.001185 best_pearson: 0.7248
Batch[7219] - loss: 0.001112 best_pearson: 0.7248
Batch[7220] - loss: 0.001419 best_pearson: 0.7248
Batch[7221] - loss: 0.000837 best_pearson: 0.7248
Batch[7222] - loss: 0.001641 best_pearson: 0.7248
Batch[7223] - loss: 0.001815 best_pearson: 0.7248
Batch[7224] - loss: 0.001264 best_pearson: 0.7248
Batch[7225] - loss: 0.000863 best_pearson: 0.7248
Batch[7226] - loss: 0.001060 best_pearson: 0.7248
Batch[7227] - loss: 0.001483 best_pearson: 0.7248
Batch[7228] - loss: 0.001026 best_pearson: 0.7248
Batch[7229] - loss: 0.000885 best_pearson: 0.7248
Batch[7230] - loss: 0.001288 best_pearson: 0.7248
Batch[7231] - loss: 0.001104 best_pearson: 0.7248
Batch[7232] - loss: 0.000455 best_pearson: 0.7248
Batch[7233] - loss: 0.000544 best_pearson: 0.7248
Batch[7234] - loss: 0.001099 best_pearson: 0.7248
Batch[7235] - loss: 0.000754 best_pearson: 0.7248
Batch[7236] - loss: 0.001088 best_pearson: 0.7248
Batch[7237] - loss: 0.000729 best_pearson: 0.7248
Batch[7238] - loss: 0.000684 best_pearson: 0.7248
Batch[7239] - loss: 0.001249 best_pearson: 0.7248
Batch[7240] - loss: 0.000463 best_pearson: 0.7248
Batch[7241] - loss: 0.000566 best_pearson: 0.7248
Batch[7242] - loss: 0.000976 best_pearson: 0.7248
Batch[7243] - loss: 0.000714 best_pearson: 0.7248
Batch[7244] - loss: 0.000927 best_pearson: 0.7248
Batch[7245] - loss: 0.000539 best_pearson: 0.7248
Batch[7246] - loss: 0.000922 best_pearson: 0.7248
Batch[7247] - loss: 0.000850 best_pearson: 0.7248
Batch[7248] - loss: 0.001133 best_pearson: 0.7248
Batch[7249] - loss: 0.000780 best_pearson: 0.7248
Batch[7250] - loss: 0.000645 best_pearson: 0.7248
Batch[7251] - loss: 0.001265 best_pearson: 0.7248
Batch[7252] - loss: 0.000963 best_pearson: 0.7248
Batch[7253] - loss: 0.000904 best_pearson: 0.7248
Batch[7254] - loss: 0.001988 best_pearson: 0.7248
Batch[7255] - loss: 0.000715 best_pearson: 0.7248
Batch[7256] - loss: 0.000540 best_pearson: 0.7248
Batch[7257] - loss: 0.000568 best_pearson: 0.7248
Batch[7258] - loss: 0.001176 best_pearson: 0.7248
Batch[7259] - loss: 0.001387 best_pearson: 0.7248
Batch[7260] - loss: 0.001232 best_pearson: 0.7248
Batch[7261] - loss: 0.000679 best_pearson: 0.7248
Batch[7262] - loss: 0.001122 best_pearson: 0.7248
Batch[7263] - loss: 0.001194 best_pearson: 0.7248
Batch[7264] - loss: 0.000670 best_pearson: 0.7248
Batch[7265] - loss: 0.000877 best_pearson: 0.7248
Batch[7266] - loss: 0.000960 best_pearson: 0.7248
Batch[7267] - loss: 0.001738 best_pearson: 0.7248
Batch[7268] - loss: 0.000816 best_pearson: 0.7248
Batch[7269] - loss: 0.000744 best_pearson: 0.7248
Batch[7270] - loss: 0.000958 best_pearson: 0.7248
Batch[7271] - loss: 0.001120 best_pearson: 0.7248
Batch[7272] - loss: 0.001664 best_pearson: 0.7248
Batch[7273] - loss: 0.000604 best_pearson: 0.7248
Batch[7274] - loss: 0.001104 best_pearson: 0.7248
Batch[7275] - loss: 0.000874 best_pearson: 0.7248
Batch[7276] - loss: 0.000844 best_pearson: 0.7248
Batch[7277] - loss: 0.000929 best_pearson: 0.7248
Batch[7278] - loss: 0.000939 best_pearson: 0.7248
Batch[7279] - loss: 0.000915 best_pearson: 0.7248
Batch[7280] - loss: 0.000643 best_pearson: 0.7248
Batch[7281] - loss: 0.000980 best_pearson: 0.7248
Batch[7282] - loss: 0.000714 best_pearson: 0.7248
Batch[7283] - loss: 0.000973 best_pearson: 0.7248
Batch[7284] - loss: 0.000662 best_pearson: 0.7248
Batch[7285] - loss: 0.001360 best_pearson: 0.7248
Batch[7286] - loss: 0.000530 best_pearson: 0.7248
Batch[7287] - loss: 0.001091 best_pearson: 0.7248
Batch[7288] - loss: 0.000705 best_pearson: 0.7248
Batch[7289] - loss: 0.001086 best_pearson: 0.7248
Batch[7290] - loss: 0.000689 best_pearson: 0.7248
Batch[7291] - loss: 0.000880 best_pearson: 0.7248
Batch[7292] - loss: 0.000539 best_pearson: 0.7248
Batch[7293] - loss: 0.000487 best_pearson: 0.7248
Batch[7294] - loss: 0.000867 best_pearson: 0.7248
Batch[7295] - loss: 0.000758 best_pearson: 0.7248
Batch[7296] - loss: 0.000872 best_pearson: 0.7248
Batch[7297] - loss: 0.001006 best_pearson: 0.7248
Batch[7298] - loss: 0.000768 best_pearson: 0.7248
Batch[7299] - loss: 0.000938 best_pearson: 0.7248
Batch[7300] - loss: 0.000511 best_pearson: 0.7248

Evaluation - loss: 0.000046 pearson: 0.7192 

early stop by 1500 steps.
Batch[7301] - loss: 0.000891 best_pearson: 0.7248
Batch[7302] - loss: 0.001186 best_pearson: 0.7248
Batch[7303] - loss: 0.000912 best_pearson: 0.7248
Batch[7304] - loss: 0.000846 best_pearson: 0.7248
Batch[7305] - loss: 0.000575 best_pearson: 0.7248
Batch[7306] - loss: 0.000600 best_pearson: 0.7248
Batch[7307] - loss: 0.000579 best_pearson: 0.7248
Batch[7308] - loss: 0.000541 best_pearson: 0.7248
Batch[7309] - loss: 0.001217 best_pearson: 0.7248
Batch[7310] - loss: 0.000476 best_pearson: 0.7248
Batch[7311] - loss: 0.000756 best_pearson: 0.7248
Batch[7312] - loss: 0.000558 best_pearson: 0.7248
Batch[7313] - loss: 0.000968 best_pearson: 0.7248
Batch[7314] - loss: 0.000886 best_pearson: 0.7248
Batch[7315] - loss: 0.001440 best_pearson: 0.7248
Batch[7316] - loss: 0.000916 best_pearson: 0.7248
Batch[7317] - loss: 0.000836 best_pearson: 0.7248
Batch[7318] - loss: 0.000460 best_pearson: 0.7248
Batch[7319] - loss: 0.000939 best_pearson: 0.7248
Batch[7320] - loss: 0.000925 best_pearson: 0.7248
Batch[7321] - loss: 0.000616 best_pearson: 0.7248
Batch[7322] - loss: 0.001000 best_pearson: 0.7248
Batch[7323] - loss: 0.001300 best_pearson: 0.7248
Batch[7324] - loss: 0.000609 best_pearson: 0.7248
Batch[7325] - loss: 0.001250 best_pearson: 0.7248
Batch[7326] - loss: 0.000855 best_pearson: 0.7248
Batch[7327] - loss: 0.000850 best_pearson: 0.7248
Batch[7328] - loss: 0.000393 best_pearson: 0.7248
Batch[7329] - loss: 0.000558 best_pearson: 0.7248
Batch[7330] - loss: 0.001174 best_pearson: 0.7248
Batch[7331] - loss: 0.000567 best_pearson: 0.7248
Batch[7332] - loss: 0.000927 best_pearson: 0.7248
Batch[7333] - loss: 0.001408 best_pearson: 0.7248
Batch[7334] - loss: 0.000643 best_pearson: 0.7248
Batch[7335] - loss: 0.000873 best_pearson: 0.7248
Batch[7336] - loss: 0.000813 best_pearson: 0.7248
Batch[7337] - loss: 0.000621 best_pearson: 0.7248
Batch[7338] - loss: 0.000944 best_pearson: 0.7248
Batch[7339] - loss: 0.001090 best_pearson: 0.7248
Batch[7340] - loss: 0.000821 best_pearson: 0.7248
Batch[7341] - loss: 0.000719 best_pearson: 0.7248
Batch[7342] - loss: 0.000818 best_pearson: 0.7248
Batch[7343] - loss: 0.000768 best_pearson: 0.7248
Batch[7344] - loss: 0.000762 best_pearson: 0.7248
Batch[7345] - loss: 0.000808 best_pearson: 0.7248
Batch[7346] - loss: 0.000848 best_pearson: 0.7248
Batch[7347] - loss: 0.000684 best_pearson: 0.7248
Batch[7348] - loss: 0.001028 best_pearson: 0.7248
Batch[7349] - loss: 0.000916 best_pearson: 0.7248
Batch[7350] - loss: 0.000722 best_pearson: 0.7248
Batch[7351] - loss: 0.001109 best_pearson: 0.7248
Batch[7352] - loss: 0.000707 best_pearson: 0.7248
Batch[7353] - loss: 0.000978 best_pearson: 0.7248
Batch[7354] - loss: 0.000637 best_pearson: 0.7248
Batch[7355] - loss: 0.000687 best_pearson: 0.7248
Batch[7356] - loss: 0.000904 best_pearson: 0.7248
Batch[7357] - loss: 0.001010 best_pearson: 0.7248
Batch[7358] - loss: 0.000767 best_pearson: 0.7248
Batch[7359] - loss: 0.001005 best_pearson: 0.7248
Batch[7360] - loss: 0.000947 best_pearson: 0.7248
Batch[7361] - loss: 0.000830 best_pearson: 0.7248
Batch[7362] - loss: 0.000799 best_pearson: 0.7248
Batch[7363] - loss: 0.000497 best_pearson: 0.7248
Batch[7364] - loss: 0.000431 best_pearson: 0.7248
Batch[7365] - loss: 0.001158 best_pearson: 0.7248
Batch[7366] - loss: 0.000847 best_pearson: 0.7248
Batch[7367] - loss: 0.000988 best_pearson: 0.7248
Batch[7368] - loss: 0.000675 best_pearson: 0.7248
Batch[7369] - loss: 0.000889 best_pearson: 0.7248
Batch[7370] - loss: 0.000845 best_pearson: 0.7248
Batch[7371] - loss: 0.000719 best_pearson: 0.7248
Batch[7372] - loss: 0.001244 best_pearson: 0.7248
Batch[7373] - loss: 0.000743 best_pearson: 0.7248
Batch[7374] - loss: 0.000992 best_pearson: 0.7248
Batch[7375] - loss: 0.000740 best_pearson: 0.7248
Batch[7376] - loss: 0.001584 best_pearson: 0.7248
Batch[7377] - loss: 0.000659 best_pearson: 0.7248
Batch[7378] - loss: 0.000801 best_pearson: 0.7248
Batch[7379] - loss: 0.000793 best_pearson: 0.7248
Batch[7380] - loss: 0.000974 best_pearson: 0.7248
Batch[7381] - loss: 0.001251 best_pearson: 0.7248
Batch[7382] - loss: 0.000828 best_pearson: 0.7248
Batch[7383] - loss: 0.000708 best_pearson: 0.7248
Batch[7384] - loss: 0.000576 best_pearson: 0.7248
Batch[7385] - loss: 0.000895 best_pearson: 0.7248
Batch[7386] - loss: 0.000676 best_pearson: 0.7248
Batch[7387] - loss: 0.000988 best_pearson: 0.7248
Batch[7388] - loss: 0.000455 best_pearson: 0.7248
Batch[7389] - loss: 0.000544 best_pearson: 0.7248
Batch[7390] - loss: 0.000571 best_pearson: 0.7248
Batch[7391] - loss: 0.000564 best_pearson: 0.7248
Batch[7392] - loss: 0.000670 best_pearson: 0.7248
Batch[7393] - loss: 0.000699 best_pearson: 0.7248
Batch[7394] - loss: 0.000770 best_pearson: 0.7248
Batch[7395] - loss: 0.000896 best_pearson: 0.7248
Batch[7396] - loss: 0.000962 best_pearson: 0.7248
Batch[7397] - loss: 0.000747 best_pearson: 0.7248
Batch[7398] - loss: 0.000933 best_pearson: 0.7248
Batch[7399] - loss: 0.000743 best_pearson: 0.7248
Batch[7400] - loss: 0.000736 best_pearson: 0.7248

Evaluation - loss: 0.000048 pearson: 0.7151 

early stop by 1500 steps.
Batch[7401] - loss: 0.000841 best_pearson: 0.7248
Batch[7402] - loss: 0.000612 best_pearson: 0.7248
Batch[7403] - loss: 0.000544 best_pearson: 0.7248
Batch[7404] - loss: 0.000911 best_pearson: 0.7248
Batch[7405] - loss: 0.000512 best_pearson: 0.7248
Batch[7406] - loss: 0.000734 best_pearson: 0.7248
Batch[7407] - loss: 0.000961 best_pearson: 0.7248
Batch[7408] - loss: 0.000485 best_pearson: 0.7248
Batch[7409] - loss: 0.000732 best_pearson: 0.7248
Batch[7410] - loss: 0.000951 best_pearson: 0.7248
Batch[7411] - loss: 0.000510 best_pearson: 0.7248
Batch[7412] - loss: 0.001051 best_pearson: 0.7248
Batch[7413] - loss: 0.000583 best_pearson: 0.7248
Batch[7414] - loss: 0.000989 best_pearson: 0.7248
Batch[7415] - loss: 0.000404 best_pearson: 0.7248
Batch[7416] - loss: 0.000897 best_pearson: 0.7248
Batch[7417] - loss: 0.000949 best_pearson: 0.7248
Batch[7418] - loss: 0.000766 best_pearson: 0.7248
Batch[7419] - loss: 0.000576 best_pearson: 0.7248
Batch[7420] - loss: 0.000616 best_pearson: 0.7248
Batch[7421] - loss: 0.000989 best_pearson: 0.7248
Batch[7422] - loss: 0.000866 best_pearson: 0.7248
Batch[7423] - loss: 0.000681 best_pearson: 0.7248
Batch[7424] - loss: 0.000531 best_pearson: 0.7248
Batch[7425] - loss: 0.000573 best_pearson: 0.7248
Batch[7426] - loss: 0.000623 best_pearson: 0.7248
Batch[7427] - loss: 0.000656 best_pearson: 0.7248
Batch[7428] - loss: 0.001085 best_pearson: 0.7248
Batch[7429] - loss: 0.001264 best_pearson: 0.7248
Batch[7430] - loss: 0.000583 best_pearson: 0.7248
Batch[7431] - loss: 0.000753 best_pearson: 0.7248
Batch[7432] - loss: 0.000676 best_pearson: 0.7248
Batch[7433] - loss: 0.000680 best_pearson: 0.7248
Batch[7434] - loss: 0.000624 best_pearson: 0.7248
Batch[7435] - loss: 0.001257 best_pearson: 0.7248
Batch[7436] - loss: 0.000863 best_pearson: 0.7248
Batch[7437] - loss: 0.001206 best_pearson: 0.7248
Batch[7438] - loss: 0.001150 best_pearson: 0.7248
Batch[7439] - loss: 0.001396 best_pearson: 0.7248
Batch[7440] - loss: 0.000539 best_pearson: 0.7248
Batch[7441] - loss: 0.000905 best_pearson: 0.7248
Batch[7442] - loss: 0.000565 best_pearson: 0.7248
Batch[7443] - loss: 0.000567 best_pearson: 0.7248
Batch[7444] - loss: 0.000505 best_pearson: 0.7248
Batch[7445] - loss: 0.000717 best_pearson: 0.7248
Batch[7446] - loss: 0.000652 best_pearson: 0.7248
Batch[7447] - loss: 0.000705 best_pearson: 0.7248
Batch[7448] - loss: 0.000616 best_pearson: 0.7248
Batch[7449] - loss: 0.000703 best_pearson: 0.7248
Batch[7450] - loss: 0.000971 best_pearson: 0.7248
Batch[7451] - loss: 0.000466 best_pearson: 0.7248
Batch[7452] - loss: 0.001084 best_pearson: 0.7248
Batch[7453] - loss: 0.000381 best_pearson: 0.7248
Batch[7454] - loss: 0.000576 best_pearson: 0.7248
Batch[7455] - loss: 0.000596 best_pearson: 0.7248
Batch[7456] - loss: 0.000585 best_pearson: 0.7248
Batch[7457] - loss: 0.001307 best_pearson: 0.7248
Batch[7458] - loss: 0.000998 best_pearson: 0.7248
Batch[7459] - loss: 0.000946 best_pearson: 0.7248
Batch[7460] - loss: 0.000914 best_pearson: 0.7248
Batch[7461] - loss: 0.000582 best_pearson: 0.7248
Batch[7462] - loss: 0.000523 best_pearson: 0.7248
Batch[7463] - loss: 0.000407 best_pearson: 0.7248
Batch[7464] - loss: 0.000871 best_pearson: 0.7248
Batch[7465] - loss: 0.000932 best_pearson: 0.7248
Batch[7466] - loss: 0.000781 best_pearson: 0.7248
Batch[7467] - loss: 0.000507 best_pearson: 0.7248
Batch[7468] - loss: 0.001317 best_pearson: 0.7248
Batch[7469] - loss: 0.001387 best_pearson: 0.7248
Batch[7470] - loss: 0.000468 best_pearson: 0.7248
Batch[7471] - loss: 0.000758 best_pearson: 0.7248
Batch[7472] - loss: 0.000899 best_pearson: 0.7248
Batch[7473] - loss: 0.000736 best_pearson: 0.7248
Batch[7474] - loss: 0.000965 best_pearson: 0.7248
Batch[7475] - loss: 0.000847 best_pearson: 0.7248
Batch[7476] - loss: 0.000850 best_pearson: 0.7248
Batch[7477] - loss: 0.000977 best_pearson: 0.7248
Batch[7478] - loss: 0.000485 best_pearson: 0.7248
Batch[7479] - loss: 0.000832 best_pearson: 0.7248
Batch[7480] - loss: 0.000800 best_pearson: 0.7248
Batch[7481] - loss: 0.001040 best_pearson: 0.7248
Batch[7482] - loss: 0.000920 best_pearson: 0.7248
Batch[7483] - loss: 0.000870 best_pearson: 0.7248
Batch[7484] - loss: 0.000748 best_pearson: 0.7248
Batch[7485] - loss: 0.000636 best_pearson: 0.7248
Batch[7486] - loss: 0.000479 best_pearson: 0.7248
Batch[7487] - loss: 0.001270 best_pearson: 0.7248
Batch[7488] - loss: 0.000688 best_pearson: 0.7248
Batch[7489] - loss: 0.000883 best_pearson: 0.7248
Batch[7490] - loss: 0.000791 best_pearson: 0.7248
Batch[7491] - loss: 0.000951 best_pearson: 0.7248
Batch[7492] - loss: 0.000748 best_pearson: 0.7248
Batch[7493] - loss: 0.000737 best_pearson: 0.7248
Batch[7494] - loss: 0.000762 best_pearson: 0.7248
Batch[7495] - loss: 0.001243 best_pearson: 0.7248
Batch[7496] - loss: 0.000753 best_pearson: 0.7248
Batch[7497] - loss: 0.000737 best_pearson: 0.7248
Batch[7498] - loss: 0.000587 best_pearson: 0.7248
Batch[7499] - loss: 0.000554 best_pearson: 0.7248
Batch[7500] - loss: 0.000756 best_pearson: 0.7248

Evaluation - loss: 0.000047 pearson: 0.7151 

early stop by 1500 steps.
Batch[7501] - loss: 0.000533 best_pearson: 0.7248
Batch[7502] - loss: 0.000469 best_pearson: 0.7248
Batch[7503] - loss: 0.000794 best_pearson: 0.7248
Batch[7504] - loss: 0.000642 best_pearson: 0.7248
Batch[7505] - loss: 0.000690 best_pearson: 0.7248
Batch[7506] - loss: 0.001213 best_pearson: 0.7248
Batch[7507] - loss: 0.000680 best_pearson: 0.7248
Batch[7508] - loss: 0.000561 best_pearson: 0.7248
Batch[7509] - loss: 0.000684 best_pearson: 0.7248
Batch[7510] - loss: 0.001588 best_pearson: 0.7248
Batch[7511] - loss: 0.000788 best_pearson: 0.7248
Batch[7512] - loss: 0.000706 best_pearson: 0.7248
Batch[7513] - loss: 0.000535 best_pearson: 0.7248
Batch[7514] - loss: 0.000520 best_pearson: 0.7248
Batch[7515] - loss: 0.000549 best_pearson: 0.7248
Batch[7516] - loss: 0.000715 best_pearson: 0.7248
Batch[7517] - loss: 0.000545 best_pearson: 0.7248
Batch[7518] - loss: 0.000518 best_pearson: 0.7248
Batch[7519] - loss: 0.000716 best_pearson: 0.7248
Batch[7520] - loss: 0.000782 best_pearson: 0.7248
Batch[7521] - loss: 0.000929 best_pearson: 0.7248
Batch[7522] - loss: 0.000552 best_pearson: 0.7248
Batch[7523] - loss: 0.000456 best_pearson: 0.7248
Batch[7524] - loss: 0.000792 best_pearson: 0.7248
Batch[7525] - loss: 0.000815 best_pearson: 0.7248
Batch[7526] - loss: 0.000527 best_pearson: 0.7248
Batch[7527] - loss: 0.000391 best_pearson: 0.7248
Batch[7528] - loss: 0.001176 best_pearson: 0.7248
Batch[7529] - loss: 0.000487 best_pearson: 0.7248
Batch[7530] - loss: 0.000790 best_pearson: 0.7248
Batch[7531] - loss: 0.000837 best_pearson: 0.7248
Batch[7532] - loss: 0.000554 best_pearson: 0.7248
Batch[7533] - loss: 0.000585 best_pearson: 0.7248
Batch[7534] - loss: 0.000662 best_pearson: 0.7248
Batch[7535] - loss: 0.000900 best_pearson: 0.7248
Batch[7536] - loss: 0.000738 best_pearson: 0.7248
Batch[7537] - loss: 0.000522 best_pearson: 0.7248
Batch[7538] - loss: 0.000748 best_pearson: 0.7248
Batch[7539] - loss: 0.000729 best_pearson: 0.7248
Batch[7540] - loss: 0.000552 best_pearson: 0.7248
Batch[7541] - loss: 0.000601 best_pearson: 0.7248
Batch[7542] - loss: 0.000564 best_pearson: 0.7248
Batch[7543] - loss: 0.001311 best_pearson: 0.7248
Batch[7544] - loss: 0.000900 best_pearson: 0.7248
Batch[7545] - loss: 0.000372 best_pearson: 0.7248
Batch[7546] - loss: 0.000410 best_pearson: 0.7248
Batch[7547] - loss: 0.000496 best_pearson: 0.7248
Batch[7548] - loss: 0.000774 best_pearson: 0.7248
Batch[7549] - loss: 0.000665 best_pearson: 0.7248
Batch[7550] - loss: 0.000555 best_pearson: 0.7248
Batch[7551] - loss: 0.000677 best_pearson: 0.7248
Batch[7552] - loss: 0.000496 best_pearson: 0.7248
Batch[7553] - loss: 0.000549 best_pearson: 0.7248
Batch[7554] - loss: 0.000912 best_pearson: 0.7248
Batch[7555] - loss: 0.000909 best_pearson: 0.7248
Batch[7556] - loss: 0.000488 best_pearson: 0.7248
Batch[7557] - loss: 0.000605 best_pearson: 0.7248
Batch[7558] - loss: 0.000939 best_pearson: 0.7248
Batch[7559] - loss: 0.000804 best_pearson: 0.7248
Batch[7560] - loss: 0.000693 best_pearson: 0.7248
Batch[7561] - loss: 0.000821 best_pearson: 0.7248
Batch[7562] - loss: 0.000811 best_pearson: 0.7248
Batch[7563] - loss: 0.001091 best_pearson: 0.7248
Batch[7564] - loss: 0.000575 best_pearson: 0.7248
Batch[7565] - loss: 0.000935 best_pearson: 0.7248
Batch[7566] - loss: 0.000581 best_pearson: 0.7248
Batch[7567] - loss: 0.001155 best_pearson: 0.7248
Batch[7568] - loss: 0.000821 best_pearson: 0.7248
Batch[7569] - loss: 0.001013 best_pearson: 0.7248
Batch[7570] - loss: 0.001014 best_pearson: 0.7248
Batch[7571] - loss: 0.000463 best_pearson: 0.7248
Batch[7572] - loss: 0.000790 best_pearson: 0.7248
Batch[7573] - loss: 0.000855 best_pearson: 0.7248
Batch[7574] - loss: 0.000592 best_pearson: 0.7248
Batch[7575] - loss: 0.000625 best_pearson: 0.7248
Batch[7576] - loss: 0.000657 best_pearson: 0.7248
Batch[7577] - loss: 0.000835 best_pearson: 0.7248
Batch[7578] - loss: 0.001037 best_pearson: 0.7248
Batch[7579] - loss: 0.000476 best_pearson: 0.7248
Batch[7580] - loss: 0.000698 best_pearson: 0.7248
Batch[7581] - loss: 0.000862 best_pearson: 0.7248
Batch[7582] - loss: 0.000501 best_pearson: 0.7248
Batch[7583] - loss: 0.000647 best_pearson: 0.7248
Batch[7584] - loss: 0.000550 best_pearson: 0.7248
Batch[7585] - loss: 0.000758 best_pearson: 0.7248
Batch[7586] - loss: 0.000531 best_pearson: 0.7248
Batch[7587] - loss: 0.001402 best_pearson: 0.7248
Batch[7588] - loss: 0.000512 best_pearson: 0.7248
Batch[7589] - loss: 0.000490 best_pearson: 0.7248
Batch[7590] - loss: 0.000961 best_pearson: 0.7248
Batch[7591] - loss: 0.000740 best_pearson: 0.7248
Batch[7592] - loss: 0.000539 best_pearson: 0.7248
Batch[7593] - loss: 0.000682 best_pearson: 0.7248
Batch[7594] - loss: 0.001060 best_pearson: 0.7248
Batch[7595] - loss: 0.000750 best_pearson: 0.7248
Batch[7596] - loss: 0.000670 best_pearson: 0.7248
Batch[7597] - loss: 0.000787 best_pearson: 0.7248
Batch[7598] - loss: 0.000577 best_pearson: 0.7248
Batch[7599] - loss: 0.000639 best_pearson: 0.7248
Batch[7600] - loss: 0.000584 best_pearson: 0.7248

Evaluation - loss: 0.000047 pearson: 0.7167 

early stop by 1500 steps.
Batch[7601] - loss: 0.000650 best_pearson: 0.7248
Batch[7602] - loss: 0.000695 best_pearson: 0.7248
Batch[7603] - loss: 0.000358 best_pearson: 0.7248
Batch[7604] - loss: 0.000765 best_pearson: 0.7248
Batch[7605] - loss: 0.000718 best_pearson: 0.7248
Batch[7606] - loss: 0.000761 best_pearson: 0.7248
Batch[7607] - loss: 0.000590 best_pearson: 0.7248
Batch[7608] - loss: 0.000761 best_pearson: 0.7248
Batch[7609] - loss: 0.000552 best_pearson: 0.7248
Batch[7610] - loss: 0.000482 best_pearson: 0.7248
Batch[7611] - loss: 0.000577 best_pearson: 0.7248
Batch[7612] - loss: 0.000542 best_pearson: 0.7248
Batch[7613] - loss: 0.000623 best_pearson: 0.7248
Batch[7614] - loss: 0.000579 best_pearson: 0.7248
Batch[7615] - loss: 0.000593 best_pearson: 0.7248
Batch[7616] - loss: 0.000553 best_pearson: 0.7248
Batch[7617] - loss: 0.000538 best_pearson: 0.7248
Batch[7618] - loss: 0.000708 best_pearson: 0.7248
Batch[7619] - loss: 0.000649 best_pearson: 0.7248
Batch[7620] - loss: 0.000729 best_pearson: 0.7248
Batch[7621] - loss: 0.000914 best_pearson: 0.7248
Batch[7622] - loss: 0.000807 best_pearson: 0.7248
Batch[7623] - loss: 0.000698 best_pearson: 0.7248
Batch[7624] - loss: 0.000455 best_pearson: 0.7248
Batch[7625] - loss: 0.000780 best_pearson: 0.7248
Batch[7626] - loss: 0.000988 best_pearson: 0.7248
Batch[7627] - loss: 0.000843 best_pearson: 0.7248
Batch[7628] - loss: 0.000494 best_pearson: 0.7248
Batch[7629] - loss: 0.001349 best_pearson: 0.7248
Batch[7630] - loss: 0.001382 best_pearson: 0.7248
Batch[7631] - loss: 0.000551 best_pearson: 0.7248
Batch[7632] - loss: 0.000985 best_pearson: 0.7248
Batch[7633] - loss: 0.000692 best_pearson: 0.7248
Batch[7634] - loss: 0.001042 best_pearson: 0.7248
Batch[7635] - loss: 0.000780 best_pearson: 0.7248
Batch[7636] - loss: 0.000903 best_pearson: 0.7248
Batch[7637] - loss: 0.001178 best_pearson: 0.7248
Batch[7638] - loss: 0.000773 best_pearson: 0.7248
Batch[7639] - loss: 0.000684 best_pearson: 0.7248
Batch[7640] - loss: 0.001073 best_pearson: 0.7248
Batch[7641] - loss: 0.000870 best_pearson: 0.7248
Batch[7642] - loss: 0.000822 best_pearson: 0.7248
Batch[7643] - loss: 0.000944 best_pearson: 0.7248
Batch[7644] - loss: 0.000581 best_pearson: 0.7248
Batch[7645] - loss: 0.000770 best_pearson: 0.7248
Batch[7646] - loss: 0.000760 best_pearson: 0.7248
Batch[7647] - loss: 0.000656 best_pearson: 0.7248
Batch[7648] - loss: 0.000797 best_pearson: 0.7248
Batch[7649] - loss: 0.001622 best_pearson: 0.7248
Batch[7650] - loss: 0.000802 best_pearson: 0.7248
Batch[7651] - loss: 0.000835 best_pearson: 0.7248
Batch[7652] - loss: 0.001239 best_pearson: 0.7248
Batch[7653] - loss: 0.000537 best_pearson: 0.7248
Batch[7654] - loss: 0.001052 best_pearson: 0.7248
Batch[7655] - loss: 0.000617 best_pearson: 0.7248
Batch[7656] - loss: 0.000398 best_pearson: 0.7248
Batch[7657] - loss: 0.000581 best_pearson: 0.7248
Batch[7658] - loss: 0.000432 best_pearson: 0.7248
Batch[7659] - loss: 0.000945 best_pearson: 0.7248
Batch[7660] - loss: 0.000868 best_pearson: 0.7248
Batch[7661] - loss: 0.000684 best_pearson: 0.7248
Batch[7662] - loss: 0.000828 best_pearson: 0.7248
Batch[7663] - loss: 0.000499 best_pearson: 0.7248
Batch[7664] - loss: 0.000768 best_pearson: 0.7248
Batch[7665] - loss: 0.000867 best_pearson: 0.7248
Batch[7666] - loss: 0.000884 best_pearson: 0.7248
Batch[7667] - loss: 0.000677 best_pearson: 0.7248
Batch[7668] - loss: 0.001446 best_pearson: 0.7248
Batch[7669] - loss: 0.000879 best_pearson: 0.7248
Batch[7670] - loss: 0.000451 best_pearson: 0.7248
Batch[7671] - loss: 0.000835 best_pearson: 0.7248
Batch[7672] - loss: 0.001460 best_pearson: 0.7248
Batch[7673] - loss: 0.000951 best_pearson: 0.7248
Batch[7674] - loss: 0.000766 best_pearson: 0.7248
Batch[7675] - loss: 0.000589 best_pearson: 0.7248
Batch[7676] - loss: 0.000858 best_pearson: 0.7248
Batch[7677] - loss: 0.000795 best_pearson: 0.7248
Batch[7678] - loss: 0.000776 best_pearson: 0.7248
Batch[7679] - loss: 0.000709 best_pearson: 0.7248
Batch[7680] - loss: 0.000641 best_pearson: 0.7248
Batch[7681] - loss: 0.000702 best_pearson: 0.7248
Batch[7682] - loss: 0.001376 best_pearson: 0.7248
Batch[7683] - loss: 0.001093 best_pearson: 0.7248
Batch[7684] - loss: 0.000677 best_pearson: 0.7248
Batch[7685] - loss: 0.001116 best_pearson: 0.7248
Batch[7686] - loss: 0.000861 best_pearson: 0.7248
Batch[7687] - loss: 0.000690 best_pearson: 0.7248
Batch[7688] - loss: 0.000901 best_pearson: 0.7248
Batch[7689] - loss: 0.000775 best_pearson: 0.7248
Batch[7690] - loss: 0.000793 best_pearson: 0.7248
Batch[7691] - loss: 0.000585 best_pearson: 0.7248
Batch[7692] - loss: 0.000652 best_pearson: 0.7248
Batch[7693] - loss: 0.000878 best_pearson: 0.7248
Batch[7694] - loss: 0.000885 best_pearson: 0.7248
Batch[7695] - loss: 0.000824 best_pearson: 0.7248
Batch[7696] - loss: 0.001305 best_pearson: 0.7248
Batch[7697] - loss: 0.000427 best_pearson: 0.7248
Batch[7698] - loss: 0.000984 best_pearson: 0.7248
Batch[7699] - loss: 0.001078 best_pearson: 0.7248
Batch[7700] - loss: 0.001171 best_pearson: 0.7248

Evaluation - loss: 0.000047 pearson: 0.7159 

early stop by 1500 steps.
Batch[7701] - loss: 0.000428 best_pearson: 0.7248
Batch[7702] - loss: 0.000917 best_pearson: 0.7248
Batch[7703] - loss: 0.000751 best_pearson: 0.7248
Batch[7704] - loss: 0.000756 best_pearson: 0.7248
Batch[7705] - loss: 0.001222 best_pearson: 0.7248
Batch[7706] - loss: 0.001006 best_pearson: 0.7248
Batch[7707] - loss: 0.001246 best_pearson: 0.7248
Batch[7708] - loss: 0.001034 best_pearson: 0.7248
Batch[7709] - loss: 0.001160 best_pearson: 0.7248
Batch[7710] - loss: 0.000973 best_pearson: 0.7248
Batch[7711] - loss: 0.000959 best_pearson: 0.7248
Batch[7712] - loss: 0.000998 best_pearson: 0.7248
Batch[7713] - loss: 0.001000 best_pearson: 0.7248
Batch[7714] - loss: 0.000830 best_pearson: 0.7248
Batch[7715] - loss: 0.000729 best_pearson: 0.7248
Batch[7716] - loss: 0.000371 best_pearson: 0.7248
Batch[7717] - loss: 0.000602 best_pearson: 0.7248
Batch[7718] - loss: 0.000845 best_pearson: 0.7248
Batch[7719] - loss: 0.000445 best_pearson: 0.7248
Batch[7720] - loss: 0.000926 best_pearson: 0.7248
Batch[7721] - loss: 0.001402 best_pearson: 0.7248
Batch[7722] - loss: 0.000751 best_pearson: 0.7248
Batch[7723] - loss: 0.000958 best_pearson: 0.7248
Batch[7724] - loss: 0.000509 best_pearson: 0.7248
Batch[7725] - loss: 0.000786 best_pearson: 0.7248
Batch[7726] - loss: 0.000777 best_pearson: 0.7248
Batch[7727] - loss: 0.000706 best_pearson: 0.7248
Batch[7728] - loss: 0.001169 best_pearson: 0.7248
Batch[7729] - loss: 0.000537 best_pearson: 0.7248
Batch[7730] - loss: 0.001056 best_pearson: 0.7248
Batch[7731] - loss: 0.001034 best_pearson: 0.7248
Batch[7732] - loss: 0.000831 best_pearson: 0.7248
Batch[7733] - loss: 0.000770 best_pearson: 0.7248
Batch[7734] - loss: 0.001444 best_pearson: 0.7248
Batch[7735] - loss: 0.000549 best_pearson: 0.7248
Batch[7736] - loss: 0.000730 best_pearson: 0.7248
Batch[7737] - loss: 0.000716 best_pearson: 0.7248
Batch[7738] - loss: 0.000554 best_pearson: 0.7248
Batch[7739] - loss: 0.000243 best_pearson: 0.7248
Batch[7740] - loss: 0.001168 best_pearson: 0.7248
Batch[7741] - loss: 0.000484 best_pearson: 0.7248
Batch[7742] - loss: 0.000753 best_pearson: 0.7248
Batch[7743] - loss: 0.000877 best_pearson: 0.7248
Batch[7744] - loss: 0.000887 best_pearson: 0.7248
Batch[7745] - loss: 0.000951 best_pearson: 0.7248
Batch[7746] - loss: 0.000967 best_pearson: 0.7248
Batch[7747] - loss: 0.000679 best_pearson: 0.7248
Batch[7748] - loss: 0.000722 best_pearson: 0.7248
Batch[7749] - loss: 0.000617 best_pearson: 0.7248
Batch[7750] - loss: 0.000910 best_pearson: 0.7248
Batch[7751] - loss: 0.001103 best_pearson: 0.7248
Batch[7752] - loss: 0.000754 best_pearson: 0.7248
Batch[7753] - loss: 0.000961 best_pearson: 0.7248
Batch[7754] - loss: 0.000866 best_pearson: 0.7248
Batch[7755] - loss: 0.000902 best_pearson: 0.7248
Batch[7756] - loss: 0.000735 best_pearson: 0.7248
Batch[7757] - loss: 0.001183 best_pearson: 0.7248
Batch[7758] - loss: 0.000648 best_pearson: 0.7248
Batch[7759] - loss: 0.000793 best_pearson: 0.7248
Batch[7760] - loss: 0.000876 best_pearson: 0.7248
Batch[7761] - loss: 0.000830 best_pearson: 0.7248
Batch[7762] - loss: 0.000859 best_pearson: 0.7248
Batch[7763] - loss: 0.000904 best_pearson: 0.7248
Batch[7764] - loss: 0.000480 best_pearson: 0.7248
Batch[7765] - loss: 0.000952 best_pearson: 0.7248
Batch[7766] - loss: 0.000293 best_pearson: 0.7248
Batch[7767] - loss: 0.001185 best_pearson: 0.7248
Batch[7768] - loss: 0.001166 best_pearson: 0.7248
Batch[7769] - loss: 0.000841 best_pearson: 0.7248
Batch[7770] - loss: 0.000772 best_pearson: 0.7248
Batch[7771] - loss: 0.000782 best_pearson: 0.7248
Batch[7772] - loss: 0.000885 best_pearson: 0.7248
Batch[7773] - loss: 0.000995 best_pearson: 0.7248
Batch[7774] - loss: 0.000580 best_pearson: 0.7248
Batch[7775] - loss: 0.000953 best_pearson: 0.7248
Batch[7776] - loss: 0.001306 best_pearson: 0.7248
Batch[7777] - loss: 0.001407 best_pearson: 0.7248
Batch[7778] - loss: 0.000609 best_pearson: 0.7248
Batch[7779] - loss: 0.001084 best_pearson: 0.7248
Batch[7780] - loss: 0.000944 best_pearson: 0.7248
Batch[7781] - loss: 0.000631 best_pearson: 0.7248
Batch[7782] - loss: 0.000729 best_pearson: 0.7248
Batch[7783] - loss: 0.000733 best_pearson: 0.7248
Batch[7784] - loss: 0.000431 best_pearson: 0.7248
Batch[7785] - loss: 0.001191 best_pearson: 0.7248
Batch[7786] - loss: 0.002390 best_pearson: 0.7248
Batch[7787] - loss: 0.001101 best_pearson: 0.7248
Batch[7788] - loss: 0.000656 best_pearson: 0.7248
Batch[7789] - loss: 0.000644 best_pearson: 0.7248
Batch[7790] - loss: 0.000764 best_pearson: 0.7248
Batch[7791] - loss: 0.001148 best_pearson: 0.7248
Batch[7792] - loss: 0.001441 best_pearson: 0.7248
Batch[7793] - loss: 0.001148 best_pearson: 0.7248
Batch[7794] - loss: 0.001740 best_pearson: 0.7248
Batch[7795] - loss: 0.001366 best_pearson: 0.7248
Batch[7796] - loss: 0.000871 best_pearson: 0.7248
Batch[7797] - loss: 0.001086 best_pearson: 0.7248
Batch[7798] - loss: 0.000828 best_pearson: 0.7248
Batch[7799] - loss: 0.001106 best_pearson: 0.7248
Batch[7800] - loss: 0.001053 best_pearson: 0.7248

Evaluation - loss: 0.000048 pearson: 0.7109 

early stop by 1500 steps.
Batch[7801] - loss: 0.001035 best_pearson: 0.7248
Batch[7802] - loss: 0.001387 best_pearson: 0.7248
Batch[7803] - loss: 0.000797 best_pearson: 0.7248
Batch[7804] - loss: 0.000946 best_pearson: 0.7248
Batch[7805] - loss: 0.000766 best_pearson: 0.7248
Batch[7806] - loss: 0.001331 best_pearson: 0.7248
Batch[7807] - loss: 0.000939 best_pearson: 0.7248
Batch[7808] - loss: 0.000606 best_pearson: 0.7248
Batch[7809] - loss: 0.001432 best_pearson: 0.7248
Batch[7810] - loss: 0.001159 best_pearson: 0.7248
Batch[7811] - loss: 0.000961 best_pearson: 0.7248
Batch[7812] - loss: 0.001931 best_pearson: 0.7248
Batch[7813] - loss: 0.002172 best_pearson: 0.7248
Batch[7814] - loss: 0.000573 best_pearson: 0.7248
Batch[7815] - loss: 0.001216 best_pearson: 0.7248
Batch[7816] - loss: 0.000817 best_pearson: 0.7248
Batch[7817] - loss: 0.000803 best_pearson: 0.7248
Batch[7818] - loss: 0.000947 best_pearson: 0.7248
Batch[7819] - loss: 0.000863 best_pearson: 0.7248
Batch[7820] - loss: 0.000887 best_pearson: 0.7248
Batch[7821] - loss: 0.000877 best_pearson: 0.7248
Batch[7822] - loss: 0.001008 best_pearson: 0.7248
Batch[7823] - loss: 0.000857 best_pearson: 0.7248
Batch[7824] - loss: 0.000637 best_pearson: 0.7248
Batch[7825] - loss: 0.001305 best_pearson: 0.7248
Batch[7826] - loss: 0.000470 best_pearson: 0.7248
Batch[7827] - loss: 0.000909 best_pearson: 0.7248
Batch[7828] - loss: 0.000628 best_pearson: 0.7248
Batch[7829] - loss: 0.000533 best_pearson: 0.7248
Batch[7830] - loss: 0.001148 best_pearson: 0.7248
Batch[7831] - loss: 0.001683 best_pearson: 0.7248
Batch[7832] - loss: 0.000746 best_pearson: 0.7248
Batch[7833] - loss: 0.000489 best_pearson: 0.7248
Batch[7834] - loss: 0.000787 best_pearson: 0.7248
Batch[7835] - loss: 0.000834 best_pearson: 0.7248
Batch[7836] - loss: 0.000431 best_pearson: 0.7248
Batch[7837] - loss: 0.000918 best_pearson: 0.7248
Batch[7838] - loss: 0.001118 best_pearson: 0.7248
Batch[7839] - loss: 0.000855 best_pearson: 0.7248
Batch[7840] - loss: 0.000565 best_pearson: 0.7248
Batch[7841] - loss: 0.000921 best_pearson: 0.7248
Batch[7842] - loss: 0.001060 best_pearson: 0.7248
Batch[7843] - loss: 0.000797 best_pearson: 0.7248
Batch[7844] - loss: 0.001026 best_pearson: 0.7248
Batch[7845] - loss: 0.000824 best_pearson: 0.7248
Batch[7846] - loss: 0.000532 best_pearson: 0.7248
Batch[7847] - loss: 0.000881 best_pearson: 0.7248
Batch[7848] - loss: 0.000979 best_pearson: 0.7248
Batch[7849] - loss: 0.000512 best_pearson: 0.7248
Batch[7850] - loss: 0.000578 best_pearson: 0.7248
Batch[7851] - loss: 0.000814 best_pearson: 0.7248
Batch[7852] - loss: 0.001139 best_pearson: 0.7248
Batch[7853] - loss: 0.001182 best_pearson: 0.7248
Batch[7854] - loss: 0.000632 best_pearson: 0.7248
Batch[7855] - loss: 0.000775 best_pearson: 0.7248
Batch[7856] - loss: 0.000824 best_pearson: 0.7248
Batch[7857] - loss: 0.000535 best_pearson: 0.7248
Batch[7858] - loss: 0.002179 best_pearson: 0.7248
Batch[7859] - loss: 0.000609 best_pearson: 0.7248
Batch[7860] - loss: 0.000868 best_pearson: 0.7248
Batch[7861] - loss: 0.000788 best_pearson: 0.7248
Batch[7862] - loss: 0.001164 best_pearson: 0.7248
Batch[7863] - loss: 0.000837 best_pearson: 0.7248
Batch[7864] - loss: 0.000884 best_pearson: 0.7248
Batch[7865] - loss: 0.000846 best_pearson: 0.7248
Batch[7866] - loss: 0.000588 best_pearson: 0.7248
Batch[7867] - loss: 0.000778 best_pearson: 0.7248
Batch[7868] - loss: 0.000955 best_pearson: 0.7248
Batch[7869] - loss: 0.000748 best_pearson: 0.7248
Batch[7870] - loss: 0.000615 best_pearson: 0.7248
Batch[7871] - loss: 0.000763 best_pearson: 0.7248
Batch[7872] - loss: 0.000881 best_pearson: 0.7248
Batch[7873] - loss: 0.001062 best_pearson: 0.7248
Batch[7874] - loss: 0.000821 best_pearson: 0.7248
Batch[7875] - loss: 0.000966 best_pearson: 0.7248
Batch[7876] - loss: 0.001217 best_pearson: 0.7248
Batch[7877] - loss: 0.000734 best_pearson: 0.7248
Batch[7878] - loss: 0.000589 best_pearson: 0.7248
Batch[7879] - loss: 0.001205 best_pearson: 0.7248
Batch[7880] - loss: 0.001278 best_pearson: 0.7248
Batch[7881] - loss: 0.000980 best_pearson: 0.7248
Batch[7882] - loss: 0.000739 best_pearson: 0.7248
Batch[7883] - loss: 0.001229 best_pearson: 0.7248
Batch[7884] - loss: 0.000676 best_pearson: 0.7248
Batch[7885] - loss: 0.001677 best_pearson: 0.7248
Batch[7886] - loss: 0.000826 best_pearson: 0.7248
Batch[7887] - loss: 0.000680 best_pearson: 0.7248
Batch[7888] - loss: 0.001112 best_pearson: 0.7248
Batch[7889] - loss: 0.001072 best_pearson: 0.7248
Batch[7890] - loss: 0.000747 best_pearson: 0.7248
Batch[7891] - loss: 0.000630 best_pearson: 0.7248
Batch[7892] - loss: 0.001363 best_pearson: 0.7248
Batch[7893] - loss: 0.001462 best_pearson: 0.7248
Batch[7894] - loss: 0.001023 best_pearson: 0.7248
Batch[7895] - loss: 0.001031 best_pearson: 0.7248
Batch[7896] - loss: 0.001093 best_pearson: 0.7248
Batch[7897] - loss: 0.000601 best_pearson: 0.7248
Batch[7898] - loss: 0.000824 best_pearson: 0.7248
Batch[7899] - loss: 0.001472 best_pearson: 0.7248
Batch[7900] - loss: 0.000902 best_pearson: 0.7248

Evaluation - loss: 0.000046 pearson: 0.7179 

early stop by 1500 steps.
Batch[7901] - loss: 0.000966 best_pearson: 0.7248
Batch[7902] - loss: 0.000624 best_pearson: 0.7248
Batch[7903] - loss: 0.000504 best_pearson: 0.7248
Batch[7904] - loss: 0.000474 best_pearson: 0.7248
Batch[7905] - loss: 0.000751 best_pearson: 0.7248
Batch[7906] - loss: 0.000709 best_pearson: 0.7248
Batch[7907] - loss: 0.001138 best_pearson: 0.7248
Batch[7908] - loss: 0.001072 best_pearson: 0.7248
Batch[7909] - loss: 0.001348 best_pearson: 0.7248
Batch[7910] - loss: 0.000677 best_pearson: 0.7248
Batch[7911] - loss: 0.000762 best_pearson: 0.7248
Batch[7912] - loss: 0.001235 best_pearson: 0.7248
Batch[7913] - loss: 0.000726 best_pearson: 0.7248
Batch[7914] - loss: 0.000709 best_pearson: 0.7248
Batch[7915] - loss: 0.000599 best_pearson: 0.7248
Batch[7916] - loss: 0.001227 best_pearson: 0.7248
Batch[7917] - loss: 0.000537 best_pearson: 0.7248
Batch[7918] - loss: 0.000886 best_pearson: 0.7248
Batch[7919] - loss: 0.000645 best_pearson: 0.7248
Batch[7920] - loss: 0.000777 best_pearson: 0.7248
Batch[7921] - loss: 0.000923 best_pearson: 0.7248
Batch[7922] - loss: 0.000767 best_pearson: 0.7248
Batch[7923] - loss: 0.000883 best_pearson: 0.7248
Batch[7924] - loss: 0.000846 best_pearson: 0.7248
Batch[7925] - loss: 0.000584 best_pearson: 0.7248
Batch[7926] - loss: 0.001227 best_pearson: 0.7248
Batch[7927] - loss: 0.000919 best_pearson: 0.7248
Batch[7928] - loss: 0.001175 best_pearson: 0.7248
Batch[7929] - loss: 0.000752 best_pearson: 0.7248
Batch[7930] - loss: 0.000801 best_pearson: 0.7248
Batch[7931] - loss: 0.000988 best_pearson: 0.7248
Batch[7932] - loss: 0.000847 best_pearson: 0.7248
Batch[7933] - loss: 0.001808 best_pearson: 0.7248
Batch[7934] - loss: 0.001131 best_pearson: 0.7248
Batch[7935] - loss: 0.000655 best_pearson: 0.7248
Batch[7936] - loss: 0.000587 best_pearson: 0.7248
Batch[7937] - loss: 0.000805 best_pearson: 0.7248
Batch[7938] - loss: 0.000700 best_pearson: 0.7248
Batch[7939] - loss: 0.000722 best_pearson: 0.7248
Batch[7940] - loss: 0.000774 best_pearson: 0.7248
Batch[7941] - loss: 0.000847 best_pearson: 0.7248
Batch[7942] - loss: 0.000812 best_pearson: 0.7248
Batch[7943] - loss: 0.000922 best_pearson: 0.7248
Batch[7944] - loss: 0.000799 best_pearson: 0.7248
Batch[7945] - loss: 0.000452 best_pearson: 0.7248
Batch[7946] - loss: 0.000926 best_pearson: 0.7248
Batch[7947] - loss: 0.000738 best_pearson: 0.7248
Batch[7948] - loss: 0.000797 best_pearson: 0.7248
Batch[7949] - loss: 0.000838 best_pearson: 0.7248
Batch[7950] - loss: 0.000755 best_pearson: 0.7248
Batch[7951] - loss: 0.000837 best_pearson: 0.7248
Batch[7952] - loss: 0.000609 best_pearson: 0.7248
Batch[7953] - loss: 0.001054 best_pearson: 0.7248
Batch[7954] - loss: 0.000603 best_pearson: 0.7248
Batch[7955] - loss: 0.000639 best_pearson: 0.7248
Batch[7956] - loss: 0.000791 best_pearson: 0.7248
Batch[7957] - loss: 0.000546 best_pearson: 0.7248
Batch[7958] - loss: 0.000387 best_pearson: 0.7248
Batch[7959] - loss: 0.000650 best_pearson: 0.7248
Batch[7960] - loss: 0.000708 best_pearson: 0.7248
Batch[7961] - loss: 0.000554 best_pearson: 0.7248
Batch[7962] - loss: 0.000851 best_pearson: 0.7248
Batch[7963] - loss: 0.000948 best_pearson: 0.7248
Batch[7964] - loss: 0.000815 best_pearson: 0.7248
Batch[7965] - loss: 0.000992 best_pearson: 0.7248
Batch[7966] - loss: 0.000869 best_pearson: 0.7248
Batch[7967] - loss: 0.000933 best_pearson: 0.7248
Batch[7968] - loss: 0.001194 best_pearson: 0.7248
Batch[7969] - loss: 0.000950 best_pearson: 0.7248
Batch[7970] - loss: 0.000379 best_pearson: 0.7248
Batch[7971] - loss: 0.001024 best_pearson: 0.7248
Batch[7972] - loss: 0.001136 best_pearson: 0.7248
Batch[7973] - loss: 0.001012 best_pearson: 0.7248
Batch[7974] - loss: 0.000704 best_pearson: 0.7248
Batch[7975] - loss: 0.000776 best_pearson: 0.7248
Batch[7976] - loss: 0.001359 best_pearson: 0.7248
Batch[7977] - loss: 0.001078 best_pearson: 0.7248
Batch[7978] - loss: 0.000851 best_pearson: 0.7248
Batch[7979] - loss: 0.000830 best_pearson: 0.7248
Batch[7980] - loss: 0.001002 best_pearson: 0.7248
Batch[7981] - loss: 0.000849 best_pearson: 0.7248
Batch[7982] - loss: 0.000741 best_pearson: 0.7248
Batch[7983] - loss: 0.000736 best_pearson: 0.7248
Batch[7984] - loss: 0.000434 best_pearson: 0.7248
Batch[7985] - loss: 0.000490 best_pearson: 0.7248
Batch[7986] - loss: 0.000899 best_pearson: 0.7248
Batch[7987] - loss: 0.000540 best_pearson: 0.7248
Batch[7988] - loss: 0.000922 best_pearson: 0.7248
Batch[7989] - loss: 0.000738 best_pearson: 0.7248
Batch[7990] - loss: 0.001167 best_pearson: 0.7248
Batch[7991] - loss: 0.000684 best_pearson: 0.7248
Batch[7992] - loss: 0.000701 best_pearson: 0.7248
Batch[7993] - loss: 0.001294 best_pearson: 0.7248
Batch[7994] - loss: 0.001285 best_pearson: 0.7248
Batch[7995] - loss: 0.000713 best_pearson: 0.7248
Batch[7996] - loss: 0.000528 best_pearson: 0.7248
Batch[7997] - loss: 0.000702 best_pearson: 0.7248
Batch[7998] - loss: 0.000832 best_pearson: 0.7248
Batch[7999] - loss: 0.000427 best_pearson: 0.7248
Batch[8000] - loss: 0.001150 best_pearson: 0.7248

Evaluation - loss: 0.000046 pearson: 0.7176 

early stop by 1500 steps.
Batch[8001] - loss: 0.000733 best_pearson: 0.7248
Batch[8002] - loss: 0.000821 best_pearson: 0.7248
Batch[8003] - loss: 0.001453 best_pearson: 0.7248
Batch[8004] - loss: 0.001035 best_pearson: 0.7248
Batch[8005] - loss: 0.001082 best_pearson: 0.7248
Batch[8006] - loss: 0.000782 best_pearson: 0.7248
Batch[8007] - loss: 0.000548 best_pearson: 0.7248
Batch[8008] - loss: 0.000941 best_pearson: 0.7248
Batch[8009] - loss: 0.000951 best_pearson: 0.7248
Batch[8010] - loss: 0.000558 best_pearson: 0.7248
Batch[8011] - loss: 0.000516 best_pearson: 0.7248
Batch[8012] - loss: 0.000470 best_pearson: 0.7248
Batch[8013] - loss: 0.000813 best_pearson: 0.7248
Batch[8014] - loss: 0.001250 best_pearson: 0.7248
Batch[8015] - loss: 0.000945 best_pearson: 0.7248
Batch[8016] - loss: 0.001085 best_pearson: 0.7248
Batch[8017] - loss: 0.001105 best_pearson: 0.7248
Batch[8018] - loss: 0.001410 best_pearson: 0.7248
Batch[8019] - loss: 0.001526 best_pearson: 0.7248
Batch[8020] - loss: 0.001071 best_pearson: 0.7248
Batch[8021] - loss: 0.001094 best_pearson: 0.7248
Batch[8022] - loss: 0.000830 best_pearson: 0.7248
Batch[8023] - loss: 0.000684 best_pearson: 0.7248
Batch[8024] - loss: 0.000636 best_pearson: 0.7248
Batch[8025] - loss: 0.000848 best_pearson: 0.7248
Batch[8026] - loss: 0.001001 best_pearson: 0.7248
Batch[8027] - loss: 0.001051 best_pearson: 0.7248
Batch[8028] - loss: 0.000632 best_pearson: 0.7248
Batch[8029] - loss: 0.000796 best_pearson: 0.7248
Batch[8030] - loss: 0.000743 best_pearson: 0.7248
Batch[8031] - loss: 0.000896 best_pearson: 0.7248
Batch[8032] - loss: 0.001224 best_pearson: 0.7248
Batch[8033] - loss: 0.000536 best_pearson: 0.7248
Batch[8034] - loss: 0.000660 best_pearson: 0.7248
Batch[8035] - loss: 0.000891 best_pearson: 0.7248
Batch[8036] - loss: 0.000772 best_pearson: 0.7248
Batch[8037] - loss: 0.000728 best_pearson: 0.7248
Batch[8038] - loss: 0.000750 best_pearson: 0.7248
Batch[8039] - loss: 0.001437 best_pearson: 0.7248
Batch[8040] - loss: 0.000752 best_pearson: 0.7248
Batch[8041] - loss: 0.000503 best_pearson: 0.7248
Batch[8042] - loss: 0.000750 best_pearson: 0.7248
Batch[8043] - loss: 0.001021 best_pearson: 0.7248
Batch[8044] - loss: 0.001096 best_pearson: 0.7248
Batch[8045] - loss: 0.000741 best_pearson: 0.7248
Batch[8046] - loss: 0.001388 best_pearson: 0.7248
Batch[8047] - loss: 0.001044 best_pearson: 0.7248
Batch[8048] - loss: 0.002264 best_pearson: 0.7248
Batch[8049] - loss: 0.000625 best_pearson: 0.7248
Batch[8050] - loss: 0.000970 best_pearson: 0.7248
Batch[8051] - loss: 0.001520 best_pearson: 0.7248
Batch[8052] - loss: 0.000972 best_pearson: 0.7248
Batch[8053] - loss: 0.000496 best_pearson: 0.7248
Batch[8054] - loss: 0.000807 best_pearson: 0.7248
Batch[8055] - loss: 0.001038 best_pearson: 0.7248
Batch[8056] - loss: 0.000468 best_pearson: 0.7248
Batch[8057] - loss: 0.000486 best_pearson: 0.7248
Batch[8058] - loss: 0.001739 best_pearson: 0.7248
Batch[8059] - loss: 0.001188 best_pearson: 0.7248
Batch[8060] - loss: 0.000691 best_pearson: 0.7248
Batch[8061] - loss: 0.000586 best_pearson: 0.7248
Batch[8062] - loss: 0.000569 best_pearson: 0.7248
Batch[8063] - loss: 0.000826 best_pearson: 0.7248
Batch[8064] - loss: 0.000987 best_pearson: 0.7248
Batch[8065] - loss: 0.000801 best_pearson: 0.7248
Batch[8066] - loss: 0.001011 best_pearson: 0.7248
Batch[8067] - loss: 0.000806 best_pearson: 0.7248
Batch[8068] - loss: 0.000843 best_pearson: 0.7248
Batch[8069] - loss: 0.000584 best_pearson: 0.7248
Batch[8070] - loss: 0.000938 best_pearson: 0.7248
Batch[8071] - loss: 0.000892 best_pearson: 0.7248
Batch[8072] - loss: 0.000950 best_pearson: 0.7248
Batch[8073] - loss: 0.000520 best_pearson: 0.7248
Batch[8074] - loss: 0.000771 best_pearson: 0.7248
Batch[8075] - loss: 0.000876 best_pearson: 0.7248
Batch[8076] - loss: 0.000916 best_pearson: 0.7248
Batch[8077] - loss: 0.000901 best_pearson: 0.7248
Batch[8078] - loss: 0.001024 best_pearson: 0.7248
Batch[8079] - loss: 0.000402 best_pearson: 0.7248
Batch[8080] - loss: 0.000932 best_pearson: 0.7248
Batch[8081] - loss: 0.000969 best_pearson: 0.7248
Batch[8082] - loss: 0.000743 best_pearson: 0.7248
Batch[8083] - loss: 0.000704 best_pearson: 0.7248
Batch[8084] - loss: 0.000820 best_pearson: 0.7248
Batch[8085] - loss: 0.000866 best_pearson: 0.7248
Batch[8086] - loss: 0.001331 best_pearson: 0.7248
Batch[8087] - loss: 0.000763 best_pearson: 0.7248
Batch[8088] - loss: 0.001451 best_pearson: 0.7248
Batch[8089] - loss: 0.001004 best_pearson: 0.7248
Batch[8090] - loss: 0.000772 best_pearson: 0.7248
Batch[8091] - loss: 0.000871 best_pearson: 0.7248
Batch[8092] - loss: 0.000729 best_pearson: 0.7248
Batch[8093] - loss: 0.001131 best_pearson: 0.7248
Batch[8094] - loss: 0.000729 best_pearson: 0.7248
Batch[8095] - loss: 0.001898 best_pearson: 0.7248
Batch[8096] - loss: 0.000869 best_pearson: 0.7248
Batch[8097] - loss: 0.001050 best_pearson: 0.7248
Batch[8098] - loss: 0.000709 best_pearson: 0.7248
Batch[8099] - loss: 0.001148 best_pearson: 0.7248
Batch[8100] - loss: 0.001050 best_pearson: 0.7248

Evaluation - loss: 0.000047 pearson: 0.7157 

early stop by 1500 steps.
Batch[8101] - loss: 0.000878 best_pearson: 0.7248
Batch[8102] - loss: 0.001032 best_pearson: 0.7248
Batch[8103] - loss: 0.000847 best_pearson: 0.7248
Batch[8104] - loss: 0.001283 best_pearson: 0.7248
Batch[8105] - loss: 0.001101 best_pearson: 0.7248
Batch[8106] - loss: 0.001015 best_pearson: 0.7248
Batch[8107] - loss: 0.001155 best_pearson: 0.7248
Batch[8108] - loss: 0.000769 best_pearson: 0.7248
Batch[8109] - loss: 0.001079 best_pearson: 0.7248
Batch[8110] - loss: 0.001216 best_pearson: 0.7248
Batch[8111] - loss: 0.000581 best_pearson: 0.7248
Batch[8112] - loss: 0.000624 best_pearson: 0.7248
Batch[8113] - loss: 0.000875 best_pearson: 0.7248
Batch[8114] - loss: 0.000974 best_pearson: 0.7248
Batch[8115] - loss: 0.000793 best_pearson: 0.7248
Batch[8116] - loss: 0.001322 best_pearson: 0.7248
Batch[8117] - loss: 0.001563 best_pearson: 0.7248
Batch[8118] - loss: 0.000702 best_pearson: 0.7248
Batch[8119] - loss: 0.000553 best_pearson: 0.7248
Batch[8120] - loss: 0.001123 best_pearson: 0.7248
Batch[8121] - loss: 0.000756 best_pearson: 0.7248
Batch[8122] - loss: 0.000891 best_pearson: 0.7248
Batch[8123] - loss: 0.001304 best_pearson: 0.7248
Batch[8124] - loss: 0.001202 best_pearson: 0.7248
Batch[8125] - loss: 0.000710 best_pearson: 0.7248
Batch[8126] - loss: 0.001503 best_pearson: 0.7248
Batch[8127] - loss: 0.000856 best_pearson: 0.7248
Batch[8128] - loss: 0.000815 best_pearson: 0.7248
Batch[8129] - loss: 0.000711 best_pearson: 0.7248
Batch[8130] - loss: 0.001005 best_pearson: 0.7248
Batch[8131] - loss: 0.000856 best_pearson: 0.7248
Batch[8132] - loss: 0.001139 best_pearson: 0.7248
Batch[8133] - loss: 0.000878 best_pearson: 0.7248
Batch[8134] - loss: 0.000769 best_pearson: 0.7248
Batch[8135] - loss: 0.000506 best_pearson: 0.7248
Batch[8136] - loss: 0.001282 best_pearson: 0.7248
Batch[8137] - loss: 0.000679 best_pearson: 0.7248
Batch[8138] - loss: 0.000936 best_pearson: 0.7248
Batch[8139] - loss: 0.000866 best_pearson: 0.7248
Batch[8140] - loss: 0.001122 best_pearson: 0.7248
Batch[8141] - loss: 0.001103 best_pearson: 0.7248
Batch[8142] - loss: 0.000558 best_pearson: 0.7248
Batch[8143] - loss: 0.000865 best_pearson: 0.7248
Batch[8144] - loss: 0.000554 best_pearson: 0.7248
Batch[8145] - loss: 0.000635 best_pearson: 0.7248
Batch[8146] - loss: 0.000753 best_pearson: 0.7248
Batch[8147] - loss: 0.000658 best_pearson: 0.7248
Batch[8148] - loss: 0.000816 best_pearson: 0.7248
Batch[8149] - loss: 0.000571 best_pearson: 0.7248
Batch[8150] - loss: 0.000566 best_pearson: 0.7248
Batch[8151] - loss: 0.001353 best_pearson: 0.7248
Batch[8152] - loss: 0.000451 best_pearson: 0.7248
Batch[8153] - loss: 0.000694 best_pearson: 0.7248
Batch[8154] - loss: 0.000936 best_pearson: 0.7248
Batch[8155] - loss: 0.000549 best_pearson: 0.7248
Batch[8156] - loss: 0.000779 best_pearson: 0.7248
Batch[8157] - loss: 0.001235 best_pearson: 0.7248
Batch[8158] - loss: 0.000756 best_pearson: 0.7248
Batch[8159] - loss: 0.001036 best_pearson: 0.7248
Batch[8160] - loss: 0.000785 best_pearson: 0.7248
Batch[8161] - loss: 0.000554 best_pearson: 0.7248
Batch[8162] - loss: 0.001161 best_pearson: 0.7248
Batch[8163] - loss: 0.001388 best_pearson: 0.7248
Batch[8164] - loss: 0.000812 best_pearson: 0.7248
Batch[8165] - loss: 0.001154 best_pearson: 0.7248
Batch[8166] - loss: 0.000644 best_pearson: 0.7248
Batch[8167] - loss: 0.000863 best_pearson: 0.7248
Batch[8168] - loss: 0.000601 best_pearson: 0.7248
Batch[8169] - loss: 0.000702 best_pearson: 0.7248
Batch[8170] - loss: 0.001424 best_pearson: 0.7248
Batch[8171] - loss: 0.000742 best_pearson: 0.7248
Batch[8172] - loss: 0.000779 best_pearson: 0.7248
Batch[8173] - loss: 0.000749 best_pearson: 0.7248
Batch[8174] - loss: 0.001331 best_pearson: 0.7248
Batch[8175] - loss: 0.000745 best_pearson: 0.7248
Batch[8176] - loss: 0.000548 best_pearson: 0.7248
Batch[8177] - loss: 0.000902 best_pearson: 0.7248
Batch[8178] - loss: 0.001270 best_pearson: 0.7248
Batch[8179] - loss: 0.000748 best_pearson: 0.7248
Batch[8180] - loss: 0.000883 best_pearson: 0.7248
Batch[8181] - loss: 0.000739 best_pearson: 0.7248
Batch[8182] - loss: 0.001103 best_pearson: 0.7248
Batch[8183] - loss: 0.000785 best_pearson: 0.7248
Batch[8184] - loss: 0.000715 best_pearson: 0.7248
Batch[8185] - loss: 0.000536 best_pearson: 0.7248
Batch[8186] - loss: 0.000971 best_pearson: 0.7248
Batch[8187] - loss: 0.000669 best_pearson: 0.7248
Batch[8188] - loss: 0.000818 best_pearson: 0.7248
Batch[8189] - loss: 0.000658 best_pearson: 0.7248
Batch[8190] - loss: 0.000812 best_pearson: 0.7248
Batch[8191] - loss: 0.001263 best_pearson: 0.7248
Batch[8192] - loss: 0.000905 best_pearson: 0.7248
Batch[8193] - loss: 0.000894 best_pearson: 0.7248
Batch[8194] - loss: 0.000693 best_pearson: 0.7248
Batch[8195] - loss: 0.001014 best_pearson: 0.7248
Batch[8196] - loss: 0.000542 best_pearson: 0.7248
Batch[8197] - loss: 0.000679 best_pearson: 0.7248
Batch[8198] - loss: 0.000903 best_pearson: 0.7248
Batch[8199] - loss: 0.001291 best_pearson: 0.7248
Batch[8200] - loss: 0.000593 best_pearson: 0.7248

Evaluation - loss: 0.000046 pearson: 0.7165 

early stop by 1500 steps.
Batch[8201] - loss: 0.000876 best_pearson: 0.7248
Batch[8202] - loss: 0.001083 best_pearson: 0.7248
Batch[8203] - loss: 0.000977 best_pearson: 0.7248
Batch[8204] - loss: 0.000507 best_pearson: 0.7248
Batch[8205] - loss: 0.000519 best_pearson: 0.7248
Batch[8206] - loss: 0.000959 best_pearson: 0.7248
Batch[8207] - loss: 0.001073 best_pearson: 0.7248
Batch[8208] - loss: 0.000911 best_pearson: 0.7248
Batch[8209] - loss: 0.000566 best_pearson: 0.7248
Batch[8210] - loss: 0.001032 best_pearson: 0.7248
Batch[8211] - loss: 0.001256 best_pearson: 0.7248
Batch[8212] - loss: 0.000465 best_pearson: 0.7248
Batch[8213] - loss: 0.000663 best_pearson: 0.7248
Batch[8214] - loss: 0.000760 best_pearson: 0.7248
Batch[8215] - loss: 0.000719 best_pearson: 0.7248
Batch[8216] - loss: 0.000899 best_pearson: 0.7248
Batch[8217] - loss: 0.000565 best_pearson: 0.7248
Batch[8218] - loss: 0.000615 best_pearson: 0.7248
Batch[8219] - loss: 0.000625 best_pearson: 0.7248
Batch[8220] - loss: 0.000828 best_pearson: 0.7248
Batch[8221] - loss: 0.000837 best_pearson: 0.7248
Batch[8222] - loss: 0.000730 best_pearson: 0.7248
Batch[8223] - loss: 0.000596 best_pearson: 0.7248
Batch[8224] - loss: 0.000816 best_pearson: 0.7248
Batch[8225] - loss: 0.000670 best_pearson: 0.7248
Batch[8226] - loss: 0.000618 best_pearson: 0.7248
Batch[8227] - loss: 0.000383 best_pearson: 0.7248
Batch[8228] - loss: 0.000949 best_pearson: 0.7248
Batch[8229] - loss: 0.000489 best_pearson: 0.7248
Batch[8230] - loss: 0.000497 best_pearson: 0.7248
Batch[8231] - loss: 0.000766 best_pearson: 0.7248
Batch[8232] - loss: 0.000811 best_pearson: 0.7248
Batch[8233] - loss: 0.000771 best_pearson: 0.7248
Batch[8234] - loss: 0.000409 best_pearson: 0.7248
Batch[8235] - loss: 0.000764 best_pearson: 0.7248
Batch[8236] - loss: 0.000844 best_pearson: 0.7248
Batch[8237] - loss: 0.000571 best_pearson: 0.7248
Batch[8238] - loss: 0.000870 best_pearson: 0.7248
Batch[8239] - loss: 0.000802 best_pearson: 0.7248
Batch[8240] - loss: 0.000895 best_pearson: 0.7248
Batch[8241] - loss: 0.000658 best_pearson: 0.7248
Batch[8242] - loss: 0.000666 best_pearson: 0.7248
Batch[8243] - loss: 0.000883 best_pearson: 0.7248
Batch[8244] - loss: 0.000495 best_pearson: 0.7248
Batch[8245] - loss: 0.000956 best_pearson: 0.7248
Batch[8246] - loss: 0.000944 best_pearson: 0.7248
Batch[8247] - loss: 0.000823 best_pearson: 0.7248
Batch[8248] - loss: 0.000642 best_pearson: 0.7248
Batch[8249] - loss: 0.000538 best_pearson: 0.7248
Batch[8250] - loss: 0.000833 best_pearson: 0.7248
Batch[8251] - loss: 0.000483 best_pearson: 0.7248
Batch[8252] - loss: 0.000717 best_pearson: 0.7248
Batch[8253] - loss: 0.000539 best_pearson: 0.7248
Batch[8254] - loss: 0.000600 best_pearson: 0.7248
Batch[8255] - loss: 0.000674 best_pearson: 0.7248
Batch[8256] - loss: 0.000902 best_pearson: 0.7248
Batch[8257] - loss: 0.000685 best_pearson: 0.7248
Batch[8258] - loss: 0.000676 best_pearson: 0.7248
Batch[8259] - loss: 0.000862 best_pearson: 0.7248
Batch[8260] - loss: 0.000941 best_pearson: 0.7248
Batch[8261] - loss: 0.001415 best_pearson: 0.7248
Batch[8262] - loss: 0.000693 best_pearson: 0.7248
Batch[8263] - loss: 0.001417 best_pearson: 0.7248
Batch[8264] - loss: 0.000674 best_pearson: 0.7248
Batch[8265] - loss: 0.000665 best_pearson: 0.7248
Batch[8266] - loss: 0.000379 best_pearson: 0.7248
Batch[8267] - loss: 0.000998 best_pearson: 0.7248
Batch[8268] - loss: 0.000530 best_pearson: 0.7248
Batch[8269] - loss: 0.001021 best_pearson: 0.7248
Batch[8270] - loss: 0.000738 best_pearson: 0.7248
Batch[8271] - loss: 0.000885 best_pearson: 0.7248
Batch[8272] - loss: 0.000695 best_pearson: 0.7248
Batch[8273] - loss: 0.000578 best_pearson: 0.7248
Batch[8274] - loss: 0.000587 best_pearson: 0.7248
Batch[8275] - loss: 0.000571 best_pearson: 0.7248
Batch[8276] - loss: 0.000629 best_pearson: 0.7248
Batch[8277] - loss: 0.000657 best_pearson: 0.7248
Batch[8278] - loss: 0.000606 best_pearson: 0.7248
Batch[8279] - loss: 0.000537 best_pearson: 0.7248
Batch[8280] - loss: 0.001163 best_pearson: 0.7248
Batch[8281] - loss: 0.000317 best_pearson: 0.7248
Batch[8282] - loss: 0.000708 best_pearson: 0.7248
Batch[8283] - loss: 0.000687 best_pearson: 0.7248
Batch[8284] - loss: 0.000326 best_pearson: 0.7248
Batch[8285] - loss: 0.000771 best_pearson: 0.7248
Batch[8286] - loss: 0.000710 best_pearson: 0.7248
Batch[8287] - loss: 0.000626 best_pearson: 0.7248
Batch[8288] - loss: 0.000696 best_pearson: 0.7248
Batch[8289] - loss: 0.000925 best_pearson: 0.7248
Batch[8290] - loss: 0.000631 best_pearson: 0.7248
Batch[8291] - loss: 0.000444 best_pearson: 0.7248
Batch[8292] - loss: 0.001329 best_pearson: 0.7248
Batch[8293] - loss: 0.000729 best_pearson: 0.7248
Batch[8294] - loss: 0.000619 best_pearson: 0.7248
Batch[8295] - loss: 0.000685 best_pearson: 0.7248
Batch[8296] - loss: 0.000427 best_pearson: 0.7248
Batch[8297] - loss: 0.000533 best_pearson: 0.7248
Batch[8298] - loss: 0.000453 best_pearson: 0.7248
Batch[8299] - loss: 0.000792 best_pearson: 0.7248
Batch[8300] - loss: 0.001211 best_pearson: 0.7248

Evaluation - loss: 0.000047 pearson: 0.7150 

early stop by 1500 steps.
Batch[8301] - loss: 0.000709 best_pearson: 0.7248
Batch[8302] - loss: 0.000652 best_pearson: 0.7248
Batch[8303] - loss: 0.000672 best_pearson: 0.7248
Batch[8304] - loss: 0.000804 best_pearson: 0.7248
Batch[8305] - loss: 0.000912 best_pearson: 0.7248
Batch[8306] - loss: 0.000771 best_pearson: 0.7248
Batch[8307] - loss: 0.000682 best_pearson: 0.7248
Batch[8308] - loss: 0.000590 best_pearson: 0.7248
Batch[8309] - loss: 0.000587 best_pearson: 0.7248
Batch[8310] - loss: 0.001124 best_pearson: 0.7248
Batch[8311] - loss: 0.000895 best_pearson: 0.7248
Batch[8312] - loss: 0.001085 best_pearson: 0.7248
Batch[8313] - loss: 0.000799 best_pearson: 0.7248
Batch[8314] - loss: 0.000670 best_pearson: 0.7248
Batch[8315] - loss: 0.000829 best_pearson: 0.7248
Batch[8316] - loss: 0.000624 best_pearson: 0.7248
Batch[8317] - loss: 0.000502 best_pearson: 0.7248
Batch[8318] - loss: 0.000743 best_pearson: 0.7248
Batch[8319] - loss: 0.000901 best_pearson: 0.7248
Batch[8320] - loss: 0.000763 best_pearson: 0.7248
Batch[8321] - loss: 0.000545 best_pearson: 0.7248
Batch[8322] - loss: 0.000761 best_pearson: 0.7248
Batch[8323] - loss: 0.001079 best_pearson: 0.7248
Batch[8324] - loss: 0.000398 best_pearson: 0.7248
Batch[8325] - loss: 0.000574 best_pearson: 0.7248
Batch[8326] - loss: 0.000587 best_pearson: 0.7248
Batch[8327] - loss: 0.000670 best_pearson: 0.7248
Batch[8328] - loss: 0.001253 best_pearson: 0.7248
Batch[8329] - loss: 0.000522 best_pearson: 0.7248
Batch[8330] - loss: 0.000456 best_pearson: 0.7248
Batch[8331] - loss: 0.001068 best_pearson: 0.7248
Batch[8332] - loss: 0.000591 best_pearson: 0.7248
Batch[8333] - loss: 0.000380 best_pearson: 0.7248
Batch[8334] - loss: 0.000364 best_pearson: 0.7248
Batch[8335] - loss: 0.000387 best_pearson: 0.7248
Batch[8336] - loss: 0.000695 best_pearson: 0.7248
Batch[8337] - loss: 0.000467 best_pearson: 0.7248
Batch[8338] - loss: 0.000572 best_pearson: 0.7248
Batch[8339] - loss: 0.000577 best_pearson: 0.7248
Batch[8340] - loss: 0.000562 best_pearson: 0.7248
Batch[8341] - loss: 0.000514 best_pearson: 0.7248
Batch[8342] - loss: 0.000701 best_pearson: 0.7248
Batch[8343] - loss: 0.000821 best_pearson: 0.7248
Batch[8344] - loss: 0.000371 best_pearson: 0.7248
Batch[8345] - loss: 0.000467 best_pearson: 0.7248
Batch[8346] - loss: 0.000634 best_pearson: 0.7248
Batch[8347] - loss: 0.000440 best_pearson: 0.7248
Batch[8348] - loss: 0.000567 best_pearson: 0.7248
Batch[8349] - loss: 0.000849 best_pearson: 0.7248
Batch[8350] - loss: 0.000476 best_pearson: 0.7248
Batch[8351] - loss: 0.000590 best_pearson: 0.7248
Batch[8352] - loss: 0.000616 best_pearson: 0.7248
Batch[8353] - loss: 0.000460 best_pearson: 0.7248
Batch[8354] - loss: 0.001031 best_pearson: 0.7248
Batch[8355] - loss: 0.000674 best_pearson: 0.7248
Batch[8356] - loss: 0.000817 best_pearson: 0.7248
Batch[8357] - loss: 0.000692 best_pearson: 0.7248
Batch[8358] - loss: 0.000507 best_pearson: 0.7248
Batch[8359] - loss: 0.000731 best_pearson: 0.7248
Batch[8360] - loss: 0.000729 best_pearson: 0.7248
Batch[8361] - loss: 0.000523 best_pearson: 0.7248
Batch[8362] - loss: 0.000893 best_pearson: 0.7248
Batch[8363] - loss: 0.000922 best_pearson: 0.7248
Batch[8364] - loss: 0.000574 best_pearson: 0.7248
Batch[8365] - loss: 0.000681 best_pearson: 0.7248
Batch[8366] - loss: 0.000689 best_pearson: 0.7248
Batch[8367] - loss: 0.000459 best_pearson: 0.7248
Batch[8368] - loss: 0.000706 best_pearson: 0.7248
Batch[8369] - loss: 0.000445 best_pearson: 0.7248
Batch[8370] - loss: 0.000977 best_pearson: 0.7248
Batch[8371] - loss: 0.000527 best_pearson: 0.7248
Batch[8372] - loss: 0.001149 best_pearson: 0.7248
Batch[8373] - loss: 0.000835 best_pearson: 0.7248
Batch[8374] - loss: 0.000740 best_pearson: 0.7248
Batch[8375] - loss: 0.000694 best_pearson: 0.7248
Batch[8376] - loss: 0.000474 best_pearson: 0.7248
Batch[8377] - loss: 0.000450 best_pearson: 0.7248
Batch[8378] - loss: 0.000759 best_pearson: 0.7248
Batch[8379] - loss: 0.000596 best_pearson: 0.7248
Batch[8380] - loss: 0.000734 best_pearson: 0.7248
Batch[8381] - loss: 0.000876 best_pearson: 0.7248
Batch[8382] - loss: 0.000455 best_pearson: 0.7248
Batch[8383] - loss: 0.000832 best_pearson: 0.7248
Batch[8384] - loss: 0.000584 best_pearson: 0.7248
Batch[8385] - loss: 0.000940 best_pearson: 0.7248
Batch[8386] - loss: 0.000625 best_pearson: 0.7248
Batch[8387] - loss: 0.001165 best_pearson: 0.7248
Batch[8388] - loss: 0.000711 best_pearson: 0.7248
Batch[8389] - loss: 0.000631 best_pearson: 0.7248
Batch[8390] - loss: 0.001618 best_pearson: 0.7248
Batch[8391] - loss: 0.001158 best_pearson: 0.7248
Batch[8392] - loss: 0.000428 best_pearson: 0.7248
Batch[8393] - loss: 0.000502 best_pearson: 0.7248
Batch[8394] - loss: 0.000629 best_pearson: 0.7248
Batch[8395] - loss: 0.000551 best_pearson: 0.7248
Batch[8396] - loss: 0.000570 best_pearson: 0.7248
Batch[8397] - loss: 0.000703 best_pearson: 0.7248
Batch[8398] - loss: 0.001488 best_pearson: 0.7248
Batch[8399] - loss: 0.000809 best_pearson: 0.7248
Batch[8400] - loss: 0.000588 best_pearson: 0.7248

Evaluation - loss: 0.000048 pearson: 0.7136 

early stop by 1500 steps.
Batch[8401] - loss: 0.000923 best_pearson: 0.7248
Batch[8402] - loss: 0.000696 best_pearson: 0.7248
Batch[8403] - loss: 0.000636 best_pearson: 0.7248
Batch[8404] - loss: 0.000704 best_pearson: 0.7248
Batch[8405] - loss: 0.001011 best_pearson: 0.7248
Batch[8406] - loss: 0.000673 best_pearson: 0.7248
Batch[8407] - loss: 0.000587 best_pearson: 0.7248
Batch[8408] - loss: 0.000779 best_pearson: 0.7248
Batch[8409] - loss: 0.000608 best_pearson: 0.7248
Batch[8410] - loss: 0.000648 best_pearson: 0.7248
Batch[8411] - loss: 0.000457 best_pearson: 0.7248
Batch[8412] - loss: 0.000604 best_pearson: 0.7248
Batch[8413] - loss: 0.000460 best_pearson: 0.7248
Batch[8414] - loss: 0.000889 best_pearson: 0.7248
Batch[8415] - loss: 0.000670 best_pearson: 0.7248
Batch[8416] - loss: 0.000324 best_pearson: 0.7248
Batch[8417] - loss: 0.000420 best_pearson: 0.7248
Batch[8418] - loss: 0.000883 best_pearson: 0.7248
Batch[8419] - loss: 0.000557 best_pearson: 0.7248
Batch[8420] - loss: 0.000614 best_pearson: 0.7248
Batch[8421] - loss: 0.000607 best_pearson: 0.7248
Batch[8422] - loss: 0.000360 best_pearson: 0.7248
Batch[8423] - loss: 0.000483 best_pearson: 0.7248
Batch[8424] - loss: 0.000598 best_pearson: 0.7248
Batch[8425] - loss: 0.000363 best_pearson: 0.7248
Batch[8426] - loss: 0.000571 best_pearson: 0.7248
Batch[8427] - loss: 0.000578 best_pearson: 0.7248
Batch[8428] - loss: 0.000666 best_pearson: 0.7248
Batch[8429] - loss: 0.000558 best_pearson: 0.7248
Batch[8430] - loss: 0.000438 best_pearson: 0.7248
Batch[8431] - loss: 0.000635 best_pearson: 0.7248
Batch[8432] - loss: 0.000930 best_pearson: 0.7248
Batch[8433] - loss: 0.000685 best_pearson: 0.7248
Batch[8434] - loss: 0.000458 best_pearson: 0.7248
Batch[8435] - loss: 0.000875 best_pearson: 0.7248
Batch[8436] - loss: 0.000572 best_pearson: 0.7248
Batch[8437] - loss: 0.000825 best_pearson: 0.7248
Batch[8438] - loss: 0.000514 best_pearson: 0.7248
Batch[8439] - loss: 0.000545 best_pearson: 0.7248
Batch[8440] - loss: 0.000687 best_pearson: 0.7248
Batch[8441] - loss: 0.000648 best_pearson: 0.7248
Batch[8442] - loss: 0.000829 best_pearson: 0.7248
Batch[8443] - loss: 0.000981 best_pearson: 0.7248
Batch[8444] - loss: 0.000634 best_pearson: 0.7248
Batch[8445] - loss: 0.000588 best_pearson: 0.7248
Batch[8446] - loss: 0.000647 best_pearson: 0.7248
Batch[8447] - loss: 0.000646 best_pearson: 0.7248
Batch[8448] - loss: 0.000589 best_pearson: 0.7248
Batch[8449] - loss: 0.001142 best_pearson: 0.7248
Batch[8450] - loss: 0.000368 best_pearson: 0.7248
Batch[8451] - loss: 0.000446 best_pearson: 0.7248
Batch[8452] - loss: 0.000650 best_pearson: 0.7248
Batch[8453] - loss: 0.001030 best_pearson: 0.7248
Batch[8454] - loss: 0.000997 best_pearson: 0.7248
Batch[8455] - loss: 0.000909 best_pearson: 0.7248
Batch[8456] - loss: 0.000358 best_pearson: 0.7248
Batch[8457] - loss: 0.001364 best_pearson: 0.7248
Batch[8458] - loss: 0.000438 best_pearson: 0.7248
Batch[8459] - loss: 0.000650 best_pearson: 0.7248
Batch[8460] - loss: 0.000557 best_pearson: 0.7248
Batch[8461] - loss: 0.000770 best_pearson: 0.7248
Batch[8462] - loss: 0.001041 best_pearson: 0.7248
Batch[8463] - loss: 0.000766 best_pearson: 0.7248
Batch[8464] - loss: 0.000675 best_pearson: 0.7248
Batch[8465] - loss: 0.000427 best_pearson: 0.7248
Batch[8466] - loss: 0.000569 best_pearson: 0.7248
Batch[8467] - loss: 0.000317 best_pearson: 0.7248
Batch[8468] - loss: 0.000796 best_pearson: 0.7248
Batch[8469] - loss: 0.000515 best_pearson: 0.7248
Batch[8470] - loss: 0.001237 best_pearson: 0.7248
Batch[8471] - loss: 0.000968 best_pearson: 0.7248
Batch[8472] - loss: 0.000557 best_pearson: 0.7248
Batch[8473] - loss: 0.000384 best_pearson: 0.7248
Batch[8474] - loss: 0.001193 best_pearson: 0.7248
Batch[8475] - loss: 0.000432 best_pearson: 0.7248
Batch[8476] - loss: 0.000542 best_pearson: 0.7248
Batch[8477] - loss: 0.000745 best_pearson: 0.7248
Batch[8478] - loss: 0.000608 best_pearson: 0.7248
Batch[8479] - loss: 0.000508 best_pearson: 0.7248
Batch[8480] - loss: 0.000496 best_pearson: 0.7248
Batch[8481] - loss: 0.000703 best_pearson: 0.7248
Batch[8482] - loss: 0.000912 best_pearson: 0.7248
Batch[8483] - loss: 0.000506 best_pearson: 0.7248
Batch[8484] - loss: 0.001326 best_pearson: 0.7248
Batch[8485] - loss: 0.000599 best_pearson: 0.7248
Batch[8486] - loss: 0.001610 best_pearson: 0.7248
Batch[8487] - loss: 0.000955 best_pearson: 0.7248
Batch[8488] - loss: 0.000564 best_pearson: 0.7248
Batch[8489] - loss: 0.000802 best_pearson: 0.7248
Batch[8490] - loss: 0.000752 best_pearson: 0.7248
Batch[8491] - loss: 0.000853 best_pearson: 0.7248
Batch[8492] - loss: 0.000616 best_pearson: 0.7248
Batch[8493] - loss: 0.001091 best_pearson: 0.7248
Batch[8494] - loss: 0.001145 best_pearson: 0.7248
Batch[8495] - loss: 0.000857 best_pearson: 0.7248
Batch[8496] - loss: 0.000487 best_pearson: 0.7248
Batch[8497] - loss: 0.000996 best_pearson: 0.7248
Batch[8498] - loss: 0.000975 best_pearson: 0.7248
Batch[8499] - loss: 0.000356 best_pearson: 0.7248
Batch[8500] - loss: 0.000576 best_pearson: 0.7248

Evaluation - loss: 0.000046 pearson: 0.7166 

early stop by 1500 steps.
Batch[8501] - loss: 0.000899 best_pearson: 0.7248
Batch[8502] - loss: 0.000798 best_pearson: 0.7248
Batch[8503] - loss: 0.000448 best_pearson: 0.7248
Batch[8504] - loss: 0.001239 best_pearson: 0.7248
Batch[8505] - loss: 0.000903 best_pearson: 0.7248
Batch[8506] - loss: 0.000565 best_pearson: 0.7248
Batch[8507] - loss: 0.000797 best_pearson: 0.7248
Batch[8508] - loss: 0.000788 best_pearson: 0.7248
Batch[8509] - loss: 0.000407 best_pearson: 0.7248
Batch[8510] - loss: 0.000588 best_pearson: 0.7248
Batch[8511] - loss: 0.000802 best_pearson: 0.7248
Batch[8512] - loss: 0.000587 best_pearson: 0.7248
Batch[8513] - loss: 0.000513 best_pearson: 0.7248
Batch[8514] - loss: 0.000519 best_pearson: 0.7248
Batch[8515] - loss: 0.000745 best_pearson: 0.7248
Batch[8516] - loss: 0.000548 best_pearson: 0.7248
Batch[8517] - loss: 0.000563 best_pearson: 0.7248
Batch[8518] - loss: 0.001135 best_pearson: 0.7248
Batch[8519] - loss: 0.000677 best_pearson: 0.7248
Batch[8520] - loss: 0.001051 best_pearson: 0.7248
Batch[8521] - loss: 0.000823 best_pearson: 0.7248
Batch[8522] - loss: 0.001645 best_pearson: 0.7248
Batch[8523] - loss: 0.000896 best_pearson: 0.7248
Batch[8524] - loss: 0.000542 best_pearson: 0.7248
Batch[8525] - loss: 0.000663 best_pearson: 0.7248
Batch[8526] - loss: 0.001292 best_pearson: 0.7248
Batch[8527] - loss: 0.000805 best_pearson: 0.7248
Batch[8528] - loss: 0.000590 best_pearson: 0.7248
Batch[8529] - loss: 0.000568 best_pearson: 0.7248
Batch[8530] - loss: 0.000564 best_pearson: 0.7248
Batch[8531] - loss: 0.000766 best_pearson: 0.7248
Batch[8532] - loss: 0.001064 best_pearson: 0.7248
Batch[8533] - loss: 0.000563 best_pearson: 0.7248
Batch[8534] - loss: 0.000713 best_pearson: 0.7248
Batch[8535] - loss: 0.000461 best_pearson: 0.7248
Batch[8536] - loss: 0.000570 best_pearson: 0.7248
Batch[8537] - loss: 0.000792 best_pearson: 0.7248
Batch[8538] - loss: 0.000735 best_pearson: 0.7248
Batch[8539] - loss: 0.000645 best_pearson: 0.7248
Batch[8540] - loss: 0.000752 best_pearson: 0.7248
Batch[8541] - loss: 0.000338 best_pearson: 0.7248
Batch[8542] - loss: 0.000507 best_pearson: 0.7248
Batch[8543] - loss: 0.001037 best_pearson: 0.7248
Batch[8544] - loss: 0.000610 best_pearson: 0.7248
Batch[8545] - loss: 0.000586 best_pearson: 0.7248
Batch[8546] - loss: 0.000344 best_pearson: 0.7248
Batch[8547] - loss: 0.000483 best_pearson: 0.7248
Batch[8548] - loss: 0.000648 best_pearson: 0.7248
Batch[8549] - loss: 0.000788 best_pearson: 0.7248
Batch[8550] - loss: 0.000505 best_pearson: 0.7248
Batch[8551] - loss: 0.000587 best_pearson: 0.7248
Batch[8552] - loss: 0.000465 best_pearson: 0.7248
Batch[8553] - loss: 0.000850 best_pearson: 0.7248
Batch[8554] - loss: 0.000520 best_pearson: 0.7248
Batch[8555] - loss: 0.000449 best_pearson: 0.7248
Batch[8556] - loss: 0.000568 best_pearson: 0.7248
Batch[8557] - loss: 0.000590 best_pearson: 0.7248
Batch[8558] - loss: 0.000541 best_pearson: 0.7248
Batch[8559] - loss: 0.000704 best_pearson: 0.7248
Batch[8560] - loss: 0.001399 best_pearson: 0.7248
Batch[8561] - loss: 0.000381 best_pearson: 0.7248
Batch[8562] - loss: 0.000746 best_pearson: 0.7248
Batch[8563] - loss: 0.000905 best_pearson: 0.7248
Batch[8564] - loss: 0.000647 best_pearson: 0.7248
Batch[8565] - loss: 0.000567 best_pearson: 0.7248
Batch[8566] - loss: 0.000624 best_pearson: 0.7248
Batch[8567] - loss: 0.000811 best_pearson: 0.7248
Batch[8568] - loss: 0.000828 best_pearson: 0.7248
Batch[8569] - loss: 0.000575 best_pearson: 0.7248
Batch[8570] - loss: 0.001075 best_pearson: 0.7248
Batch[8571] - loss: 0.000815 best_pearson: 0.7248
Batch[8572] - loss: 0.000637 best_pearson: 0.7248
Batch[8573] - loss: 0.000394 best_pearson: 0.7248
Batch[8574] - loss: 0.000513 best_pearson: 0.7248
Batch[8575] - loss: 0.000972 best_pearson: 0.7248
Batch[8576] - loss: 0.000729 best_pearson: 0.7248
Batch[8577] - loss: 0.000509 best_pearson: 0.7248
Batch[8578] - loss: 0.000611 best_pearson: 0.7248
Batch[8579] - loss: 0.000790 best_pearson: 0.7248
Batch[8580] - loss: 0.001175 best_pearson: 0.7248
Batch[8581] - loss: 0.000489 best_pearson: 0.7248
Batch[8582] - loss: 0.000652 best_pearson: 0.7248
Batch[8583] - loss: 0.000568 best_pearson: 0.7248
Batch[8584] - loss: 0.001436 best_pearson: 0.7248
Batch[8585] - loss: 0.000760 best_pearson: 0.7248
Batch[8586] - loss: 0.000741 best_pearson: 0.7248
Batch[8587] - loss: 0.000569 best_pearson: 0.7248
Batch[8588] - loss: 0.000754 best_pearson: 0.7248
Batch[8589] - loss: 0.000556 best_pearson: 0.7248
Batch[8590] - loss: 0.000933 best_pearson: 0.7248
Batch[8591] - loss: 0.000663 best_pearson: 0.7248
Batch[8592] - loss: 0.000718 best_pearson: 0.7248
Batch[8593] - loss: 0.000833 best_pearson: 0.7248
Batch[8594] - loss: 0.000934 best_pearson: 0.7248
Batch[8595] - loss: 0.000697 best_pearson: 0.7248
Batch[8596] - loss: 0.000788 best_pearson: 0.7248
Batch[8597] - loss: 0.000533 best_pearson: 0.7248
Batch[8598] - loss: 0.000666 best_pearson: 0.7248
Batch[8599] - loss: 0.000550 best_pearson: 0.7248
Batch[8600] - loss: 0.000600 best_pearson: 0.7248

Evaluation - loss: 0.000048 pearson: 0.7129 

early stop by 1500 steps.
Batch[8601] - loss: 0.000981 best_pearson: 0.7248
Batch[8602] - loss: 0.000770 best_pearson: 0.7248
Batch[8603] - loss: 0.000640 best_pearson: 0.7248
Batch[8604] - loss: 0.001103 best_pearson: 0.7248
Batch[8605] - loss: 0.001174 best_pearson: 0.7248
Batch[8606] - loss: 0.001522 best_pearson: 0.7248
Batch[8607] - loss: 0.000648 best_pearson: 0.7248
Batch[8608] - loss: 0.000899 best_pearson: 0.7248
Batch[8609] - loss: 0.000565 best_pearson: 0.7248
Batch[8610] - loss: 0.000902 best_pearson: 0.7248
Batch[8611] - loss: 0.000839 best_pearson: 0.7248
Batch[8612] - loss: 0.001118 best_pearson: 0.7248
Batch[8613] - loss: 0.001330 best_pearson: 0.7248
Batch[8614] - loss: 0.001072 best_pearson: 0.7248
Batch[8615] - loss: 0.000567 best_pearson: 0.7248
Batch[8616] - loss: 0.000912 best_pearson: 0.7248
Batch[8617] - loss: 0.000827 best_pearson: 0.7248
Batch[8618] - loss: 0.000910 best_pearson: 0.7248
Batch[8619] - loss: 0.000394 best_pearson: 0.7248
Batch[8620] - loss: 0.000971 best_pearson: 0.7248
Batch[8621] - loss: 0.001119 best_pearson: 0.7248
Batch[8622] - loss: 0.000546 best_pearson: 0.7248
Batch[8623] - loss: 0.001543 best_pearson: 0.7248
Batch[8624] - loss: 0.000672 best_pearson: 0.7248
Batch[8625] - loss: 0.000609 best_pearson: 0.7248
Batch[8626] - loss: 0.000696 best_pearson: 0.7248
Batch[8627] - loss: 0.001106 best_pearson: 0.7248
Batch[8628] - loss: 0.001057 best_pearson: 0.7248
Batch[8629] - loss: 0.000463 best_pearson: 0.7248
Batch[8630] - loss: 0.001155 best_pearson: 0.7248
Batch[8631] - loss: 0.000738 best_pearson: 0.7248
Batch[8632] - loss: 0.000747 best_pearson: 0.7248
Batch[8633] - loss: 0.000551 best_pearson: 0.7248
Batch[8634] - loss: 0.000477 best_pearson: 0.7248
Batch[8635] - loss: 0.001107 best_pearson: 0.7248
Batch[8636] - loss: 0.001120 best_pearson: 0.7248
Batch[8637] - loss: 0.000357 best_pearson: 0.7248
Batch[8638] - loss: 0.000805 best_pearson: 0.7248
Batch[8639] - loss: 0.000858 best_pearson: 0.7248
Batch[8640] - loss: 0.000497 best_pearson: 0.7248
Batch[8641] - loss: 0.001057 best_pearson: 0.7248
Batch[8642] - loss: 0.000937 best_pearson: 0.7248
Batch[8643] - loss: 0.001117 best_pearson: 0.7248
Batch[8644] - loss: 0.000603 best_pearson: 0.7248
Batch[8645] - loss: 0.001019 best_pearson: 0.7248
Batch[8646] - loss: 0.000528 best_pearson: 0.7248
Batch[8647] - loss: 0.000644 best_pearson: 0.7248
Batch[8648] - loss: 0.000774 best_pearson: 0.7248
Batch[8649] - loss: 0.000757 best_pearson: 0.7248
Batch[8650] - loss: 0.000590 best_pearson: 0.7248
Batch[8651] - loss: 0.000960 best_pearson: 0.7248
Batch[8652] - loss: 0.001037 best_pearson: 0.7248
Batch[8653] - loss: 0.000638 best_pearson: 0.7248
Batch[8654] - loss: 0.000729 best_pearson: 0.7248
Batch[8655] - loss: 0.000645 best_pearson: 0.7248
Batch[8656] - loss: 0.000805 best_pearson: 0.7248
Batch[8657] - loss: 0.001033 best_pearson: 0.7248
Batch[8658] - loss: 0.000798 best_pearson: 0.7248
Batch[8659] - loss: 0.001256 best_pearson: 0.7248
Batch[8660] - loss: 0.000537 best_pearson: 0.7248
Batch[8661] - loss: 0.000676 best_pearson: 0.7248
Batch[8662] - loss: 0.000510 best_pearson: 0.7248
Batch[8663] - loss: 0.000589 best_pearson: 0.7248
Batch[8664] - loss: 0.000933 best_pearson: 0.7248
Batch[8665] - loss: 0.000906 best_pearson: 0.7248
Batch[8666] - loss: 0.001093 best_pearson: 0.7248
Batch[8667] - loss: 0.000666 best_pearson: 0.7248
Batch[8668] - loss: 0.000779 best_pearson: 0.7248
Batch[8669] - loss: 0.000770 best_pearson: 0.7248
Batch[8670] - loss: 0.000636 best_pearson: 0.7248
Batch[8671] - loss: 0.000636 best_pearson: 0.7248
Batch[8672] - loss: 0.000595 best_pearson: 0.7248
Batch[8673] - loss: 0.000879 best_pearson: 0.7248
Batch[8674] - loss: 0.000614 best_pearson: 0.7248
Batch[8675] - loss: 0.000926 best_pearson: 0.7248
Batch[8676] - loss: 0.000623 best_pearson: 0.7248
Batch[8677] - loss: 0.000901 best_pearson: 0.7248
Batch[8678] - loss: 0.001011 best_pearson: 0.7248
Batch[8679] - loss: 0.001064 best_pearson: 0.7248
Batch[8680] - loss: 0.000984 best_pearson: 0.7248
Batch[8681] - loss: 0.000773 best_pearson: 0.7248
Batch[8682] - loss: 0.000618 best_pearson: 0.7248
Batch[8683] - loss: 0.000875 best_pearson: 0.7248
Batch[8684] - loss: 0.000599 best_pearson: 0.7248
Batch[8685] - loss: 0.000651 best_pearson: 0.7248
Batch[8686] - loss: 0.000859 best_pearson: 0.7248
Batch[8687] - loss: 0.000490 best_pearson: 0.7248
Batch[8688] - loss: 0.000786 best_pearson: 0.7248
Batch[8689] - loss: 0.000723 best_pearson: 0.7248
Batch[8690] - loss: 0.000705 best_pearson: 0.7248
Batch[8691] - loss: 0.000940 best_pearson: 0.7248
Batch[8692] - loss: 0.000870 best_pearson: 0.7248
Batch[8693] - loss: 0.000933 best_pearson: 0.7248
Batch[8694] - loss: 0.000952 best_pearson: 0.7248
Batch[8695] - loss: 0.000913 best_pearson: 0.7248
Batch[8696] - loss: 0.000630 best_pearson: 0.7248
Batch[8697] - loss: 0.000732 best_pearson: 0.7248
Batch[8698] - loss: 0.000402 best_pearson: 0.7248
Batch[8699] - loss: 0.000656 best_pearson: 0.7248
Batch[8700] - loss: 0.000690 best_pearson: 0.7248

Evaluation - loss: 0.000047 pearson: 0.7144 

early stop by 1500 steps.
Batch[8701] - loss: 0.000601 best_pearson: 0.7248
Batch[8702] - loss: 0.000557 best_pearson: 0.7248
Batch[8703] - loss: 0.000727 best_pearson: 0.7248
Batch[8704] - loss: 0.000920 best_pearson: 0.7248
Batch[8705] - loss: 0.001126 best_pearson: 0.7248
Batch[8706] - loss: 0.000540 best_pearson: 0.7248
Batch[8707] - loss: 0.000622 best_pearson: 0.7248
Batch[8708] - loss: 0.000575 best_pearson: 0.7248
Batch[8709] - loss: 0.000607 best_pearson: 0.7248
Batch[8710] - loss: 0.000805 best_pearson: 0.7248
Batch[8711] - loss: 0.000518 best_pearson: 0.7248
Batch[8712] - loss: 0.000823 best_pearson: 0.7248
Batch[8713] - loss: 0.000677 best_pearson: 0.7248
Batch[8714] - loss: 0.001164 best_pearson: 0.7248
Batch[8715] - loss: 0.000900 best_pearson: 0.7248
Batch[8716] - loss: 0.000947 best_pearson: 0.7248
Batch[8717] - loss: 0.000980 best_pearson: 0.7248
Batch[8718] - loss: 0.000743 best_pearson: 0.7248
Batch[8719] - loss: 0.000838 best_pearson: 0.7248
Batch[8720] - loss: 0.000787 best_pearson: 0.7248
Batch[8721] - loss: 0.000728 best_pearson: 0.7248
Batch[8722] - loss: 0.000779 best_pearson: 0.7248
Batch[8723] - loss: 0.000627 best_pearson: 0.7248
Batch[8724] - loss: 0.000618 best_pearson: 0.7248
Batch[8725] - loss: 0.000894 best_pearson: 0.7248
Batch[8726] - loss: 0.000659 best_pearson: 0.7248
Batch[8727] - loss: 0.000657 best_pearson: 0.7248
Batch[8728] - loss: 0.000970 best_pearson: 0.7248
Batch[8729] - loss: 0.000619 best_pearson: 0.7248
Batch[8730] - loss: 0.000521 best_pearson: 0.7248
Batch[8731] - loss: 0.000876 best_pearson: 0.7248
Batch[8732] - loss: 0.000464 best_pearson: 0.7248
Batch[8733] - loss: 0.001039 best_pearson: 0.7248
Batch[8734] - loss: 0.000468 best_pearson: 0.7248
Batch[8735] - loss: 0.000490 best_pearson: 0.7248
Batch[8736] - loss: 0.000442 best_pearson: 0.7248
Batch[8737] - loss: 0.000615 best_pearson: 0.7248
Batch[8738] - loss: 0.000779 best_pearson: 0.7248
Batch[8739] - loss: 0.000473 best_pearson: 0.7248
Batch[8740] - loss: 0.000321 best_pearson: 0.7248
Batch[8741] - loss: 0.001127 best_pearson: 0.7248
Batch[8742] - loss: 0.000642 best_pearson: 0.7248
Batch[8743] - loss: 0.000895 best_pearson: 0.7248
Batch[8744] - loss: 0.000801 best_pearson: 0.7248
Batch[8745] - loss: 0.000775 best_pearson: 0.7248
Batch[8746] - loss: 0.000577 best_pearson: 0.7248
Batch[8747] - loss: 0.000495 best_pearson: 0.7248
Batch[8748] - loss: 0.000479 best_pearson: 0.7248
Batch[8749] - loss: 0.000704 best_pearson: 0.7248
Batch[8750] - loss: 0.001623 best_pearson: 0.7248
Batch[8751] - loss: 0.000766 best_pearson: 0.7248
Batch[8752] - loss: 0.000519 best_pearson: 0.7248
Batch[8753] - loss: 0.000801 best_pearson: 0.7248
Batch[8754] - loss: 0.000745 best_pearson: 0.7248
Batch[8755] - loss: 0.000485 best_pearson: 0.7248
Batch[8756] - loss: 0.001192 best_pearson: 0.7248
Batch[8757] - loss: 0.000946 best_pearson: 0.7248
Batch[8758] - loss: 0.000833 best_pearson: 0.7248
Batch[8759] - loss: 0.000702 best_pearson: 0.7248
Batch[8760] - loss: 0.000628 best_pearson: 0.7248
Batch[8761] - loss: 0.000896 best_pearson: 0.7248
Batch[8762] - loss: 0.000765 best_pearson: 0.7248
Batch[8763] - loss: 0.000831 best_pearson: 0.7248
Batch[8764] - loss: 0.000583 best_pearson: 0.7248
Batch[8765] - loss: 0.000946 best_pearson: 0.7248
Batch[8766] - loss: 0.000969 best_pearson: 0.7248
Batch[8767] - loss: 0.000601 best_pearson: 0.7248
Batch[8768] - loss: 0.000630 best_pearson: 0.7248
Batch[8769] - loss: 0.000818 best_pearson: 0.7248
Batch[8770] - loss: 0.000911 best_pearson: 0.7248
Batch[8771] - loss: 0.000499 best_pearson: 0.7248
Batch[8772] - loss: 0.000513 best_pearson: 0.7248
Batch[8773] - loss: 0.000763 best_pearson: 0.7248
Batch[8774] - loss: 0.000705 best_pearson: 0.7248
Batch[8775] - loss: 0.000411 best_pearson: 0.7248
Batch[8776] - loss: 0.000705 best_pearson: 0.7248
Batch[8777] - loss: 0.000448 best_pearson: 0.7248
Batch[8778] - loss: 0.000730 best_pearson: 0.7248
Batch[8779] - loss: 0.000430 best_pearson: 0.7248
Batch[8780] - loss: 0.000648 best_pearson: 0.7248
Batch[8781] - loss: 0.000906 best_pearson: 0.7248
Batch[8782] - loss: 0.000776 best_pearson: 0.7248
Batch[8783] - loss: 0.000716 best_pearson: 0.7248
Batch[8784] - loss: 0.001041 best_pearson: 0.7248
Batch[8785] - loss: 0.000751 best_pearson: 0.7248
Batch[8786] - loss: 0.000496 best_pearson: 0.7248
Batch[8787] - loss: 0.000885 best_pearson: 0.7248
Batch[8788] - loss: 0.001042 best_pearson: 0.7248
Batch[8789] - loss: 0.001049 best_pearson: 0.7248
Batch[8790] - loss: 0.000611 best_pearson: 0.7248
Batch[8791] - loss: 0.000727 best_pearson: 0.7248
Batch[8792] - loss: 0.000803 best_pearson: 0.7248
Batch[8793] - loss: 0.000512 best_pearson: 0.7248
Batch[8794] - loss: 0.000681 best_pearson: 0.7248
Batch[8795] - loss: 0.001121 best_pearson: 0.7248
Batch[8796] - loss: 0.000587 best_pearson: 0.7248
Batch[8797] - loss: 0.000927 best_pearson: 0.7248
Batch[8798] - loss: 0.000608 best_pearson: 0.7248
Batch[8799] - loss: 0.001146 best_pearson: 0.7248
Batch[8800] - loss: 0.000966 best_pearson: 0.7248

Evaluation - loss: 0.000046 pearson: 0.7167 

early stop by 1500 steps.
Batch[8801] - loss: 0.000627 best_pearson: 0.7248
Batch[8802] - loss: 0.000793 best_pearson: 0.7248
Batch[8803] - loss: 0.000462 best_pearson: 0.7248
Batch[8804] - loss: 0.000587 best_pearson: 0.7248
Batch[8805] - loss: 0.000963 best_pearson: 0.7248
Batch[8806] - loss: 0.000609 best_pearson: 0.7248
Batch[8807] - loss: 0.000512 best_pearson: 0.7248
Batch[8808] - loss: 0.000839 best_pearson: 0.7248
Batch[8809] - loss: 0.000745 best_pearson: 0.7248
Batch[8810] - loss: 0.000735 best_pearson: 0.7248
Batch[8811] - loss: 0.000431 best_pearson: 0.7248
Batch[8812] - loss: 0.000521 best_pearson: 0.7248
Batch[8813] - loss: 0.000672 best_pearson: 0.7248
Batch[8814] - loss: 0.000479 best_pearson: 0.7248
Batch[8815] - loss: 0.000343 best_pearson: 0.7248
Batch[8816] - loss: 0.000909 best_pearson: 0.7248
Batch[8817] - loss: 0.001002 best_pearson: 0.7248
Batch[8818] - loss: 0.000535 best_pearson: 0.7248
Batch[8819] - loss: 0.001036 best_pearson: 0.7248
Batch[8820] - loss: 0.000343 best_pearson: 0.7248
Batch[8821] - loss: 0.000554 best_pearson: 0.7248
Batch[8822] - loss: 0.000912 best_pearson: 0.7248
Batch[8823] - loss: 0.000736 best_pearson: 0.7248
Batch[8824] - loss: 0.000819 best_pearson: 0.7248
Batch[8825] - loss: 0.000415 best_pearson: 0.7248
Batch[8826] - loss: 0.001551 best_pearson: 0.7248
Batch[8827] - loss: 0.000441 best_pearson: 0.7248
Batch[8828] - loss: 0.000578 best_pearson: 0.7248
Batch[8829] - loss: 0.000780 best_pearson: 0.7248
Batch[8830] - loss: 0.000769 best_pearson: 0.7248
Batch[8831] - loss: 0.000969 best_pearson: 0.7248
Batch[8832] - loss: 0.000518 best_pearson: 0.7248
Batch[8833] - loss: 0.000788 best_pearson: 0.7248
Batch[8834] - loss: 0.000548 best_pearson: 0.7248
Batch[8835] - loss: 0.000588 best_pearson: 0.7248
Batch[8836] - loss: 0.000860 best_pearson: 0.7248
Batch[8837] - loss: 0.000599 best_pearson: 0.7248
Batch[8838] - loss: 0.000608 best_pearson: 0.7248
Batch[8839] - loss: 0.000422 best_pearson: 0.7248
Batch[8840] - loss: 0.000753 best_pearson: 0.7248
Batch[8841] - loss: 0.000672 best_pearson: 0.7248
Batch[8842] - loss: 0.000940 best_pearson: 0.7248
Batch[8843] - loss: 0.000858 best_pearson: 0.7248
Batch[8844] - loss: 0.000592 best_pearson: 0.7248
Batch[8845] - loss: 0.000521 best_pearson: 0.7248
Batch[8846] - loss: 0.000677 best_pearson: 0.7248
Batch[8847] - loss: 0.001137 best_pearson: 0.7248
Batch[8848] - loss: 0.000945 best_pearson: 0.7248
Batch[8849] - loss: 0.000669 best_pearson: 0.7248
Batch[8850] - loss: 0.000630 best_pearson: 0.7248
Batch[8851] - loss: 0.001203 best_pearson: 0.7248
Batch[8852] - loss: 0.000582 best_pearson: 0.7248
Batch[8853] - loss: 0.000790 best_pearson: 0.7248
Batch[8854] - loss: 0.000550 best_pearson: 0.7248
Batch[8855] - loss: 0.000594 best_pearson: 0.7248
Batch[8856] - loss: 0.000535 best_pearson: 0.7248
Batch[8857] - loss: 0.000592 best_pearson: 0.7248
Batch[8858] - loss: 0.000643 best_pearson: 0.7248
Batch[8859] - loss: 0.000491 best_pearson: 0.7248
Batch[8860] - loss: 0.000954 best_pearson: 0.7248
Batch[8861] - loss: 0.000964 best_pearson: 0.7248
Batch[8862] - loss: 0.000629 best_pearson: 0.7248
Batch[8863] - loss: 0.000664 best_pearson: 0.7248
Batch[8864] - loss: 0.000820 best_pearson: 0.7248
Batch[8865] - loss: 0.000581 best_pearson: 0.7248
Batch[8866] - loss: 0.000558 best_pearson: 0.7248
Batch[8867] - loss: 0.000590 best_pearson: 0.7248
Batch[8868] - loss: 0.000677 best_pearson: 0.7248
Batch[8869] - loss: 0.000851 best_pearson: 0.7248
Batch[8870] - loss: 0.000582 best_pearson: 0.7248
Batch[8871] - loss: 0.000932 best_pearson: 0.7248
Batch[8872] - loss: 0.000904 best_pearson: 0.7248
Batch[8873] - loss: 0.000377 best_pearson: 0.7248
Batch[8874] - loss: 0.000395 best_pearson: 0.7248
Batch[8875] - loss: 0.000688 best_pearson: 0.7248
Batch[8876] - loss: 0.000862 best_pearson: 0.7248
Batch[8877] - loss: 0.000294 best_pearson: 0.7248
Batch[8878] - loss: 0.000484 best_pearson: 0.7248
Batch[8879] - loss: 0.000493 best_pearson: 0.7248
Batch[8880] - loss: 0.000349 best_pearson: 0.7248
Batch[8881] - loss: 0.000580 best_pearson: 0.7248
Batch[8882] - loss: 0.001029 best_pearson: 0.7248
Batch[8883] - loss: 0.001586 best_pearson: 0.7248
Batch[8884] - loss: 0.000630 best_pearson: 0.7248
Batch[8885] - loss: 0.001071 best_pearson: 0.7248
Batch[8886] - loss: 0.000585 best_pearson: 0.7248
Batch[8887] - loss: 0.000818 best_pearson: 0.7248
Batch[8888] - loss: 0.000783 best_pearson: 0.7248
Batch[8889] - loss: 0.000362 best_pearson: 0.7248
Batch[8890] - loss: 0.000765 best_pearson: 0.7248
Batch[8891] - loss: 0.000421 best_pearson: 0.7248
Batch[8892] - loss: 0.000598 best_pearson: 0.7248
Batch[8893] - loss: 0.000493 best_pearson: 0.7248
Batch[8894] - loss: 0.000682 best_pearson: 0.7248
Batch[8895] - loss: 0.000784 best_pearson: 0.7248
Batch[8896] - loss: 0.000456 best_pearson: 0.7248
Batch[8897] - loss: 0.000683 best_pearson: 0.7248
Batch[8898] - loss: 0.000741 best_pearson: 0.7248
Batch[8899] - loss: 0.000530 best_pearson: 0.7248
Batch[8900] - loss: 0.000702 best_pearson: 0.7248

Evaluation - loss: 0.000047 pearson: 0.7144 

early stop by 1500 steps.
Batch[8901] - loss: 0.000874 best_pearson: 0.7248
Batch[8902] - loss: 0.000712 best_pearson: 0.7248
Batch[8903] - loss: 0.000528 best_pearson: 0.7248
Batch[8904] - loss: 0.000953 best_pearson: 0.7248
Batch[8905] - loss: 0.000388 best_pearson: 0.7248
Batch[8906] - loss: 0.000728 best_pearson: 0.7248
Batch[8907] - loss: 0.000652 best_pearson: 0.7248
Batch[8908] - loss: 0.000459 best_pearson: 0.7248
Batch[8909] - loss: 0.001175 best_pearson: 0.7248
Batch[8910] - loss: 0.000519 best_pearson: 0.7248
Batch[8911] - loss: 0.000850 best_pearson: 0.7248
Batch[8912] - loss: 0.000556 best_pearson: 0.7248
Batch[8913] - loss: 0.000751 best_pearson: 0.7248
Batch[8914] - loss: 0.000361 best_pearson: 0.7248
Batch[8915] - loss: 0.000765 best_pearson: 0.7248
Batch[8916] - loss: 0.000952 best_pearson: 0.7248
Batch[8917] - loss: 0.000450 best_pearson: 0.7248
Batch[8918] - loss: 0.000543 best_pearson: 0.7248
Batch[8919] - loss: 0.000911 best_pearson: 0.7248
Batch[8920] - loss: 0.000520 best_pearson: 0.7248
Batch[8921] - loss: 0.000609 best_pearson: 0.7248
Batch[8922] - loss: 0.000593 best_pearson: 0.7248
Batch[8923] - loss: 0.000628 best_pearson: 0.7248
Batch[8924] - loss: 0.000388 best_pearson: 0.7248
Batch[8925] - loss: 0.000811 best_pearson: 0.7248
Batch[8926] - loss: 0.000707 best_pearson: 0.7248
Batch[8927] - loss: 0.000603 best_pearson: 0.7248
Batch[8928] - loss: 0.000576 best_pearson: 0.7248
Batch[8929] - loss: 0.000913 best_pearson: 0.7248
Batch[8930] - loss: 0.000529 best_pearson: 0.7248
Batch[8931] - loss: 0.000387 best_pearson: 0.7248
Batch[8932] - loss: 0.000836 best_pearson: 0.7248
Batch[8933] - loss: 0.000912 best_pearson: 0.7248
Batch[8934] - loss: 0.000419 best_pearson: 0.7248
Batch[8935] - loss: 0.000368 best_pearson: 0.7248
Batch[8936] - loss: 0.000432 best_pearson: 0.7248
Batch[8937] - loss: 0.000463 best_pearson: 0.7248
Batch[8938] - loss: 0.001230 best_pearson: 0.7248
Batch[8939] - loss: 0.000556 best_pearson: 0.7248
Batch[8940] - loss: 0.000581 best_pearson: 0.7248
Batch[8941] - loss: 0.000740 best_pearson: 0.7248
Batch[8942] - loss: 0.000830 best_pearson: 0.7248
Batch[8943] - loss: 0.000726 best_pearson: 0.7248
Batch[8944] - loss: 0.000827 best_pearson: 0.7248
Batch[8945] - loss: 0.000465 best_pearson: 0.7248
Batch[8946] - loss: 0.000686 best_pearson: 0.7248
Batch[8947] - loss: 0.000571 best_pearson: 0.7248
Batch[8948] - loss: 0.000832 best_pearson: 0.7248
Batch[8949] - loss: 0.000690 best_pearson: 0.7248
Batch[8950] - loss: 0.000971 best_pearson: 0.7248
Batch[8951] - loss: 0.000374 best_pearson: 0.7248
Batch[8952] - loss: 0.001238 best_pearson: 0.7248
Batch[8953] - loss: 0.000551 best_pearson: 0.7248
Batch[8954] - loss: 0.000568 best_pearson: 0.7248
Batch[8955] - loss: 0.000914 best_pearson: 0.7248
Batch[8956] - loss: 0.000972 best_pearson: 0.7248
Batch[8957] - loss: 0.000808 best_pearson: 0.7248
Batch[8958] - loss: 0.001050 best_pearson: 0.7248
Batch[8959] - loss: 0.000600 best_pearson: 0.7248
Batch[8960] - loss: 0.001157 best_pearson: 0.7248
Batch[8961] - loss: 0.000900 best_pearson: 0.7248
Batch[8962] - loss: 0.000424 best_pearson: 0.7248
Batch[8963] - loss: 0.000634 best_pearson: 0.7248
Batch[8964] - loss: 0.000795 best_pearson: 0.7248
Batch[8965] - loss: 0.000581 best_pearson: 0.7248
Batch[8966] - loss: 0.000544 best_pearson: 0.7248
Batch[8967] - loss: 0.000698 best_pearson: 0.7248
Batch[8968] - loss: 0.000502 best_pearson: 0.7248
Batch[8969] - loss: 0.000374 best_pearson: 0.7248
Batch[8970] - loss: 0.000733 best_pearson: 0.7248
Batch[8971] - loss: 0.000678 best_pearson: 0.7248
Batch[8972] - loss: 0.000361 best_pearson: 0.7248
Batch[8973] - loss: 0.000575 best_pearson: 0.7248
Batch[8974] - loss: 0.000727 best_pearson: 0.7248
Batch[8975] - loss: 0.000357 best_pearson: 0.7248
Batch[8976] - loss: 0.000795 best_pearson: 0.7248
Batch[8977] - loss: 0.000520 best_pearson: 0.7248
Batch[8978] - loss: 0.000949 best_pearson: 0.7248
Batch[8979] - loss: 0.000381 best_pearson: 0.7248
Batch[8980] - loss: 0.000714 best_pearson: 0.7248
Batch[8981] - loss: 0.000749 best_pearson: 0.7248
Batch[8982] - loss: 0.000637 best_pearson: 0.7248
Batch[8983] - loss: 0.000320 best_pearson: 0.7248
Batch[8984] - loss: 0.000703 best_pearson: 0.7248
Batch[8985] - loss: 0.000542 best_pearson: 0.7248
Batch[8986] - loss: 0.001007 best_pearson: 0.7248
Batch[8987] - loss: 0.000699 best_pearson: 0.7248
Batch[8988] - loss: 0.001234 best_pearson: 0.7248
Batch[8989] - loss: 0.000986 best_pearson: 0.7248
Batch[8990] - loss: 0.000429 best_pearson: 0.7248
Batch[8991] - loss: 0.001085 best_pearson: 0.7248
Batch[8992] - loss: 0.000956 best_pearson: 0.7248
Batch[8993] - loss: 0.000716 best_pearson: 0.7248
Batch[8994] - loss: 0.000593 best_pearson: 0.7248
Batch[8995] - loss: 0.001463 best_pearson: 0.7248
Batch[8996] - loss: 0.000681 best_pearson: 0.7248
Batch[8997] - loss: 0.000635 best_pearson: 0.7248
Batch[8998] - loss: 0.000904 best_pearson: 0.7248
Batch[8999] - loss: 0.000701 best_pearson: 0.7248
Batch[9000] - loss: 0.001343 best_pearson: 0.7248

Evaluation - loss: 0.000048 pearson: 0.7118 

early stop by 1500 steps.
Batch[9001] - loss: 0.000409 best_pearson: 0.7248
Batch[9002] - loss: 0.000394 best_pearson: 0.7248
Batch[9003] - loss: 0.000704 best_pearson: 0.7248
Batch[9004] - loss: 0.000460 best_pearson: 0.7248
Batch[9005] - loss: 0.000564 best_pearson: 0.7248
Batch[9006] - loss: 0.001007 best_pearson: 0.7248
Batch[9007] - loss: 0.000682 best_pearson: 0.7248
Batch[9008] - loss: 0.000639 best_pearson: 0.7248
Batch[9009] - loss: 0.000471 best_pearson: 0.7248
Batch[9010] - loss: 0.000616 best_pearson: 0.7248
Batch[9011] - loss: 0.000547 best_pearson: 0.7248
Batch[9012] - loss: 0.000890 best_pearson: 0.7248
Batch[9013] - loss: 0.000459 best_pearson: 0.7248
Batch[9014] - loss: 0.000651 best_pearson: 0.7248
Batch[9015] - loss: 0.000663 best_pearson: 0.7248
Batch[9016] - loss: 0.000481 best_pearson: 0.7248
Batch[9017] - loss: 0.000819 best_pearson: 0.7248
Batch[9018] - loss: 0.000890 best_pearson: 0.7248
Batch[9019] - loss: 0.000454 best_pearson: 0.7248
Batch[9020] - loss: 0.000582 best_pearson: 0.7248
Batch[9021] - loss: 0.000499 best_pearson: 0.7248
Batch[9022] - loss: 0.000698 best_pearson: 0.7248
Batch[9023] - loss: 0.000488 best_pearson: 0.7248
Batch[9024] - loss: 0.000967 best_pearson: 0.7248
Batch[9025] - loss: 0.000464 best_pearson: 0.7248
Batch[9026] - loss: 0.000916 best_pearson: 0.7248
Batch[9027] - loss: 0.000779 best_pearson: 0.7248
Batch[9028] - loss: 0.000791 best_pearson: 0.7248
Batch[9029] - loss: 0.000616 best_pearson: 0.7248
Batch[9030] - loss: 0.000687 best_pearson: 0.7248
Batch[9031] - loss: 0.001141 best_pearson: 0.7248
Batch[9032] - loss: 0.000344 best_pearson: 0.7248
Batch[9033] - loss: 0.000697 best_pearson: 0.7248
Batch[9034] - loss: 0.000362 best_pearson: 0.7248
Batch[9035] - loss: 0.000724 best_pearson: 0.7248
Batch[9036] - loss: 0.000551 best_pearson: 0.7248
Batch[9037] - loss: 0.000605 best_pearson: 0.7248
Batch[9038] - loss: 0.000796 best_pearson: 0.7248
Batch[9039] - loss: 0.000700 best_pearson: 0.7248
Batch[9040] - loss: 0.000315 best_pearson: 0.7248
Batch[9041] - loss: 0.000534 best_pearson: 0.7248
Batch[9042] - loss: 0.000404 best_pearson: 0.7248
Batch[9043] - loss: 0.000240 best_pearson: 0.7248
Batch[9044] - loss: 0.000844 best_pearson: 0.7248
Batch[9045] - loss: 0.000430 best_pearson: 0.7248
Batch[9046] - loss: 0.000889 best_pearson: 0.7248
Batch[9047] - loss: 0.000776 best_pearson: 0.7248
Batch[9048] - loss: 0.000400 best_pearson: 0.7248
Batch[9049] - loss: 0.000567 best_pearson: 0.7248
Batch[9050] - loss: 0.000417 best_pearson: 0.7248
Batch[9051] - loss: 0.000360 best_pearson: 0.7248
Batch[9052] - loss: 0.000640 best_pearson: 0.7248
Batch[9053] - loss: 0.000480 best_pearson: 0.7248
Batch[9054] - loss: 0.000473 best_pearson: 0.7248
Batch[9055] - loss: 0.000808 best_pearson: 0.7248
Batch[9056] - loss: 0.000780 best_pearson: 0.7248
Batch[9057] - loss: 0.000624 best_pearson: 0.7248
Batch[9058] - loss: 0.000779 best_pearson: 0.7248
Batch[9059] - loss: 0.000652 best_pearson: 0.7248
Batch[9060] - loss: 0.000490 best_pearson: 0.7248
Batch[9061] - loss: 0.000537 best_pearson: 0.7248
Batch[9062] - loss: 0.000900 best_pearson: 0.7248
Batch[9063] - loss: 0.000511 best_pearson: 0.7248
Batch[9064] - loss: 0.001058 best_pearson: 0.7248
Batch[9065] - loss: 0.001032 best_pearson: 0.7248
Batch[9066] - loss: 0.000948 best_pearson: 0.7248
Batch[9067] - loss: 0.000715 best_pearson: 0.7248
Batch[9068] - loss: 0.000734 best_pearson: 0.7248
Batch[9069] - loss: 0.000587 best_pearson: 0.7248
Batch[9070] - loss: 0.000743 best_pearson: 0.7248
Batch[9071] - loss: 0.000622 best_pearson: 0.7248
Batch[9072] - loss: 0.000606 best_pearson: 0.7248
Batch[9073] - loss: 0.000484 best_pearson: 0.7248
Batch[9074] - loss: 0.000616 best_pearson: 0.7248
Batch[9075] - loss: 0.000471 best_pearson: 0.7248
Batch[9076] - loss: 0.000506 best_pearson: 0.7248
Batch[9077] - loss: 0.000820 best_pearson: 0.7248
Batch[9078] - loss: 0.000664 best_pearson: 0.7248
Batch[9079] - loss: 0.000384 best_pearson: 0.7248
Batch[9080] - loss: 0.000380 best_pearson: 0.7248
Batch[9081] - loss: 0.000614 best_pearson: 0.7248
Batch[9082] - loss: 0.000523 best_pearson: 0.7248
Batch[9083] - loss: 0.000481 best_pearson: 0.7248
Batch[9084] - loss: 0.000484 best_pearson: 0.7248
Batch[9085] - loss: 0.000539 best_pearson: 0.7248
Batch[9086] - loss: 0.000656 best_pearson: 0.7248
Batch[9087] - loss: 0.000346 best_pearson: 0.7248
Batch[9088] - loss: 0.000862 best_pearson: 0.7248
Batch[9089] - loss: 0.000633 best_pearson: 0.7248
Batch[9090] - loss: 0.000526 best_pearson: 0.7248
Batch[9091] - loss: 0.000843 best_pearson: 0.7248
Batch[9092] - loss: 0.000765 best_pearson: 0.7248
Batch[9093] - loss: 0.001012 best_pearson: 0.7248
Batch[9094] - loss: 0.000299 best_pearson: 0.7248
Batch[9095] - loss: 0.000508 best_pearson: 0.7248
Batch[9096] - loss: 0.000466 best_pearson: 0.7248
Batch[9097] - loss: 0.000298 best_pearson: 0.7248
Batch[9098] - loss: 0.000746 best_pearson: 0.7248
Batch[9099] - loss: 0.000966 best_pearson: 0.7248
Batch[9100] - loss: 0.000796 best_pearson: 0.7248

Evaluation - loss: 0.000050 pearson: 0.7072 

early stop by 1500 steps.
Batch[9101] - loss: 0.000893 best_pearson: 0.7248
Batch[9102] - loss: 0.000492 best_pearson: 0.7248
Batch[9103] - loss: 0.000676 best_pearson: 0.7248
Batch[9104] - loss: 0.000473 best_pearson: 0.7248
Batch[9105] - loss: 0.000909 best_pearson: 0.7248
Batch[9106] - loss: 0.000497 best_pearson: 0.7248
Batch[9107] - loss: 0.000482 best_pearson: 0.7248
Batch[9108] - loss: 0.000416 best_pearson: 0.7248
Batch[9109] - loss: 0.000582 best_pearson: 0.7248
Batch[9110] - loss: 0.000649 best_pearson: 0.7248
Batch[9111] - loss: 0.000431 best_pearson: 0.7248
Batch[9112] - loss: 0.000545 best_pearson: 0.7248
Batch[9113] - loss: 0.000856 best_pearson: 0.7248
Batch[9114] - loss: 0.000461 best_pearson: 0.7248
Batch[9115] - loss: 0.000597 best_pearson: 0.7248
Batch[9116] - loss: 0.000720 best_pearson: 0.7248
Batch[9117] - loss: 0.000981 best_pearson: 0.7248
Batch[9118] - loss: 0.000469 best_pearson: 0.7248
Batch[9119] - loss: 0.000519 best_pearson: 0.7248
Batch[9120] - loss: 0.000385 best_pearson: 0.7248
Batch[9121] - loss: 0.000899 best_pearson: 0.7248
Batch[9122] - loss: 0.000423 best_pearson: 0.7248
Batch[9123] - loss: 0.001087 best_pearson: 0.7248
Batch[9124] - loss: 0.000517 best_pearson: 0.7248
Batch[9125] - loss: 0.000680 best_pearson: 0.7248
Batch[9126] - loss: 0.000490 best_pearson: 0.7248
Batch[9127] - loss: 0.000578 best_pearson: 0.7248
Batch[9128] - loss: 0.000543 best_pearson: 0.7248
Batch[9129] - loss: 0.000607 best_pearson: 0.7248
Batch[9130] - loss: 0.000773 best_pearson: 0.7248
Batch[9131] - loss: 0.000483 best_pearson: 0.7248
Batch[9132] - loss: 0.000651 best_pearson: 0.7248
Batch[9133] - loss: 0.000778 best_pearson: 0.7248
Batch[9134] - loss: 0.000744 best_pearson: 0.7248
Batch[9135] - loss: 0.000425 best_pearson: 0.7248
Batch[9136] - loss: 0.001051 best_pearson: 0.7248
Batch[9137] - loss: 0.001057 best_pearson: 0.7248
Batch[9138] - loss: 0.000524 best_pearson: 0.7248
Batch[9139] - loss: 0.000629 best_pearson: 0.7248
Batch[9140] - loss: 0.000936 best_pearson: 0.7248
Batch[9141] - loss: 0.000637 best_pearson: 0.7248
Batch[9142] - loss: 0.000577 best_pearson: 0.7248
Batch[9143] - loss: 0.000787 best_pearson: 0.7248
Batch[9144] - loss: 0.000469 best_pearson: 0.7248
Batch[9145] - loss: 0.000683 best_pearson: 0.7248
Batch[9146] - loss: 0.000494 best_pearson: 0.7248
Batch[9147] - loss: 0.000494 best_pearson: 0.7248
Batch[9148] - loss: 0.000629 best_pearson: 0.7248
Batch[9149] - loss: 0.000509 best_pearson: 0.7248
Batch[9150] - loss: 0.000723 best_pearson: 0.7248
Batch[9151] - loss: 0.001009 best_pearson: 0.7248
Batch[9152] - loss: 0.000560 best_pearson: 0.7248
Batch[9153] - loss: 0.000403 best_pearson: 0.7248
Batch[9154] - loss: 0.000968 best_pearson: 0.7248
Batch[9155] - loss: 0.000894 best_pearson: 0.7248
Batch[9156] - loss: 0.000812 best_pearson: 0.7248
Batch[9157] - loss: 0.000404 best_pearson: 0.7248
Batch[9158] - loss: 0.000873 best_pearson: 0.7248
Batch[9159] - loss: 0.000644 best_pearson: 0.7248
Batch[9160] - loss: 0.000769 best_pearson: 0.7248
Batch[9161] - loss: 0.000614 best_pearson: 0.7248
Batch[9162] - loss: 0.000531 best_pearson: 0.7248
Batch[9163] - loss: 0.000519 best_pearson: 0.7248
Batch[9164] - loss: 0.000571 best_pearson: 0.7248
Batch[9165] - loss: 0.000657 best_pearson: 0.7248
Batch[9166] - loss: 0.000917 best_pearson: 0.7248
Batch[9167] - loss: 0.000847 best_pearson: 0.7248
Batch[9168] - loss: 0.000532 best_pearson: 0.7248
Batch[9169] - loss: 0.000438 best_pearson: 0.7248
Batch[9170] - loss: 0.000576 best_pearson: 0.7248
Batch[9171] - loss: 0.000629 best_pearson: 0.7248
Batch[9172] - loss: 0.000340 best_pearson: 0.7248
Batch[9173] - loss: 0.000585 best_pearson: 0.7248
Batch[9174] - loss: 0.000317 best_pearson: 0.7248
Batch[9175] - loss: 0.000812 best_pearson: 0.7248
Batch[9176] - loss: 0.000844 best_pearson: 0.7248
Batch[9177] - loss: 0.000862 best_pearson: 0.7248
Batch[9178] - loss: 0.000424 best_pearson: 0.7248
Batch[9179] - loss: 0.000521 best_pearson: 0.7248
Batch[9180] - loss: 0.000974 best_pearson: 0.7248
Batch[9181] - loss: 0.000638 best_pearson: 0.7248
Batch[9182] - loss: 0.000577 best_pearson: 0.7248
Batch[9183] - loss: 0.001046 best_pearson: 0.7248
Batch[9184] - loss: 0.001004 best_pearson: 0.7248
Batch[9185] - loss: 0.000620 best_pearson: 0.7248
Batch[9186] - loss: 0.001098 best_pearson: 0.7248
Batch[9187] - loss: 0.001057 best_pearson: 0.7248
Batch[9188] - loss: 0.000625 best_pearson: 0.7248
Batch[9189] - loss: 0.000647 best_pearson: 0.7248
Batch[9190] - loss: 0.002160 best_pearson: 0.7248
Batch[9191] - loss: 0.000785 best_pearson: 0.7248
Batch[9192] - loss: 0.000515 best_pearson: 0.7248
Batch[9193] - loss: 0.000616 best_pearson: 0.7248
Batch[9194] - loss: 0.000537 best_pearson: 0.7248
Batch[9195] - loss: 0.000657 best_pearson: 0.7248
Batch[9196] - loss: 0.000488 best_pearson: 0.7248
Batch[9197] - loss: 0.000736 best_pearson: 0.7248
Batch[9198] - loss: 0.001013 best_pearson: 0.7248
Batch[9199] - loss: 0.000453 best_pearson: 0.7248
Batch[9200] - loss: 0.000806 best_pearson: 0.7248

Evaluation - loss: 0.000049 pearson: 0.7088 

early stop by 1500 steps.
Batch[9201] - loss: 0.000984 best_pearson: 0.7248
Batch[9202] - loss: 0.000584 best_pearson: 0.7248
Batch[9203] - loss: 0.000460 best_pearson: 0.7248
Batch[9204] - loss: 0.000632 best_pearson: 0.7248
Batch[9205] - loss: 0.000458 best_pearson: 0.7248
Batch[9206] - loss: 0.000890 best_pearson: 0.7248
Batch[9207] - loss: 0.000489 best_pearson: 0.7248
Batch[9208] - loss: 0.000737 best_pearson: 0.7248
Batch[9209] - loss: 0.000999 best_pearson: 0.7248
Batch[9210] - loss: 0.000411 best_pearson: 0.7248
Batch[9211] - loss: 0.001205 best_pearson: 0.7248
Batch[9212] - loss: 0.001002 best_pearson: 0.7248
Batch[9213] - loss: 0.000773 best_pearson: 0.7248
Batch[9214] - loss: 0.000744 best_pearson: 0.7248
Batch[9215] - loss: 0.000821 best_pearson: 0.7248
Batch[9216] - loss: 0.000368 best_pearson: 0.7248
Batch[9217] - loss: 0.000749 best_pearson: 0.7248
Batch[9218] - loss: 0.000776 best_pearson: 0.7248
Batch[9219] - loss: 0.000456 best_pearson: 0.7248
Batch[9220] - loss: 0.000574 best_pearson: 0.7248
Batch[9221] - loss: 0.000544 best_pearson: 0.7248
Batch[9222] - loss: 0.000691 best_pearson: 0.7248
Batch[9223] - loss: 0.000471 best_pearson: 0.7248
Batch[9224] - loss: 0.000513 best_pearson: 0.7248
Batch[9225] - loss: 0.000812 best_pearson: 0.7248
Batch[9226] - loss: 0.000583 best_pearson: 0.7248
Batch[9227] - loss: 0.000972 best_pearson: 0.7248
Batch[9228] - loss: 0.000702 best_pearson: 0.7248
Batch[9229] - loss: 0.000972 best_pearson: 0.7248
Batch[9230] - loss: 0.000940 best_pearson: 0.7248
Batch[9231] - loss: 0.001240 best_pearson: 0.7248
Batch[9232] - loss: 0.000821 best_pearson: 0.7248
Batch[9233] - loss: 0.001195 best_pearson: 0.7248
Batch[9234] - loss: 0.000798 best_pearson: 0.7248
Batch[9235] - loss: 0.000790 best_pearson: 0.7248
Batch[9236] - loss: 0.000866 best_pearson: 0.7248
Batch[9237] - loss: 0.000533 best_pearson: 0.7248
Batch[9238] - loss: 0.000972 best_pearson: 0.7248
Batch[9239] - loss: 0.000436 best_pearson: 0.7248
Batch[9240] - loss: 0.000682 best_pearson: 0.7248
Batch[9241] - loss: 0.000584 best_pearson: 0.7248
Batch[9242] - loss: 0.000678 best_pearson: 0.7248
Batch[9243] - loss: 0.001052 best_pearson: 0.7248
Batch[9244] - loss: 0.000424 best_pearson: 0.7248
Batch[9245] - loss: 0.000506 best_pearson: 0.7248
Batch[9246] - loss: 0.000900 best_pearson: 0.7248
Batch[9247] - loss: 0.000443 best_pearson: 0.7248
Batch[9248] - loss: 0.000709 best_pearson: 0.7248
Batch[9249] - loss: 0.000525 best_pearson: 0.7248
Batch[9250] - loss: 0.000835 best_pearson: 0.7248
Batch[9251] - loss: 0.000620 best_pearson: 0.7248
Batch[9252] - loss: 0.000675 best_pearson: 0.7248
Batch[9253] - loss: 0.000761 best_pearson: 0.7248
Batch[9254] - loss: 0.000591 best_pearson: 0.7248
Batch[9255] - loss: 0.000941 best_pearson: 0.7248
Batch[9256] - loss: 0.000538 best_pearson: 0.7248
Batch[9257] - loss: 0.000720 best_pearson: 0.7248
Batch[9258] - loss: 0.000581 best_pearson: 0.7248
Batch[9259] - loss: 0.000663 best_pearson: 0.7248
Batch[9260] - loss: 0.000804 best_pearson: 0.7248
Batch[9261] - loss: 0.000809 best_pearson: 0.7248
Batch[9262] - loss: 0.000907 best_pearson: 0.7248
Batch[9263] - loss: 0.001011 best_pearson: 0.7248
Batch[9264] - loss: 0.000735 best_pearson: 0.7248
Batch[9265] - loss: 0.000922 best_pearson: 0.7248
Batch[9266] - loss: 0.001306 best_pearson: 0.7248
Batch[9267] - loss: 0.000491 best_pearson: 0.7248
Batch[9268] - loss: 0.000985 best_pearson: 0.7248
Batch[9269] - loss: 0.001010 best_pearson: 0.7248
Batch[9270] - loss: 0.000778 best_pearson: 0.7248
Batch[9271] - loss: 0.000834 best_pearson: 0.7248
Batch[9272] - loss: 0.000536 best_pearson: 0.7248
Batch[9273] - loss: 0.000641 best_pearson: 0.7248
Batch[9274] - loss: 0.000707 best_pearson: 0.7248
Batch[9275] - loss: 0.001662 best_pearson: 0.7248
Batch[9276] - loss: 0.000451 best_pearson: 0.7248
Batch[9277] - loss: 0.000563 best_pearson: 0.7248
Batch[9278] - loss: 0.000475 best_pearson: 0.7248
Batch[9279] - loss: 0.000714 best_pearson: 0.7248
Batch[9280] - loss: 0.000638 best_pearson: 0.7248
Batch[9281] - loss: 0.001013 best_pearson: 0.7248
Batch[9282] - loss: 0.000584 best_pearson: 0.7248
Batch[9283] - loss: 0.001001 best_pearson: 0.7248
Batch[9284] - loss: 0.000723 best_pearson: 0.7248
Batch[9285] - loss: 0.000774 best_pearson: 0.7248
Batch[9286] - loss: 0.000641 best_pearson: 0.7248
Batch[9287] - loss: 0.000662 best_pearson: 0.7248
Batch[9288] - loss: 0.000987 best_pearson: 0.7248
Batch[9289] - loss: 0.001240 best_pearson: 0.7248
Batch[9290] - loss: 0.000931 best_pearson: 0.7248
Batch[9291] - loss: 0.000527 best_pearson: 0.7248
Batch[9292] - loss: 0.000842 best_pearson: 0.7248
Batch[9293] - loss: 0.000581 best_pearson: 0.7248
Batch[9294] - loss: 0.000974 best_pearson: 0.7248
Batch[9295] - loss: 0.000961 best_pearson: 0.7248
Batch[9296] - loss: 0.000928 best_pearson: 0.7248
Batch[9297] - loss: 0.000528 best_pearson: 0.7248
Batch[9298] - loss: 0.000631 best_pearson: 0.7248
Batch[9299] - loss: 0.000700 best_pearson: 0.7248
Batch[9300] - loss: 0.000934 best_pearson: 0.7248

Evaluation - loss: 0.000048 pearson: 0.7119 

early stop by 1500 steps.
Batch[9301] - loss: 0.001022 best_pearson: 0.7248
Batch[9302] - loss: 0.000848 best_pearson: 0.7248
Batch[9303] - loss: 0.001074 best_pearson: 0.7248
Batch[9304] - loss: 0.000686 best_pearson: 0.7248
Batch[9305] - loss: 0.000944 best_pearson: 0.7248
Batch[9306] - loss: 0.000393 best_pearson: 0.7248
Batch[9307] - loss: 0.000687 best_pearson: 0.7248
Batch[9308] - loss: 0.001334 best_pearson: 0.7248
Batch[9309] - loss: 0.000531 best_pearson: 0.7248
Batch[9310] - loss: 0.000712 best_pearson: 0.7248
Batch[9311] - loss: 0.000628 best_pearson: 0.7248
Batch[9312] - loss: 0.000660 best_pearson: 0.7248
Batch[9313] - loss: 0.000495 best_pearson: 0.7248
Batch[9314] - loss: 0.000543 best_pearson: 0.7248
Batch[9315] - loss: 0.000873 best_pearson: 0.7248
Batch[9316] - loss: 0.000449 best_pearson: 0.7248
Batch[9317] - loss: 0.000684 best_pearson: 0.7248
Batch[9318] - loss: 0.000565 best_pearson: 0.7248
Batch[9319] - loss: 0.000508 best_pearson: 0.7248
Batch[9320] - loss: 0.000937 best_pearson: 0.7248
Batch[9321] - loss: 0.000569 best_pearson: 0.7248
Batch[9322] - loss: 0.000406 best_pearson: 0.7248
Batch[9323] - loss: 0.000780 best_pearson: 0.7248
Batch[9324] - loss: 0.000681 best_pearson: 0.7248
Batch[9325] - loss: 0.000881 best_pearson: 0.7248
Batch[9326] - loss: 0.000520 best_pearson: 0.7248
Batch[9327] - loss: 0.000762 best_pearson: 0.7248
Batch[9328] - loss: 0.000530 best_pearson: 0.7248
Batch[9329] - loss: 0.000567 best_pearson: 0.7248
Batch[9330] - loss: 0.000893 best_pearson: 0.7248
Batch[9331] - loss: 0.000714 best_pearson: 0.7248
Batch[9332] - loss: 0.000680 best_pearson: 0.7248
Batch[9333] - loss: 0.000784 best_pearson: 0.7248
Batch[9334] - loss: 0.000708 best_pearson: 0.7248
Batch[9335] - loss: 0.000737 best_pearson: 0.7248
Batch[9336] - loss: 0.000538 best_pearson: 0.7248
Batch[9337] - loss: 0.000681 best_pearson: 0.7248
Batch[9338] - loss: 0.000415 best_pearson: 0.7248
Batch[9339] - loss: 0.001141 best_pearson: 0.7248
Batch[9340] - loss: 0.001344 best_pearson: 0.7248
Batch[9341] - loss: 0.000553 best_pearson: 0.7248
Batch[9342] - loss: 0.001001 best_pearson: 0.7248
Batch[9343] - loss: 0.000301 best_pearson: 0.7248
Batch[9344] - loss: 0.000637 best_pearson: 0.7248
Batch[9345] - loss: 0.001113 best_pearson: 0.7248
Batch[9346] - loss: 0.000719 best_pearson: 0.7248
Batch[9347] - loss: 0.001204 best_pearson: 0.7248
Batch[9348] - loss: 0.000553 best_pearson: 0.7248
Batch[9349] - loss: 0.000672 best_pearson: 0.7248
Batch[9350] - loss: 0.000713 best_pearson: 0.7248
Batch[9351] - loss: 0.001185 best_pearson: 0.7248
Batch[9352] - loss: 0.000574 best_pearson: 0.7248
Batch[9353] - loss: 0.001094 best_pearson: 0.7248
Batch[9354] - loss: 0.000620 best_pearson: 0.7248
Batch[9355] - loss: 0.000718 best_pearson: 0.7248
Batch[9356] - loss: 0.000951 best_pearson: 0.7248
Batch[9357] - loss: 0.000783 best_pearson: 0.7248
Batch[9358] - loss: 0.000655 best_pearson: 0.7248
Batch[9359] - loss: 0.000695 best_pearson: 0.7248
Batch[9360] - loss: 0.000923 best_pearson: 0.7248
Batch[9361] - loss: 0.000552 best_pearson: 0.7248
Batch[9362] - loss: 0.000671 best_pearson: 0.7248
Batch[9363] - loss: 0.000490 best_pearson: 0.7248
Batch[9364] - loss: 0.000865 best_pearson: 0.7248
Batch[9365] - loss: 0.000610 best_pearson: 0.7248
Batch[9366] - loss: 0.000797 best_pearson: 0.7248
Batch[9367] - loss: 0.000536 best_pearson: 0.7248
Batch[9368] - loss: 0.000964 best_pearson: 0.7248
Batch[9369] - loss: 0.001034 best_pearson: 0.7248
Batch[9370] - loss: 0.000497 best_pearson: 0.7248
Batch[9371] - loss: 0.000623 best_pearson: 0.7248
Batch[9372] - loss: 0.000912 best_pearson: 0.7248
Batch[9373] - loss: 0.000710 best_pearson: 0.7248
Batch[9374] - loss: 0.000802 best_pearson: 0.7248
Batch[9375] - loss: 0.000993 best_pearson: 0.7248
Batch[9376] - loss: 0.000645 best_pearson: 0.7248
Batch[9377] - loss: 0.000728 best_pearson: 0.7248
Batch[9378] - loss: 0.000684 best_pearson: 0.7248
Batch[9379] - loss: 0.000664 best_pearson: 0.7248
Batch[9380] - loss: 0.000943 best_pearson: 0.7248
Batch[9381] - loss: 0.000427 best_pearson: 0.7248
Batch[9382] - loss: 0.000371 best_pearson: 0.7248
Batch[9383] - loss: 0.000579 best_pearson: 0.7248
Batch[9384] - loss: 0.000820 best_pearson: 0.7248
Batch[9385] - loss: 0.000607 best_pearson: 0.7248
Batch[9386] - loss: 0.000351 best_pearson: 0.7248
Batch[9387] - loss: 0.000595 best_pearson: 0.7248
Batch[9388] - loss: 0.000716 best_pearson: 0.7248
Batch[9389] - loss: 0.000525 best_pearson: 0.7248
Batch[9390] - loss: 0.000472 best_pearson: 0.7248
Batch[9391] - loss: 0.000509 best_pearson: 0.7248
Batch[9392] - loss: 0.000885 best_pearson: 0.7248
Batch[9393] - loss: 0.000704 best_pearson: 0.7248
Batch[9394] - loss: 0.000479 best_pearson: 0.7248
Batch[9395] - loss: 0.000334 best_pearson: 0.7248
Batch[9396] - loss: 0.001132 best_pearson: 0.7248
Batch[9397] - loss: 0.000567 best_pearson: 0.7248
Batch[9398] - loss: 0.000450 best_pearson: 0.7248
Batch[9399] - loss: 0.000513 best_pearson: 0.7248
Batch[9400] - loss: 0.000648 best_pearson: 0.7248

Evaluation - loss: 0.000048 pearson: 0.7120 

early stop by 1500 steps.
Batch[9401] - loss: 0.001072 best_pearson: 0.7248
Batch[9402] - loss: 0.000765 best_pearson: 0.7248
Batch[9403] - loss: 0.000556 best_pearson: 0.7248
Batch[9404] - loss: 0.000611 best_pearson: 0.7248
Batch[9405] - loss: 0.000547 best_pearson: 0.7248
Batch[9406] - loss: 0.000881 best_pearson: 0.7248
Batch[9407] - loss: 0.001405 best_pearson: 0.7248
Batch[9408] - loss: 0.000527 best_pearson: 0.7248
Batch[9409] - loss: 0.000516 best_pearson: 0.7248
Batch[9410] - loss: 0.000814 best_pearson: 0.7248
Batch[9411] - loss: 0.000623 best_pearson: 0.7248
Batch[9412] - loss: 0.000693 best_pearson: 0.7248
Batch[9413] - loss: 0.000457 best_pearson: 0.7248
Batch[9414] - loss: 0.000536 best_pearson: 0.7248
Batch[9415] - loss: 0.000629 best_pearson: 0.7248
Batch[9416] - loss: 0.000727 best_pearson: 0.7248
Batch[9417] - loss: 0.000837 best_pearson: 0.7248
Batch[9418] - loss: 0.000316 best_pearson: 0.7248
Batch[9419] - loss: 0.001137 best_pearson: 0.7248
Batch[9420] - loss: 0.000643 best_pearson: 0.7248
Batch[9421] - loss: 0.000630 best_pearson: 0.7248
Batch[9422] - loss: 0.001436 best_pearson: 0.7248
Batch[9423] - loss: 0.000620 best_pearson: 0.7248
Batch[9424] - loss: 0.000423 best_pearson: 0.7248
Batch[9425] - loss: 0.000302 best_pearson: 0.7248
Batch[9426] - loss: 0.000621 best_pearson: 0.7248
Batch[9427] - loss: 0.000831 best_pearson: 0.7248
Batch[9428] - loss: 0.000976 best_pearson: 0.7248
Batch[9429] - loss: 0.000798 best_pearson: 0.7248
Batch[9430] - loss: 0.000499 best_pearson: 0.7248
Batch[9431] - loss: 0.000916 best_pearson: 0.7248
Batch[9432] - loss: 0.000453 best_pearson: 0.7248
Batch[9433] - loss: 0.000736 best_pearson: 0.7248
Batch[9434] - loss: 0.000472 best_pearson: 0.7248
Batch[9435] - loss: 0.000525 best_pearson: 0.7248
Batch[9436] - loss: 0.000591 best_pearson: 0.7248
Batch[9437] - loss: 0.000552 best_pearson: 0.7248
Batch[9438] - loss: 0.001085 best_pearson: 0.7248
Batch[9439] - loss: 0.000807 best_pearson: 0.7248
Batch[9440] - loss: 0.000639 best_pearson: 0.7248
Batch[9441] - loss: 0.000790 best_pearson: 0.7248
Batch[9442] - loss: 0.000793 best_pearson: 0.7248
Batch[9443] - loss: 0.000438 best_pearson: 0.7248
Batch[9444] - loss: 0.000359 best_pearson: 0.7248
Batch[9445] - loss: 0.000577 best_pearson: 0.7248
Batch[9446] - loss: 0.001488 best_pearson: 0.7248
Batch[9447] - loss: 0.000778 best_pearson: 0.7248
Batch[9448] - loss: 0.000467 best_pearson: 0.7248
Batch[9449] - loss: 0.000681 best_pearson: 0.7248
Batch[9450] - loss: 0.000724 best_pearson: 0.7248
Batch[9451] - loss: 0.000576 best_pearson: 0.7248
Batch[9452] - loss: 0.000602 best_pearson: 0.7248
Batch[9453] - loss: 0.000575 best_pearson: 0.7248
Batch[9454] - loss: 0.000688 best_pearson: 0.7248
Batch[9455] - loss: 0.000629 best_pearson: 0.7248
Batch[9456] - loss: 0.000335 best_pearson: 0.7248
Batch[9457] - loss: 0.000925 best_pearson: 0.7248
Batch[9458] - loss: 0.000495 best_pearson: 0.7248
Batch[9459] - loss: 0.000901 best_pearson: 0.7248
Batch[9460] - loss: 0.000632 best_pearson: 0.7248
Batch[9461] - loss: 0.000557 best_pearson: 0.7248
Batch[9462] - loss: 0.000399 best_pearson: 0.7248
Batch[9463] - loss: 0.001109 best_pearson: 0.7248
Batch[9464] - loss: 0.000838 best_pearson: 0.7248
Batch[9465] - loss: 0.000476 best_pearson: 0.7248
Batch[9466] - loss: 0.000849 best_pearson: 0.7248
Batch[9467] - loss: 0.000641 best_pearson: 0.7248
Batch[9468] - loss: 0.000458 best_pearson: 0.7248
Batch[9469] - loss: 0.000567 best_pearson: 0.7248
Batch[9470] - loss: 0.000855 best_pearson: 0.7248
Batch[9471] - loss: 0.000679 best_pearson: 0.7248
Batch[9472] - loss: 0.000867 best_pearson: 0.7248
Batch[9473] - loss: 0.001212 best_pearson: 0.7248
Batch[9474] - loss: 0.001545 best_pearson: 0.7248
Batch[9475] - loss: 0.002336 best_pearson: 0.7248
Batch[9476] - loss: 0.000402 best_pearson: 0.7248
Batch[9477] - loss: 0.001229 best_pearson: 0.7248
Batch[9478] - loss: 0.001107 best_pearson: 0.7248
Batch[9479] - loss: 0.000802 best_pearson: 0.7248
Batch[9480] - loss: 0.000659 best_pearson: 0.7248
Batch[9481] - loss: 0.001034 best_pearson: 0.7248
Batch[9482] - loss: 0.000927 best_pearson: 0.7248
Batch[9483] - loss: 0.000444 best_pearson: 0.7248
Batch[9484] - loss: 0.000500 best_pearson: 0.7248
Batch[9485] - loss: 0.000558 best_pearson: 0.7248
Batch[9486] - loss: 0.000788 best_pearson: 0.7248
Batch[9487] - loss: 0.000517 best_pearson: 0.7248
Batch[9488] - loss: 0.000803 best_pearson: 0.7248
Batch[9489] - loss: 0.000920 best_pearson: 0.7248
Batch[9490] - loss: 0.000535 best_pearson: 0.7248
Batch[9491] - loss: 0.000460 best_pearson: 0.7248
Batch[9492] - loss: 0.000675 best_pearson: 0.7248
Batch[9493] - loss: 0.001395 best_pearson: 0.7248
Batch[9494] - loss: 0.000528 best_pearson: 0.7248
Batch[9495] - loss: 0.000573 best_pearson: 0.7248
Batch[9496] - loss: 0.000554 best_pearson: 0.7248
Batch[9497] - loss: 0.000803 best_pearson: 0.7248
Batch[9498] - loss: 0.000696 best_pearson: 0.7248
Batch[9499] - loss: 0.000437 best_pearson: 0.7248
Batch[9500] - loss: 0.000846 best_pearson: 0.7248

Evaluation - loss: 0.000048 pearson: 0.7108 

early stop by 1500 steps.
Batch[9501] - loss: 0.000779 best_pearson: 0.7248
Batch[9502] - loss: 0.000618 best_pearson: 0.7248
Batch[9503] - loss: 0.000661 best_pearson: 0.7248
Batch[9504] - loss: 0.000745 best_pearson: 0.7248
Batch[9505] - loss: 0.000458 best_pearson: 0.7248
Batch[9506] - loss: 0.000805 best_pearson: 0.7248
Batch[9507] - loss: 0.001059 best_pearson: 0.7248
Batch[9508] - loss: 0.000525 best_pearson: 0.7248
Batch[9509] - loss: 0.000644 best_pearson: 0.7248
Batch[9510] - loss: 0.000845 best_pearson: 0.7248
Batch[9511] - loss: 0.001155 best_pearson: 0.7248
Batch[9512] - loss: 0.000386 best_pearson: 0.7248
Batch[9513] - loss: 0.000494 best_pearson: 0.7248
Batch[9514] - loss: 0.000542 best_pearson: 0.7248
Batch[9515] - loss: 0.000564 best_pearson: 0.7248
Batch[9516] - loss: 0.000523 best_pearson: 0.7248
Batch[9517] - loss: 0.000480 best_pearson: 0.7248
Batch[9518] - loss: 0.000634 best_pearson: 0.7248
Batch[9519] - loss: 0.001333 best_pearson: 0.7248
Batch[9520] - loss: 0.000842 best_pearson: 0.7248
Batch[9521] - loss: 0.000615 best_pearson: 0.7248
Batch[9522] - loss: 0.001263 best_pearson: 0.7248
Batch[9523] - loss: 0.000951 best_pearson: 0.7248
Batch[9524] - loss: 0.000570 best_pearson: 0.7248
Batch[9525] - loss: 0.000534 best_pearson: 0.7248
Batch[9526] - loss: 0.000951 best_pearson: 0.7248
Batch[9527] - loss: 0.001103 best_pearson: 0.7248
Batch[9528] - loss: 0.000800 best_pearson: 0.7248
Batch[9529] - loss: 0.000638 best_pearson: 0.7248
Batch[9530] - loss: 0.000676 best_pearson: 0.7248
Batch[9531] - loss: 0.000842 best_pearson: 0.7248
Batch[9532] - loss: 0.000807 best_pearson: 0.7248
Batch[9533] - loss: 0.000279 best_pearson: 0.7248
Batch[9534] - loss: 0.000668 best_pearson: 0.7248
Batch[9535] - loss: 0.001157 best_pearson: 0.7248
Batch[9536] - loss: 0.000667 best_pearson: 0.7248
Batch[9537] - loss: 0.000778 best_pearson: 0.7248
Batch[9538] - loss: 0.000798 best_pearson: 0.7248
Batch[9539] - loss: 0.000753 best_pearson: 0.7248
Batch[9540] - loss: 0.001283 best_pearson: 0.7248
Batch[9541] - loss: 0.000720 best_pearson: 0.7248
Batch[9542] - loss: 0.001260 best_pearson: 0.7248
Batch[9543] - loss: 0.000564 best_pearson: 0.7248
Batch[9544] - loss: 0.000629 best_pearson: 0.7248
Batch[9545] - loss: 0.000447 best_pearson: 0.7248
Batch[9546] - loss: 0.000783 best_pearson: 0.7248
Batch[9547] - loss: 0.000772 best_pearson: 0.7248
Batch[9548] - loss: 0.000936 best_pearson: 0.7248
Batch[9549] - loss: 0.000614 best_pearson: 0.7248
Batch[9550] - loss: 0.000637 best_pearson: 0.7248
Batch[9551] - loss: 0.000866 best_pearson: 0.7248
Batch[9552] - loss: 0.000869 best_pearson: 0.7248
Batch[9553] - loss: 0.000824 best_pearson: 0.7248
Batch[9554] - loss: 0.000921 best_pearson: 0.7248
Batch[9555] - loss: 0.000529 best_pearson: 0.7248
Batch[9556] - loss: 0.000656 best_pearson: 0.7248
Batch[9557] - loss: 0.001837 best_pearson: 0.7248
Batch[9558] - loss: 0.001251 best_pearson: 0.7248
Batch[9559] - loss: 0.000914 best_pearson: 0.7248
Batch[9560] - loss: 0.000475 best_pearson: 0.7248
Batch[9561] - loss: 0.000829 best_pearson: 0.7248
Batch[9562] - loss: 0.000769 best_pearson: 0.7248
Batch[9563] - loss: 0.000979 best_pearson: 0.7248
Batch[9564] - loss: 0.000810 best_pearson: 0.7248
Batch[9565] - loss: 0.000738 best_pearson: 0.7248
Batch[9566] - loss: 0.001213 best_pearson: 0.7248
Batch[9567] - loss: 0.000884 best_pearson: 0.7248
Batch[9568] - loss: 0.000601 best_pearson: 0.7248
Batch[9569] - loss: 0.001066 best_pearson: 0.7248
Batch[9570] - loss: 0.000950 best_pearson: 0.7248
Batch[9571] - loss: 0.000715 best_pearson: 0.7248
Batch[9572] - loss: 0.000656 best_pearson: 0.7248
Batch[9573] - loss: 0.000735 best_pearson: 0.7248
Batch[9574] - loss: 0.000886 best_pearson: 0.7248
Batch[9575] - loss: 0.000797 best_pearson: 0.7248
Batch[9576] - loss: 0.000830 best_pearson: 0.7248
Batch[9577] - loss: 0.000903 best_pearson: 0.7248
Batch[9578] - loss: 0.000670 best_pearson: 0.7248
Batch[9579] - loss: 0.000953 best_pearson: 0.7248
Batch[9580] - loss: 0.000579 best_pearson: 0.7248
Batch[9581] - loss: 0.000624 best_pearson: 0.7248
Batch[9582] - loss: 0.000889 best_pearson: 0.7248
Batch[9583] - loss: 0.000605 best_pearson: 0.7248
Batch[9584] - loss: 0.000620 best_pearson: 0.7248
Batch[9585] - loss: 0.000598 best_pearson: 0.7248
Batch[9586] - loss: 0.000706 best_pearson: 0.7248
Batch[9587] - loss: 0.000590 best_pearson: 0.7248
Batch[9588] - loss: 0.000649 best_pearson: 0.7248
Batch[9589] - loss: 0.000591 best_pearson: 0.7248
Batch[9590] - loss: 0.000672 best_pearson: 0.7248
Batch[9591] - loss: 0.000449 best_pearson: 0.7248
Batch[9592] - loss: 0.000336 best_pearson: 0.7248
Batch[9593] - loss: 0.000864 best_pearson: 0.7248
Batch[9594] - loss: 0.000866 best_pearson: 0.7248
Batch[9595] - loss: 0.001325 best_pearson: 0.7248
Batch[9596] - loss: 0.000890 best_pearson: 0.7248
Batch[9597] - loss: 0.001021 best_pearson: 0.7248
Batch[9598] - loss: 0.001042 best_pearson: 0.7248
Batch[9599] - loss: 0.001162 best_pearson: 0.7248
Batch[9600] - loss: 0.000530 best_pearson: 0.7248

Evaluation - loss: 0.000046 pearson: 0.7158 

early stop by 1500 steps.
Batch[9601] - loss: 0.001199 best_pearson: 0.7248
Batch[9602] - loss: 0.001027 best_pearson: 0.7248
Batch[9603] - loss: 0.000822 best_pearson: 0.7248
Batch[9604] - loss: 0.001023 best_pearson: 0.7248
Batch[9605] - loss: 0.001406 best_pearson: 0.7248
Batch[9606] - loss: 0.001149 best_pearson: 0.7248
Batch[9607] - loss: 0.000961 best_pearson: 0.7248
Batch[9608] - loss: 0.000596 best_pearson: 0.7248
Batch[9609] - loss: 0.000512 best_pearson: 0.7248
Batch[9610] - loss: 0.000566 best_pearson: 0.7248
Batch[9611] - loss: 0.000829 best_pearson: 0.7248
Batch[9612] - loss: 0.000609 best_pearson: 0.7248
Batch[9613] - loss: 0.000797 best_pearson: 0.7248
Batch[9614] - loss: 0.001425 best_pearson: 0.7248
Batch[9615] - loss: 0.001194 best_pearson: 0.7248
Batch[9616] - loss: 0.000944 best_pearson: 0.7248
Batch[9617] - loss: 0.000463 best_pearson: 0.7248
Batch[9618] - loss: 0.000813 best_pearson: 0.7248
Batch[9619] - loss: 0.001085 best_pearson: 0.7248
Batch[9620] - loss: 0.000447 best_pearson: 0.7248
Batch[9621] - loss: 0.001188 best_pearson: 0.7248
Batch[9622] - loss: 0.000776 best_pearson: 0.7248
Batch[9623] - loss: 0.000721 best_pearson: 0.7248
Batch[9624] - loss: 0.000522 best_pearson: 0.7248
Batch[9625] - loss: 0.000986 best_pearson: 0.7248
Batch[9626] - loss: 0.000426 best_pearson: 0.7248
Batch[9627] - loss: 0.000505 best_pearson: 0.7248
Batch[9628] - loss: 0.000472 best_pearson: 0.7248
Batch[9629] - loss: 0.000591 best_pearson: 0.7248
Batch[9630] - loss: 0.000974 best_pearson: 0.7248
Batch[9631] - loss: 0.000697 best_pearson: 0.7248
Batch[9632] - loss: 0.000897 best_pearson: 0.7248
Batch[9633] - loss: 0.000935 best_pearson: 0.7248
Batch[9634] - loss: 0.000761 best_pearson: 0.7248
Batch[9635] - loss: 0.000688 best_pearson: 0.7248
Batch[9636] - loss: 0.001098 best_pearson: 0.7248
Batch[9637] - loss: 0.000862 best_pearson: 0.7248
Batch[9638] - loss: 0.000775 best_pearson: 0.7248
Batch[9639] - loss: 0.001115 best_pearson: 0.7248
Batch[9640] - loss: 0.000680 best_pearson: 0.7248
Batch[9641] - loss: 0.000671 best_pearson: 0.7248
Batch[9642] - loss: 0.000682 best_pearson: 0.7248
Batch[9643] - loss: 0.001122 best_pearson: 0.7248
Batch[9644] - loss: 0.000722 best_pearson: 0.7248
Batch[9645] - loss: 0.001121 best_pearson: 0.7248
Batch[9646] - loss: 0.000862 best_pearson: 0.7248
Batch[9647] - loss: 0.001124 best_pearson: 0.7248
Batch[9648] - loss: 0.000907 best_pearson: 0.7248
Batch[9649] - loss: 0.000817 best_pearson: 0.7248
Batch[9650] - loss: 0.000978 best_pearson: 0.7248
Batch[9651] - loss: 0.000958 best_pearson: 0.7248
Batch[9652] - loss: 0.000691 best_pearson: 0.7248
Batch[9653] - loss: 0.000901 best_pearson: 0.7248
Batch[9654] - loss: 0.000742 best_pearson: 0.7248
Batch[9655] - loss: 0.000792 best_pearson: 0.7248
Batch[9656] - loss: 0.001293 best_pearson: 0.7248
Batch[9657] - loss: 0.000599 best_pearson: 0.7248
Batch[9658] - loss: 0.000967 best_pearson: 0.7248
Batch[9659] - loss: 0.000621 best_pearson: 0.7248
Batch[9660] - loss: 0.001068 best_pearson: 0.7248
Batch[9661] - loss: 0.000688 best_pearson: 0.7248
Batch[9662] - loss: 0.000322 best_pearson: 0.7248
Batch[9663] - loss: 0.001044 best_pearson: 0.7248
Batch[9664] - loss: 0.001072 best_pearson: 0.7248
Batch[9665] - loss: 0.001011 best_pearson: 0.7248
Batch[9666] - loss: 0.000588 best_pearson: 0.7248
Batch[9667] - loss: 0.000727 best_pearson: 0.7248
Batch[9668] - loss: 0.000691 best_pearson: 0.7248
Batch[9669] - loss: 0.000715 best_pearson: 0.7248
Batch[9670] - loss: 0.000679 best_pearson: 0.7248
Batch[9671] - loss: 0.000738 best_pearson: 0.7248
Batch[9672] - loss: 0.000692 best_pearson: 0.7248
Batch[9673] - loss: 0.001164 best_pearson: 0.7248
Batch[9674] - loss: 0.000910 best_pearson: 0.7248
Batch[9675] - loss: 0.000883 best_pearson: 0.7248
Batch[9676] - loss: 0.000735 best_pearson: 0.7248
Batch[9677] - loss: 0.000946 best_pearson: 0.7248
Batch[9678] - loss: 0.000803 best_pearson: 0.7248
Batch[9679] - loss: 0.001190 best_pearson: 0.7248
Batch[9680] - loss: 0.000639 best_pearson: 0.7248
Batch[9681] - loss: 0.000558 best_pearson: 0.7248
Batch[9682] - loss: 0.001081 best_pearson: 0.7248
Batch[9683] - loss: 0.001073 best_pearson: 0.7248
Batch[9684] - loss: 0.000812 best_pearson: 0.7248
Batch[9685] - loss: 0.001738 best_pearson: 0.7248
Batch[9686] - loss: 0.000859 best_pearson: 0.7248
Batch[9687] - loss: 0.000707 best_pearson: 0.7248
Batch[9688] - loss: 0.000695 best_pearson: 0.7248
Batch[9689] - loss: 0.000595 best_pearson: 0.7248
Batch[9690] - loss: 0.000838 best_pearson: 0.7248
Batch[9691] - loss: 0.000607 best_pearson: 0.7248
Batch[9692] - loss: 0.000893 best_pearson: 0.7248
Batch[9693] - loss: 0.000847 best_pearson: 0.7248
Batch[9694] - loss: 0.000760 best_pearson: 0.7248
Batch[9695] - loss: 0.001322 best_pearson: 0.7248
Batch[9696] - loss: 0.001104 best_pearson: 0.7248
Batch[9697] - loss: 0.000630 best_pearson: 0.7248
Batch[9698] - loss: 0.001023 best_pearson: 0.7248
Batch[9699] - loss: 0.000609 best_pearson: 0.7248
Batch[9700] - loss: 0.000968 best_pearson: 0.7248

Evaluation - loss: 0.000047 pearson: 0.7134 

early stop by 1500 steps.
Batch[9701] - loss: 0.000833 best_pearson: 0.7248
Batch[9702] - loss: 0.001229 best_pearson: 0.7248
Batch[9703] - loss: 0.001038 best_pearson: 0.7248
Batch[9704] - loss: 0.001092 best_pearson: 0.7248
Batch[9705] - loss: 0.000835 best_pearson: 0.7248
Batch[9706] - loss: 0.000671 best_pearson: 0.7248
Batch[9707] - loss: 0.000684 best_pearson: 0.7248
Batch[9708] - loss: 0.000810 best_pearson: 0.7248
Batch[9709] - loss: 0.000741 best_pearson: 0.7248
Batch[9710] - loss: 0.000928 best_pearson: 0.7248
Batch[9711] - loss: 0.000549 best_pearson: 0.7248
Batch[9712] - loss: 0.000531 best_pearson: 0.7248
Batch[9713] - loss: 0.000922 best_pearson: 0.7248
Batch[9714] - loss: 0.001010 best_pearson: 0.7248
Batch[9715] - loss: 0.000863 best_pearson: 0.7248
Batch[9716] - loss: 0.000731 best_pearson: 0.7248
Batch[9717] - loss: 0.000615 best_pearson: 0.7248
Batch[9718] - loss: 0.000660 best_pearson: 0.7248
Batch[9719] - loss: 0.000816 best_pearson: 0.7248
Batch[9720] - loss: 0.001122 best_pearson: 0.7248
Batch[9721] - loss: 0.001253 best_pearson: 0.7248
Batch[9722] - loss: 0.000736 best_pearson: 0.7248
Batch[9723] - loss: 0.000764 best_pearson: 0.7248
Batch[9724] - loss: 0.000717 best_pearson: 0.7248
Batch[9725] - loss: 0.001013 best_pearson: 0.7248
Batch[9726] - loss: 0.000647 best_pearson: 0.7248
Batch[9727] - loss: 0.000457 best_pearson: 0.7248
Batch[9728] - loss: 0.000896 best_pearson: 0.7248
Batch[9729] - loss: 0.000661 best_pearson: 0.7248
Batch[9730] - loss: 0.000471 best_pearson: 0.7248
Batch[9731] - loss: 0.000811 best_pearson: 0.7248
Batch[9732] - loss: 0.001153 best_pearson: 0.7248
Batch[9733] - loss: 0.000872 best_pearson: 0.7248
Batch[9734] - loss: 0.000581 best_pearson: 0.7248
Batch[9735] - loss: 0.000609 best_pearson: 0.7248
Batch[9736] - loss: 0.000780 best_pearson: 0.7248
Batch[9737] - loss: 0.001137 best_pearson: 0.7248
Batch[9738] - loss: 0.000472 best_pearson: 0.7248
Batch[9739] - loss: 0.000785 best_pearson: 0.7248
Batch[9740] - loss: 0.000414 best_pearson: 0.7248
Batch[9741] - loss: 0.000751 best_pearson: 0.7248
Batch[9742] - loss: 0.000672 best_pearson: 0.7248
Batch[9743] - loss: 0.000426 best_pearson: 0.7248
Batch[9744] - loss: 0.000603 best_pearson: 0.7248
Batch[9745] - loss: 0.000530 best_pearson: 0.7248
Batch[9746] - loss: 0.000658 best_pearson: 0.7248
Batch[9747] - loss: 0.000604 best_pearson: 0.7248
Batch[9748] - loss: 0.000648 best_pearson: 0.7248
Batch[9749] - loss: 0.001281 best_pearson: 0.7248
Batch[9750] - loss: 0.000563 best_pearson: 0.7248
Batch[9751] - loss: 0.000911 best_pearson: 0.7248
Batch[9752] - loss: 0.000927 best_pearson: 0.7248
Batch[9753] - loss: 0.000796 best_pearson: 0.7248
Batch[9754] - loss: 0.000477 best_pearson: 0.7248
Batch[9755] - loss: 0.000515 best_pearson: 0.7248
Batch[9756] - loss: 0.000793 best_pearson: 0.7248
Batch[9757] - loss: 0.000990 best_pearson: 0.7248
Batch[9758] - loss: 0.000309 best_pearson: 0.7248
Batch[9759] - loss: 0.000623 best_pearson: 0.7248
Batch[9760] - loss: 0.001442 best_pearson: 0.7248
Batch[9761] - loss: 0.001207 best_pearson: 0.7248
Batch[9762] - loss: 0.000862 best_pearson: 0.7248
Batch[9763] - loss: 0.000541 best_pearson: 0.7248
Batch[9764] - loss: 0.000782 best_pearson: 0.7248
Batch[9765] - loss: 0.000949 best_pearson: 0.7248
Batch[9766] - loss: 0.000868 best_pearson: 0.7248
Batch[9767] - loss: 0.000921 best_pearson: 0.7248
Batch[9768] - loss: 0.000429 best_pearson: 0.7248
Batch[9769] - loss: 0.000773 best_pearson: 0.7248
Batch[9770] - loss: 0.000634 best_pearson: 0.7248
Batch[9771] - loss: 0.000592 best_pearson: 0.7248
Batch[9772] - loss: 0.000624 best_pearson: 0.7248
Batch[9773] - loss: 0.000709 best_pearson: 0.7248
Batch[9774] - loss: 0.000513 best_pearson: 0.7248
Batch[9775] - loss: 0.000824 best_pearson: 0.7248
Batch[9776] - loss: 0.000284 best_pearson: 0.7248
Batch[9777] - loss: 0.000481 best_pearson: 0.7248
Batch[9778] - loss: 0.001016 best_pearson: 0.7248
Batch[9779] - loss: 0.000510 best_pearson: 0.7248
Batch[9780] - loss: 0.000483 best_pearson: 0.7248
Batch[9781] - loss: 0.000757 best_pearson: 0.7248
Batch[9782] - loss: 0.000788 best_pearson: 0.7248
Batch[9783] - loss: 0.000709 best_pearson: 0.7248
Batch[9784] - loss: 0.000945 best_pearson: 0.7248
Batch[9785] - loss: 0.000902 best_pearson: 0.7248
Batch[9786] - loss: 0.000872 best_pearson: 0.7248
Batch[9787] - loss: 0.001057 best_pearson: 0.7248
Batch[9788] - loss: 0.000648 best_pearson: 0.7248
Batch[9789] - loss: 0.000566 best_pearson: 0.7248
Batch[9790] - loss: 0.000799 best_pearson: 0.7248
Batch[9791] - loss: 0.000956 best_pearson: 0.7248
Batch[9792] - loss: 0.000436 best_pearson: 0.7248
Batch[9793] - loss: 0.000831 best_pearson: 0.7248
Batch[9794] - loss: 0.000769 best_pearson: 0.7248
Batch[9795] - loss: 0.001030 best_pearson: 0.7248
Batch[9796] - loss: 0.000498 best_pearson: 0.7248
Batch[9797] - loss: 0.000867 best_pearson: 0.7248
Batch[9798] - loss: 0.001248 best_pearson: 0.7248
Batch[9799] - loss: 0.000940 best_pearson: 0.7248
Batch[9800] - loss: 0.000599 best_pearson: 0.7248

Evaluation - loss: 0.000048 pearson: 0.7091 

early stop by 1500 steps.
Batch[9801] - loss: 0.000835 best_pearson: 0.7248
Batch[9802] - loss: 0.000755 best_pearson: 0.7248
Batch[9803] - loss: 0.000609 best_pearson: 0.7248
Batch[9804] - loss: 0.000537 best_pearson: 0.7248
Batch[9805] - loss: 0.000608 best_pearson: 0.7248
Batch[9806] - loss: 0.000453 best_pearson: 0.7248
Batch[9807] - loss: 0.000599 best_pearson: 0.7248
Batch[9808] - loss: 0.000845 best_pearson: 0.7248
Batch[9809] - loss: 0.000653 best_pearson: 0.7248
Batch[9810] - loss: 0.000674 best_pearson: 0.7248
Batch[9811] - loss: 0.000675 best_pearson: 0.7248
Batch[9812] - loss: 0.000589 best_pearson: 0.7248
Batch[9813] - loss: 0.000705 best_pearson: 0.7248
Batch[9814] - loss: 0.000874 best_pearson: 0.7248
Batch[9815] - loss: 0.000846 best_pearson: 0.7248
Batch[9816] - loss: 0.000695 best_pearson: 0.7248
Batch[9817] - loss: 0.000689 best_pearson: 0.7248
Batch[9818] - loss: 0.000882 best_pearson: 0.7248
Batch[9819] - loss: 0.000789 best_pearson: 0.7248
Batch[9820] - loss: 0.000783 best_pearson: 0.7248
Batch[9821] - loss: 0.000568 best_pearson: 0.7248
Batch[9822] - loss: 0.001083 best_pearson: 0.7248
Batch[9823] - loss: 0.000792 best_pearson: 0.7248
Batch[9824] - loss: 0.000755 best_pearson: 0.7248
Batch[9825] - loss: 0.000733 best_pearson: 0.7248
Batch[9826] - loss: 0.000681 best_pearson: 0.7248
Batch[9827] - loss: 0.000472 best_pearson: 0.7248
Batch[9828] - loss: 0.000869 best_pearson: 0.7248
Batch[9829] - loss: 0.000470 best_pearson: 0.7248
Batch[9830] - loss: 0.000503 best_pearson: 0.7248
Batch[9831] - loss: 0.000820 best_pearson: 0.7248
Batch[9832] - loss: 0.000573 best_pearson: 0.7248
Batch[9833] - loss: 0.000540 best_pearson: 0.7248
Batch[9834] - loss: 0.000531 best_pearson: 0.7248
Batch[9835] - loss: 0.000809 best_pearson: 0.7248
Batch[9836] - loss: 0.000543 best_pearson: 0.7248
Batch[9837] - loss: 0.000586 best_pearson: 0.7248
Batch[9838] - loss: 0.001078 best_pearson: 0.7248
Batch[9839] - loss: 0.000867 best_pearson: 0.7248
Batch[9840] - loss: 0.000717 best_pearson: 0.7248
Batch[9841] - loss: 0.000453 best_pearson: 0.7248
Batch[9842] - loss: 0.000686 best_pearson: 0.7248
Batch[9843] - loss: 0.000565 best_pearson: 0.7248
Batch[9844] - loss: 0.000753 best_pearson: 0.7248
Batch[9845] - loss: 0.000601 best_pearson: 0.7248
Batch[9846] - loss: 0.000792 best_pearson: 0.7248
Batch[9847] - loss: 0.000600 best_pearson: 0.7248
Batch[9848] - loss: 0.000467 best_pearson: 0.7248
Batch[9849] - loss: 0.000721 best_pearson: 0.7248
Batch[9850] - loss: 0.000639 best_pearson: 0.7248
Batch[9851] - loss: 0.000382 best_pearson: 0.7248
Batch[9852] - loss: 0.000908 best_pearson: 0.7248
Batch[9853] - loss: 0.000967 best_pearson: 0.7248
Batch[9854] - loss: 0.000611 best_pearson: 0.7248
Batch[9855] - loss: 0.000349 best_pearson: 0.7248
Batch[9856] - loss: 0.000408 best_pearson: 0.7248
Batch[9857] - loss: 0.000662 best_pearson: 0.7248
Batch[9858] - loss: 0.000367 best_pearson: 0.7248
Batch[9859] - loss: 0.000734 best_pearson: 0.7248
Batch[9860] - loss: 0.000964 best_pearson: 0.7248
Batch[9861] - loss: 0.000592 best_pearson: 0.7248
Batch[9862] - loss: 0.000354 best_pearson: 0.7248
Batch[9863] - loss: 0.000553 best_pearson: 0.7248
Batch[9864] - loss: 0.000485 best_pearson: 0.7248
Batch[9865] - loss: 0.000624 best_pearson: 0.7248
Batch[9866] - loss: 0.000482 best_pearson: 0.7248
Batch[9867] - loss: 0.000372 best_pearson: 0.7248
Batch[9868] - loss: 0.000716 best_pearson: 0.7248
Batch[9869] - loss: 0.000261 best_pearson: 0.7248
Batch[9870] - loss: 0.000269 best_pearson: 0.7248
Batch[9871] - loss: 0.000480 best_pearson: 0.7248
Batch[9872] - loss: 0.000562 best_pearson: 0.7248
Batch[9873] - loss: 0.000592 best_pearson: 0.7248
Batch[9874] - loss: 0.000468 best_pearson: 0.7248
Batch[9875] - loss: 0.000586 best_pearson: 0.7248
Batch[9876] - loss: 0.000494 best_pearson: 0.7248
Batch[9877] - loss: 0.000366 best_pearson: 0.7248
Batch[9878] - loss: 0.000650 best_pearson: 0.7248
Batch[9879] - loss: 0.000730 best_pearson: 0.7248
Batch[9880] - loss: 0.000472 best_pearson: 0.7248
Batch[9881] - loss: 0.000769 best_pearson: 0.7248
Batch[9882] - loss: 0.000540 best_pearson: 0.7248
Batch[9883] - loss: 0.000621 best_pearson: 0.7248
Batch[9884] - loss: 0.000620 best_pearson: 0.7248
Batch[9885] - loss: 0.000621 best_pearson: 0.7248
Batch[9886] - loss: 0.001085 best_pearson: 0.7248
Batch[9887] - loss: 0.000661 best_pearson: 0.7248
Batch[9888] - loss: 0.000632 best_pearson: 0.7248
Batch[9889] - loss: 0.000642 best_pearson: 0.7248
Batch[9890] - loss: 0.000652 best_pearson: 0.7248
Batch[9891] - loss: 0.000728 best_pearson: 0.7248
Batch[9892] - loss: 0.000743 best_pearson: 0.7248
Batch[9893] - loss: 0.000694 best_pearson: 0.7248
Batch[9894] - loss: 0.000586 best_pearson: 0.7248
Batch[9895] - loss: 0.000517 best_pearson: 0.7248
Batch[9896] - loss: 0.000263 best_pearson: 0.7248
Batch[9897] - loss: 0.000484 best_pearson: 0.7248
Batch[9898] - loss: 0.000261 best_pearson: 0.7248
Batch[9899] - loss: 0.000589 best_pearson: 0.7248
Batch[9900] - loss: 0.000531 best_pearson: 0.7248

Evaluation - loss: 0.000046 pearson: 0.7145 

early stop by 1500 steps.
Batch[9901] - loss: 0.000737 best_pearson: 0.7248
Batch[9902] - loss: 0.000377 best_pearson: 0.7248
Batch[9903] - loss: 0.000734 best_pearson: 0.7248
Batch[9904] - loss: 0.000559 best_pearson: 0.7248
Batch[9905] - loss: 0.000536 best_pearson: 0.7248
Batch[9906] - loss: 0.000647 best_pearson: 0.7248
Batch[9907] - loss: 0.000651 best_pearson: 0.7248
Batch[9908] - loss: 0.000334 best_pearson: 0.7248
Batch[9909] - loss: 0.000527 best_pearson: 0.7248
Batch[9910] - loss: 0.000581 best_pearson: 0.7248
Batch[9911] - loss: 0.000520 best_pearson: 0.7248
Batch[9912] - loss: 0.000409 best_pearson: 0.7248
Batch[9913] - loss: 0.001001 best_pearson: 0.7248
Batch[9914] - loss: 0.000628 best_pearson: 0.7248
Batch[9915] - loss: 0.000706 best_pearson: 0.7248
Batch[9916] - loss: 0.000288 best_pearson: 0.7248
Batch[9917] - loss: 0.000614 best_pearson: 0.7248
Batch[9918] - loss: 0.000607 best_pearson: 0.7248
Batch[9919] - loss: 0.000483 best_pearson: 0.7248
Batch[9920] - loss: 0.000409 best_pearson: 0.7248
Batch[9921] - loss: 0.000653 best_pearson: 0.7248
Batch[9922] - loss: 0.000855 best_pearson: 0.7248
Batch[9923] - loss: 0.000676 best_pearson: 0.7248
Batch[9924] - loss: 0.000680 best_pearson: 0.7248
Batch[9925] - loss: 0.000471 best_pearson: 0.7248
Batch[9926] - loss: 0.000689 best_pearson: 0.7248
Batch[9927] - loss: 0.000740 best_pearson: 0.7248
Batch[9928] - loss: 0.000460 best_pearson: 0.7248
Batch[9929] - loss: 0.000563 best_pearson: 0.7248
Batch[9930] - loss: 0.000665 best_pearson: 0.7248
Batch[9931] - loss: 0.000594 best_pearson: 0.7248
Batch[9932] - loss: 0.000305 best_pearson: 0.7248
Batch[9933] - loss: 0.000534 best_pearson: 0.7248
Batch[9934] - loss: 0.000418 best_pearson: 0.7248
Batch[9935] - loss: 0.000465 best_pearson: 0.7248
Batch[9936] - loss: 0.000482 best_pearson: 0.7248
Batch[9937] - loss: 0.000285 best_pearson: 0.7248
Batch[9938] - loss: 0.000913 best_pearson: 0.7248
Batch[9939] - loss: 0.000492 best_pearson: 0.7248
Batch[9940] - loss: 0.000489 best_pearson: 0.7248
Batch[9941] - loss: 0.000575 best_pearson: 0.7248
Batch[9942] - loss: 0.000437 best_pearson: 0.7248
Batch[9943] - loss: 0.000477 best_pearson: 0.7248
Batch[9944] - loss: 0.000450 best_pearson: 0.7248
Batch[9945] - loss: 0.000479 best_pearson: 0.7248
Batch[9946] - loss: 0.000364 best_pearson: 0.7248
Batch[9947] - loss: 0.000357 best_pearson: 0.7248
Batch[9948] - loss: 0.000603 best_pearson: 0.7248
Batch[9949] - loss: 0.000401 best_pearson: 0.7248
Batch[9950] - loss: 0.000608 best_pearson: 0.7248
Batch[9951] - loss: 0.000523 best_pearson: 0.7248
Batch[9952] - loss: 0.000578 best_pearson: 0.7248
Batch[9953] - loss: 0.000548 best_pearson: 0.7248
Batch[9954] - loss: 0.000583 best_pearson: 0.7248
Batch[9955] - loss: 0.000586 best_pearson: 0.7248
Batch[9956] - loss: 0.000666 best_pearson: 0.7248
Batch[9957] - loss: 0.000961 best_pearson: 0.7248
Batch[9958] - loss: 0.000778 best_pearson: 0.7248
Batch[9959] - loss: 0.000581 best_pearson: 0.7248
Batch[9960] - loss: 0.000617 best_pearson: 0.7248
Batch[9961] - loss: 0.000391 best_pearson: 0.7248
Batch[9962] - loss: 0.001051 best_pearson: 0.7248
Batch[9963] - loss: 0.000484 best_pearson: 0.7248
Batch[9964] - loss: 0.000450 best_pearson: 0.7248
Batch[9965] - loss: 0.000222 best_pearson: 0.7248
Batch[9966] - loss: 0.000401 best_pearson: 0.7248
Batch[9967] - loss: 0.000876 best_pearson: 0.7248
Batch[9968] - loss: 0.000571 best_pearson: 0.7248
Batch[9969] - loss: 0.000537 best_pearson: 0.7248
Batch[9970] - loss: 0.000480 best_pearson: 0.7248
Batch[9971] - loss: 0.001191 best_pearson: 0.7248
Batch[9972] - loss: 0.000546 best_pearson: 0.7248
Batch[9973] - loss: 0.000738 best_pearson: 0.7248
Batch[9974] - loss: 0.000799 best_pearson: 0.7248
Batch[9975] - loss: 0.000908 best_pearson: 0.7248
Batch[9976] - loss: 0.000555 best_pearson: 0.7248
Batch[9977] - loss: 0.000493 best_pearson: 0.7248
Batch[9978] - loss: 0.000833 best_pearson: 0.7248
Batch[9979] - loss: 0.000566 best_pearson: 0.7248
Batch[9980] - loss: 0.000949 best_pearson: 0.7248
Batch[9981] - loss: 0.000279 best_pearson: 0.7248
Batch[9982] - loss: 0.000457 best_pearson: 0.7248
Batch[9983] - loss: 0.000434 best_pearson: 0.7248
Batch[9984] - loss: 0.000599 best_pearson: 0.7248
Batch[9985] - loss: 0.000634 best_pearson: 0.7248
Batch[9986] - loss: 0.000501 best_pearson: 0.7248
Batch[9987] - loss: 0.000748 best_pearson: 0.7248
Batch[9988] - loss: 0.000576 best_pearson: 0.7248
Batch[9989] - loss: 0.000834 best_pearson: 0.7248
Batch[9990] - loss: 0.000384 best_pearson: 0.7248
Batch[9991] - loss: 0.000350 best_pearson: 0.7248
Batch[9992] - loss: 0.000844 best_pearson: 0.7248
Batch[9993] - loss: 0.000494 best_pearson: 0.7248
Batch[9994] - loss: 0.000409 best_pearson: 0.7248
Batch[9995] - loss: 0.000924 best_pearson: 0.7248
Batch[9996] - loss: 0.000543 best_pearson: 0.7248
Batch[9997] - loss: 0.000505 best_pearson: 0.7248
Batch[9998] - loss: 0.000405 best_pearson: 0.7248
Batch[9999] - loss: 0.001264 best_pearson: 0.7248
Batch[10000] - loss: 0.000419 best_pearson: 0.7248

Evaluation - loss: 0.000047 pearson: 0.7133 

early stop by 1500 steps.
Batch[10001] - loss: 0.000517 best_pearson: 0.7248
Batch[10002] - loss: 0.000590 best_pearson: 0.7248
Batch[10003] - loss: 0.000499 best_pearson: 0.7248
Batch[10004] - loss: 0.000484 best_pearson: 0.7248
Batch[10005] - loss: 0.000237 best_pearson: 0.7248
Batch[10006] - loss: 0.000664 best_pearson: 0.7248
Batch[10007] - loss: 0.000284 best_pearson: 0.7248
Batch[10008] - loss: 0.000465 best_pearson: 0.7248
Batch[10009] - loss: 0.000374 best_pearson: 0.7248
Batch[10010] - loss: 0.000620 best_pearson: 0.7248
Batch[10011] - loss: 0.000482 best_pearson: 0.7248
Batch[10012] - loss: 0.000575 best_pearson: 0.7248
Batch[10013] - loss: 0.000399 best_pearson: 0.7248
Batch[10014] - loss: 0.000787 best_pearson: 0.7248
Batch[10015] - loss: 0.000582 best_pearson: 0.7248
Batch[10016] - loss: 0.000768 best_pearson: 0.7248
Batch[10017] - loss: 0.000578 best_pearson: 0.7248
Batch[10018] - loss: 0.000891 best_pearson: 0.7248
Batch[10019] - loss: 0.000602 best_pearson: 0.7248
Batch[10020] - loss: 0.000550 best_pearson: 0.7248
Batch[10021] - loss: 0.001070 best_pearson: 0.7248
Batch[10022] - loss: 0.000850 best_pearson: 0.7248
Batch[10023] - loss: 0.000978 best_pearson: 0.7248
Batch[10024] - loss: 0.000639 best_pearson: 0.7248
Batch[10025] - loss: 0.000730 best_pearson: 0.7248
Batch[10026] - loss: 0.000516 best_pearson: 0.7248
Batch[10027] - loss: 0.000255 best_pearson: 0.7248
Batch[10028] - loss: 0.000770 best_pearson: 0.7248
Batch[10029] - loss: 0.000688 best_pearson: 0.7248
Batch[10030] - loss: 0.000946 best_pearson: 0.7248
Batch[10031] - loss: 0.000691 best_pearson: 0.7248
Batch[10032] - loss: 0.000504 best_pearson: 0.7248
Batch[10033] - loss: 0.000607 best_pearson: 0.7248
Batch[10034] - loss: 0.000549 best_pearson: 0.7248
Batch[10035] - loss: 0.000563 best_pearson: 0.7248
Batch[10036] - loss: 0.000416 best_pearson: 0.7248
Batch[10037] - loss: 0.000633 best_pearson: 0.7248
Batch[10038] - loss: 0.000558 best_pearson: 0.7248
Batch[10039] - loss: 0.000707 best_pearson: 0.7248
Batch[10040] - loss: 0.000550 best_pearson: 0.7248
Batch[10041] - loss: 0.000574 best_pearson: 0.7248
Batch[10042] - loss: 0.000596 best_pearson: 0.7248
Batch[10043] - loss: 0.000691 best_pearson: 0.7248
Batch[10044] - loss: 0.000495 best_pearson: 0.7248
Batch[10045] - loss: 0.000507 best_pearson: 0.7248
Batch[10046] - loss: 0.000461 best_pearson: 0.7248
Batch[10047] - loss: 0.000437 best_pearson: 0.7248
Batch[10048] - loss: 0.000451 best_pearson: 0.7248
Batch[10049] - loss: 0.000819 best_pearson: 0.7248
Batch[10050] - loss: 0.000527 best_pearson: 0.7248
Batch[10051] - loss: 0.000958 best_pearson: 0.7248
Batch[10052] - loss: 0.000967 best_pearson: 0.7248
Batch[10053] - loss: 0.000642 best_pearson: 0.7248
Batch[10054] - loss: 0.000659 best_pearson: 0.7248
Batch[10055] - loss: 0.000711 best_pearson: 0.7248
Batch[10056] - loss: 0.000643 best_pearson: 0.7248
Batch[10057] - loss: 0.000732 best_pearson: 0.7248
Batch[10058] - loss: 0.001003 best_pearson: 0.7248
Batch[10059] - loss: 0.000423 best_pearson: 0.7248
Batch[10060] - loss: 0.000767 best_pearson: 0.7248
Batch[10061] - loss: 0.000623 best_pearson: 0.7248
Batch[10062] - loss: 0.000754 best_pearson: 0.7248
Batch[10063] - loss: 0.000711 best_pearson: 0.7248
Batch[10064] - loss: 0.000508 best_pearson: 0.7248
Batch[10065] - loss: 0.000515 best_pearson: 0.7248
Batch[10066] - loss: 0.000909 best_pearson: 0.7248
Batch[10067] - loss: 0.000656 best_pearson: 0.7248
Batch[10068] - loss: 0.000778 best_pearson: 0.7248
Batch[10069] - loss: 0.000749 best_pearson: 0.7248
Batch[10070] - loss: 0.000316 best_pearson: 0.7248
Batch[10071] - loss: 0.000514 best_pearson: 0.7248
Batch[10072] - loss: 0.000464 best_pearson: 0.7248
Batch[10073] - loss: 0.000746 best_pearson: 0.7248
Batch[10074] - loss: 0.000531 best_pearson: 0.7248
Batch[10075] - loss: 0.000394 best_pearson: 0.7248
Batch[10076] - loss: 0.000494 best_pearson: 0.7248
Batch[10077] - loss: 0.000406 best_pearson: 0.7248
Batch[10078] - loss: 0.000734 best_pearson: 0.7248
Batch[10079] - loss: 0.000443 best_pearson: 0.7248
Batch[10080] - loss: 0.000563 best_pearson: 0.7248
Batch[10081] - loss: 0.000551 best_pearson: 0.7248
Batch[10082] - loss: 0.000569 best_pearson: 0.7248
Batch[10083] - loss: 0.000374 best_pearson: 0.7248
Batch[10084] - loss: 0.000921 best_pearson: 0.7248
Batch[10085] - loss: 0.000516 best_pearson: 0.7248
Batch[10086] - loss: 0.000570 best_pearson: 0.7248
Batch[10087] - loss: 0.000632 best_pearson: 0.7248
Batch[10088] - loss: 0.000871 best_pearson: 0.7248
Batch[10089] - loss: 0.000614 best_pearson: 0.7248
Batch[10090] - loss: 0.000761 best_pearson: 0.7248
Batch[10091] - loss: 0.000391 best_pearson: 0.7248
Batch[10092] - loss: 0.000526 best_pearson: 0.7248
Batch[10093] - loss: 0.000750 best_pearson: 0.7248
Batch[10094] - loss: 0.000805 best_pearson: 0.7248
Batch[10095] - loss: 0.000301 best_pearson: 0.7248
Batch[10096] - loss: 0.000669 best_pearson: 0.7248
Batch[10097] - loss: 0.000467 best_pearson: 0.7248
Batch[10098] - loss: 0.000456 best_pearson: 0.7248
Batch[10099] - loss: 0.000797 best_pearson: 0.7248
Batch[10100] - loss: 0.000500 best_pearson: 0.7248

Evaluation - loss: 0.000048 pearson: 0.7071 

early stop by 1500 steps.
Batch[10101] - loss: 0.000384 best_pearson: 0.7248
Batch[10102] - loss: 0.000555 best_pearson: 0.7248
Batch[10103] - loss: 0.000750 best_pearson: 0.7248
Batch[10104] - loss: 0.000531 best_pearson: 0.7248
Batch[10105] - loss: 0.000393 best_pearson: 0.7248
Batch[10106] - loss: 0.000607 best_pearson: 0.7248
Batch[10107] - loss: 0.000578 best_pearson: 0.7248
Batch[10108] - loss: 0.001179 best_pearson: 0.7248
Batch[10109] - loss: 0.000530 best_pearson: 0.7248
Batch[10110] - loss: 0.000672 best_pearson: 0.7248
Batch[10111] - loss: 0.000581 best_pearson: 0.7248
Batch[10112] - loss: 0.000715 best_pearson: 0.7248
Batch[10113] - loss: 0.000706 best_pearson: 0.7248
Batch[10114] - loss: 0.000526 best_pearson: 0.7248
Batch[10115] - loss: 0.000578 best_pearson: 0.7248
Batch[10116] - loss: 0.000923 best_pearson: 0.7248
Batch[10117] - loss: 0.000518 best_pearson: 0.7248
Batch[10118] - loss: 0.000340 best_pearson: 0.7248
Batch[10119] - loss: 0.000529 best_pearson: 0.7248
Batch[10120] - loss: 0.000454 best_pearson: 0.7248
Batch[10121] - loss: 0.000488 best_pearson: 0.7248
Batch[10122] - loss: 0.000405 best_pearson: 0.7248
Batch[10123] - loss: 0.000647 best_pearson: 0.7248
Batch[10124] - loss: 0.000719 best_pearson: 0.7248
Batch[10125] - loss: 0.001004 best_pearson: 0.7248
Batch[10126] - loss: 0.000477 best_pearson: 0.7248
Batch[10127] - loss: 0.000614 best_pearson: 0.7248
Batch[10128] - loss: 0.000639 best_pearson: 0.7248
Batch[10129] - loss: 0.000786 best_pearson: 0.7248
Batch[10130] - loss: 0.000496 best_pearson: 0.7248
Batch[10131] - loss: 0.000626 best_pearson: 0.7248
Batch[10132] - loss: 0.000927 best_pearson: 0.7248
Batch[10133] - loss: 0.000607 best_pearson: 0.7248
Batch[10134] - loss: 0.000923 best_pearson: 0.7248
Batch[10135] - loss: 0.000350 best_pearson: 0.7248
Batch[10136] - loss: 0.000475 best_pearson: 0.7248
Batch[10137] - loss: 0.000613 best_pearson: 0.7248
Batch[10138] - loss: 0.000437 best_pearson: 0.7248
Batch[10139] - loss: 0.000688 best_pearson: 0.7248
Batch[10140] - loss: 0.000498 best_pearson: 0.7248
Batch[10141] - loss: 0.000850 best_pearson: 0.7248
Batch[10142] - loss: 0.000381 best_pearson: 0.7248
Batch[10143] - loss: 0.000525 best_pearson: 0.7248
Batch[10144] - loss: 0.000270 best_pearson: 0.7248
Batch[10145] - loss: 0.000522 best_pearson: 0.7248
Batch[10146] - loss: 0.000548 best_pearson: 0.7248
Batch[10147] - loss: 0.000596 best_pearson: 0.7248
Batch[10148] - loss: 0.000325 best_pearson: 0.7248
Batch[10149] - loss: 0.000310 best_pearson: 0.7248
Batch[10150] - loss: 0.000488 best_pearson: 0.7248
Batch[10151] - loss: 0.001056 best_pearson: 0.7248
Batch[10152] - loss: 0.000458 best_pearson: 0.7248
Batch[10153] - loss: 0.000699 best_pearson: 0.7248
Batch[10154] - loss: 0.000741 best_pearson: 0.7248
Batch[10155] - loss: 0.000829 best_pearson: 0.7248
Batch[10156] - loss: 0.000556 best_pearson: 0.7248
Batch[10157] - loss: 0.000584 best_pearson: 0.7248
Batch[10158] - loss: 0.000710 best_pearson: 0.7248
Batch[10159] - loss: 0.000356 best_pearson: 0.7248
Batch[10160] - loss: 0.000609 best_pearson: 0.7248
Batch[10161] - loss: 0.000553 best_pearson: 0.7248
Batch[10162] - loss: 0.000600 best_pearson: 0.7248
Batch[10163] - loss: 0.000551 best_pearson: 0.7248
Batch[10164] - loss: 0.000793 best_pearson: 0.7248
Batch[10165] - loss: 0.000678 best_pearson: 0.7248
Batch[10166] - loss: 0.000719 best_pearson: 0.7248
Batch[10167] - loss: 0.000788 best_pearson: 0.7248
Batch[10168] - loss: 0.000945 best_pearson: 0.7248
Batch[10169] - loss: 0.000433 best_pearson: 0.7248
Batch[10170] - loss: 0.000429 best_pearson: 0.7248
Batch[10171] - loss: 0.000587 best_pearson: 0.7248
Batch[10172] - loss: 0.000645 best_pearson: 0.7248
Batch[10173] - loss: 0.000510 best_pearson: 0.7248
Batch[10174] - loss: 0.000771 best_pearson: 0.7248
Batch[10175] - loss: 0.000464 best_pearson: 0.7248
Batch[10176] - loss: 0.000834 best_pearson: 0.7248
Batch[10177] - loss: 0.000757 best_pearson: 0.7248
Batch[10178] - loss: 0.000404 best_pearson: 0.7248
Batch[10179] - loss: 0.000359 best_pearson: 0.7248
Batch[10180] - loss: 0.000596 best_pearson: 0.7248
Batch[10181] - loss: 0.000421 best_pearson: 0.7248
Batch[10182] - loss: 0.000427 best_pearson: 0.7248
Batch[10183] - loss: 0.000592 best_pearson: 0.7248
Batch[10184] - loss: 0.000690 best_pearson: 0.7248
Batch[10185] - loss: 0.000340 best_pearson: 0.7248
Batch[10186] - loss: 0.000342 best_pearson: 0.7248
Batch[10187] - loss: 0.000576 best_pearson: 0.7248
Batch[10188] - loss: 0.000456 best_pearson: 0.7248
Batch[10189] - loss: 0.000689 best_pearson: 0.7248
Batch[10190] - loss: 0.000789 best_pearson: 0.7248
Batch[10191] - loss: 0.000314 best_pearson: 0.7248
Batch[10192] - loss: 0.000580 best_pearson: 0.7248
Batch[10193] - loss: 0.000602 best_pearson: 0.7248
Batch[10194] - loss: 0.000818 best_pearson: 0.7248
Batch[10195] - loss: 0.000611 best_pearson: 0.7248
Batch[10196] - loss: 0.000282 best_pearson: 0.7248
Batch[10197] - loss: 0.000489 best_pearson: 0.7248
Batch[10198] - loss: 0.000618 best_pearson: 0.7248
Batch[10199] - loss: 0.000528 best_pearson: 0.7248
Batch[10200] - loss: 0.000376 best_pearson: 0.7248

Evaluation - loss: 0.000047 pearson: 0.7131 

early stop by 1500 steps.
Batch[10201] - loss: 0.000449 best_pearson: 0.7248
Batch[10202] - loss: 0.000557 best_pearson: 0.7248
Batch[10203] - loss: 0.000444 best_pearson: 0.7248
Batch[10204] - loss: 0.000649 best_pearson: 0.7248
Batch[10205] - loss: 0.000335 best_pearson: 0.7248
Batch[10206] - loss: 0.000476 best_pearson: 0.7248
Batch[10207] - loss: 0.001061 best_pearson: 0.7248
Batch[10208] - loss: 0.000454 best_pearson: 0.7248
Batch[10209] - loss: 0.000811 best_pearson: 0.7248
Batch[10210] - loss: 0.000782 best_pearson: 0.7248
Batch[10211] - loss: 0.001256 best_pearson: 0.7248
Batch[10212] - loss: 0.000313 best_pearson: 0.7248
Batch[10213] - loss: 0.000430 best_pearson: 0.7248
Batch[10214] - loss: 0.000716 best_pearson: 0.7248
Batch[10215] - loss: 0.000666 best_pearson: 0.7248
Batch[10216] - loss: 0.000577 best_pearson: 0.7248
Batch[10217] - loss: 0.000594 best_pearson: 0.7248
Batch[10218] - loss: 0.000586 best_pearson: 0.7248
Batch[10219] - loss: 0.001180 best_pearson: 0.7248
Batch[10220] - loss: 0.000633 best_pearson: 0.7248
Batch[10221] - loss: 0.000491 best_pearson: 0.7248
Batch[10222] - loss: 0.000756 best_pearson: 0.7248
Batch[10223] - loss: 0.000737 best_pearson: 0.7248
Batch[10224] - loss: 0.000510 best_pearson: 0.7248
Batch[10225] - loss: 0.000512 best_pearson: 0.7248
Batch[10226] - loss: 0.001220 best_pearson: 0.7248
Batch[10227] - loss: 0.000780 best_pearson: 0.7248
Batch[10228] - loss: 0.000676 best_pearson: 0.7248
Batch[10229] - loss: 0.000463 best_pearson: 0.7248
Batch[10230] - loss: 0.000678 best_pearson: 0.7248
Batch[10231] - loss: 0.001094 best_pearson: 0.7248
Batch[10232] - loss: 0.000993 best_pearson: 0.7248
Batch[10233] - loss: 0.000561 best_pearson: 0.7248
Batch[10234] - loss: 0.000687 best_pearson: 0.7248
Batch[10235] - loss: 0.000704 best_pearson: 0.7248
Batch[10236] - loss: 0.000783 best_pearson: 0.7248
Batch[10237] - loss: 0.000516 best_pearson: 0.7248
Batch[10238] - loss: 0.000748 best_pearson: 0.7248
Batch[10239] - loss: 0.000629 best_pearson: 0.7248
Batch[10240] - loss: 0.000482 best_pearson: 0.7248
Batch[10241] - loss: 0.000528 best_pearson: 0.7248
Batch[10242] - loss: 0.000626 best_pearson: 0.7248
Batch[10243] - loss: 0.000550 best_pearson: 0.7248
Batch[10244] - loss: 0.000489 best_pearson: 0.7248
Batch[10245] - loss: 0.000434 best_pearson: 0.7248
Batch[10246] - loss: 0.001177 best_pearson: 0.7248
Batch[10247] - loss: 0.000893 best_pearson: 0.7248
Batch[10248] - loss: 0.000660 best_pearson: 0.7248
Batch[10249] - loss: 0.000627 best_pearson: 0.7248
Batch[10250] - loss: 0.000809 best_pearson: 0.7248
Batch[10251] - loss: 0.000709 best_pearson: 0.7248
Batch[10252] - loss: 0.000586 best_pearson: 0.7248
Batch[10253] - loss: 0.001101 best_pearson: 0.7248
Batch[10254] - loss: 0.000393 best_pearson: 0.7248
Batch[10255] - loss: 0.000765 best_pearson: 0.7248
Batch[10256] - loss: 0.000677 best_pearson: 0.7248
Batch[10257] - loss: 0.000848 best_pearson: 0.7248
Batch[10258] - loss: 0.000464 best_pearson: 0.7248
Batch[10259] - loss: 0.000546 best_pearson: 0.7248
Batch[10260] - loss: 0.000816 best_pearson: 0.7248
Batch[10261] - loss: 0.000700 best_pearson: 0.7248
Batch[10262] - loss: 0.000497 best_pearson: 0.7248
Batch[10263] - loss: 0.000511 best_pearson: 0.7248
Batch[10264] - loss: 0.000730 best_pearson: 0.7248
Batch[10265] - loss: 0.000494 best_pearson: 0.7248
Batch[10266] - loss: 0.000388 best_pearson: 0.7248
Batch[10267] - loss: 0.000800 best_pearson: 0.7248
Batch[10268] - loss: 0.000821 best_pearson: 0.7248
Batch[10269] - loss: 0.000805 best_pearson: 0.7248
Batch[10270] - loss: 0.000561 best_pearson: 0.7248
Batch[10271] - loss: 0.000756 best_pearson: 0.7248
Batch[10272] - loss: 0.000777 best_pearson: 0.7248
Batch[10273] - loss: 0.000909 best_pearson: 0.7248
Batch[10274] - loss: 0.000529 best_pearson: 0.7248
Batch[10275] - loss: 0.000770 best_pearson: 0.7248
Batch[10276] - loss: 0.001112 best_pearson: 0.7248
Batch[10277] - loss: 0.000536 best_pearson: 0.7248
Batch[10278] - loss: 0.000495 best_pearson: 0.7248
Batch[10279] - loss: 0.000990 best_pearson: 0.7248
Batch[10280] - loss: 0.000640 best_pearson: 0.7248
Batch[10281] - loss: 0.000380 best_pearson: 0.7248
Batch[10282] - loss: 0.000521 best_pearson: 0.7248
Batch[10283] - loss: 0.000617 best_pearson: 0.7248
Batch[10284] - loss: 0.000780 best_pearson: 0.7248
Batch[10285] - loss: 0.000496 best_pearson: 0.7248
Batch[10286] - loss: 0.000739 best_pearson: 0.7248
Batch[10287] - loss: 0.001175 best_pearson: 0.7248
Batch[10288] - loss: 0.000414 best_pearson: 0.7248
Batch[10289] - loss: 0.000599 best_pearson: 0.7248
Batch[10290] - loss: 0.000892 best_pearson: 0.7248
Batch[10291] - loss: 0.000774 best_pearson: 0.7248
Batch[10292] - loss: 0.000695 best_pearson: 0.7248
Batch[10293] - loss: 0.000527 best_pearson: 0.7248
Batch[10294] - loss: 0.000519 best_pearson: 0.7248
Batch[10295] - loss: 0.000721 best_pearson: 0.7248
Batch[10296] - loss: 0.000858 best_pearson: 0.7248
Batch[10297] - loss: 0.000602 best_pearson: 0.7248
Batch[10298] - loss: 0.000934 best_pearson: 0.7248
Batch[10299] - loss: 0.000551 best_pearson: 0.7248
Batch[10300] - loss: 0.000943 best_pearson: 0.7248

Evaluation - loss: 0.000048 pearson: 0.7072 

early stop by 1500 steps.
Batch[10301] - loss: 0.000894 best_pearson: 0.7248
Batch[10302] - loss: 0.000711 best_pearson: 0.7248
Batch[10303] - loss: 0.001048 best_pearson: 0.7248
Batch[10304] - loss: 0.000324 best_pearson: 0.7248
Batch[10305] - loss: 0.000841 best_pearson: 0.7248
Batch[10306] - loss: 0.000972 best_pearson: 0.7248
Batch[10307] - loss: 0.000978 best_pearson: 0.7248
Batch[10308] - loss: 0.001033 best_pearson: 0.7248
Batch[10309] - loss: 0.000809 best_pearson: 0.7248
Batch[10310] - loss: 0.000583 best_pearson: 0.7248
Batch[10311] - loss: 0.000559 best_pearson: 0.7248
Batch[10312] - loss: 0.000894 best_pearson: 0.7248
Batch[10313] - loss: 0.000495 best_pearson: 0.7248
Batch[10314] - loss: 0.001090 best_pearson: 0.7248
Batch[10315] - loss: 0.000794 best_pearson: 0.7248
Batch[10316] - loss: 0.000573 best_pearson: 0.7248
Batch[10317] - loss: 0.000433 best_pearson: 0.7248
Batch[10318] - loss: 0.000507 best_pearson: 0.7248
Batch[10319] - loss: 0.000500 best_pearson: 0.7248
Batch[10320] - loss: 0.000846 best_pearson: 0.7248
Batch[10321] - loss: 0.000527 best_pearson: 0.7248
Batch[10322] - loss: 0.001078 best_pearson: 0.7248
Batch[10323] - loss: 0.000597 best_pearson: 0.7248
Batch[10324] - loss: 0.000832 best_pearson: 0.7248
Batch[10325] - loss: 0.000677 best_pearson: 0.7248
Batch[10326] - loss: 0.000495 best_pearson: 0.7248
Batch[10327] - loss: 0.000522 best_pearson: 0.7248
Batch[10328] - loss: 0.001041 best_pearson: 0.7248
Batch[10329] - loss: 0.000970 best_pearson: 0.7248
Batch[10330] - loss: 0.000822 best_pearson: 0.7248
Batch[10331] - loss: 0.000730 best_pearson: 0.7248
Batch[10332] - loss: 0.000648 best_pearson: 0.7248
Batch[10333] - loss: 0.000804 best_pearson: 0.7248
Batch[10334] - loss: 0.000309 best_pearson: 0.7248
Batch[10335] - loss: 0.000646 best_pearson: 0.7248
Batch[10336] - loss: 0.000688 best_pearson: 0.7248
Batch[10337] - loss: 0.000848 best_pearson: 0.7248
Batch[10338] - loss: 0.001328 best_pearson: 0.7248
Batch[10339] - loss: 0.000578 best_pearson: 0.7248
Batch[10340] - loss: 0.000735 best_pearson: 0.7248
Batch[10341] - loss: 0.000599 best_pearson: 0.7248
Batch[10342] - loss: 0.000762 best_pearson: 0.7248
Batch[10343] - loss: 0.000765 best_pearson: 0.7248
Batch[10344] - loss: 0.000998 best_pearson: 0.7248
Batch[10345] - loss: 0.000504 best_pearson: 0.7248
Batch[10346] - loss: 0.000876 best_pearson: 0.7248
Batch[10347] - loss: 0.000709 best_pearson: 0.7248
Batch[10348] - loss: 0.000593 best_pearson: 0.7248
Batch[10349] - loss: 0.000895 best_pearson: 0.7248
Batch[10350] - loss: 0.000889 best_pearson: 0.7248
Batch[10351] - loss: 0.000564 best_pearson: 0.7248
Batch[10352] - loss: 0.000485 best_pearson: 0.7248
Batch[10353] - loss: 0.000463 best_pearson: 0.7248
Batch[10354] - loss: 0.000554 best_pearson: 0.7248
Batch[10355] - loss: 0.000637 best_pearson: 0.7248
Batch[10356] - loss: 0.000619 best_pearson: 0.7248
Batch[10357] - loss: 0.000544 best_pearson: 0.7248
Batch[10358] - loss: 0.000593 best_pearson: 0.7248
Batch[10359] - loss: 0.000634 best_pearson: 0.7248
Batch[10360] - loss: 0.000517 best_pearson: 0.7248
Batch[10361] - loss: 0.000575 best_pearson: 0.7248
Batch[10362] - loss: 0.000869 best_pearson: 0.7248
Batch[10363] - loss: 0.000670 best_pearson: 0.7248
Batch[10364] - loss: 0.000598 best_pearson: 0.7248
Batch[10365] - loss: 0.000630 best_pearson: 0.7248
Batch[10366] - loss: 0.000940 best_pearson: 0.7248
Batch[10367] - loss: 0.000744 best_pearson: 0.7248
Batch[10368] - loss: 0.000832 best_pearson: 0.7248
Batch[10369] - loss: 0.000412 best_pearson: 0.7248
Batch[10370] - loss: 0.000747 best_pearson: 0.7248
Batch[10371] - loss: 0.000844 best_pearson: 0.7248
Batch[10372] - loss: 0.000523 best_pearson: 0.7248
Batch[10373] - loss: 0.000873 best_pearson: 0.7248
Batch[10374] - loss: 0.000568 best_pearson: 0.7248
Batch[10375] - loss: 0.000987 best_pearson: 0.7248
Batch[10376] - loss: 0.000582 best_pearson: 0.7248
Batch[10377] - loss: 0.000930 best_pearson: 0.7248
Batch[10378] - loss: 0.000456 best_pearson: 0.7248
Batch[10379] - loss: 0.000625 best_pearson: 0.7248
Batch[10380] - loss: 0.000890 best_pearson: 0.7248
Batch[10381] - loss: 0.000700 best_pearson: 0.7248
Batch[10382] - loss: 0.000725 best_pearson: 0.7248
Batch[10383] - loss: 0.000714 best_pearson: 0.7248
Batch[10384] - loss: 0.000744 best_pearson: 0.7248
Batch[10385] - loss: 0.000870 best_pearson: 0.7248
Batch[10386] - loss: 0.000560 best_pearson: 0.7248
Batch[10387] - loss: 0.000858 best_pearson: 0.7248
Batch[10388] - loss: 0.000827 best_pearson: 0.7248
Batch[10389] - loss: 0.000820 best_pearson: 0.7248
Batch[10390] - loss: 0.000475 best_pearson: 0.7248
Batch[10391] - loss: 0.000788 best_pearson: 0.7248
Batch[10392] - loss: 0.000561 best_pearson: 0.7248
Batch[10393] - loss: 0.000905 best_pearson: 0.7248
Batch[10394] - loss: 0.000826 best_pearson: 0.7248
Batch[10395] - loss: 0.000810 best_pearson: 0.7248
Batch[10396] - loss: 0.000760 best_pearson: 0.7248
Batch[10397] - loss: 0.000694 best_pearson: 0.7248
Batch[10398] - loss: 0.000345 best_pearson: 0.7248
Batch[10399] - loss: 0.001040 best_pearson: 0.7248
Batch[10400] - loss: 0.000604 best_pearson: 0.7248

Evaluation - loss: 0.000048 pearson: 0.7081 

early stop by 1500 steps.
Batch[10401] - loss: 0.000858 best_pearson: 0.7248
Batch[10402] - loss: 0.000765 best_pearson: 0.7248
Batch[10403] - loss: 0.000915 best_pearson: 0.7248
Batch[10404] - loss: 0.001040 best_pearson: 0.7248
Batch[10405] - loss: 0.000616 best_pearson: 0.7248
Batch[10406] - loss: 0.000461 best_pearson: 0.7248
Batch[10407] - loss: 0.000773 best_pearson: 0.7248
Batch[10408] - loss: 0.000510 best_pearson: 0.7248
Batch[10409] - loss: 0.001053 best_pearson: 0.7248
Batch[10410] - loss: 0.000544 best_pearson: 0.7248
Batch[10411] - loss: 0.000572 best_pearson: 0.7248
Batch[10412] - loss: 0.001198 best_pearson: 0.7248
Batch[10413] - loss: 0.000502 best_pearson: 0.7248
Batch[10414] - loss: 0.000543 best_pearson: 0.7248
Batch[10415] - loss: 0.000386 best_pearson: 0.7248
Batch[10416] - loss: 0.000838 best_pearson: 0.7248
Batch[10417] - loss: 0.000629 best_pearson: 0.7248
Batch[10418] - loss: 0.000975 best_pearson: 0.7248
Batch[10419] - loss: 0.000300 best_pearson: 0.7248
Batch[10420] - loss: 0.000710 best_pearson: 0.7248
Batch[10421] - loss: 0.000723 best_pearson: 0.7248
Batch[10422] - loss: 0.000893 best_pearson: 0.7248
Batch[10423] - loss: 0.000730 best_pearson: 0.7248
Batch[10424] - loss: 0.000828 best_pearson: 0.7248
Batch[10425] - loss: 0.000977 best_pearson: 0.7248
Batch[10426] - loss: 0.001170 best_pearson: 0.7248
Batch[10427] - loss: 0.000830 best_pearson: 0.7248
Batch[10428] - loss: 0.000645 best_pearson: 0.7248
Batch[10429] - loss: 0.000553 best_pearson: 0.7248
Batch[10430] - loss: 0.001361 best_pearson: 0.7248
Batch[10431] - loss: 0.001042 best_pearson: 0.7248
Batch[10432] - loss: 0.000640 best_pearson: 0.7248
Batch[10433] - loss: 0.000950 best_pearson: 0.7248
Batch[10434] - loss: 0.000644 best_pearson: 0.7248
Batch[10435] - loss: 0.000871 best_pearson: 0.7248
Batch[10436] - loss: 0.000670 best_pearson: 0.7248
Batch[10437] - loss: 0.000978 best_pearson: 0.7248
Batch[10438] - loss: 0.000728 best_pearson: 0.7248
Batch[10439] - loss: 0.000695 best_pearson: 0.7248
Batch[10440] - loss: 0.001231 best_pearson: 0.7248
Batch[10441] - loss: 0.000695 best_pearson: 0.7248
Batch[10442] - loss: 0.000734 best_pearson: 0.7248
Batch[10443] - loss: 0.000497 best_pearson: 0.7248
Batch[10444] - loss: 0.000961 best_pearson: 0.7248
Batch[10445] - loss: 0.000657 best_pearson: 0.7248
Batch[10446] - loss: 0.000641 best_pearson: 0.7248
Batch[10447] - loss: 0.000577 best_pearson: 0.7248
Batch[10448] - loss: 0.000522 best_pearson: 0.7248
Batch[10449] - loss: 0.000467 best_pearson: 0.7248
Batch[10450] - loss: 0.000469 best_pearson: 0.7248
Batch[10451] - loss: 0.000518 best_pearson: 0.7248
Batch[10452] - loss: 0.000813 best_pearson: 0.7248
Batch[10453] - loss: 0.000703 best_pearson: 0.7248
Batch[10454] - loss: 0.000553 best_pearson: 0.7248
Batch[10455] - loss: 0.000751 best_pearson: 0.7248
Batch[10456] - loss: 0.000753 best_pearson: 0.7248
Batch[10457] - loss: 0.000953 best_pearson: 0.7248
Batch[10458] - loss: 0.000909 best_pearson: 0.7248
Batch[10459] - loss: 0.001507 best_pearson: 0.7248
Batch[10460] - loss: 0.000522 best_pearson: 0.7248
Batch[10461] - loss: 0.000482 best_pearson: 0.7248
Batch[10462] - loss: 0.000510 best_pearson: 0.7248
Batch[10463] - loss: 0.000475 best_pearson: 0.7248
Batch[10464] - loss: 0.000890 best_pearson: 0.7248
Batch[10465] - loss: 0.000473 best_pearson: 0.7248
Batch[10466] - loss: 0.000656 best_pearson: 0.7248
Batch[10467] - loss: 0.000751 best_pearson: 0.7248
Batch[10468] - loss: 0.000741 best_pearson: 0.7248
Batch[10469] - loss: 0.000784 best_pearson: 0.7248
Batch[10470] - loss: 0.000508 best_pearson: 0.7248
Batch[10471] - loss: 0.000416 best_pearson: 0.7248
Batch[10472] - loss: 0.000518 best_pearson: 0.7248
Batch[10473] - loss: 0.000810 best_pearson: 0.7248
Batch[10474] - loss: 0.000609 best_pearson: 0.7248
Batch[10475] - loss: 0.000362 best_pearson: 0.7248
Batch[10476] - loss: 0.000888 best_pearson: 0.7248
Batch[10477] - loss: 0.000494 best_pearson: 0.7248
Batch[10478] - loss: 0.000548 best_pearson: 0.7248
Batch[10479] - loss: 0.000685 best_pearson: 0.7248
Batch[10480] - loss: 0.000992 best_pearson: 0.7248
Batch[10481] - loss: 0.000520 best_pearson: 0.7248
Batch[10482] - loss: 0.000672 best_pearson: 0.7248
Batch[10483] - loss: 0.000619 best_pearson: 0.7248
Batch[10484] - loss: 0.000948 best_pearson: 0.7248
Batch[10485] - loss: 0.000680 best_pearson: 0.7248
Batch[10486] - loss: 0.000308 best_pearson: 0.7248
Batch[10487] - loss: 0.000516 best_pearson: 0.7248
Batch[10488] - loss: 0.000420 best_pearson: 0.7248
Batch[10489] - loss: 0.000610 best_pearson: 0.7248
Batch[10490] - loss: 0.000505 best_pearson: 0.7248
Batch[10491] - loss: 0.000573 best_pearson: 0.7248
Batch[10492] - loss: 0.000433 best_pearson: 0.7248
Batch[10493] - loss: 0.000706 best_pearson: 0.7248
Batch[10494] - loss: 0.000388 best_pearson: 0.7248
Batch[10495] - loss: 0.000548 best_pearson: 0.7248
Batch[10496] - loss: 0.000810 best_pearson: 0.7248
Batch[10497] - loss: 0.000441 best_pearson: 0.7248
Batch[10498] - loss: 0.000716 best_pearson: 0.7248
Batch[10499] - loss: 0.000488 best_pearson: 0.7248
Batch[10500] - loss: 0.000246 best_pearson: 0.7248

Evaluation - loss: 0.000048 pearson: 0.7069 

early stop by 1500 steps.
Batch[10501] - loss: 0.000427 best_pearson: 0.7248
Batch[10502] - loss: 0.000477 best_pearson: 0.7248
Batch[10503] - loss: 0.000778 best_pearson: 0.7248
Batch[10504] - loss: 0.000801 best_pearson: 0.7248
Batch[10505] - loss: 0.000606 best_pearson: 0.7248
Batch[10506] - loss: 0.000607 best_pearson: 0.7248
Batch[10507] - loss: 0.000668 best_pearson: 0.7248
Batch[10508] - loss: 0.000630 best_pearson: 0.7248
Batch[10509] - loss: 0.000560 best_pearson: 0.7248
Batch[10510] - loss: 0.000983 best_pearson: 0.7248
Batch[10511] - loss: 0.001330 best_pearson: 0.7248
Batch[10512] - loss: 0.000530 best_pearson: 0.7248
Batch[10513] - loss: 0.000727 best_pearson: 0.7248
Batch[10514] - loss: 0.000757 best_pearson: 0.7248
Batch[10515] - loss: 0.000596 best_pearson: 0.7248
Batch[10516] - loss: 0.000573 best_pearson: 0.7248
Batch[10517] - loss: 0.000468 best_pearson: 0.7248
Batch[10518] - loss: 0.000489 best_pearson: 0.7248
Batch[10519] - loss: 0.000511 best_pearson: 0.7248
Batch[10520] - loss: 0.000629 best_pearson: 0.7248
Batch[10521] - loss: 0.001034 best_pearson: 0.7248
Batch[10522] - loss: 0.000648 best_pearson: 0.7248
Batch[10523] - loss: 0.000727 best_pearson: 0.7248
Batch[10524] - loss: 0.001238 best_pearson: 0.7248
Batch[10525] - loss: 0.001294 best_pearson: 0.7248
Batch[10526] - loss: 0.000691 best_pearson: 0.7248
Batch[10527] - loss: 0.000481 best_pearson: 0.7248
Batch[10528] - loss: 0.000792 best_pearson: 0.7248
Batch[10529] - loss: 0.000639 best_pearson: 0.7248
Batch[10530] - loss: 0.000416 best_pearson: 0.7248
Batch[10531] - loss: 0.000635 best_pearson: 0.7248
Batch[10532] - loss: 0.000713 best_pearson: 0.7248
Batch[10533] - loss: 0.000699 best_pearson: 0.7248
Batch[10534] - loss: 0.000675 best_pearson: 0.7248
Batch[10535] - loss: 0.000894 best_pearson: 0.7248
Batch[10536] - loss: 0.000547 best_pearson: 0.7248
Batch[10537] - loss: 0.000559 best_pearson: 0.7248
Batch[10538] - loss: 0.000606 best_pearson: 0.7248
Batch[10539] - loss: 0.000659 best_pearson: 0.7248
Batch[10540] - loss: 0.000512 best_pearson: 0.7248
Batch[10541] - loss: 0.000480 best_pearson: 0.7248
Batch[10542] - loss: 0.000717 best_pearson: 0.7248
Batch[10543] - loss: 0.000572 best_pearson: 0.7248
Batch[10544] - loss: 0.000498 best_pearson: 0.7248
Batch[10545] - loss: 0.000562 best_pearson: 0.7248
Batch[10546] - loss: 0.000763 best_pearson: 0.7248
Batch[10547] - loss: 0.000533 best_pearson: 0.7248
Batch[10548] - loss: 0.000624 best_pearson: 0.7248
Batch[10549] - loss: 0.001088 best_pearson: 0.7248
Batch[10550] - loss: 0.000285 best_pearson: 0.7248
Batch[10551] - loss: 0.000652 best_pearson: 0.7248
Batch[10552] - loss: 0.000606 best_pearson: 0.7248
Batch[10553] - loss: 0.000787 best_pearson: 0.7248
Batch[10554] - loss: 0.000844 best_pearson: 0.7248
Batch[10555] - loss: 0.000716 best_pearson: 0.7248
Batch[10556] - loss: 0.000525 best_pearson: 0.7248
Batch[10557] - loss: 0.001028 best_pearson: 0.7248
Batch[10558] - loss: 0.000420 best_pearson: 0.7248
Batch[10559] - loss: 0.000643 best_pearson: 0.7248
Batch[10560] - loss: 0.000406 best_pearson: 0.7248
Batch[10561] - loss: 0.000413 best_pearson: 0.7248
Batch[10562] - loss: 0.000687 best_pearson: 0.7248
Batch[10563] - loss: 0.000662 best_pearson: 0.7248
Batch[10564] - loss: 0.001368 best_pearson: 0.7248
Batch[10565] - loss: 0.000503 best_pearson: 0.7248
Batch[10566] - loss: 0.000565 best_pearson: 0.7248
Batch[10567] - loss: 0.000225 best_pearson: 0.7248
Batch[10568] - loss: 0.000813 best_pearson: 0.7248
Batch[10569] - loss: 0.000442 best_pearson: 0.7248
Batch[10570] - loss: 0.000647 best_pearson: 0.7248
Batch[10571] - loss: 0.000465 best_pearson: 0.7248
Batch[10572] - loss: 0.000518 best_pearson: 0.7248
Batch[10573] - loss: 0.000564 best_pearson: 0.7248
Batch[10574] - loss: 0.000534 best_pearson: 0.7248
Batch[10575] - loss: 0.000459 best_pearson: 0.7248
Batch[10576] - loss: 0.000617 best_pearson: 0.7248
Batch[10577] - loss: 0.000497 best_pearson: 0.7248
Batch[10578] - loss: 0.000737 best_pearson: 0.7248
Batch[10579] - loss: 0.000765 best_pearson: 0.7248
Batch[10580] - loss: 0.000655 best_pearson: 0.7248
Batch[10581] - loss: 0.000445 best_pearson: 0.7248
Batch[10582] - loss: 0.000458 best_pearson: 0.7248
Batch[10583] - loss: 0.000418 best_pearson: 0.7248
Batch[10584] - loss: 0.000457 best_pearson: 0.7248
Batch[10585] - loss: 0.000335 best_pearson: 0.7248
Batch[10586] - loss: 0.000334 best_pearson: 0.7248
Batch[10587] - loss: 0.000479 best_pearson: 0.7248
Batch[10588] - loss: 0.000492 best_pearson: 0.7248
Batch[10589] - loss: 0.000551 best_pearson: 0.7248
Batch[10590] - loss: 0.000447 best_pearson: 0.7248
Batch[10591] - loss: 0.000648 best_pearson: 0.7248
Batch[10592] - loss: 0.000427 best_pearson: 0.7248
Batch[10593] - loss: 0.000418 best_pearson: 0.7248
Batch[10594] - loss: 0.000820 best_pearson: 0.7248
Batch[10595] - loss: 0.000501 best_pearson: 0.7248
Batch[10596] - loss: 0.000703 best_pearson: 0.7248
Batch[10597] - loss: 0.000440 best_pearson: 0.7248
Batch[10598] - loss: 0.000895 best_pearson: 0.7248
Batch[10599] - loss: 0.000517 best_pearson: 0.7248
Batch[10600] - loss: 0.000337 best_pearson: 0.7248

Evaluation - loss: 0.000048 pearson: 0.7082 

early stop by 1500 steps.
Batch[10601] - loss: 0.000695 best_pearson: 0.7248
Batch[10602] - loss: 0.000551 best_pearson: 0.7248
Batch[10603] - loss: 0.001186 best_pearson: 0.7248
Batch[10604] - loss: 0.000489 best_pearson: 0.7248
Batch[10605] - loss: 0.000327 best_pearson: 0.7248
Batch[10606] - loss: 0.000442 best_pearson: 0.7248
Batch[10607] - loss: 0.000402 best_pearson: 0.7248
Batch[10608] - loss: 0.000429 best_pearson: 0.7248
Batch[10609] - loss: 0.000605 best_pearson: 0.7248
Batch[10610] - loss: 0.000635 best_pearson: 0.7248
Batch[10611] - loss: 0.000730 best_pearson: 0.7248
Batch[10612] - loss: 0.000456 best_pearson: 0.7248
Batch[10613] - loss: 0.000337 best_pearson: 0.7248
Batch[10614] - loss: 0.000452 best_pearson: 0.7248
Batch[10615] - loss: 0.000401 best_pearson: 0.7248
Batch[10616] - loss: 0.000510 best_pearson: 0.7248
Batch[10617] - loss: 0.000388 best_pearson: 0.7248
Batch[10618] - loss: 0.000632 best_pearson: 0.7248
Batch[10619] - loss: 0.000407 best_pearson: 0.7248
Batch[10620] - loss: 0.000497 best_pearson: 0.7248
Batch[10621] - loss: 0.000389 best_pearson: 0.7248
Batch[10622] - loss: 0.000620 best_pearson: 0.7248
Batch[10623] - loss: 0.000401 best_pearson: 0.7248
Batch[10624] - loss: 0.000603 best_pearson: 0.7248
Batch[10625] - loss: 0.000393 best_pearson: 0.7248
Batch[10626] - loss: 0.001024 best_pearson: 0.7248
Batch[10627] - loss: 0.000330 best_pearson: 0.7248
Batch[10628] - loss: 0.000294 best_pearson: 0.7248
Batch[10629] - loss: 0.000569 best_pearson: 0.7248
Batch[10630] - loss: 0.000388 best_pearson: 0.7248
Batch[10631] - loss: 0.000483 best_pearson: 0.7248
Batch[10632] - loss: 0.000811 best_pearson: 0.7248
Batch[10633] - loss: 0.000789 best_pearson: 0.7248
Batch[10634] - loss: 0.000639 best_pearson: 0.7248
Batch[10635] - loss: 0.000443 best_pearson: 0.7248
Batch[10636] - loss: 0.000830 best_pearson: 0.7248
Batch[10637] - loss: 0.000457 best_pearson: 0.7248
Batch[10638] - loss: 0.000449 best_pearson: 0.7248
Batch[10639] - loss: 0.000428 best_pearson: 0.7248
Batch[10640] - loss: 0.000402 best_pearson: 0.7248
Batch[10641] - loss: 0.000535 best_pearson: 0.7248
Batch[10642] - loss: 0.000563 best_pearson: 0.7248
Batch[10643] - loss: 0.000500 best_pearson: 0.7248
Batch[10644] - loss: 0.000456 best_pearson: 0.7248
Batch[10645] - loss: 0.000479 best_pearson: 0.7248
Batch[10646] - loss: 0.000446 best_pearson: 0.7248
Batch[10647] - loss: 0.000349 best_pearson: 0.7248
Batch[10648] - loss: 0.000209 best_pearson: 0.7248
Batch[10649] - loss: 0.000428 best_pearson: 0.7248
Batch[10650] - loss: 0.000474 best_pearson: 0.7248
Batch[10651] - loss: 0.000368 best_pearson: 0.7248
Batch[10652] - loss: 0.000409 best_pearson: 0.7248
Batch[10653] - loss: 0.000693 best_pearson: 0.7248
Batch[10654] - loss: 0.000320 best_pearson: 0.7248
Batch[10655] - loss: 0.000325 best_pearson: 0.7248
Batch[10656] - loss: 0.000342 best_pearson: 0.7248
Batch[10657] - loss: 0.000365 best_pearson: 0.7248
Batch[10658] - loss: 0.000473 best_pearson: 0.7248
Batch[10659] - loss: 0.000450 best_pearson: 0.7248
Batch[10660] - loss: 0.000405 best_pearson: 0.7248
Batch[10661] - loss: 0.000480 best_pearson: 0.7248
Batch[10662] - loss: 0.000394 best_pearson: 0.7248
Batch[10663] - loss: 0.000505 best_pearson: 0.7248
Batch[10664] - loss: 0.000439 best_pearson: 0.7248
Batch[10665] - loss: 0.000281 best_pearson: 0.7248
Batch[10666] - loss: 0.000191 best_pearson: 0.7248
Batch[10667] - loss: 0.000521 best_pearson: 0.7248
Batch[10668] - loss: 0.000372 best_pearson: 0.7248
Batch[10669] - loss: 0.000405 best_pearson: 0.7248
Batch[10670] - loss: 0.000337 best_pearson: 0.7248
Batch[10671] - loss: 0.000536 best_pearson: 0.7248
Batch[10672] - loss: 0.000230 best_pearson: 0.7248
Batch[10673] - loss: 0.000302 best_pearson: 0.7248
Batch[10674] - loss: 0.000370 best_pearson: 0.7248
Batch[10675] - loss: 0.000607 best_pearson: 0.7248
Batch[10676] - loss: 0.000496 best_pearson: 0.7248
Batch[10677] - loss: 0.000339 best_pearson: 0.7248
Batch[10678] - loss: 0.000321 best_pearson: 0.7248
Batch[10679] - loss: 0.000817 best_pearson: 0.7248
Batch[10680] - loss: 0.000682 best_pearson: 0.7248
Batch[10681] - loss: 0.000501 best_pearson: 0.7248
Batch[10682] - loss: 0.001278 best_pearson: 0.7248
Batch[10683] - loss: 0.000625 best_pearson: 0.7248
Batch[10684] - loss: 0.000529 best_pearson: 0.7248
Batch[10685] - loss: 0.000339 best_pearson: 0.7248
Batch[10686] - loss: 0.000586 best_pearson: 0.7248
Batch[10687] - loss: 0.000463 best_pearson: 0.7248
Batch[10688] - loss: 0.000685 best_pearson: 0.7248
Batch[10689] - loss: 0.000397 best_pearson: 0.7248
Batch[10690] - loss: 0.000366 best_pearson: 0.7248
Batch[10691] - loss: 0.000959 best_pearson: 0.7248
Batch[10692] - loss: 0.000603 best_pearson: 0.7248
Batch[10693] - loss: 0.000191 best_pearson: 0.7248
Batch[10694] - loss: 0.000720 best_pearson: 0.7248
Batch[10695] - loss: 0.001660 best_pearson: 0.7248
Batch[10696] - loss: 0.000345 best_pearson: 0.7248
Batch[10697] - loss: 0.000534 best_pearson: 0.7248
Batch[10698] - loss: 0.001009 best_pearson: 0.7248
Batch[10699] - loss: 0.000504 best_pearson: 0.7248
Batch[10700] - loss: 0.000345 best_pearson: 0.7248

Evaluation - loss: 0.000047 pearson: 0.7088 

early stop by 1500 steps.
Batch[10701] - loss: 0.000661 best_pearson: 0.7248
Batch[10702] - loss: 0.000820 best_pearson: 0.7248
Batch[10703] - loss: 0.000498 best_pearson: 0.7248
Batch[10704] - loss: 0.000427 best_pearson: 0.7248
Batch[10705] - loss: 0.000496 best_pearson: 0.7248
Batch[10706] - loss: 0.000662 best_pearson: 0.7248
Batch[10707] - loss: 0.000758 best_pearson: 0.7248
Batch[10708] - loss: 0.000426 best_pearson: 0.7248
Batch[10709] - loss: 0.000575 best_pearson: 0.7248
Batch[10710] - loss: 0.000451 best_pearson: 0.7248
Batch[10711] - loss: 0.000383 best_pearson: 0.7248
Batch[10712] - loss: 0.000624 best_pearson: 0.7248
Batch[10713] - loss: 0.000591 best_pearson: 0.7248
Batch[10714] - loss: 0.000718 best_pearson: 0.7248
Batch[10715] - loss: 0.000712 best_pearson: 0.7248
Batch[10716] - loss: 0.000270 best_pearson: 0.7248
Batch[10717] - loss: 0.000822 best_pearson: 0.7248
Batch[10718] - loss: 0.000742 best_pearson: 0.7248
Batch[10719] - loss: 0.000429 best_pearson: 0.7248
Batch[10720] - loss: 0.000363 best_pearson: 0.7248
Batch[10721] - loss: 0.000391 best_pearson: 0.7248
Batch[10722] - loss: 0.000464 best_pearson: 0.7248
Batch[10723] - loss: 0.000713 best_pearson: 0.7248
Batch[10724] - loss: 0.000404 best_pearson: 0.7248
Batch[10725] - loss: 0.000463 best_pearson: 0.7248
Batch[10726] - loss: 0.000587 best_pearson: 0.7248
Batch[10727] - loss: 0.000360 best_pearson: 0.7248
Batch[10728] - loss: 0.000507 best_pearson: 0.7248
Batch[10729] - loss: 0.000552 best_pearson: 0.7248
Batch[10730] - loss: 0.000368 best_pearson: 0.7248
Batch[10731] - loss: 0.000428 best_pearson: 0.7248
Batch[10732] - loss: 0.000424 best_pearson: 0.7248
Batch[10733] - loss: 0.000356 best_pearson: 0.7248
Batch[10734] - loss: 0.000451 best_pearson: 0.7248
Batch[10735] - loss: 0.000612 best_pearson: 0.7248
Batch[10736] - loss: 0.000389 best_pearson: 0.7248
Batch[10737] - loss: 0.000534 best_pearson: 0.7248
Batch[10738] - loss: 0.000359 best_pearson: 0.7248
Batch[10739] - loss: 0.000431 best_pearson: 0.7248
Batch[10740] - loss: 0.000622 best_pearson: 0.7248
Batch[10741] - loss: 0.000458 best_pearson: 0.7248
Batch[10742] - loss: 0.002053 best_pearson: 0.7248
Batch[10743] - loss: 0.000613 best_pearson: 0.7248
Batch[10744] - loss: 0.000243 best_pearson: 0.7248
Batch[10745] - loss: 0.000334 best_pearson: 0.7248
Batch[10746] - loss: 0.000407 best_pearson: 0.7248
Batch[10747] - loss: 0.000511 best_pearson: 0.7248
Batch[10748] - loss: 0.000867 best_pearson: 0.7248
Batch[10749] - loss: 0.000496 best_pearson: 0.7248
Batch[10750] - loss: 0.000941 best_pearson: 0.7248
Batch[10751] - loss: 0.000738 best_pearson: 0.7248
Batch[10752] - loss: 0.000501 best_pearson: 0.7248
Batch[10753] - loss: 0.000925 best_pearson: 0.7248
Batch[10754] - loss: 0.001619 best_pearson: 0.7248
Batch[10755] - loss: 0.000279 best_pearson: 0.7248
Batch[10756] - loss: 0.000559 best_pearson: 0.7248
Batch[10757] - loss: 0.000304 best_pearson: 0.7248
Batch[10758] - loss: 0.001023 best_pearson: 0.7248
Batch[10759] - loss: 0.000709 best_pearson: 0.7248
Batch[10760] - loss: 0.000563 best_pearson: 0.7248
Batch[10761] - loss: 0.000444 best_pearson: 0.7248
Batch[10762] - loss: 0.000588 best_pearson: 0.7248
Batch[10763] - loss: 0.000535 best_pearson: 0.7248
Batch[10764] - loss: 0.000490 best_pearson: 0.7248
Batch[10765] - loss: 0.000546 best_pearson: 0.7248
Batch[10766] - loss: 0.000509 best_pearson: 0.7248
Batch[10767] - loss: 0.000486 best_pearson: 0.7248
Batch[10768] - loss: 0.000211 best_pearson: 0.7248
Batch[10769] - loss: 0.000597 best_pearson: 0.7248
Batch[10770] - loss: 0.000390 best_pearson: 0.7248
Batch[10771] - loss: 0.000958 best_pearson: 0.7248
Batch[10772] - loss: 0.000588 best_pearson: 0.7248
Batch[10773] - loss: 0.000588 best_pearson: 0.7248
Batch[10774] - loss: 0.000481 best_pearson: 0.7248
Batch[10775] - loss: 0.000438 best_pearson: 0.7248
Batch[10776] - loss: 0.000534 best_pearson: 0.7248
Batch[10777] - loss: 0.000551 best_pearson: 0.7248
Batch[10778] - loss: 0.000625 best_pearson: 0.7248
Batch[10779] - loss: 0.000779 best_pearson: 0.7248
Batch[10780] - loss: 0.000845 best_pearson: 0.7248
Batch[10781] - loss: 0.000497 best_pearson: 0.7248
Batch[10782] - loss: 0.000682 best_pearson: 0.7248
Batch[10783] - loss: 0.000440 best_pearson: 0.7248
Batch[10784] - loss: 0.000278 best_pearson: 0.7248
Batch[10785] - loss: 0.000388 best_pearson: 0.7248
Batch[10786] - loss: 0.000753 best_pearson: 0.7248
Batch[10787] - loss: 0.000734 best_pearson: 0.7248
Batch[10788] - loss: 0.000334 best_pearson: 0.7248
Batch[10789] - loss: 0.000781 best_pearson: 0.7248
Batch[10790] - loss: 0.000580 best_pearson: 0.7248
Batch[10791] - loss: 0.000758 best_pearson: 0.7248
Batch[10792] - loss: 0.001294 best_pearson: 0.7248
Batch[10793] - loss: 0.000456 best_pearson: 0.7248
Batch[10794] - loss: 0.000374 best_pearson: 0.7248
Batch[10795] - loss: 0.000857 best_pearson: 0.7248
Batch[10796] - loss: 0.000613 best_pearson: 0.7248
Batch[10797] - loss: 0.000559 best_pearson: 0.7248
Batch[10798] - loss: 0.000498 best_pearson: 0.7248
Batch[10799] - loss: 0.000552 best_pearson: 0.7248
Batch[10800] - loss: 0.000815 best_pearson: 0.7248

Evaluation - loss: 0.000048 pearson: 0.7073 

early stop by 1500 steps.
Batch[10801] - loss: 0.000499 best_pearson: 0.7248
Batch[10802] - loss: 0.000433 best_pearson: 0.7248
Batch[10803] - loss: 0.000459 best_pearson: 0.7248
Batch[10804] - loss: 0.000597 best_pearson: 0.7248
Batch[10805] - loss: 0.000459 best_pearson: 0.7248
Batch[10806] - loss: 0.000488 best_pearson: 0.7248
Batch[10807] - loss: 0.000463 best_pearson: 0.7248
Batch[10808] - loss: 0.000448 best_pearson: 0.7248
Batch[10809] - loss: 0.000528 best_pearson: 0.7248
Batch[10810] - loss: 0.000583 best_pearson: 0.7248
Batch[10811] - loss: 0.000308 best_pearson: 0.7248
Batch[10812] - loss: 0.000599 best_pearson: 0.7248
Batch[10813] - loss: 0.000831 best_pearson: 0.7248
Batch[10814] - loss: 0.000504 best_pearson: 0.7248
Batch[10815] - loss: 0.000514 best_pearson: 0.7248
Batch[10816] - loss: 0.000531 best_pearson: 0.7248
Batch[10817] - loss: 0.000261 best_pearson: 0.7248
Batch[10818] - loss: 0.000697 best_pearson: 0.7248
Batch[10819] - loss: 0.000695 best_pearson: 0.7248
Batch[10820] - loss: 0.000462 best_pearson: 0.7248
Batch[10821] - loss: 0.000910 best_pearson: 0.7248
Batch[10822] - loss: 0.000429 best_pearson: 0.7248
Batch[10823] - loss: 0.000953 best_pearson: 0.7248
Batch[10824] - loss: 0.000551 best_pearson: 0.7248
Batch[10825] - loss: 0.000420 best_pearson: 0.7248
Batch[10826] - loss: 0.000538 best_pearson: 0.7248
Batch[10827] - loss: 0.000815 best_pearson: 0.7248
Batch[10828] - loss: 0.000485 best_pearson: 0.7248
Batch[10829] - loss: 0.000432 best_pearson: 0.7248
Batch[10830] - loss: 0.000553 best_pearson: 0.7248
Batch[10831] - loss: 0.000495 best_pearson: 0.7248
Batch[10832] - loss: 0.000565 best_pearson: 0.7248
Batch[10833] - loss: 0.000654 best_pearson: 0.7248
Batch[10834] - loss: 0.000952 best_pearson: 0.7248
Batch[10835] - loss: 0.000847 best_pearson: 0.7248
Batch[10836] - loss: 0.000522 best_pearson: 0.7248
Batch[10837] - loss: 0.000516 best_pearson: 0.7248
Batch[10838] - loss: 0.000201 best_pearson: 0.7248
Batch[10839] - loss: 0.000408 best_pearson: 0.7248
Batch[10840] - loss: 0.000663 best_pearson: 0.7248
Batch[10841] - loss: 0.000641 best_pearson: 0.7248
Batch[10842] - loss: 0.000739 best_pearson: 0.7248
Batch[10843] - loss: 0.000790 best_pearson: 0.7248
Batch[10844] - loss: 0.000587 best_pearson: 0.7248
Batch[10845] - loss: 0.000502 best_pearson: 0.7248
Batch[10846] - loss: 0.000390 best_pearson: 0.7248
Batch[10847] - loss: 0.000685 best_pearson: 0.7248
Batch[10848] - loss: 0.000405 best_pearson: 0.7248
Batch[10849] - loss: 0.000642 best_pearson: 0.7248
Batch[10850] - loss: 0.000475 best_pearson: 0.7248
Batch[10851] - loss: 0.000383 best_pearson: 0.7248
Batch[10852] - loss: 0.000450 best_pearson: 0.7248
Batch[10853] - loss: 0.000731 best_pearson: 0.7248
Batch[10854] - loss: 0.000418 best_pearson: 0.7248
Batch[10855] - loss: 0.000613 best_pearson: 0.7248
Batch[10856] - loss: 0.000716 best_pearson: 0.7248
Batch[10857] - loss: 0.000758 best_pearson: 0.7248
Batch[10858] - loss: 0.000884 best_pearson: 0.7248
Batch[10859] - loss: 0.000706 best_pearson: 0.7248
Batch[10860] - loss: 0.000458 best_pearson: 0.7248
Batch[10861] - loss: 0.000502 best_pearson: 0.7248
Batch[10862] - loss: 0.000608 best_pearson: 0.7248
Batch[10863] - loss: 0.000442 best_pearson: 0.7248
Batch[10864] - loss: 0.000369 best_pearson: 0.7248
Batch[10865] - loss: 0.000975 best_pearson: 0.7248
Batch[10866] - loss: 0.000813 best_pearson: 0.7248
Batch[10867] - loss: 0.000537 best_pearson: 0.7248
Batch[10868] - loss: 0.000509 best_pearson: 0.7248
Batch[10869] - loss: 0.000702 best_pearson: 0.7248
Batch[10870] - loss: 0.000549 best_pearson: 0.7248
Batch[10871] - loss: 0.000542 best_pearson: 0.7248
Batch[10872] - loss: 0.000555 best_pearson: 0.7248
Batch[10873] - loss: 0.000479 best_pearson: 0.7248
Batch[10874] - loss: 0.000564 best_pearson: 0.7248
Batch[10875] - loss: 0.000765 best_pearson: 0.7248
Batch[10876] - loss: 0.000575 best_pearson: 0.7248
Batch[10877] - loss: 0.000690 best_pearson: 0.7248
Batch[10878] - loss: 0.000740 best_pearson: 0.7248
Batch[10879] - loss: 0.000473 best_pearson: 0.7248
Batch[10880] - loss: 0.000380 best_pearson: 0.7248
Batch[10881] - loss: 0.000372 best_pearson: 0.7248
Batch[10882] - loss: 0.000489 best_pearson: 0.7248
Batch[10883] - loss: 0.000372 best_pearson: 0.7248
Batch[10884] - loss: 0.000479 best_pearson: 0.7248
Batch[10885] - loss: 0.000723 best_pearson: 0.7248
Batch[10886] - loss: 0.000513 best_pearson: 0.7248
Batch[10887] - loss: 0.000678 best_pearson: 0.7248
Batch[10888] - loss: 0.000463 best_pearson: 0.7248
Batch[10889] - loss: 0.001010 best_pearson: 0.7248
Batch[10890] - loss: 0.000523 best_pearson: 0.7248
Batch[10891] - loss: 0.001192 best_pearson: 0.7248
Batch[10892] - loss: 0.000707 best_pearson: 0.7248
Batch[10893] - loss: 0.000381 best_pearson: 0.7248
Batch[10894] - loss: 0.000527 best_pearson: 0.7248
Batch[10895] - loss: 0.000410 best_pearson: 0.7248
Batch[10896] - loss: 0.000585 best_pearson: 0.7248
Batch[10897] - loss: 0.000451 best_pearson: 0.7248
Batch[10898] - loss: 0.000473 best_pearson: 0.7248
Batch[10899] - loss: 0.000564 best_pearson: 0.7248
Batch[10900] - loss: 0.000404 best_pearson: 0.7248

Evaluation - loss: 0.000048 pearson: 0.7065 

early stop by 1500 steps.
Batch[10901] - loss: 0.000465 best_pearson: 0.7248
Batch[10902] - loss: 0.000660 best_pearson: 0.7248
Batch[10903] - loss: 0.000597 best_pearson: 0.7248
Batch[10904] - loss: 0.000559 best_pearson: 0.7248
Batch[10905] - loss: 0.000429 best_pearson: 0.7248
Batch[10906] - loss: 0.000527 best_pearson: 0.7248
Batch[10907] - loss: 0.000437 best_pearson: 0.7248
Batch[10908] - loss: 0.000823 best_pearson: 0.7248
Batch[10909] - loss: 0.000541 best_pearson: 0.7248
Batch[10910] - loss: 0.000558 best_pearson: 0.7248
Batch[10911] - loss: 0.000537 best_pearson: 0.7248
Batch[10912] - loss: 0.000440 best_pearson: 0.7248
Batch[10913] - loss: 0.000429 best_pearson: 0.7248
Batch[10914] - loss: 0.000427 best_pearson: 0.7248
Batch[10915] - loss: 0.000779 best_pearson: 0.7248
Batch[10916] - loss: 0.000605 best_pearson: 0.7248
Batch[10917] - loss: 0.000408 best_pearson: 0.7248
Batch[10918] - loss: 0.000662 best_pearson: 0.7248
Batch[10919] - loss: 0.000882 best_pearson: 0.7248
Batch[10920] - loss: 0.000536 best_pearson: 0.7248
Batch[10921] - loss: 0.000702 best_pearson: 0.7248
Batch[10922] - loss: 0.000460 best_pearson: 0.7248
Batch[10923] - loss: 0.000843 best_pearson: 0.7248
Batch[10924] - loss: 0.000430 best_pearson: 0.7248
Batch[10925] - loss: 0.000490 best_pearson: 0.7248
Batch[10926] - loss: 0.000447 best_pearson: 0.7248
Batch[10927] - loss: 0.000603 best_pearson: 0.7248
Batch[10928] - loss: 0.000505 best_pearson: 0.7248
Batch[10929] - loss: 0.000384 best_pearson: 0.7248
Batch[10930] - loss: 0.000638 best_pearson: 0.7248
Batch[10931] - loss: 0.000633 best_pearson: 0.7248
Batch[10932] - loss: 0.000607 best_pearson: 0.7248
Batch[10933] - loss: 0.000565 best_pearson: 0.7248
Batch[10934] - loss: 0.000585 best_pearson: 0.7248
Batch[10935] - loss: 0.000622 best_pearson: 0.7248
Batch[10936] - loss: 0.000471 best_pearson: 0.7248
Batch[10937] - loss: 0.000566 best_pearson: 0.7248
Batch[10938] - loss: 0.000526 best_pearson: 0.7248
Batch[10939] - loss: 0.000799 best_pearson: 0.7248
Batch[10940] - loss: 0.000625 best_pearson: 0.7248
Batch[10941] - loss: 0.000413 best_pearson: 0.7248
Batch[10942] - loss: 0.000879 best_pearson: 0.7248
Batch[10943] - loss: 0.000611 best_pearson: 0.7248
Batch[10944] - loss: 0.000400 best_pearson: 0.7248
Batch[10945] - loss: 0.000373 best_pearson: 0.7248
Batch[10946] - loss: 0.000367 best_pearson: 0.7248
Batch[10947] - loss: 0.000476 best_pearson: 0.7248
Batch[10948] - loss: 0.000549 best_pearson: 0.7248
Batch[10949] - loss: 0.000709 best_pearson: 0.7248
Batch[10950] - loss: 0.000649 best_pearson: 0.7248
Batch[10951] - loss: 0.000368 best_pearson: 0.7248
Batch[10952] - loss: 0.000623 best_pearson: 0.7248
Batch[10953] - loss: 0.000677 best_pearson: 0.7248
Batch[10954] - loss: 0.000558 best_pearson: 0.7248
Batch[10955] - loss: 0.000589 best_pearson: 0.7248
Batch[10956] - loss: 0.000574 best_pearson: 0.7248
Batch[10957] - loss: 0.000359 best_pearson: 0.7248
Batch[10958] - loss: 0.000341 best_pearson: 0.7248
Batch[10959] - loss: 0.000477 best_pearson: 0.7248
Batch[10960] - loss: 0.000866 best_pearson: 0.7248
Batch[10961] - loss: 0.000406 best_pearson: 0.7248
Batch[10962] - loss: 0.000303 best_pearson: 0.7248
Batch[10963] - loss: 0.000744 best_pearson: 0.7248
Batch[10964] - loss: 0.000518 best_pearson: 0.7248
Batch[10965] - loss: 0.000684 best_pearson: 0.7248
Batch[10966] - loss: 0.000647 best_pearson: 0.7248
Batch[10967] - loss: 0.000421 best_pearson: 0.7248
Batch[10968] - loss: 0.000664 best_pearson: 0.7248
Batch[10969] - loss: 0.000620 best_pearson: 0.7248
Batch[10970] - loss: 0.000627 best_pearson: 0.7248
Batch[10971] - loss: 0.000302 best_pearson: 0.7248
Batch[10972] - loss: 0.000523 best_pearson: 0.7248
Batch[10973] - loss: 0.000397 best_pearson: 0.7248
Batch[10974] - loss: 0.000606 best_pearson: 0.7248
Batch[10975] - loss: 0.000895 best_pearson: 0.7248
Batch[10976] - loss: 0.000237 best_pearson: 0.7248
Batch[10977] - loss: 0.000720 best_pearson: 0.7248
Batch[10978] - loss: 0.000334 best_pearson: 0.7248
Batch[10979] - loss: 0.000472 best_pearson: 0.7248
Batch[10980] - loss: 0.000314 best_pearson: 0.7248
Batch[10981] - loss: 0.000607 best_pearson: 0.7248
Batch[10982] - loss: 0.000822 best_pearson: 0.7248
Batch[10983] - loss: 0.000759 best_pearson: 0.7248
Batch[10984] - loss: 0.000366 best_pearson: 0.7248
Batch[10985] - loss: 0.000342 best_pearson: 0.7248
Batch[10986] - loss: 0.000606 best_pearson: 0.7248
Batch[10987] - loss: 0.000442 best_pearson: 0.7248
Batch[10988] - loss: 0.000651 best_pearson: 0.7248
Batch[10989] - loss: 0.000560 best_pearson: 0.7248
Batch[10990] - loss: 0.000579 best_pearson: 0.7248
Batch[10991] - loss: 0.000577 best_pearson: 0.7248
Batch[10992] - loss: 0.000632 best_pearson: 0.7248
Batch[10993] - loss: 0.000234 best_pearson: 0.7248
Batch[10994] - loss: 0.000591 best_pearson: 0.7248
Batch[10995] - loss: 0.000392 best_pearson: 0.7248
Batch[10996] - loss: 0.000498 best_pearson: 0.7248
Batch[10997] - loss: 0.000483 best_pearson: 0.7248
Batch[10998] - loss: 0.000339 best_pearson: 0.7248
Batch[10999] - loss: 0.000587 best_pearson: 0.7248
Batch[11000] - loss: 0.000473 best_pearson: 0.7248

Evaluation - loss: 0.000049 pearson: 0.7045 

early stop by 1500 steps.
Batch[11001] - loss: 0.000533 best_pearson: 0.7248
Batch[11002] - loss: 0.000549 best_pearson: 0.7248
Batch[11003] - loss: 0.000738 best_pearson: 0.7248
Batch[11004] - loss: 0.000367 best_pearson: 0.7248
Batch[11005] - loss: 0.000488 best_pearson: 0.7248
Batch[11006] - loss: 0.000432 best_pearson: 0.7248
Batch[11007] - loss: 0.000514 best_pearson: 0.7248
Batch[11008] - loss: 0.000768 best_pearson: 0.7248
Batch[11009] - loss: 0.000508 best_pearson: 0.7248
Batch[11010] - loss: 0.000805 best_pearson: 0.7248
Batch[11011] - loss: 0.000640 best_pearson: 0.7248
Batch[11012] - loss: 0.000555 best_pearson: 0.7248
Batch[11013] - loss: 0.000583 best_pearson: 0.7248
Batch[11014] - loss: 0.000344 best_pearson: 0.7248
Batch[11015] - loss: 0.000393 best_pearson: 0.7248
Batch[11016] - loss: 0.000366 best_pearson: 0.7248
Batch[11017] - loss: 0.000407 best_pearson: 0.7248
Batch[11018] - loss: 0.000599 best_pearson: 0.7248
Batch[11019] - loss: 0.000650 best_pearson: 0.7248
Batch[11020] - loss: 0.000656 best_pearson: 0.7248
Batch[11021] - loss: 0.000447 best_pearson: 0.7248
Batch[11022] - loss: 0.000394 best_pearson: 0.7248
Batch[11023] - loss: 0.000594 best_pearson: 0.7248
Batch[11024] - loss: 0.000568 best_pearson: 0.7248
Batch[11025] - loss: 0.000355 best_pearson: 0.7248
Batch[11026] - loss: 0.000608 best_pearson: 0.7248
Batch[11027] - loss: 0.000601 best_pearson: 0.7248
Batch[11028] - loss: 0.000579 best_pearson: 0.7248
Batch[11029] - loss: 0.000356 best_pearson: 0.7248
Batch[11030] - loss: 0.000508 best_pearson: 0.7248
Batch[11031] - loss: 0.000635 best_pearson: 0.7248
Batch[11032] - loss: 0.000549 best_pearson: 0.7248
Batch[11033] - loss: 0.000463 best_pearson: 0.7248
Batch[11034] - loss: 0.000461 best_pearson: 0.7248
Batch[11035] - loss: 0.000526 best_pearson: 0.7248
Batch[11036] - loss: 0.000420 best_pearson: 0.7248
Batch[11037] - loss: 0.000598 best_pearson: 0.7248
Batch[11038] - loss: 0.000572 best_pearson: 0.7248
Batch[11039] - loss: 0.000708 best_pearson: 0.7248
Batch[11040] - loss: 0.000525 best_pearson: 0.7248
Batch[11041] - loss: 0.000438 best_pearson: 0.7248
Batch[11042] - loss: 0.000413 best_pearson: 0.7248
Batch[11043] - loss: 0.000283 best_pearson: 0.7248
Batch[11044] - loss: 0.000296 best_pearson: 0.7248
Batch[11045] - loss: 0.000263 best_pearson: 0.7248
Batch[11046] - loss: 0.000605 best_pearson: 0.7248
Batch[11047] - loss: 0.000485 best_pearson: 0.7248
Batch[11048] - loss: 0.000436 best_pearson: 0.7248
Batch[11049] - loss: 0.000656 best_pearson: 0.7248
Batch[11050] - loss: 0.000452 best_pearson: 0.7248
Batch[11051] - loss: 0.000383 best_pearson: 0.7248
Batch[11052] - loss: 0.000423 best_pearson: 0.7248
Batch[11053] - loss: 0.000848 best_pearson: 0.7248
Batch[11054] - loss: 0.000428 best_pearson: 0.7248
Batch[11055] - loss: 0.000446 best_pearson: 0.7248
Batch[11056] - loss: 0.000514 best_pearson: 0.7248
Batch[11057] - loss: 0.000349 best_pearson: 0.7248
Batch[11058] - loss: 0.000484 best_pearson: 0.7248
Batch[11059] - loss: 0.000295 best_pearson: 0.7248
Batch[11060] - loss: 0.000803 best_pearson: 0.7248
Batch[11061] - loss: 0.000492 best_pearson: 0.7248
Batch[11062] - loss: 0.000539 best_pearson: 0.7248
Batch[11063] - loss: 0.000459 best_pearson: 0.7248
Batch[11064] - loss: 0.000405 best_pearson: 0.7248
Batch[11065] - loss: 0.000483 best_pearson: 0.7248
Batch[11066] - loss: 0.000899 best_pearson: 0.7248
Batch[11067] - loss: 0.000555 best_pearson: 0.7248
Batch[11068] - loss: 0.000299 best_pearson: 0.7248
Batch[11069] - loss: 0.000816 best_pearson: 0.7248
Batch[11070] - loss: 0.000503 best_pearson: 0.7248
Batch[11071] - loss: 0.000401 best_pearson: 0.7248
Batch[11072] - loss: 0.000827 best_pearson: 0.7248
Batch[11073] - loss: 0.000693 best_pearson: 0.7248
Batch[11074] - loss: 0.000555 best_pearson: 0.7248
Batch[11075] - loss: 0.000731 best_pearson: 0.7248
Batch[11076] - loss: 0.000616 best_pearson: 0.7248
Batch[11077] - loss: 0.000467 best_pearson: 0.7248
Batch[11078] - loss: 0.000956 best_pearson: 0.7248
Batch[11079] - loss: 0.000375 best_pearson: 0.7248
Batch[11080] - loss: 0.000678 best_pearson: 0.7248
Batch[11081] - loss: 0.000719 best_pearson: 0.7248
Batch[11082] - loss: 0.000647 best_pearson: 0.7248
Batch[11083] - loss: 0.000476 best_pearson: 0.7248
Batch[11084] - loss: 0.000773 best_pearson: 0.7248
Batch[11085] - loss: 0.000571 best_pearson: 0.7248
Batch[11086] - loss: 0.000942 best_pearson: 0.7248
Batch[11087] - loss: 0.000320 best_pearson: 0.7248
Batch[11088] - loss: 0.000658 best_pearson: 0.7248
Batch[11089] - loss: 0.000296 best_pearson: 0.7248
Batch[11090] - loss: 0.000741 best_pearson: 0.7248
Batch[11091] - loss: 0.000829 best_pearson: 0.7248
Batch[11092] - loss: 0.000372 best_pearson: 0.7248
Batch[11093] - loss: 0.000624 best_pearson: 0.7248
Batch[11094] - loss: 0.000639 best_pearson: 0.7248
Batch[11095] - loss: 0.000453 best_pearson: 0.7248
Batch[11096] - loss: 0.000634 best_pearson: 0.7248
Batch[11097] - loss: 0.000584 best_pearson: 0.7248
Batch[11098] - loss: 0.000631 best_pearson: 0.7248
Batch[11099] - loss: 0.000418 best_pearson: 0.7248
Batch[11100] - loss: 0.000423 best_pearson: 0.7248

Evaluation - loss: 0.000048 pearson: 0.7046 

early stop by 1500 steps.
Batch[11101] - loss: 0.000423 best_pearson: 0.7248
Batch[11102] - loss: 0.000475 best_pearson: 0.7248
Batch[11103] - loss: 0.000715 best_pearson: 0.7248
Batch[11104] - loss: 0.000550 best_pearson: 0.7248
Batch[11105] - loss: 0.000651 best_pearson: 0.7248
Batch[11106] - loss: 0.000406 best_pearson: 0.7248
Batch[11107] - loss: 0.000653 best_pearson: 0.7248
Batch[11108] - loss: 0.000313 best_pearson: 0.7248
Batch[11109] - loss: 0.000802 best_pearson: 0.7248
Batch[11110] - loss: 0.000498 best_pearson: 0.7248
Batch[11111] - loss: 0.000545 best_pearson: 0.7248
Batch[11112] - loss: 0.000669 best_pearson: 0.7248
Batch[11113] - loss: 0.000632 best_pearson: 0.7248
Batch[11114] - loss: 0.000492 best_pearson: 0.7248
Batch[11115] - loss: 0.000468 best_pearson: 0.7248
Batch[11116] - loss: 0.000493 best_pearson: 0.7248
Batch[11117] - loss: 0.000475 best_pearson: 0.7248
Batch[11118] - loss: 0.000403 best_pearson: 0.7248
Batch[11119] - loss: 0.000679 best_pearson: 0.7248
Batch[11120] - loss: 0.000594 best_pearson: 0.7248
Batch[11121] - loss: 0.000660 best_pearson: 0.7248
Batch[11122] - loss: 0.000499 best_pearson: 0.7248
Batch[11123] - loss: 0.000545 best_pearson: 0.7248
Batch[11124] - loss: 0.000664 best_pearson: 0.7248
Batch[11125] - loss: 0.000755 best_pearson: 0.7248
Batch[11126] - loss: 0.001750 best_pearson: 0.7248
Batch[11127] - loss: 0.000809 best_pearson: 0.7248
Batch[11128] - loss: 0.000856 best_pearson: 0.7248
Batch[11129] - loss: 0.000434 best_pearson: 0.7248
Batch[11130] - loss: 0.001614 best_pearson: 0.7248
Batch[11131] - loss: 0.000924 best_pearson: 0.7248
Batch[11132] - loss: 0.000832 best_pearson: 0.7248
Batch[11133] - loss: 0.000606 best_pearson: 0.7248
Batch[11134] - loss: 0.000980 best_pearson: 0.7248
Batch[11135] - loss: 0.000656 best_pearson: 0.7248
Batch[11136] - loss: 0.000273 best_pearson: 0.7248
Batch[11137] - loss: 0.001036 best_pearson: 0.7248
Batch[11138] - loss: 0.000485 best_pearson: 0.7248
Batch[11139] - loss: 0.000529 best_pearson: 0.7248
Batch[11140] - loss: 0.000766 best_pearson: 0.7248
Batch[11141] - loss: 0.000903 best_pearson: 0.7248
Batch[11142] - loss: 0.000684 best_pearson: 0.7248
Batch[11143] - loss: 0.000870 best_pearson: 0.7248
Batch[11144] - loss: 0.001146 best_pearson: 0.7248
Batch[11145] - loss: 0.000793 best_pearson: 0.7248
Batch[11146] - loss: 0.000914 best_pearson: 0.7248
Batch[11147] - loss: 0.000635 best_pearson: 0.7248
Batch[11148] - loss: 0.000827 best_pearson: 0.7248
Batch[11149] - loss: 0.000449 best_pearson: 0.7248
Batch[11150] - loss: 0.000674 best_pearson: 0.7248
Batch[11151] - loss: 0.000778 best_pearson: 0.7248
Batch[11152] - loss: 0.000592 best_pearson: 0.7248
Batch[11153] - loss: 0.000683 best_pearson: 0.7248
Batch[11154] - loss: 0.000456 best_pearson: 0.7248
Batch[11155] - loss: 0.000726 best_pearson: 0.7248
Batch[11156] - loss: 0.000798 best_pearson: 0.7248
Batch[11157] - loss: 0.000592 best_pearson: 0.7248
Batch[11158] - loss: 0.000944 best_pearson: 0.7248
Batch[11159] - loss: 0.000844 best_pearson: 0.7248
Batch[11160] - loss: 0.001137 best_pearson: 0.7248
Batch[11161] - loss: 0.000516 best_pearson: 0.7248
Batch[11162] - loss: 0.000645 best_pearson: 0.7248
Batch[11163] - loss: 0.000647 best_pearson: 0.7248
Batch[11164] - loss: 0.000690 best_pearson: 0.7248
Batch[11165] - loss: 0.000555 best_pearson: 0.7248
Batch[11166] - loss: 0.000674 best_pearson: 0.7248
Batch[11167] - loss: 0.000651 best_pearson: 0.7248
Batch[11168] - loss: 0.000582 best_pearson: 0.7248
Batch[11169] - loss: 0.000777 best_pearson: 0.7248
Batch[11170] - loss: 0.000705 best_pearson: 0.7248
Batch[11171] - loss: 0.000515 best_pearson: 0.7248
Batch[11172] - loss: 0.000395 best_pearson: 0.7248
Batch[11173] - loss: 0.000652 best_pearson: 0.7248
Batch[11174] - loss: 0.000844 best_pearson: 0.7248
Batch[11175] - loss: 0.000536 best_pearson: 0.7248
Batch[11176] - loss: 0.000499 best_pearson: 0.7248
Batch[11177] - loss: 0.000948 best_pearson: 0.7248
Batch[11178] - loss: 0.000468 best_pearson: 0.7248
Batch[11179] - loss: 0.000527 best_pearson: 0.7248
Batch[11180] - loss: 0.000530 best_pearson: 0.7248
Batch[11181] - loss: 0.000577 best_pearson: 0.7248
Batch[11182] - loss: 0.000548 best_pearson: 0.7248
Batch[11183] - loss: 0.000704 best_pearson: 0.7248
Batch[11184] - loss: 0.000510 best_pearson: 0.7248
Batch[11185] - loss: 0.000752 best_pearson: 0.7248
Batch[11186] - loss: 0.000722 best_pearson: 0.7248
Batch[11187] - loss: 0.000516 best_pearson: 0.7248
Batch[11188] - loss: 0.001333 best_pearson: 0.7248
Batch[11189] - loss: 0.000513 best_pearson: 0.7248
Batch[11190] - loss: 0.000526 best_pearson: 0.7248
Batch[11191] - loss: 0.001072 best_pearson: 0.7248
Batch[11192] - loss: 0.000598 best_pearson: 0.7248
Batch[11193] - loss: 0.000776 best_pearson: 0.7248
Batch[11194] - loss: 0.000672 best_pearson: 0.7248
Batch[11195] - loss: 0.000492 best_pearson: 0.7248
Batch[11196] - loss: 0.000577 best_pearson: 0.7248
Batch[11197] - loss: 0.000647 best_pearson: 0.7248
Batch[11198] - loss: 0.000633 best_pearson: 0.7248
Batch[11199] - loss: 0.000652 best_pearson: 0.7248
Batch[11200] - loss: 0.000713 best_pearson: 0.7248

Evaluation - loss: 0.000049 pearson: 0.7019 

early stop by 1500 steps.
Batch[11201] - loss: 0.001037 best_pearson: 0.7248
Batch[11202] - loss: 0.001013 best_pearson: 0.7248
Batch[11203] - loss: 0.000695 best_pearson: 0.7248
Batch[11204] - loss: 0.000754 best_pearson: 0.7248
Batch[11205] - loss: 0.000518 best_pearson: 0.7248
Batch[11206] - loss: 0.000915 best_pearson: 0.7248
Batch[11207] - loss: 0.000606 best_pearson: 0.7248
Batch[11208] - loss: 0.000682 best_pearson: 0.7248
Batch[11209] - loss: 0.000672 best_pearson: 0.7248
Batch[11210] - loss: 0.000811 best_pearson: 0.7248
Batch[11211] - loss: 0.000716 best_pearson: 0.7248
Batch[11212] - loss: 0.000757 best_pearson: 0.7248
Batch[11213] - loss: 0.000828 best_pearson: 0.7248
Batch[11214] - loss: 0.000428 best_pearson: 0.7248
Batch[11215] - loss: 0.000506 best_pearson: 0.7248
Batch[11216] - loss: 0.000617 best_pearson: 0.7248
Batch[11217] - loss: 0.000806 best_pearson: 0.7248
Batch[11218] - loss: 0.000533 best_pearson: 0.7248
Batch[11219] - loss: 0.000554 best_pearson: 0.7248
Batch[11220] - loss: 0.000731 best_pearson: 0.7248
Batch[11221] - loss: 0.000680 best_pearson: 0.7248
Batch[11222] - loss: 0.000780 best_pearson: 0.7248
Batch[11223] - loss: 0.000572 best_pearson: 0.7248
Batch[11224] - loss: 0.001354 best_pearson: 0.7248
Batch[11225] - loss: 0.000687 best_pearson: 0.7248
Batch[11226] - loss: 0.000688 best_pearson: 0.7248
Batch[11227] - loss: 0.000539 best_pearson: 0.7248
Batch[11228] - loss: 0.000935 best_pearson: 0.7248
Batch[11229] - loss: 0.000484 best_pearson: 0.7248
Batch[11230] - loss: 0.000909 best_pearson: 0.7248
Batch[11231] - loss: 0.000428 best_pearson: 0.7248
Batch[11232] - loss: 0.000436 best_pearson: 0.7248
Batch[11233] - loss: 0.000677 best_pearson: 0.7248
Batch[11234] - loss: 0.000413 best_pearson: 0.7248
Batch[11235] - loss: 0.000664 best_pearson: 0.7248
Batch[11236] - loss: 0.001066 best_pearson: 0.7248
Batch[11237] - loss: 0.000867 best_pearson: 0.7248
Batch[11238] - loss: 0.000521 best_pearson: 0.7248
Batch[11239] - loss: 0.000522 best_pearson: 0.7248
Batch[11240] - loss: 0.000683 best_pearson: 0.7248
Batch[11241] - loss: 0.000451 best_pearson: 0.7248
Batch[11242] - loss: 0.000597 best_pearson: 0.7248
Batch[11243] - loss: 0.000661 best_pearson: 0.7248
Batch[11244] - loss: 0.000957 best_pearson: 0.7248
Batch[11245] - loss: 0.000542 best_pearson: 0.7248
Batch[11246] - loss: 0.000870 best_pearson: 0.7248
Batch[11247] - loss: 0.000437 best_pearson: 0.7248
Batch[11248] - loss: 0.000823 best_pearson: 0.7248
Batch[11249] - loss: 0.000800 best_pearson: 0.7248
Batch[11250] - loss: 0.000715 best_pearson: 0.7248
Batch[11251] - loss: 0.000684 best_pearson: 0.7248
Batch[11252] - loss: 0.000686 best_pearson: 0.7248
Batch[11253] - loss: 0.000828 best_pearson: 0.7248
Batch[11254] - loss: 0.000372 best_pearson: 0.7248
Batch[11255] - loss: 0.000602 best_pearson: 0.7248
Batch[11256] - loss: 0.000771 best_pearson: 0.7248
Batch[11257] - loss: 0.001229 best_pearson: 0.7248
Batch[11258] - loss: 0.000726 best_pearson: 0.7248
Batch[11259] - loss: 0.000602 best_pearson: 0.7248
Batch[11260] - loss: 0.000729 best_pearson: 0.7248
Batch[11261] - loss: 0.000699 best_pearson: 0.7248
Batch[11262] - loss: 0.000725 best_pearson: 0.7248
Batch[11263] - loss: 0.000604 best_pearson: 0.7248
Batch[11264] - loss: 0.000498 best_pearson: 0.7248
Batch[11265] - loss: 0.000859 best_pearson: 0.7248
Batch[11266] - loss: 0.000420 best_pearson: 0.7248
Batch[11267] - loss: 0.000548 best_pearson: 0.7248
Batch[11268] - loss: 0.000781 best_pearson: 0.7248
Batch[11269] - loss: 0.000519 best_pearson: 0.7248
Batch[11270] - loss: 0.000608 best_pearson: 0.7248
Batch[11271] - loss: 0.000497 best_pearson: 0.7248
Batch[11272] - loss: 0.000535 best_pearson: 0.7248
Batch[11273] - loss: 0.001045 best_pearson: 0.7248
Batch[11274] - loss: 0.000719 best_pearson: 0.7248
Batch[11275] - loss: 0.000451 best_pearson: 0.7248
Batch[11276] - loss: 0.000542 best_pearson: 0.7248
Batch[11277] - loss: 0.000625 best_pearson: 0.7248
Batch[11278] - loss: 0.000485 best_pearson: 0.7248
Batch[11279] - loss: 0.000526 best_pearson: 0.7248
Batch[11280] - loss: 0.000609 best_pearson: 0.7248
Batch[11281] - loss: 0.000526 best_pearson: 0.7248
Batch[11282] - loss: 0.000822 best_pearson: 0.7248
Batch[11283] - loss: 0.000678 best_pearson: 0.7248
Batch[11284] - loss: 0.000518 best_pearson: 0.7248
Batch[11285] - loss: 0.000336 best_pearson: 0.7248
Batch[11286] - loss: 0.000505 best_pearson: 0.7248
Batch[11287] - loss: 0.000513 best_pearson: 0.7248
Batch[11288] - loss: 0.000404 best_pearson: 0.7248
Batch[11289] - loss: 0.000687 best_pearson: 0.7248
Batch[11290] - loss: 0.000582 best_pearson: 0.7248
Batch[11291] - loss: 0.000785 best_pearson: 0.7248
Batch[11292] - loss: 0.000524 best_pearson: 0.7248
Batch[11293] - loss: 0.000619 best_pearson: 0.7248
Batch[11294] - loss: 0.000763 best_pearson: 0.7248
Batch[11295] - loss: 0.000400 best_pearson: 0.7248
Batch[11296] - loss: 0.000403 best_pearson: 0.7248
Batch[11297] - loss: 0.000763 best_pearson: 0.7248
Batch[11298] - loss: 0.000849 best_pearson: 0.7248
Batch[11299] - loss: 0.000744 best_pearson: 0.7248
Batch[11300] - loss: 0.001057 best_pearson: 0.7248

Evaluation - loss: 0.000049 pearson: 0.7041 

early stop by 1500 steps.
Batch[11301] - loss: 0.000739 best_pearson: 0.7248
Batch[11302] - loss: 0.000576 best_pearson: 0.7248
Batch[11303] - loss: 0.000567 best_pearson: 0.7248
Batch[11304] - loss: 0.000873 best_pearson: 0.7248
Batch[11305] - loss: 0.000663 best_pearson: 0.7248
Batch[11306] - loss: 0.000680 best_pearson: 0.7248
Batch[11307] - loss: 0.000573 best_pearson: 0.7248
Batch[11308] - loss: 0.000819 best_pearson: 0.7248
Batch[11309] - loss: 0.000691 best_pearson: 0.7248
Batch[11310] - loss: 0.000507 best_pearson: 0.7248
Batch[11311] - loss: 0.000459 best_pearson: 0.7248
Batch[11312] - loss: 0.000330 best_pearson: 0.7248
Batch[11313] - loss: 0.000424 best_pearson: 0.7248
Batch[11314] - loss: 0.000745 best_pearson: 0.7248
Batch[11315] - loss: 0.000657 best_pearson: 0.7248
Batch[11316] - loss: 0.000596 best_pearson: 0.7248
Batch[11317] - loss: 0.000774 best_pearson: 0.7248
Batch[11318] - loss: 0.000759 best_pearson: 0.7248
Batch[11319] - loss: 0.000361 best_pearson: 0.7248
Batch[11320] - loss: 0.000414 best_pearson: 0.7248
Batch[11321] - loss: 0.000818 best_pearson: 0.7248
Batch[11322] - loss: 0.000625 best_pearson: 0.7248
Batch[11323] - loss: 0.000727 best_pearson: 0.7248
Batch[11324] - loss: 0.001222 best_pearson: 0.7248
Batch[11325] - loss: 0.000614 best_pearson: 0.7248
Batch[11326] - loss: 0.000721 best_pearson: 0.7248
Batch[11327] - loss: 0.001220 best_pearson: 0.7248
Batch[11328] - loss: 0.000525 best_pearson: 0.7248
Batch[11329] - loss: 0.000641 best_pearson: 0.7248
Batch[11330] - loss: 0.000806 best_pearson: 0.7248
Batch[11331] - loss: 0.000948 best_pearson: 0.7248
Batch[11332] - loss: 0.000475 best_pearson: 0.7248
Batch[11333] - loss: 0.001103 best_pearson: 0.7248
Batch[11334] - loss: 0.000702 best_pearson: 0.7248
Batch[11335] - loss: 0.000437 best_pearson: 0.7248
Batch[11336] - loss: 0.000509 best_pearson: 0.7248
Batch[11337] - loss: 0.000491 best_pearson: 0.7248
Batch[11338] - loss: 0.000871 best_pearson: 0.7248
Batch[11339] - loss: 0.000790 best_pearson: 0.7248
Batch[11340] - loss: 0.000739 best_pearson: 0.7248
Batch[11341] - loss: 0.001175 best_pearson: 0.7248
Batch[11342] - loss: 0.000571 best_pearson: 0.7248
Batch[11343] - loss: 0.001244 best_pearson: 0.7248
Batch[11344] - loss: 0.000470 best_pearson: 0.7248
Batch[11345] - loss: 0.000594 best_pearson: 0.7248
Batch[11346] - loss: 0.000807 best_pearson: 0.7248
Batch[11347] - loss: 0.000438 best_pearson: 0.7248
Batch[11348] - loss: 0.000708 best_pearson: 0.7248
Batch[11349] - loss: 0.000485 best_pearson: 0.7248
Batch[11350] - loss: 0.001018 best_pearson: 0.7248
Batch[11351] - loss: 0.000495 best_pearson: 0.7248
Batch[11352] - loss: 0.000869 best_pearson: 0.7248
Batch[11353] - loss: 0.000685 best_pearson: 0.7248
Batch[11354] - loss: 0.000399 best_pearson: 0.7248
Batch[11355] - loss: 0.000617 best_pearson: 0.7248
Batch[11356] - loss: 0.000511 best_pearson: 0.7248
Batch[11357] - loss: 0.000360 best_pearson: 0.7248
Batch[11358] - loss: 0.000639 best_pearson: 0.7248
Batch[11359] - loss: 0.000653 best_pearson: 0.7248
Batch[11360] - loss: 0.000460 best_pearson: 0.7248
Batch[11361] - loss: 0.000330 best_pearson: 0.7248
Batch[11362] - loss: 0.000497 best_pearson: 0.7248
Batch[11363] - loss: 0.000486 best_pearson: 0.7248
Batch[11364] - loss: 0.000602 best_pearson: 0.7248
Batch[11365] - loss: 0.001149 best_pearson: 0.7248
Batch[11366] - loss: 0.000453 best_pearson: 0.7248
Batch[11367] - loss: 0.000526 best_pearson: 0.7248
Batch[11368] - loss: 0.000868 best_pearson: 0.7248
Batch[11369] - loss: 0.000883 best_pearson: 0.7248
Batch[11370] - loss: 0.000386 best_pearson: 0.7248
Batch[11371] - loss: 0.000529 best_pearson: 0.7248
Batch[11372] - loss: 0.000607 best_pearson: 0.7248
Batch[11373] - loss: 0.000610 best_pearson: 0.7248
Batch[11374] - loss: 0.000750 best_pearson: 0.7248
Batch[11375] - loss: 0.000400 best_pearson: 0.7248
Batch[11376] - loss: 0.000819 best_pearson: 0.7248
Batch[11377] - loss: 0.000900 best_pearson: 0.7248
Batch[11378] - loss: 0.000531 best_pearson: 0.7248
Batch[11379] - loss: 0.000901 best_pearson: 0.7248
Batch[11380] - loss: 0.000714 best_pearson: 0.7248
Batch[11381] - loss: 0.000594 best_pearson: 0.7248
Batch[11382] - loss: 0.000754 best_pearson: 0.7248
Batch[11383] - loss: 0.000557 best_pearson: 0.7248
Batch[11384] - loss: 0.000375 best_pearson: 0.7248
Batch[11385] - loss: 0.000528 best_pearson: 0.7248
Batch[11386] - loss: 0.000632 best_pearson: 0.7248
Batch[11387] - loss: 0.000640 best_pearson: 0.7248
Batch[11388] - loss: 0.000877 best_pearson: 0.7248
Batch[11389] - loss: 0.000534 best_pearson: 0.7248
Batch[11390] - loss: 0.000447 best_pearson: 0.7248
Batch[11391] - loss: 0.000553 best_pearson: 0.7248
Batch[11392] - loss: 0.000539 best_pearson: 0.7248
Batch[11393] - loss: 0.000599 best_pearson: 0.7248
Batch[11394] - loss: 0.000709 best_pearson: 0.7248
Batch[11395] - loss: 0.000505 best_pearson: 0.7248
Batch[11396] - loss: 0.000801 best_pearson: 0.7248
Batch[11397] - loss: 0.000339 best_pearson: 0.7248
Batch[11398] - loss: 0.000527 best_pearson: 0.7248
Batch[11399] - loss: 0.000692 best_pearson: 0.7248
Batch[11400] - loss: 0.000689 best_pearson: 0.7248

Evaluation - loss: 0.000049 pearson: 0.7045 

early stop by 1500 steps.
Batch[11401] - loss: 0.000630 best_pearson: 0.7248
Batch[11402] - loss: 0.000440 best_pearson: 0.7248
Batch[11403] - loss: 0.000316 best_pearson: 0.7248
Batch[11404] - loss: 0.000612 best_pearson: 0.7248
Batch[11405] - loss: 0.000653 best_pearson: 0.7248
Batch[11406] - loss: 0.000755 best_pearson: 0.7248
Batch[11407] - loss: 0.000819 best_pearson: 0.7248
Batch[11408] - loss: 0.000484 best_pearson: 0.7248
Batch[11409] - loss: 0.000751 best_pearson: 0.7248
Batch[11410] - loss: 0.001061 best_pearson: 0.7248
Batch[11411] - loss: 0.000784 best_pearson: 0.7248
Batch[11412] - loss: 0.000683 best_pearson: 0.7248
Batch[11413] - loss: 0.000771 best_pearson: 0.7248
Batch[11414] - loss: 0.000583 best_pearson: 0.7248
Batch[11415] - loss: 0.001072 best_pearson: 0.7248
Batch[11416] - loss: 0.000565 best_pearson: 0.7248
Batch[11417] - loss: 0.000578 best_pearson: 0.7248
Batch[11418] - loss: 0.001267 best_pearson: 0.7248
Batch[11419] - loss: 0.000543 best_pearson: 0.7248
Batch[11420] - loss: 0.000908 best_pearson: 0.7248
Batch[11421] - loss: 0.000547 best_pearson: 0.7248
Batch[11422] - loss: 0.000439 best_pearson: 0.7248
Batch[11423] - loss: 0.000752 best_pearson: 0.7248
Batch[11424] - loss: 0.000620 best_pearson: 0.7248
Batch[11425] - loss: 0.000737 best_pearson: 0.7248
Batch[11426] - loss: 0.000765 best_pearson: 0.7248
Batch[11427] - loss: 0.000501 best_pearson: 0.7248
Batch[11428] - loss: 0.000839 best_pearson: 0.7248
Batch[11429] - loss: 0.000829 best_pearson: 0.7248
Batch[11430] - loss: 0.000697 best_pearson: 0.7248
Batch[11431] - loss: 0.000598 best_pearson: 0.7248
Batch[11432] - loss: 0.000703 best_pearson: 0.7248
Batch[11433] - loss: 0.000717 best_pearson: 0.7248
Batch[11434] - loss: 0.000618 best_pearson: 0.7248
Batch[11435] - loss: 0.000372 best_pearson: 0.7248
Batch[11436] - loss: 0.001059 best_pearson: 0.7248
Batch[11437] - loss: 0.000581 best_pearson: 0.7248
Batch[11438] - loss: 0.000865 best_pearson: 0.7248
Batch[11439] - loss: 0.000407 best_pearson: 0.7248
Batch[11440] - loss: 0.000453 best_pearson: 0.7248
Batch[11441] - loss: 0.000357 best_pearson: 0.7248
Batch[11442] - loss: 0.000531 best_pearson: 0.7248
Batch[11443] - loss: 0.000541 best_pearson: 0.7248
Batch[11444] - loss: 0.000262 best_pearson: 0.7248
Batch[11445] - loss: 0.000717 best_pearson: 0.7248
Batch[11446] - loss: 0.000594 best_pearson: 0.7248
Batch[11447] - loss: 0.000335 best_pearson: 0.7248
Batch[11448] - loss: 0.000914 best_pearson: 0.7248
Batch[11449] - loss: 0.000521 best_pearson: 0.7248
Batch[11450] - loss: 0.000531 best_pearson: 0.7248
Batch[11451] - loss: 0.000614 best_pearson: 0.7248
Batch[11452] - loss: 0.000254 best_pearson: 0.7248
Batch[11453] - loss: 0.000494 best_pearson: 0.7248
Batch[11454] - loss: 0.000345 best_pearson: 0.7248
Batch[11455] - loss: 0.000355 best_pearson: 0.7248
Batch[11456] - loss: 0.000279 best_pearson: 0.7248
Batch[11457] - loss: 0.000545 best_pearson: 0.7248
Batch[11458] - loss: 0.000497 best_pearson: 0.7248
Batch[11459] - loss: 0.000447 best_pearson: 0.7248
Batch[11460] - loss: 0.000540 best_pearson: 0.7248
Batch[11461] - loss: 0.000507 best_pearson: 0.7248
Batch[11462] - loss: 0.000635 best_pearson: 0.7248
Batch[11463] - loss: 0.000495 best_pearson: 0.7248
Batch[11464] - loss: 0.000380 best_pearson: 0.7248
Batch[11465] - loss: 0.000259 best_pearson: 0.7248
Batch[11466] - loss: 0.000589 best_pearson: 0.7248
Batch[11467] - loss: 0.000624 best_pearson: 0.7248
Batch[11468] - loss: 0.000699 best_pearson: 0.7248
Batch[11469] - loss: 0.000842 best_pearson: 0.7248
Batch[11470] - loss: 0.000356 best_pearson: 0.7248
Batch[11471] - loss: 0.000735 best_pearson: 0.7248
Batch[11472] - loss: 0.000607 best_pearson: 0.7248
Batch[11473] - loss: 0.000476 best_pearson: 0.7248
Batch[11474] - loss: 0.000638 best_pearson: 0.7248
Batch[11475] - loss: 0.000336 best_pearson: 0.7248
Batch[11476] - loss: 0.000582 best_pearson: 0.7248
Batch[11477] - loss: 0.000439 best_pearson: 0.7248
Batch[11478] - loss: 0.000341 best_pearson: 0.7248
Batch[11479] - loss: 0.000436 best_pearson: 0.7248
Batch[11480] - loss: 0.000451 best_pearson: 0.7248
Batch[11481] - loss: 0.000510 best_pearson: 0.7248
Batch[11482] - loss: 0.000549 best_pearson: 0.7248
Batch[11483] - loss: 0.000551 best_pearson: 0.7248
Batch[11484] - loss: 0.000968 best_pearson: 0.7248
Batch[11485] - loss: 0.000438 best_pearson: 0.7248
Batch[11486] - loss: 0.000319 best_pearson: 0.7248
Batch[11487] - loss: 0.000411 best_pearson: 0.7248
Batch[11488] - loss: 0.000945 best_pearson: 0.7248
Batch[11489] - loss: 0.000696 best_pearson: 0.7248
Batch[11490] - loss: 0.000456 best_pearson: 0.7248
Batch[11491] - loss: 0.000689 best_pearson: 0.7248
Batch[11492] - loss: 0.000490 best_pearson: 0.7248
Batch[11493] - loss: 0.000761 best_pearson: 0.7248
Batch[11494] - loss: 0.000366 best_pearson: 0.7248
Batch[11495] - loss: 0.000407 best_pearson: 0.7248
Batch[11496] - loss: 0.000644 best_pearson: 0.7248
Batch[11497] - loss: 0.000402 best_pearson: 0.7248
Batch[11498] - loss: 0.000567 best_pearson: 0.7248
Batch[11499] - loss: 0.000339 best_pearson: 0.7248
Batch[11500] - loss: 0.000454 best_pearson: 0.7248

Evaluation - loss: 0.000048 pearson: 0.7067 

early stop by 1500 steps.
Batch[11501] - loss: 0.000634 best_pearson: 0.7248
Batch[11502] - loss: 0.000372 best_pearson: 0.7248
Batch[11503] - loss: 0.000295 best_pearson: 0.7248
Batch[11504] - loss: 0.000546 best_pearson: 0.7248
Batch[11505] - loss: 0.000431 best_pearson: 0.7248
Batch[11506] - loss: 0.000647 best_pearson: 0.7248
Batch[11507] - loss: 0.000568 best_pearson: 0.7248
Batch[11508] - loss: 0.000599 best_pearson: 0.7248
Batch[11509] - loss: 0.000623 best_pearson: 0.7248
Batch[11510] - loss: 0.000957 best_pearson: 0.7248
Batch[11511] - loss: 0.000587 best_pearson: 0.7248
Batch[11512] - loss: 0.000459 best_pearson: 0.7248
Batch[11513] - loss: 0.000538 best_pearson: 0.7248
Batch[11514] - loss: 0.000476 best_pearson: 0.7248
Batch[11515] - loss: 0.000594 best_pearson: 0.7248
Batch[11516] - loss: 0.000448 best_pearson: 0.7248
Batch[11517] - loss: 0.000542 best_pearson: 0.7248
Batch[11518] - loss: 0.000440 best_pearson: 0.7248
Batch[11519] - loss: 0.000678 best_pearson: 0.7248
Batch[11520] - loss: 0.000610 best_pearson: 0.7248
Batch[11521] - loss: 0.000508 best_pearson: 0.7248
Batch[11522] - loss: 0.000579 best_pearson: 0.7248
Batch[11523] - loss: 0.000571 best_pearson: 0.7248
Batch[11524] - loss: 0.000409 best_pearson: 0.7248
Batch[11525] - loss: 0.000518 best_pearson: 0.7248
Batch[11526] - loss: 0.000389 best_pearson: 0.7248
Batch[11527] - loss: 0.000316 best_pearson: 0.7248
Batch[11528] - loss: 0.000246 best_pearson: 0.7248
Batch[11529] - loss: 0.000692 best_pearson: 0.7248
Batch[11530] - loss: 0.000514 best_pearson: 0.7248
Batch[11531] - loss: 0.000451 best_pearson: 0.7248
Batch[11532] - loss: 0.000376 best_pearson: 0.7248
Batch[11533] - loss: 0.000615 best_pearson: 0.7248
Batch[11534] - loss: 0.000982 best_pearson: 0.7248
Batch[11535] - loss: 0.000604 best_pearson: 0.7248
Batch[11536] - loss: 0.000823 best_pearson: 0.7248
Batch[11537] - loss: 0.000550 best_pearson: 0.7248
Batch[11538] - loss: 0.000343 best_pearson: 0.7248
Batch[11539] - loss: 0.000493 best_pearson: 0.7248
Batch[11540] - loss: 0.000388 best_pearson: 0.7248
Batch[11541] - loss: 0.000771 best_pearson: 0.7248
Batch[11542] - loss: 0.000470 best_pearson: 0.7248
Batch[11543] - loss: 0.000535 best_pearson: 0.7248
Batch[11544] - loss: 0.000359 best_pearson: 0.7248
Batch[11545] - loss: 0.000622 best_pearson: 0.7248
Batch[11546] - loss: 0.000562 best_pearson: 0.7248
Batch[11547] - loss: 0.000485 best_pearson: 0.7248
Batch[11548] - loss: 0.000301 best_pearson: 0.7248
Batch[11549] - loss: 0.000492 best_pearson: 0.7248
Batch[11550] - loss: 0.000706 best_pearson: 0.7248
Batch[11551] - loss: 0.000448 best_pearson: 0.7248
Batch[11552] - loss: 0.000913 best_pearson: 0.7248
Batch[11553] - loss: 0.000364 best_pearson: 0.7248
Batch[11554] - loss: 0.000645 best_pearson: 0.7248
Batch[11555] - loss: 0.000572 best_pearson: 0.7248
Batch[11556] - loss: 0.000529 best_pearson: 0.7248
Batch[11557] - loss: 0.000610 best_pearson: 0.7248
Batch[11558] - loss: 0.000590 best_pearson: 0.7248
Batch[11559] - loss: 0.000633 best_pearson: 0.7248
Batch[11560] - loss: 0.000406 best_pearson: 0.7248
Batch[11561] - loss: 0.000501 best_pearson: 0.7248
Batch[11562] - loss: 0.000442 best_pearson: 0.7248
Batch[11563] - loss: 0.000461 best_pearson: 0.7248
Batch[11564] - loss: 0.000724 best_pearson: 0.7248
Batch[11565] - loss: 0.000652 best_pearson: 0.7248
Batch[11566] - loss: 0.000684 best_pearson: 0.7248
Batch[11567] - loss: 0.000367 best_pearson: 0.7248
Batch[11568] - loss: 0.000547 best_pearson: 0.7248
Batch[11569] - loss: 0.000404 best_pearson: 0.7248
Batch[11570] - loss: 0.000608 best_pearson: 0.7248
Batch[11571] - loss: 0.000445 best_pearson: 0.7248
Batch[11572] - loss: 0.000529 best_pearson: 0.7248
Batch[11573] - loss: 0.000366 best_pearson: 0.7248
Batch[11574] - loss: 0.000365 best_pearson: 0.7248
Batch[11575] - loss: 0.000630 best_pearson: 0.7248
Batch[11576] - loss: 0.000447 best_pearson: 0.7248
Batch[11577] - loss: 0.000778 best_pearson: 0.7248
Batch[11578] - loss: 0.000253 best_pearson: 0.7248
Batch[11579] - loss: 0.000472 best_pearson: 0.7248
Batch[11580] - loss: 0.000576 best_pearson: 0.7248
Batch[11581] - loss: 0.000481 best_pearson: 0.7248
Batch[11582] - loss: 0.000548 best_pearson: 0.7248
Batch[11583] - loss: 0.000372 best_pearson: 0.7248
Batch[11584] - loss: 0.000519 best_pearson: 0.7248
Batch[11585] - loss: 0.000376 best_pearson: 0.7248
Batch[11586] - loss: 0.000377 best_pearson: 0.7248
Batch[11587] - loss: 0.000428 best_pearson: 0.7248
Batch[11588] - loss: 0.000522 best_pearson: 0.7248
Batch[11589] - loss: 0.000818 best_pearson: 0.7248
Batch[11590] - loss: 0.000481 best_pearson: 0.7248
Batch[11591] - loss: 0.000418 best_pearson: 0.7248
Batch[11592] - loss: 0.000274 best_pearson: 0.7248
Batch[11593] - loss: 0.000383 best_pearson: 0.7248
Batch[11594] - loss: 0.000518 best_pearson: 0.7248
Batch[11595] - loss: 0.000382 best_pearson: 0.7248
Batch[11596] - loss: 0.000620 best_pearson: 0.7248
Batch[11597] - loss: 0.000386 best_pearson: 0.7248
Batch[11598] - loss: 0.000405 best_pearson: 0.7248
Batch[11599] - loss: 0.000496 best_pearson: 0.7248
Batch[11600] - loss: 0.000413 best_pearson: 0.7248

Evaluation - loss: 0.000048 pearson: 0.7051 

early stop by 1500 steps.
Batch[11601] - loss: 0.000917 best_pearson: 0.7248
Batch[11602] - loss: 0.000413 best_pearson: 0.7248
Batch[11603] - loss: 0.000565 best_pearson: 0.7248
Batch[11604] - loss: 0.000721 best_pearson: 0.7248
Batch[11605] - loss: 0.000661 best_pearson: 0.7248
Batch[11606] - loss: 0.000477 best_pearson: 0.7248
Batch[11607] - loss: 0.000383 best_pearson: 0.7248
Batch[11608] - loss: 0.000380 best_pearson: 0.7248
Batch[11609] - loss: 0.000713 best_pearson: 0.7248
Batch[11610] - loss: 0.000423 best_pearson: 0.7248
Batch[11611] - loss: 0.000379 best_pearson: 0.7248
Batch[11612] - loss: 0.000518 best_pearson: 0.7248
Batch[11613] - loss: 0.000470 best_pearson: 0.7248
Batch[11614] - loss: 0.000533 best_pearson: 0.7248
Batch[11615] - loss: 0.000578 best_pearson: 0.7248
Batch[11616] - loss: 0.000575 best_pearson: 0.7248
Batch[11617] - loss: 0.000480 best_pearson: 0.7248
Batch[11618] - loss: 0.000616 best_pearson: 0.7248
Batch[11619] - loss: 0.000473 best_pearson: 0.7248
Batch[11620] - loss: 0.000497 best_pearson: 0.7248
Batch[11621] - loss: 0.000297 best_pearson: 0.7248
Batch[11622] - loss: 0.000375 best_pearson: 0.7248
Batch[11623] - loss: 0.000380 best_pearson: 0.7248
Batch[11624] - loss: 0.000520 best_pearson: 0.7248
Batch[11625] - loss: 0.000399 best_pearson: 0.7248
Batch[11626] - loss: 0.000408 best_pearson: 0.7248
Batch[11627] - loss: 0.000483 best_pearson: 0.7248
Batch[11628] - loss: 0.000495 best_pearson: 0.7248
Batch[11629] - loss: 0.000568 best_pearson: 0.7248
Batch[11630] - loss: 0.000672 best_pearson: 0.7248
Batch[11631] - loss: 0.000490 best_pearson: 0.7248
Batch[11632] - loss: 0.000547 best_pearson: 0.7248
Batch[11633] - loss: 0.000762 best_pearson: 0.7248
Batch[11634] - loss: 0.000394 best_pearson: 0.7248
Batch[11635] - loss: 0.000369 best_pearson: 0.7248
Batch[11636] - loss: 0.000484 best_pearson: 0.7248
Batch[11637] - loss: 0.000406 best_pearson: 0.7248
Batch[11638] - loss: 0.000614 best_pearson: 0.7248
Batch[11639] - loss: 0.000377 best_pearson: 0.7248
Batch[11640] - loss: 0.000395 best_pearson: 0.7248
Batch[11641] - loss: 0.000484 best_pearson: 0.7248
Batch[11642] - loss: 0.000420 best_pearson: 0.7248
Batch[11643] - loss: 0.000950 best_pearson: 0.7248
Batch[11644] - loss: 0.000600 best_pearson: 0.7248
Batch[11645] - loss: 0.000837 best_pearson: 0.7248
Batch[11646] - loss: 0.000603 best_pearson: 0.7248
Batch[11647] - loss: 0.000765 best_pearson: 0.7248
Batch[11648] - loss: 0.000665 best_pearson: 0.7248
Batch[11649] - loss: 0.000343 best_pearson: 0.7248
Batch[11650] - loss: 0.000414 best_pearson: 0.7248
Batch[11651] - loss: 0.000465 best_pearson: 0.7248
Batch[11652] - loss: 0.000289 best_pearson: 0.7248
Batch[11653] - loss: 0.000187 best_pearson: 0.7248
Batch[11654] - loss: 0.000362 best_pearson: 0.7248
Batch[11655] - loss: 0.000273 best_pearson: 0.7248
Batch[11656] - loss: 0.000401 best_pearson: 0.7248
Batch[11657] - loss: 0.000518 best_pearson: 0.7248
Batch[11658] - loss: 0.000494 best_pearson: 0.7248
Batch[11659] - loss: 0.000263 best_pearson: 0.7248
Batch[11660] - loss: 0.000541 best_pearson: 0.7248
Batch[11661] - loss: 0.000556 best_pearson: 0.7248
Batch[11662] - loss: 0.000475 best_pearson: 0.7248
Batch[11663] - loss: 0.000536 best_pearson: 0.7248
Batch[11664] - loss: 0.000374 best_pearson: 0.7248
Batch[11665] - loss: 0.000312 best_pearson: 0.7248
Batch[11666] - loss: 0.000417 best_pearson: 0.7248
Batch[11667] - loss: 0.000390 best_pearson: 0.7248
Batch[11668] - loss: 0.000440 best_pearson: 0.7248
Batch[11669] - loss: 0.000318 best_pearson: 0.7248
Batch[11670] - loss: 0.000422 best_pearson: 0.7248
Batch[11671] - loss: 0.000560 best_pearson: 0.7248
Batch[11672] - loss: 0.000362 best_pearson: 0.7248
Batch[11673] - loss: 0.000790 best_pearson: 0.7248
Batch[11674] - loss: 0.000374 best_pearson: 0.7248
Batch[11675] - loss: 0.000300 best_pearson: 0.7248
Batch[11676] - loss: 0.000629 best_pearson: 0.7248
Batch[11677] - loss: 0.000398 best_pearson: 0.7248
Batch[11678] - loss: 0.000430 best_pearson: 0.7248
Batch[11679] - loss: 0.000356 best_pearson: 0.7248
Batch[11680] - loss: 0.000358 best_pearson: 0.7248
Batch[11681] - loss: 0.000485 best_pearson: 0.7248
Batch[11682] - loss: 0.000612 best_pearson: 0.7248
Batch[11683] - loss: 0.000809 best_pearson: 0.7248
Batch[11684] - loss: 0.000375 best_pearson: 0.7248
Batch[11685] - loss: 0.000471 best_pearson: 0.7248
Batch[11686] - loss: 0.000436 best_pearson: 0.7248
Batch[11687] - loss: 0.000656 best_pearson: 0.7248
Batch[11688] - loss: 0.000708 best_pearson: 0.7248
Batch[11689] - loss: 0.000235 best_pearson: 0.7248
Batch[11690] - loss: 0.000546 best_pearson: 0.7248
Batch[11691] - loss: 0.000454 best_pearson: 0.7248
Batch[11692] - loss: 0.000403 best_pearson: 0.7248
Batch[11693] - loss: 0.000561 best_pearson: 0.7248
Batch[11694] - loss: 0.000528 best_pearson: 0.7248
Batch[11695] - loss: 0.000581 best_pearson: 0.7248
Batch[11696] - loss: 0.000461 best_pearson: 0.7248
Batch[11697] - loss: 0.000521 best_pearson: 0.7248
Batch[11698] - loss: 0.000534 best_pearson: 0.7248
Batch[11699] - loss: 0.000314 best_pearson: 0.7248
Batch[11700] - loss: 0.000433 best_pearson: 0.7248

Evaluation - loss: 0.000048 pearson: 0.7047 

early stop by 1500 steps.
Batch[11701] - loss: 0.000421 best_pearson: 0.7248
Batch[11702] - loss: 0.000471 best_pearson: 0.7248
Batch[11703] - loss: 0.000432 best_pearson: 0.7248
Batch[11704] - loss: 0.000629 best_pearson: 0.7248
Batch[11705] - loss: 0.000377 best_pearson: 0.7248
Batch[11706] - loss: 0.000508 best_pearson: 0.7248
Batch[11707] - loss: 0.000578 best_pearson: 0.7248
Batch[11708] - loss: 0.000494 best_pearson: 0.7248
Batch[11709] - loss: 0.000865 best_pearson: 0.7248
Batch[11710] - loss: 0.000777 best_pearson: 0.7248
Batch[11711] - loss: 0.000389 best_pearson: 0.7248
Batch[11712] - loss: 0.000554 best_pearson: 0.7248
Batch[11713] - loss: 0.000472 best_pearson: 0.7248
Batch[11714] - loss: 0.001174 best_pearson: 0.7248
Batch[11715] - loss: 0.000920 best_pearson: 0.7248
Batch[11716] - loss: 0.000409 best_pearson: 0.7248
Batch[11717] - loss: 0.000419 best_pearson: 0.7248
Batch[11718] - loss: 0.000344 best_pearson: 0.7248
Batch[11719] - loss: 0.000644 best_pearson: 0.7248
Batch[11720] - loss: 0.000788 best_pearson: 0.7248
Batch[11721] - loss: 0.000714 best_pearson: 0.7248
Batch[11722] - loss: 0.000223 best_pearson: 0.7248
Batch[11723] - loss: 0.000516 best_pearson: 0.7248
Batch[11724] - loss: 0.000339 best_pearson: 0.7248
Batch[11725] - loss: 0.000424 best_pearson: 0.7248
Batch[11726] - loss: 0.000351 best_pearson: 0.7248
Batch[11727] - loss: 0.000640 best_pearson: 0.7248
Batch[11728] - loss: 0.000604 best_pearson: 0.7248
Batch[11729] - loss: 0.000674 best_pearson: 0.7248
Batch[11730] - loss: 0.001343 best_pearson: 0.7248
Batch[11731] - loss: 0.000582 best_pearson: 0.7248
Batch[11732] - loss: 0.000535 best_pearson: 0.7248
Batch[11733] - loss: 0.000610 best_pearson: 0.7248
Batch[11734] - loss: 0.000300 best_pearson: 0.7248
Batch[11735] - loss: 0.000367 best_pearson: 0.7248
Batch[11736] - loss: 0.000419 best_pearson: 0.7248
Batch[11737] - loss: 0.000599 best_pearson: 0.7248
Batch[11738] - loss: 0.000403 best_pearson: 0.7248
Batch[11739] - loss: 0.000348 best_pearson: 0.7248
Batch[11740] - loss: 0.000582 best_pearson: 0.7248
Batch[11741] - loss: 0.000491 best_pearson: 0.7248
Batch[11742] - loss: 0.001118 best_pearson: 0.7248
Batch[11743] - loss: 0.000518 best_pearson: 0.7248
Batch[11744] - loss: 0.000248 best_pearson: 0.7248
Batch[11745] - loss: 0.000588 best_pearson: 0.7248
Batch[11746] - loss: 0.000566 best_pearson: 0.7248
Batch[11747] - loss: 0.000405 best_pearson: 0.7248
Batch[11748] - loss: 0.000399 best_pearson: 0.7248
Batch[11749] - loss: 0.000495 best_pearson: 0.7248
Batch[11750] - loss: 0.000435 best_pearson: 0.7248
Batch[11751] - loss: 0.000585 best_pearson: 0.7248
Batch[11752] - loss: 0.000321 best_pearson: 0.7248
Batch[11753] - loss: 0.000418 best_pearson: 0.7248
Batch[11754] - loss: 0.000572 best_pearson: 0.7248
Batch[11755] - loss: 0.000264 best_pearson: 0.7248
Batch[11756] - loss: 0.000498 best_pearson: 0.7248
Batch[11757] - loss: 0.000453 best_pearson: 0.7248
Batch[11758] - loss: 0.000530 best_pearson: 0.7248
Batch[11759] - loss: 0.000552 best_pearson: 0.7248
Batch[11760] - loss: 0.000433 best_pearson: 0.7248
Batch[11761] - loss: 0.000680 best_pearson: 0.7248
Batch[11762] - loss: 0.000603 best_pearson: 0.7248
Batch[11763] - loss: 0.000419 best_pearson: 0.7248
Batch[11764] - loss: 0.000675 best_pearson: 0.7248
Batch[11765] - loss: 0.000277 best_pearson: 0.7248
Batch[11766] - loss: 0.000308 best_pearson: 0.7248
Batch[11767] - loss: 0.000482 best_pearson: 0.7248
Batch[11768] - loss: 0.000614 best_pearson: 0.7248
Batch[11769] - loss: 0.000477 best_pearson: 0.7248
Batch[11770] - loss: 0.000658 best_pearson: 0.7248
Batch[11771] - loss: 0.000475 best_pearson: 0.7248
Batch[11772] - loss: 0.000509 best_pearson: 0.7248
Batch[11773] - loss: 0.000695 best_pearson: 0.7248
Batch[11774] - loss: 0.000723 best_pearson: 0.7248
Batch[11775] - loss: 0.000448 best_pearson: 0.7248
Batch[11776] - loss: 0.000635 best_pearson: 0.7248
Batch[11777] - loss: 0.000540 best_pearson: 0.7248
Batch[11778] - loss: 0.000950 best_pearson: 0.7248
Batch[11779] - loss: 0.000633 best_pearson: 0.7248
Batch[11780] - loss: 0.000735 best_pearson: 0.7248
Batch[11781] - loss: 0.000971 best_pearson: 0.7248
Batch[11782] - loss: 0.000410 best_pearson: 0.7248
Batch[11783] - loss: 0.000740 best_pearson: 0.7248
Batch[11784] - loss: 0.000597 best_pearson: 0.7248
Batch[11785] - loss: 0.000612 best_pearson: 0.7248
Batch[11786] - loss: 0.000664 best_pearson: 0.7248
Batch[11787] - loss: 0.000555 best_pearson: 0.7248
Batch[11788] - loss: 0.000514 best_pearson: 0.7248
Batch[11789] - loss: 0.000485 best_pearson: 0.7248
Batch[11790] - loss: 0.000360 best_pearson: 0.7248
Batch[11791] - loss: 0.000211 best_pearson: 0.7248
Batch[11792] - loss: 0.000322 best_pearson: 0.7248
Batch[11793] - loss: 0.000590 best_pearson: 0.7248
Batch[11794] - loss: 0.000405 best_pearson: 0.7248
Batch[11795] - loss: 0.000693 best_pearson: 0.7248
Batch[11796] - loss: 0.000437 best_pearson: 0.7248
Batch[11797] - loss: 0.000475 best_pearson: 0.7248
Batch[11798] - loss: 0.000438 best_pearson: 0.7248
Batch[11799] - loss: 0.000542 best_pearson: 0.7248
Batch[11800] - loss: 0.000556 best_pearson: 0.7248

Evaluation - loss: 0.000048 pearson: 0.7042 

early stop by 1500 steps.
Batch[11801] - loss: 0.000478 best_pearson: 0.7248
Batch[11802] - loss: 0.000377 best_pearson: 0.7248
Batch[11803] - loss: 0.000680 best_pearson: 0.7248
Batch[11804] - loss: 0.000474 best_pearson: 0.7248
Batch[11805] - loss: 0.000377 best_pearson: 0.7248
Batch[11806] - loss: 0.000582 best_pearson: 0.7248
Batch[11807] - loss: 0.000779 best_pearson: 0.7248
Batch[11808] - loss: 0.000477 best_pearson: 0.7248
Batch[11809] - loss: 0.000742 best_pearson: 0.7248
Batch[11810] - loss: 0.000268 best_pearson: 0.7248
Batch[11811] - loss: 0.000609 best_pearson: 0.7248
Batch[11812] - loss: 0.000514 best_pearson: 0.7248
Batch[11813] - loss: 0.000295 best_pearson: 0.7248
Batch[11814] - loss: 0.000472 best_pearson: 0.7248
Batch[11815] - loss: 0.000620 best_pearson: 0.7248
Batch[11816] - loss: 0.000399 best_pearson: 0.7248
Batch[11817] - loss: 0.000568 best_pearson: 0.7248
Batch[11818] - loss: 0.000396 best_pearson: 0.7248
Batch[11819] - loss: 0.000433 best_pearson: 0.7248
Batch[11820] - loss: 0.000448 best_pearson: 0.7248
Batch[11821] - loss: 0.000377 best_pearson: 0.7248
Batch[11822] - loss: 0.000516 best_pearson: 0.7248
Batch[11823] - loss: 0.000382 best_pearson: 0.7248
Batch[11824] - loss: 0.000718 best_pearson: 0.7248
Batch[11825] - loss: 0.000521 best_pearson: 0.7248
Batch[11826] - loss: 0.000398 best_pearson: 0.7248
Batch[11827] - loss: 0.000872 best_pearson: 0.7248
Batch[11828] - loss: 0.000341 best_pearson: 0.7248
Batch[11829] - loss: 0.000616 best_pearson: 0.7248
Batch[11830] - loss: 0.000371 best_pearson: 0.7248
Batch[11831] - loss: 0.000388 best_pearson: 0.7248
Batch[11832] - loss: 0.001040 best_pearson: 0.7248
Batch[11833] - loss: 0.000261 best_pearson: 0.7248
Batch[11834] - loss: 0.000789 best_pearson: 0.7248
Batch[11835] - loss: 0.000609 best_pearson: 0.7248
Batch[11836] - loss: 0.000450 best_pearson: 0.7248
Batch[11837] - loss: 0.001073 best_pearson: 0.7248
Batch[11838] - loss: 0.000658 best_pearson: 0.7248
Batch[11839] - loss: 0.000339 best_pearson: 0.7248
Batch[11840] - loss: 0.000466 best_pearson: 0.7248
Batch[11841] - loss: 0.000313 best_pearson: 0.7248
Batch[11842] - loss: 0.000453 best_pearson: 0.7248
Batch[11843] - loss: 0.000385 best_pearson: 0.7248
Batch[11844] - loss: 0.000680 best_pearson: 0.7248
Batch[11845] - loss: 0.000638 best_pearson: 0.7248
Batch[11846] - loss: 0.000693 best_pearson: 0.7248
Batch[11847] - loss: 0.000328 best_pearson: 0.7248
Batch[11848] - loss: 0.000388 best_pearson: 0.7248
Batch[11849] - loss: 0.000720 best_pearson: 0.7248
Batch[11850] - loss: 0.000465 best_pearson: 0.7248
Batch[11851] - loss: 0.000360 best_pearson: 0.7248
Batch[11852] - loss: 0.000396 best_pearson: 0.7248
Batch[11853] - loss: 0.000459 best_pearson: 0.7248
Batch[11854] - loss: 0.000564 best_pearson: 0.7248
Batch[11855] - loss: 0.000619 best_pearson: 0.7248
Batch[11856] - loss: 0.000431 best_pearson: 0.7248
Batch[11857] - loss: 0.000456 best_pearson: 0.7248
Batch[11858] - loss: 0.000415 best_pearson: 0.7248
Batch[11859] - loss: 0.000499 best_pearson: 0.7248
Batch[11860] - loss: 0.000525 best_pearson: 0.7248
Batch[11861] - loss: 0.000491 best_pearson: 0.7248
Batch[11862] - loss: 0.000773 best_pearson: 0.7248
Batch[11863] - loss: 0.000520 best_pearson: 0.7248
Batch[11864] - loss: 0.000413 best_pearson: 0.7248
Batch[11865] - loss: 0.000557 best_pearson: 0.7248
Batch[11866] - loss: 0.000467 best_pearson: 0.7248
Batch[11867] - loss: 0.000606 best_pearson: 0.7248
Batch[11868] - loss: 0.000378 best_pearson: 0.7248
Batch[11869] - loss: 0.000450 best_pearson: 0.7248
Batch[11870] - loss: 0.000517 best_pearson: 0.7248
Batch[11871] - loss: 0.000361 best_pearson: 0.7248
Batch[11872] - loss: 0.000413 best_pearson: 0.7248
Batch[11873] - loss: 0.000529 best_pearson: 0.7248
Batch[11874] - loss: 0.000389 best_pearson: 0.7248
Batch[11875] - loss: 0.000575 best_pearson: 0.7248
Batch[11876] - loss: 0.000251 best_pearson: 0.7248
Batch[11877] - loss: 0.000436 best_pearson: 0.7248
Batch[11878] - loss: 0.000840 best_pearson: 0.7248
Batch[11879] - loss: 0.000602 best_pearson: 0.7248
Batch[11880] - loss: 0.000638 best_pearson: 0.7248
Batch[11881] - loss: 0.000567 best_pearson: 0.7248
Batch[11882] - loss: 0.000700 best_pearson: 0.7248
Batch[11883] - loss: 0.000538 best_pearson: 0.7248
Batch[11884] - loss: 0.000197 best_pearson: 0.7248
Batch[11885] - loss: 0.000590 best_pearson: 0.7248
Batch[11886] - loss: 0.000433 best_pearson: 0.7248
Batch[11887] - loss: 0.000621 best_pearson: 0.7248
Batch[11888] - loss: 0.000478 best_pearson: 0.7248
Batch[11889] - loss: 0.000286 best_pearson: 0.7248
Batch[11890] - loss: 0.000434 best_pearson: 0.7248
Batch[11891] - loss: 0.000653 best_pearson: 0.7248
Batch[11892] - loss: 0.000322 best_pearson: 0.7248
Batch[11893] - loss: 0.000599 best_pearson: 0.7248
Batch[11894] - loss: 0.000653 best_pearson: 0.7248
Batch[11895] - loss: 0.000395 best_pearson: 0.7248
Batch[11896] - loss: 0.000796 best_pearson: 0.7248
Batch[11897] - loss: 0.000529 best_pearson: 0.7248
Batch[11898] - loss: 0.000525 best_pearson: 0.7248
Batch[11899] - loss: 0.000567 best_pearson: 0.7248
Batch[11900] - loss: 0.000560 best_pearson: 0.7248

Evaluation - loss: 0.000048 pearson: 0.7023 

early stop by 1500 steps.
Batch[11901] - loss: 0.000401 best_pearson: 0.7248
Batch[11902] - loss: 0.000396 best_pearson: 0.7248
Batch[11903] - loss: 0.000790 best_pearson: 0.7248
Batch[11904] - loss: 0.000462 best_pearson: 0.7248
Batch[11905] - loss: 0.000316 best_pearson: 0.7248
Batch[11906] - loss: 0.000616 best_pearson: 0.7248
Batch[11907] - loss: 0.000709 best_pearson: 0.7248
Batch[11908] - loss: 0.000539 best_pearson: 0.7248
Batch[11909] - loss: 0.000877 best_pearson: 0.7248
Batch[11910] - loss: 0.000543 best_pearson: 0.7248
Batch[11911] - loss: 0.000689 best_pearson: 0.7248
Batch[11912] - loss: 0.000790 best_pearson: 0.7248
Batch[11913] - loss: 0.000298 best_pearson: 0.7248
Batch[11914] - loss: 0.000572 best_pearson: 0.7248
Batch[11915] - loss: 0.000548 best_pearson: 0.7248
Batch[11916] - loss: 0.000662 best_pearson: 0.7248
Batch[11917] - loss: 0.000496 best_pearson: 0.7248
Batch[11918] - loss: 0.000835 best_pearson: 0.7248
Batch[11919] - loss: 0.000672 best_pearson: 0.7248
Batch[11920] - loss: 0.000439 best_pearson: 0.7248
Batch[11921] - loss: 0.000482 best_pearson: 0.7248
Batch[11922] - loss: 0.000336 best_pearson: 0.7248
Batch[11923] - loss: 0.000441 best_pearson: 0.7248
Batch[11924] - loss: 0.000708 best_pearson: 0.7248
Batch[11925] - loss: 0.000489 best_pearson: 0.7248
Batch[11926] - loss: 0.000454 best_pearson: 0.7248
Batch[11927] - loss: 0.000341 best_pearson: 0.7248
Batch[11928] - loss: 0.000304 best_pearson: 0.7248
Batch[11929] - loss: 0.000565 best_pearson: 0.7248
Batch[11930] - loss: 0.000324 best_pearson: 0.7248
Batch[11931] - loss: 0.000420 best_pearson: 0.7248
Batch[11932] - loss: 0.000802 best_pearson: 0.7248
Batch[11933] - loss: 0.000548 best_pearson: 0.7248
Batch[11934] - loss: 0.000345 best_pearson: 0.7248
Batch[11935] - loss: 0.000414 best_pearson: 0.7248
Batch[11936] - loss: 0.000387 best_pearson: 0.7248
Batch[11937] - loss: 0.000489 best_pearson: 0.7248
Batch[11938] - loss: 0.000600 best_pearson: 0.7248
Batch[11939] - loss: 0.000548 best_pearson: 0.7248
Batch[11940] - loss: 0.000822 best_pearson: 0.7248
Batch[11941] - loss: 0.000789 best_pearson: 0.7248
Batch[11942] - loss: 0.000563 best_pearson: 0.7248
Batch[11943] - loss: 0.000546 best_pearson: 0.7248
Batch[11944] - loss: 0.001600 best_pearson: 0.7248
Batch[11945] - loss: 0.000410 best_pearson: 0.7248
Batch[11946] - loss: 0.000523 best_pearson: 0.7248
Batch[11947] - loss: 0.000643 best_pearson: 0.7248
Batch[11948] - loss: 0.000991 best_pearson: 0.7248
Batch[11949] - loss: 0.000463 best_pearson: 0.7248
Batch[11950] - loss: 0.000332 best_pearson: 0.7248
Batch[11951] - loss: 0.000683 best_pearson: 0.7248
Batch[11952] - loss: 0.000427 best_pearson: 0.7248
Batch[11953] - loss: 0.000725 best_pearson: 0.7248
Batch[11954] - loss: 0.000488 best_pearson: 0.7248
Batch[11955] - loss: 0.000594 best_pearson: 0.7248
Batch[11956] - loss: 0.000864 best_pearson: 0.7248
Batch[11957] - loss: 0.000796 best_pearson: 0.7248
Batch[11958] - loss: 0.000740 best_pearson: 0.7248
Batch[11959] - loss: 0.000865 best_pearson: 0.7248
Batch[11960] - loss: 0.000618 best_pearson: 0.7248
Batch[11961] - loss: 0.000677 best_pearson: 0.7248
Batch[11962] - loss: 0.000807 best_pearson: 0.7248
Batch[11963] - loss: 0.000332 best_pearson: 0.7248
Batch[11964] - loss: 0.000863 best_pearson: 0.7248
Batch[11965] - loss: 0.000856 best_pearson: 0.7248
Batch[11966] - loss: 0.000835 best_pearson: 0.7248
Batch[11967] - loss: 0.000723 best_pearson: 0.7248
Batch[11968] - loss: 0.001065 best_pearson: 0.7248
Batch[11969] - loss: 0.000800 best_pearson: 0.7248
Batch[11970] - loss: 0.000581 best_pearson: 0.7248
Batch[11971] - loss: 0.000346 best_pearson: 0.7248
Batch[11972] - loss: 0.000662 best_pearson: 0.7248
Batch[11973] - loss: 0.000775 best_pearson: 0.7248
Batch[11974] - loss: 0.000962 best_pearson: 0.7248
Batch[11975] - loss: 0.000763 best_pearson: 0.7248
Batch[11976] - loss: 0.000659 best_pearson: 0.7248
Batch[11977] - loss: 0.000756 best_pearson: 0.7248
Batch[11978] - loss: 0.000892 best_pearson: 0.7248
Batch[11979] - loss: 0.000546 best_pearson: 0.7248
Batch[11980] - loss: 0.000801 best_pearson: 0.7248
Batch[11981] - loss: 0.000946 best_pearson: 0.7248
Batch[11982] - loss: 0.000906 best_pearson: 0.7248
Batch[11983] - loss: 0.000640 best_pearson: 0.7248
Batch[11984] - loss: 0.000758 best_pearson: 0.7248
Batch[11985] - loss: 0.000514 best_pearson: 0.7248
Batch[11986] - loss: 0.000594 best_pearson: 0.7248
Batch[11987] - loss: 0.000804 best_pearson: 0.7248
Batch[11988] - loss: 0.000594 best_pearson: 0.7248
Batch[11989] - loss: 0.000369 best_pearson: 0.7248
Batch[11990] - loss: 0.000594 best_pearson: 0.7248
Batch[11991] - loss: 0.000595 best_pearson: 0.7248
Batch[11992] - loss: 0.000371 best_pearson: 0.7248
Batch[11993] - loss: 0.000396 best_pearson: 0.7248
Batch[11994] - loss: 0.000873 best_pearson: 0.7248
Batch[11995] - loss: 0.000467 best_pearson: 0.7248
Batch[11996] - loss: 0.000721 best_pearson: 0.7248
Batch[11997] - loss: 0.001000 best_pearson: 0.7248
Batch[11998] - loss: 0.000641 best_pearson: 0.7248
Batch[11999] - loss: 0.000654 best_pearson: 0.7248
Batch[12000] - loss: 0.000479 best_pearson: 0.7248

Evaluation - loss: 0.000048 pearson: 0.7041 

early stop by 1500 steps.
Batch[12001] - loss: 0.000520 best_pearson: 0.7248
Batch[12002] - loss: 0.000540 best_pearson: 0.7248
Batch[12003] - loss: 0.000536 best_pearson: 0.7248
Batch[12004] - loss: 0.000391 best_pearson: 0.7248
Batch[12005] - loss: 0.000572 best_pearson: 0.7248
Batch[12006] - loss: 0.000579 best_pearson: 0.7248
Batch[12007] - loss: 0.000566 best_pearson: 0.7248
Batch[12008] - loss: 0.000432 best_pearson: 0.7248
Batch[12009] - loss: 0.000493 best_pearson: 0.7248
Batch[12010] - loss: 0.000657 best_pearson: 0.7248
Batch[12011] - loss: 0.000669 best_pearson: 0.7248
Batch[12012] - loss: 0.000706 best_pearson: 0.7248
Batch[12013] - loss: 0.000857 best_pearson: 0.7248
Batch[12014] - loss: 0.001067 best_pearson: 0.7248
Batch[12015] - loss: 0.000681 best_pearson: 0.7248
Batch[12016] - loss: 0.000917 best_pearson: 0.7248
Batch[12017] - loss: 0.000610 best_pearson: 0.7248
Batch[12018] - loss: 0.000590 best_pearson: 0.7248
Batch[12019] - loss: 0.000603 best_pearson: 0.7248
Batch[12020] - loss: 0.001007 best_pearson: 0.7248
Batch[12021] - loss: 0.000669 best_pearson: 0.7248
Batch[12022] - loss: 0.000771 best_pearson: 0.7248
Batch[12023] - loss: 0.000558 best_pearson: 0.7248
Batch[12024] - loss: 0.000675 best_pearson: 0.7248
Batch[12025] - loss: 0.000620 best_pearson: 0.7248
Batch[12026] - loss: 0.000859 best_pearson: 0.7248
Batch[12027] - loss: 0.001157 best_pearson: 0.7248
Batch[12028] - loss: 0.000578 best_pearson: 0.7248
Batch[12029] - loss: 0.000646 best_pearson: 0.7248
Batch[12030] - loss: 0.000580 best_pearson: 0.7248
Batch[12031] - loss: 0.000838 best_pearson: 0.7248
Batch[12032] - loss: 0.000816 best_pearson: 0.7248
Batch[12033] - loss: 0.000818 best_pearson: 0.7248
Batch[12034] - loss: 0.001127 best_pearson: 0.7248
Batch[12035] - loss: 0.000572 best_pearson: 0.7248
Batch[12036] - loss: 0.000507 best_pearson: 0.7248
Batch[12037] - loss: 0.000455 best_pearson: 0.7248
Batch[12038] - loss: 0.000588 best_pearson: 0.7248
Batch[12039] - loss: 0.000760 best_pearson: 0.7248
Batch[12040] - loss: 0.000635 best_pearson: 0.7248
Batch[12041] - loss: 0.000674 best_pearson: 0.7248
Batch[12042] - loss: 0.000763 best_pearson: 0.7248
Batch[12043] - loss: 0.000742 best_pearson: 0.7248
Batch[12044] - loss: 0.000971 best_pearson: 0.7248
Batch[12045] - loss: 0.000513 best_pearson: 0.7248
Batch[12046] - loss: 0.000795 best_pearson: 0.7248
Batch[12047] - loss: 0.001517 best_pearson: 0.7248
Batch[12048] - loss: 0.000813 best_pearson: 0.7248
Batch[12049] - loss: 0.001557 best_pearson: 0.7248
Batch[12050] - loss: 0.001082 best_pearson: 0.7248
Batch[12051] - loss: 0.000905 best_pearson: 0.7248
Batch[12052] - loss: 0.000582 best_pearson: 0.7248
Batch[12053] - loss: 0.000601 best_pearson: 0.7248
Batch[12054] - loss: 0.000537 best_pearson: 0.7248
Batch[12055] - loss: 0.000834 best_pearson: 0.7248
Batch[12056] - loss: 0.000745 best_pearson: 0.7248
Batch[12057] - loss: 0.001045 best_pearson: 0.7248
Batch[12058] - loss: 0.000864 best_pearson: 0.7248
Batch[12059] - loss: 0.000908 best_pearson: 0.7248
Batch[12060] - loss: 0.001049 best_pearson: 0.7248
Batch[12061] - loss: 0.000669 best_pearson: 0.7248
Batch[12062] - loss: 0.000586 best_pearson: 0.7248
Batch[12063] - loss: 0.000904 best_pearson: 0.7248
Batch[12064] - loss: 0.000946 best_pearson: 0.7248
Batch[12065] - loss: 0.000952 best_pearson: 0.7248
Batch[12066] - loss: 0.001254 best_pearson: 0.7248
Batch[12067] - loss: 0.000435 best_pearson: 0.7248
Batch[12068] - loss: 0.000918 best_pearson: 0.7248
Batch[12069] - loss: 0.000661 best_pearson: 0.7248
Batch[12070] - loss: 0.000666 best_pearson: 0.7248
Batch[12071] - loss: 0.000444 best_pearson: 0.7248
Batch[12072] - loss: 0.000531 best_pearson: 0.7248
Batch[12073] - loss: 0.000839 best_pearson: 0.7248
Batch[12074] - loss: 0.000809 best_pearson: 0.7248
Batch[12075] - loss: 0.000409 best_pearson: 0.7248
Batch[12076] - loss: 0.001023 best_pearson: 0.7248
Batch[12077] - loss: 0.001102 best_pearson: 0.7248
Batch[12078] - loss: 0.000514 best_pearson: 0.7248
Batch[12079] - loss: 0.000569 best_pearson: 0.7248
Batch[12080] - loss: 0.000606 best_pearson: 0.7248
Batch[12081] - loss: 0.000534 best_pearson: 0.7248
Batch[12082] - loss: 0.000538 best_pearson: 0.7248
Batch[12083] - loss: 0.000698 best_pearson: 0.7248
Batch[12084] - loss: 0.000585 best_pearson: 0.7248
Batch[12085] - loss: 0.000647 best_pearson: 0.7248
Batch[12086] - loss: 0.000691 best_pearson: 0.7248
Batch[12087] - loss: 0.000516 best_pearson: 0.7248
Batch[12088] - loss: 0.001006 best_pearson: 0.7248
Batch[12089] - loss: 0.000411 best_pearson: 0.7248
Batch[12090] - loss: 0.000719 best_pearson: 0.7248
Batch[12091] - loss: 0.000746 best_pearson: 0.7248
Batch[12092] - loss: 0.000551 best_pearson: 0.7248
Batch[12093] - loss: 0.000658 best_pearson: 0.7248
Batch[12094] - loss: 0.000462 best_pearson: 0.7248
Batch[12095] - loss: 0.000429 best_pearson: 0.7248
Batch[12096] - loss: 0.000716 best_pearson: 0.7248
Batch[12097] - loss: 0.000578 best_pearson: 0.7248
Batch[12098] - loss: 0.000904 best_pearson: 0.7248
Batch[12099] - loss: 0.000786 best_pearson: 0.7248
Batch[12100] - loss: 0.000581 best_pearson: 0.7248

Evaluation - loss: 0.000049 pearson: 0.7022 

early stop by 1500 steps.
Batch[12101] - loss: 0.000416 best_pearson: 0.7248
Batch[12102] - loss: 0.000457 best_pearson: 0.7248
Batch[12103] - loss: 0.000488 best_pearson: 0.7248
Batch[12104] - loss: 0.000761 best_pearson: 0.7248
Batch[12105] - loss: 0.000528 best_pearson: 0.7248
Batch[12106] - loss: 0.000732 best_pearson: 0.7248
Batch[12107] - loss: 0.000656 best_pearson: 0.7248
Batch[12108] - loss: 0.000952 best_pearson: 0.7248
Batch[12109] - loss: 0.000675 best_pearson: 0.7248
Batch[12110] - loss: 0.000726 best_pearson: 0.7248
Batch[12111] - loss: 0.000698 best_pearson: 0.7248
Batch[12112] - loss: 0.000353 best_pearson: 0.7248
Batch[12113] - loss: 0.000671 best_pearson: 0.7248
Batch[12114] - loss: 0.000556 best_pearson: 0.7248
Batch[12115] - loss: 0.000665 best_pearson: 0.7248
Batch[12116] - loss: 0.000626 best_pearson: 0.7248
Batch[12117] - loss: 0.000567 best_pearson: 0.7248
Batch[12118] - loss: 0.000306 best_pearson: 0.7248
Batch[12119] - loss: 0.000906 best_pearson: 0.7248
Batch[12120] - loss: 0.000523 best_pearson: 0.7248
Batch[12121] - loss: 0.000534 best_pearson: 0.7248
Batch[12122] - loss: 0.000763 best_pearson: 0.7248
Batch[12123] - loss: 0.000776 best_pearson: 0.7248
Batch[12124] - loss: 0.000632 best_pearson: 0.7248
Batch[12125] - loss: 0.000721 best_pearson: 0.7248
Batch[12126] - loss: 0.000518 best_pearson: 0.7248
Batch[12127] - loss: 0.000782 best_pearson: 0.7248
Batch[12128] - loss: 0.000725 best_pearson: 0.7248
Batch[12129] - loss: 0.000813 best_pearson: 0.7248
Batch[12130] - loss: 0.000553 best_pearson: 0.7248
Batch[12131] - loss: 0.000394 best_pearson: 0.7248
Batch[12132] - loss: 0.000912 best_pearson: 0.7248
Batch[12133] - loss: 0.000620 best_pearson: 0.7248
Batch[12134] - loss: 0.000698 best_pearson: 0.7248
Batch[12135] - loss: 0.000449 best_pearson: 0.7248
Batch[12136] - loss: 0.000797 best_pearson: 0.7248
Batch[12137] - loss: 0.000588 best_pearson: 0.7248
Batch[12138] - loss: 0.000556 best_pearson: 0.7248
Batch[12139] - loss: 0.000450 best_pearson: 0.7248
Batch[12140] - loss: 0.000467 best_pearson: 0.7248
Batch[12141] - loss: 0.000543 best_pearson: 0.7248
Batch[12142] - loss: 0.000372 best_pearson: 0.7248
Batch[12143] - loss: 0.000470 best_pearson: 0.7248
Batch[12144] - loss: 0.000791 best_pearson: 0.7248
Batch[12145] - loss: 0.000601 best_pearson: 0.7248
Batch[12146] - loss: 0.000464 best_pearson: 0.7248
Batch[12147] - loss: 0.000249 best_pearson: 0.7248
Batch[12148] - loss: 0.000643 best_pearson: 0.7248
Batch[12149] - loss: 0.000355 best_pearson: 0.7248
Batch[12150] - loss: 0.000405 best_pearson: 0.7248
Batch[12151] - loss: 0.000583 best_pearson: 0.7248
Batch[12152] - loss: 0.000391 best_pearson: 0.7248
Batch[12153] - loss: 0.000336 best_pearson: 0.7248
Batch[12154] - loss: 0.000576 best_pearson: 0.7248
Batch[12155] - loss: 0.000656 best_pearson: 0.7248
Batch[12156] - loss: 0.000665 best_pearson: 0.7248
Batch[12157] - loss: 0.001154 best_pearson: 0.7248
Batch[12158] - loss: 0.000484 best_pearson: 0.7248
Batch[12159] - loss: 0.000487 best_pearson: 0.7248
Batch[12160] - loss: 0.000563 best_pearson: 0.7248
Batch[12161] - loss: 0.000553 best_pearson: 0.7248
Batch[12162] - loss: 0.000528 best_pearson: 0.7248
Batch[12163] - loss: 0.000991 best_pearson: 0.7248
Batch[12164] - loss: 0.000917 best_pearson: 0.7248
Batch[12165] - loss: 0.000498 best_pearson: 0.7248
Batch[12166] - loss: 0.000486 best_pearson: 0.7248
Batch[12167] - loss: 0.000683 best_pearson: 0.7248
Batch[12168] - loss: 0.000596 best_pearson: 0.7248
Batch[12169] - loss: 0.000814 best_pearson: 0.7248
Batch[12170] - loss: 0.000501 best_pearson: 0.7248
Batch[12171] - loss: 0.000471 best_pearson: 0.7248
Batch[12172] - loss: 0.000523 best_pearson: 0.7248
Batch[12173] - loss: 0.000556 best_pearson: 0.7248
Batch[12174] - loss: 0.000712 best_pearson: 0.7248
Batch[12175] - loss: 0.000321 best_pearson: 0.7248
Batch[12176] - loss: 0.000625 best_pearson: 0.7248
Batch[12177] - loss: 0.000770 best_pearson: 0.7248
Batch[12178] - loss: 0.000401 best_pearson: 0.7248
Batch[12179] - loss: 0.000748 best_pearson: 0.7248
Batch[12180] - loss: 0.000591 best_pearson: 0.7248
Batch[12181] - loss: 0.000456 best_pearson: 0.7248
Batch[12182] - loss: 0.001116 best_pearson: 0.7248
Batch[12183] - loss: 0.000390 best_pearson: 0.7248
Batch[12184] - loss: 0.000248 best_pearson: 0.7248
Batch[12185] - loss: 0.000473 best_pearson: 0.7248
Batch[12186] - loss: 0.000321 best_pearson: 0.7248
Batch[12187] - loss: 0.000463 best_pearson: 0.7248
Batch[12188] - loss: 0.000576 best_pearson: 0.7248
Batch[12189] - loss: 0.000312 best_pearson: 0.7248
Batch[12190] - loss: 0.000632 best_pearson: 0.7248
Batch[12191] - loss: 0.000470 best_pearson: 0.7248
Batch[12192] - loss: 0.000568 best_pearson: 0.7248
Batch[12193] - loss: 0.000378 best_pearson: 0.7248
Batch[12194] - loss: 0.000338 best_pearson: 0.7248
Batch[12195] - loss: 0.000584 best_pearson: 0.7248
Batch[12196] - loss: 0.000504 best_pearson: 0.7248
Batch[12197] - loss: 0.000651 best_pearson: 0.7248
Batch[12198] - loss: 0.000554 best_pearson: 0.7248
Batch[12199] - loss: 0.000465 best_pearson: 0.7248
Batch[12200] - loss: 0.000793 best_pearson: 0.7248

Evaluation - loss: 0.000049 pearson: 0.7017 

early stop by 1500 steps.
Batch[12201] - loss: 0.000563 best_pearson: 0.7248
Batch[12202] - loss: 0.000439 best_pearson: 0.7248
Batch[12203] - loss: 0.000356 best_pearson: 0.7248
Batch[12204] - loss: 0.000421 best_pearson: 0.7248
Batch[12205] - loss: 0.000529 best_pearson: 0.7248
Batch[12206] - loss: 0.000497 best_pearson: 0.7248
Batch[12207] - loss: 0.001270 best_pearson: 0.7248
Batch[12208] - loss: 0.000618 best_pearson: 0.7248
Batch[12209] - loss: 0.000815 best_pearson: 0.7248
Batch[12210] - loss: 0.000645 best_pearson: 0.7248
Batch[12211] - loss: 0.000610 best_pearson: 0.7248
Batch[12212] - loss: 0.000676 best_pearson: 0.7248
Batch[12213] - loss: 0.000432 best_pearson: 0.7248
Batch[12214] - loss: 0.000401 best_pearson: 0.7248
Batch[12215] - loss: 0.000390 best_pearson: 0.7248
Batch[12216] - loss: 0.000444 best_pearson: 0.7248
Batch[12217] - loss: 0.000277 best_pearson: 0.7248
Batch[12218] - loss: 0.000454 best_pearson: 0.7248
Batch[12219] - loss: 0.000387 best_pearson: 0.7248
Batch[12220] - loss: 0.000411 best_pearson: 0.7248
Batch[12221] - loss: 0.000418 best_pearson: 0.7248
Batch[12222] - loss: 0.000626 best_pearson: 0.7248
Batch[12223] - loss: 0.000454 best_pearson: 0.7248
Batch[12224] - loss: 0.000383 best_pearson: 0.7248
Batch[12225] - loss: 0.000768 best_pearson: 0.7248
Batch[12226] - loss: 0.000552 best_pearson: 0.7248
Batch[12227] - loss: 0.000483 best_pearson: 0.7248
Batch[12228] - loss: 0.000467 best_pearson: 0.7248
Batch[12229] - loss: 0.000657 best_pearson: 0.7248
Batch[12230] - loss: 0.000626 best_pearson: 0.7248
Batch[12231] - loss: 0.000803 best_pearson: 0.7248
Batch[12232] - loss: 0.000451 best_pearson: 0.7248
Batch[12233] - loss: 0.000911 best_pearson: 0.7248
Batch[12234] - loss: 0.000617 best_pearson: 0.7248
Batch[12235] - loss: 0.000760 best_pearson: 0.7248
Batch[12236] - loss: 0.000297 best_pearson: 0.7248
Batch[12237] - loss: 0.000551 best_pearson: 0.7248
Batch[12238] - loss: 0.000532 best_pearson: 0.7248
Batch[12239] - loss: 0.000469 best_pearson: 0.7248
Batch[12240] - loss: 0.000648 best_pearson: 0.7248
Batch[12241] - loss: 0.000383 best_pearson: 0.7248
Batch[12242] - loss: 0.000430 best_pearson: 0.7248
Batch[12243] - loss: 0.000643 best_pearson: 0.7248
Batch[12244] - loss: 0.000691 best_pearson: 0.7248
Batch[12245] - loss: 0.000571 best_pearson: 0.7248
Batch[12246] - loss: 0.000462 best_pearson: 0.7248
Batch[12247] - loss: 0.000572 best_pearson: 0.7248
Batch[12248] - loss: 0.000453 best_pearson: 0.7248
Batch[12249] - loss: 0.000595 best_pearson: 0.7248
Batch[12250] - loss: 0.000520 best_pearson: 0.7248
Batch[12251] - loss: 0.000378 best_pearson: 0.7248
Batch[12252] - loss: 0.000707 best_pearson: 0.7248
Batch[12253] - loss: 0.000493 best_pearson: 0.7248
Batch[12254] - loss: 0.000636 best_pearson: 0.7248
Batch[12255] - loss: 0.000953 best_pearson: 0.7248
Batch[12256] - loss: 0.000658 best_pearson: 0.7248
Batch[12257] - loss: 0.000364 best_pearson: 0.7248
Batch[12258] - loss: 0.000809 best_pearson: 0.7248
Batch[12259] - loss: 0.000648 best_pearson: 0.7248
Batch[12260] - loss: 0.000946 best_pearson: 0.7248
Batch[12261] - loss: 0.000903 best_pearson: 0.7248
Batch[12262] - loss: 0.001155 best_pearson: 0.7248
Batch[12263] - loss: 0.000754 best_pearson: 0.7248
Batch[12264] - loss: 0.000753 best_pearson: 0.7248
Batch[12265] - loss: 0.000540 best_pearson: 0.7248
Batch[12266] - loss: 0.000564 best_pearson: 0.7248
Batch[12267] - loss: 0.000930 best_pearson: 0.7248
Batch[12268] - loss: 0.000690 best_pearson: 0.7248
Batch[12269] - loss: 0.000751 best_pearson: 0.7248
Batch[12270] - loss: 0.000524 best_pearson: 0.7248
Batch[12271] - loss: 0.000887 best_pearson: 0.7248
Batch[12272] - loss: 0.000591 best_pearson: 0.7248
Batch[12273] - loss: 0.000443 best_pearson: 0.7248
Batch[12274] - loss: 0.000429 best_pearson: 0.7248
Batch[12275] - loss: 0.000842 best_pearson: 0.7248
Batch[12276] - loss: 0.000383 best_pearson: 0.7248
Batch[12277] - loss: 0.000737 best_pearson: 0.7248
Batch[12278] - loss: 0.000542 best_pearson: 0.7248
Batch[12279] - loss: 0.000259 best_pearson: 0.7248
Batch[12280] - loss: 0.000618 best_pearson: 0.7248
Batch[12281] - loss: 0.000554 best_pearson: 0.7248
Batch[12282] - loss: 0.000350 best_pearson: 0.7248
Batch[12283] - loss: 0.000461 best_pearson: 0.7248
Batch[12284] - loss: 0.000503 best_pearson: 0.7248
Batch[12285] - loss: 0.000529 best_pearson: 0.7248
Batch[12286] - loss: 0.000478 best_pearson: 0.7248
Batch[12287] - loss: 0.000408 best_pearson: 0.7248
Batch[12288] - loss: 0.000480 best_pearson: 0.7248
Batch[12289] - loss: 0.001162 best_pearson: 0.7248
Batch[12290] - loss: 0.000869 best_pearson: 0.7248
Batch[12291] - loss: 0.000536 best_pearson: 0.7248
Batch[12292] - loss: 0.000310 best_pearson: 0.7248
Batch[12293] - loss: 0.000525 best_pearson: 0.7248
Batch[12294] - loss: 0.000315 best_pearson: 0.7248
Batch[12295] - loss: 0.000616 best_pearson: 0.7248
Batch[12296] - loss: 0.000754 best_pearson: 0.7248
Batch[12297] - loss: 0.000570 best_pearson: 0.7248
Batch[12298] - loss: 0.000701 best_pearson: 0.7248
Batch[12299] - loss: 0.000787 best_pearson: 0.7248
Batch[12300] - loss: 0.000581 best_pearson: 0.7248

Evaluation - loss: 0.000048 pearson: 0.7029 

early stop by 1500 steps.
Batch[12301] - loss: 0.000629 best_pearson: 0.7248
Batch[12302] - loss: 0.000764 best_pearson: 0.7248
Batch[12303] - loss: 0.000471 best_pearson: 0.7248
Batch[12304] - loss: 0.001319 best_pearson: 0.7248
Batch[12305] - loss: 0.001094 best_pearson: 0.7248
Batch[12306] - loss: 0.000688 best_pearson: 0.7248
Batch[12307] - loss: 0.000428 best_pearson: 0.7248
Batch[12308] - loss: 0.000895 best_pearson: 0.7248
Batch[12309] - loss: 0.000531 best_pearson: 0.7248
Batch[12310] - loss: 0.000523 best_pearson: 0.7248
Batch[12311] - loss: 0.001183 best_pearson: 0.7248
Batch[12312] - loss: 0.000593 best_pearson: 0.7248
Batch[12313] - loss: 0.000745 best_pearson: 0.7248
Batch[12314] - loss: 0.000554 best_pearson: 0.7248
Batch[12315] - loss: 0.000504 best_pearson: 0.7248
Batch[12316] - loss: 0.000664 best_pearson: 0.7248
Batch[12317] - loss: 0.000748 best_pearson: 0.7248
Batch[12318] - loss: 0.000386 best_pearson: 0.7248
Batch[12319] - loss: 0.000533 best_pearson: 0.7248
Batch[12320] - loss: 0.000598 best_pearson: 0.7248
Batch[12321] - loss: 0.000701 best_pearson: 0.7248
Batch[12322] - loss: 0.000567 best_pearson: 0.7248
Batch[12323] - loss: 0.000428 best_pearson: 0.7248
Batch[12324] - loss: 0.000337 best_pearson: 0.7248
Batch[12325] - loss: 0.000619 best_pearson: 0.7248
Batch[12326] - loss: 0.000638 best_pearson: 0.7248
Batch[12327] - loss: 0.000465 best_pearson: 0.7248
Batch[12328] - loss: 0.000367 best_pearson: 0.7248
Batch[12329] - loss: 0.000575 best_pearson: 0.7248
Batch[12330] - loss: 0.000591 best_pearson: 0.7248
Batch[12331] - loss: 0.000582 best_pearson: 0.7248
Batch[12332] - loss: 0.000351 best_pearson: 0.7248
Batch[12333] - loss: 0.000589 best_pearson: 0.7248
Batch[12334] - loss: 0.001009 best_pearson: 0.7248
Batch[12335] - loss: 0.000681 best_pearson: 0.7248
Batch[12336] - loss: 0.000563 best_pearson: 0.7248
Batch[12337] - loss: 0.000693 best_pearson: 0.7248
Batch[12338] - loss: 0.000720 best_pearson: 0.7248
Batch[12339] - loss: 0.000749 best_pearson: 0.7248
Batch[12340] - loss: 0.000870 best_pearson: 0.7248
Batch[12341] - loss: 0.000631 best_pearson: 0.7248
Batch[12342] - loss: 0.000732 best_pearson: 0.7248
Batch[12343] - loss: 0.000678 best_pearson: 0.7248
Batch[12344] - loss: 0.000614 best_pearson: 0.7248
Batch[12345] - loss: 0.000405 best_pearson: 0.7248
Batch[12346] - loss: 0.000596 best_pearson: 0.7248
Batch[12347] - loss: 0.000988 best_pearson: 0.7248
Batch[12348] - loss: 0.000873 best_pearson: 0.7248
Batch[12349] - loss: 0.000381 best_pearson: 0.7248
Batch[12350] - loss: 0.000790 best_pearson: 0.7248
Batch[12351] - loss: 0.000856 best_pearson: 0.7248
Batch[12352] - loss: 0.000501 best_pearson: 0.7248
Batch[12353] - loss: 0.000347 best_pearson: 0.7248
Batch[12354] - loss: 0.000564 best_pearson: 0.7248
Batch[12355] - loss: 0.000874 best_pearson: 0.7248
Batch[12356] - loss: 0.000685 best_pearson: 0.7248
Batch[12357] - loss: 0.000464 best_pearson: 0.7248
Batch[12358] - loss: 0.001049 best_pearson: 0.7248
Batch[12359] - loss: 0.000890 best_pearson: 0.7248
Batch[12360] - loss: 0.000433 best_pearson: 0.7248
Batch[12361] - loss: 0.000765 best_pearson: 0.7248
Batch[12362] - loss: 0.000508 best_pearson: 0.7248
Batch[12363] - loss: 0.000711 best_pearson: 0.7248
Batch[12364] - loss: 0.000688 best_pearson: 0.7248
Batch[12365] - loss: 0.000739 best_pearson: 0.7248
Batch[12366] - loss: 0.000702 best_pearson: 0.7248
Batch[12367] - loss: 0.000812 best_pearson: 0.7248
Batch[12368] - loss: 0.000821 best_pearson: 0.7248
Batch[12369] - loss: 0.000587 best_pearson: 0.7248
Batch[12370] - loss: 0.000559 best_pearson: 0.7248
Batch[12371] - loss: 0.000652 best_pearson: 0.7248
Batch[12372] - loss: 0.000742 best_pearson: 0.7248
Batch[12373] - loss: 0.000577 best_pearson: 0.7248
Batch[12374] - loss: 0.000450 best_pearson: 0.7248
Batch[12375] - loss: 0.000626 best_pearson: 0.7248
Batch[12376] - loss: 0.000570 best_pearson: 0.7248
Batch[12377] - loss: 0.000945 best_pearson: 0.7248
Batch[12378] - loss: 0.000618 best_pearson: 0.7248
Batch[12379] - loss: 0.000390 best_pearson: 0.7248
Batch[12380] - loss: 0.000505 best_pearson: 0.7248
Batch[12381] - loss: 0.000829 best_pearson: 0.7248
Batch[12382] - loss: 0.000596 best_pearson: 0.7248
Batch[12383] - loss: 0.000327 best_pearson: 0.7248
Batch[12384] - loss: 0.000386 best_pearson: 0.7248
Batch[12385] - loss: 0.000761 best_pearson: 0.7248
Batch[12386] - loss: 0.000602 best_pearson: 0.7248
Batch[12387] - loss: 0.000696 best_pearson: 0.7248
Batch[12388] - loss: 0.000677 best_pearson: 0.7248
Batch[12389] - loss: 0.000970 best_pearson: 0.7248
Batch[12390] - loss: 0.000873 best_pearson: 0.7248
Batch[12391] - loss: 0.000516 best_pearson: 0.7248
Batch[12392] - loss: 0.000473 best_pearson: 0.7248
Batch[12393] - loss: 0.000544 best_pearson: 0.7248
Batch[12394] - loss: 0.000399 best_pearson: 0.7248
Batch[12395] - loss: 0.000642 best_pearson: 0.7248
Batch[12396] - loss: 0.000594 best_pearson: 0.7248
Batch[12397] - loss: 0.000724 best_pearson: 0.7248
Batch[12398] - loss: 0.000685 best_pearson: 0.7248
Batch[12399] - loss: 0.000484 best_pearson: 0.7248
Batch[12400] - loss: 0.000560 best_pearson: 0.7248

Evaluation - loss: 0.000049 pearson: 0.7001 

early stop by 1500 steps.
Batch[12401] - loss: 0.000568 best_pearson: 0.7248
Batch[12402] - loss: 0.000283 best_pearson: 0.7248
Batch[12403] - loss: 0.000443 best_pearson: 0.7248
Batch[12404] - loss: 0.000683 best_pearson: 0.7248
Batch[12405] - loss: 0.000660 best_pearson: 0.7248
Batch[12406] - loss: 0.000600 best_pearson: 0.7248
Batch[12407] - loss: 0.000363 best_pearson: 0.7248
Batch[12408] - loss: 0.000413 best_pearson: 0.7248
Batch[12409] - loss: 0.000544 best_pearson: 0.7248
Batch[12410] - loss: 0.000415 best_pearson: 0.7248
Batch[12411] - loss: 0.000281 best_pearson: 0.7248
Batch[12412] - loss: 0.000472 best_pearson: 0.7248
Batch[12413] - loss: 0.000497 best_pearson: 0.7248
Batch[12414] - loss: 0.000720 best_pearson: 0.7248
Batch[12415] - loss: 0.000613 best_pearson: 0.7248
Batch[12416] - loss: 0.000493 best_pearson: 0.7248
Batch[12417] - loss: 0.000516 best_pearson: 0.7248
Batch[12418] - loss: 0.000418 best_pearson: 0.7248
Batch[12419] - loss: 0.001025 best_pearson: 0.7248
Batch[12420] - loss: 0.000464 best_pearson: 0.7248
Batch[12421] - loss: 0.000396 best_pearson: 0.7248
Batch[12422] - loss: 0.000582 best_pearson: 0.7248
Batch[12423] - loss: 0.000432 best_pearson: 0.7248
Batch[12424] - loss: 0.000457 best_pearson: 0.7248
Batch[12425] - loss: 0.000388 best_pearson: 0.7248
Batch[12426] - loss: 0.000404 best_pearson: 0.7248
Batch[12427] - loss: 0.000557 best_pearson: 0.7248
Batch[12428] - loss: 0.000704 best_pearson: 0.7248
Batch[12429] - loss: 0.000918 best_pearson: 0.7248
Batch[12430] - loss: 0.000432 best_pearson: 0.7248
Batch[12431] - loss: 0.000414 best_pearson: 0.7248
Batch[12432] - loss: 0.000400 best_pearson: 0.7248
Batch[12433] - loss: 0.000561 best_pearson: 0.7248
Batch[12434] - loss: 0.000742 best_pearson: 0.7248
Batch[12435] - loss: 0.000426 best_pearson: 0.7248
Batch[12436] - loss: 0.000581 best_pearson: 0.7248
Batch[12437] - loss: 0.000541 best_pearson: 0.7248
Batch[12438] - loss: 0.000440 best_pearson: 0.7248
Batch[12439] - loss: 0.000503 best_pearson: 0.7248
Batch[12440] - loss: 0.000371 best_pearson: 0.7248
Batch[12441] - loss: 0.000507 best_pearson: 0.7248
Batch[12442] - loss: 0.000445 best_pearson: 0.7248
Batch[12443] - loss: 0.000524 best_pearson: 0.7248
Batch[12444] - loss: 0.000586 best_pearson: 0.7248
Batch[12445] - loss: 0.000434 best_pearson: 0.7248
Batch[12446] - loss: 0.000473 best_pearson: 0.7248
Batch[12447] - loss: 0.000627 best_pearson: 0.7248
Batch[12448] - loss: 0.000644 best_pearson: 0.7248
Batch[12449] - loss: 0.000345 best_pearson: 0.7248
Batch[12450] - loss: 0.000376 best_pearson: 0.7248
Batch[12451] - loss: 0.000628 best_pearson: 0.7248
Batch[12452] - loss: 0.000525 best_pearson: 0.7248
Batch[12453] - loss: 0.000559 best_pearson: 0.7248
Batch[12454] - loss: 0.000577 best_pearson: 0.7248
Batch[12455] - loss: 0.000598 best_pearson: 0.7248
Batch[12456] - loss: 0.000770 best_pearson: 0.7248
Batch[12457] - loss: 0.000623 best_pearson: 0.7248
Batch[12458] - loss: 0.000682 best_pearson: 0.7248
Batch[12459] - loss: 0.000333 best_pearson: 0.7248
Batch[12460] - loss: 0.000510 best_pearson: 0.7248
Batch[12461] - loss: 0.000732 best_pearson: 0.7248
Batch[12462] - loss: 0.000595 best_pearson: 0.7248
Batch[12463] - loss: 0.000641 best_pearson: 0.7248
Batch[12464] - loss: 0.000424 best_pearson: 0.7248
Batch[12465] - loss: 0.000457 best_pearson: 0.7248
Batch[12466] - loss: 0.000982 best_pearson: 0.7248
Batch[12467] - loss: 0.000675 best_pearson: 0.7248
Batch[12468] - loss: 0.000383 best_pearson: 0.7248
Batch[12469] - loss: 0.000527 best_pearson: 0.7248
Batch[12470] - loss: 0.000579 best_pearson: 0.7248
Batch[12471] - loss: 0.000472 best_pearson: 0.7248
Batch[12472] - loss: 0.000374 best_pearson: 0.7248
Batch[12473] - loss: 0.000502 best_pearson: 0.7248
Batch[12474] - loss: 0.000403 best_pearson: 0.7248
Batch[12475] - loss: 0.000510 best_pearson: 0.7248
Batch[12476] - loss: 0.000504 best_pearson: 0.7248
Batch[12477] - loss: 0.000582 best_pearson: 0.7248
Batch[12478] - loss: 0.000643 best_pearson: 0.7248
Batch[12479] - loss: 0.000351 best_pearson: 0.7248
Batch[12480] - loss: 0.000504 best_pearson: 0.7248
Batch[12481] - loss: 0.000408 best_pearson: 0.7248
Batch[12482] - loss: 0.000635 best_pearson: 0.7248
Batch[12483] - loss: 0.000396 best_pearson: 0.7248
Batch[12484] - loss: 0.000471 best_pearson: 0.7248
Batch[12485] - loss: 0.000328 best_pearson: 0.7248
Batch[12486] - loss: 0.000294 best_pearson: 0.7248
Batch[12487] - loss: 0.000424 best_pearson: 0.7248
Batch[12488] - loss: 0.000674 best_pearson: 0.7248
Batch[12489] - loss: 0.000808 best_pearson: 0.7248
Batch[12490] - loss: 0.000829 best_pearson: 0.7248
Batch[12491] - loss: 0.000570 best_pearson: 0.7248
Batch[12492] - loss: 0.000290 best_pearson: 0.7248
Batch[12493] - loss: 0.000354 best_pearson: 0.7248
Batch[12494] - loss: 0.000617 best_pearson: 0.7248
Batch[12495] - loss: 0.000645 best_pearson: 0.7248
Batch[12496] - loss: 0.000484 best_pearson: 0.7248
Batch[12497] - loss: 0.000492 best_pearson: 0.7248
Batch[12498] - loss: 0.000362 best_pearson: 0.7248
Batch[12499] - loss: 0.000481 best_pearson: 0.7248
Batch[12500] - loss: 0.000380 best_pearson: 0.7248

Evaluation - loss: 0.000048 pearson: 0.7038 

early stop by 1500 steps.
Batch[12501] - loss: 0.000546 best_pearson: 0.7248
Batch[12502] - loss: 0.000211 best_pearson: 0.7248
Batch[12503] - loss: 0.000372 best_pearson: 0.7248
Batch[12504] - loss: 0.000703 best_pearson: 0.7248
Batch[12505] - loss: 0.000464 best_pearson: 0.7248
Batch[12506] - loss: 0.000718 best_pearson: 0.7248
Batch[12507] - loss: 0.000493 best_pearson: 0.7248
Batch[12508] - loss: 0.000288 best_pearson: 0.7248
Batch[12509] - loss: 0.000374 best_pearson: 0.7248
Batch[12510] - loss: 0.000709 best_pearson: 0.7248
Batch[12511] - loss: 0.000365 best_pearson: 0.7248
Batch[12512] - loss: 0.000567 best_pearson: 0.7248
Batch[12513] - loss: 0.001293 best_pearson: 0.7248
Batch[12514] - loss: 0.000505 best_pearson: 0.7248
Batch[12515] - loss: 0.000504 best_pearson: 0.7248
Batch[12516] - loss: 0.000511 best_pearson: 0.7248
Batch[12517] - loss: 0.000485 best_pearson: 0.7248
Batch[12518] - loss: 0.000368 best_pearson: 0.7248
Batch[12519] - loss: 0.000408 best_pearson: 0.7248
Batch[12520] - loss: 0.000408 best_pearson: 0.7248
Batch[12521] - loss: 0.000421 best_pearson: 0.7248
Batch[12522] - loss: 0.000452 best_pearson: 0.7248
Batch[12523] - loss: 0.000603 best_pearson: 0.7248
Batch[12524] - loss: 0.000462 best_pearson: 0.7248
Batch[12525] - loss: 0.000603 best_pearson: 0.7248
Batch[12526] - loss: 0.000348 best_pearson: 0.7248
Batch[12527] - loss: 0.000577 best_pearson: 0.7248
Batch[12528] - loss: 0.000479 best_pearson: 0.7248
Batch[12529] - loss: 0.000507 best_pearson: 0.7248
Batch[12530] - loss: 0.000479 best_pearson: 0.7248
Batch[12531] - loss: 0.000448 best_pearson: 0.7248
Batch[12532] - loss: 0.000426 best_pearson: 0.7248
Batch[12533] - loss: 0.000442 best_pearson: 0.7248
Batch[12534] - loss: 0.000481 best_pearson: 0.7248
Batch[12535] - loss: 0.000390 best_pearson: 0.7248
Batch[12536] - loss: 0.000364 best_pearson: 0.7248
Batch[12537] - loss: 0.000446 best_pearson: 0.7248
Batch[12538] - loss: 0.000472 best_pearson: 0.7248
Batch[12539] - loss: 0.000530 best_pearson: 0.7248
Batch[12540] - loss: 0.000737 best_pearson: 0.7248
Batch[12541] - loss: 0.000473 best_pearson: 0.7248
Batch[12542] - loss: 0.000421 best_pearson: 0.7248
Batch[12543] - loss: 0.000672 best_pearson: 0.7248
Batch[12544] - loss: 0.000539 best_pearson: 0.7248
Batch[12545] - loss: 0.000597 best_pearson: 0.7248
Batch[12546] - loss: 0.000394 best_pearson: 0.7248
Batch[12547] - loss: 0.000350 best_pearson: 0.7248
Batch[12548] - loss: 0.000421 best_pearson: 0.7248
Batch[12549] - loss: 0.000311 best_pearson: 0.7248
Batch[12550] - loss: 0.000355 best_pearson: 0.7248
Batch[12551] - loss: 0.000514 best_pearson: 0.7248
Batch[12552] - loss: 0.000428 best_pearson: 0.7248
Batch[12553] - loss: 0.000395 best_pearson: 0.7248
Batch[12554] - loss: 0.000361 best_pearson: 0.7248
Batch[12555] - loss: 0.000470 best_pearson: 0.7248
Batch[12556] - loss: 0.000747 best_pearson: 0.7248
Batch[12557] - loss: 0.000594 best_pearson: 0.7248
Batch[12558] - loss: 0.000402 best_pearson: 0.7248
Batch[12559] - loss: 0.000394 best_pearson: 0.7248
Batch[12560] - loss: 0.000460 best_pearson: 0.7248
Batch[12561] - loss: 0.000386 best_pearson: 0.7248
Batch[12562] - loss: 0.000364 best_pearson: 0.7248
Batch[12563] - loss: 0.000765 best_pearson: 0.7248
Batch[12564] - loss: 0.000362 best_pearson: 0.7248
Batch[12565] - loss: 0.000523 best_pearson: 0.7248
Batch[12566] - loss: 0.000658 best_pearson: 0.7248
Batch[12567] - loss: 0.000512 best_pearson: 0.7248
Batch[12568] - loss: 0.000338 best_pearson: 0.7248
Batch[12569] - loss: 0.000380 best_pearson: 0.7248
Batch[12570] - loss: 0.000249 best_pearson: 0.7248
Batch[12571] - loss: 0.000288 best_pearson: 0.7248
Batch[12572] - loss: 0.000298 best_pearson: 0.7248
Batch[12573] - loss: 0.000351 best_pearson: 0.7248
Batch[12574] - loss: 0.000414 best_pearson: 0.7248
Batch[12575] - loss: 0.000255 best_pearson: 0.7248
Batch[12576] - loss: 0.000249 best_pearson: 0.7248
Batch[12577] - loss: 0.000315 best_pearson: 0.7248
Batch[12578] - loss: 0.000652 best_pearson: 0.7248
Batch[12579] - loss: 0.000250 best_pearson: 0.7248
Batch[12580] - loss: 0.000709 best_pearson: 0.7248
Batch[12581] - loss: 0.000676 best_pearson: 0.7248
Batch[12582] - loss: 0.000396 best_pearson: 0.7248
Batch[12583] - loss: 0.000456 best_pearson: 0.7248
Batch[12584] - loss: 0.000405 best_pearson: 0.7248
Batch[12585] - loss: 0.000445 best_pearson: 0.7248
Batch[12586] - loss: 0.000453 best_pearson: 0.7248
Batch[12587] - loss: 0.000574 best_pearson: 0.7248
Batch[12588] - loss: 0.000449 best_pearson: 0.7248
Batch[12589] - loss: 0.000492 best_pearson: 0.7248
Batch[12590] - loss: 0.000731 best_pearson: 0.7248
Batch[12591] - loss: 0.000546 best_pearson: 0.7248
Batch[12592] - loss: 0.000539 best_pearson: 0.7248
Batch[12593] - loss: 0.000483 best_pearson: 0.7248
Batch[12594] - loss: 0.000567 best_pearson: 0.7248
Batch[12595] - loss: 0.000446 best_pearson: 0.7248
Batch[12596] - loss: 0.000574 best_pearson: 0.7248
Batch[12597] - loss: 0.000313 best_pearson: 0.7248
Batch[12598] - loss: 0.000481 best_pearson: 0.7248
Batch[12599] - loss: 0.000657 best_pearson: 0.7248
Batch[12600] - loss: 0.000302 best_pearson: 0.7248

Evaluation - loss: 0.000049 pearson: 0.7036 

early stop by 1500 steps.
Batch[12601] - loss: 0.000494 best_pearson: 0.7248
Batch[12602] - loss: 0.000387 best_pearson: 0.7248
Batch[12603] - loss: 0.000592 best_pearson: 0.7248
Batch[12604] - loss: 0.000394 best_pearson: 0.7248
Batch[12605] - loss: 0.000459 best_pearson: 0.7248
Batch[12606] - loss: 0.000419 best_pearson: 0.7248
Batch[12607] - loss: 0.000614 best_pearson: 0.7248
Batch[12608] - loss: 0.000309 best_pearson: 0.7248
Batch[12609] - loss: 0.000352 best_pearson: 0.7248
Batch[12610] - loss: 0.000496 best_pearson: 0.7248
Batch[12611] - loss: 0.000441 best_pearson: 0.7248
Batch[12612] - loss: 0.000687 best_pearson: 0.7248
Batch[12613] - loss: 0.000408 best_pearson: 0.7248
Batch[12614] - loss: 0.000844 best_pearson: 0.7248
Batch[12615] - loss: 0.000614 best_pearson: 0.7248
Batch[12616] - loss: 0.000378 best_pearson: 0.7248
Batch[12617] - loss: 0.000385 best_pearson: 0.7248
Batch[12618] - loss: 0.000292 best_pearson: 0.7248
Batch[12619] - loss: 0.000323 best_pearson: 0.7248
Batch[12620] - loss: 0.000590 best_pearson: 0.7248
Batch[12621] - loss: 0.000474 best_pearson: 0.7248
Batch[12622] - loss: 0.000453 best_pearson: 0.7248
Batch[12623] - loss: 0.000309 best_pearson: 0.7248
Batch[12624] - loss: 0.000290 best_pearson: 0.7248
Batch[12625] - loss: 0.000588 best_pearson: 0.7248
Batch[12626] - loss: 0.000325 best_pearson: 0.7248
Batch[12627] - loss: 0.000410 best_pearson: 0.7248
Batch[12628] - loss: 0.000313 best_pearson: 0.7248
Batch[12629] - loss: 0.000489 best_pearson: 0.7248
Batch[12630] - loss: 0.000500 best_pearson: 0.7248
Batch[12631] - loss: 0.000349 best_pearson: 0.7248
Batch[12632] - loss: 0.000286 best_pearson: 0.7248
Batch[12633] - loss: 0.000184 best_pearson: 0.7248
Batch[12634] - loss: 0.000171 best_pearson: 0.7248
Batch[12635] - loss: 0.000650 best_pearson: 0.7248
Batch[12636] - loss: 0.000342 best_pearson: 0.7248
Batch[12637] - loss: 0.000340 best_pearson: 0.7248
Batch[12638] - loss: 0.000457 best_pearson: 0.7248
Batch[12639] - loss: 0.000574 best_pearson: 0.7248
Batch[12640] - loss: 0.000615 best_pearson: 0.7248
Batch[12641] - loss: 0.000472 best_pearson: 0.7248
Batch[12642] - loss: 0.000764 best_pearson: 0.7248
Batch[12643] - loss: 0.000540 best_pearson: 0.7248
Batch[12644] - loss: 0.000323 best_pearson: 0.7248
Batch[12645] - loss: 0.000256 best_pearson: 0.7248
Batch[12646] - loss: 0.000798 best_pearson: 0.7248
Batch[12647] - loss: 0.000491 best_pearson: 0.7248
Batch[12648] - loss: 0.000307 best_pearson: 0.7248
Batch[12649] - loss: 0.000467 best_pearson: 0.7248
Batch[12650] - loss: 0.000362 best_pearson: 0.7248
Batch[12651] - loss: 0.000738 best_pearson: 0.7248
Batch[12652] - loss: 0.000385 best_pearson: 0.7248
Batch[12653] - loss: 0.000393 best_pearson: 0.7248
Batch[12654] - loss: 0.000803 best_pearson: 0.7248
Batch[12655] - loss: 0.000788 best_pearson: 0.7248
Batch[12656] - loss: 0.000601 best_pearson: 0.7248
Batch[12657] - loss: 0.000444 best_pearson: 0.7248
Batch[12658] - loss: 0.000363 best_pearson: 0.7248
Batch[12659] - loss: 0.000253 best_pearson: 0.7248
Batch[12660] - loss: 0.000652 best_pearson: 0.7248
Batch[12661] - loss: 0.000481 best_pearson: 0.7248
Batch[12662] - loss: 0.000748 best_pearson: 0.7248
Batch[12663] - loss: 0.000576 best_pearson: 0.7248
Batch[12664] - loss: 0.000309 best_pearson: 0.7248
Batch[12665] - loss: 0.000404 best_pearson: 0.7248
Batch[12666] - loss: 0.000409 best_pearson: 0.7248
Batch[12667] - loss: 0.000627 best_pearson: 0.7248
Batch[12668] - loss: 0.000388 best_pearson: 0.7248
Batch[12669] - loss: 0.000318 best_pearson: 0.7248
Batch[12670] - loss: 0.000240 best_pearson: 0.7248
Batch[12671] - loss: 0.000448 best_pearson: 0.7248
Batch[12672] - loss: 0.000354 best_pearson: 0.7248
Batch[12673] - loss: 0.000462 best_pearson: 0.7248
Batch[12674] - loss: 0.000342 best_pearson: 0.7248
Batch[12675] - loss: 0.000363 best_pearson: 0.7248
Batch[12676] - loss: 0.000389 best_pearson: 0.7248
Batch[12677] - loss: 0.000797 best_pearson: 0.7248
Batch[12678] - loss: 0.000381 best_pearson: 0.7248
Batch[12679] - loss: 0.000332 best_pearson: 0.7248
Batch[12680] - loss: 0.000502 best_pearson: 0.7248
Batch[12681] - loss: 0.000443 best_pearson: 0.7248
Batch[12682] - loss: 0.000380 best_pearson: 0.7248
Batch[12683] - loss: 0.000359 best_pearson: 0.7248
Batch[12684] - loss: 0.000300 best_pearson: 0.7248
Batch[12685] - loss: 0.000677 best_pearson: 0.7248
Batch[12686] - loss: 0.000257 best_pearson: 0.7248
Batch[12687] - loss: 0.000398 best_pearson: 0.7248
Batch[12688] - loss: 0.000369 best_pearson: 0.7248
Batch[12689] - loss: 0.000527 best_pearson: 0.7248
Batch[12690] - loss: 0.000418 best_pearson: 0.7248
Batch[12691] - loss: 0.000309 best_pearson: 0.7248
Batch[12692] - loss: 0.000378 best_pearson: 0.7248
Batch[12693] - loss: 0.000574 best_pearson: 0.7248
Batch[12694] - loss: 0.000765 best_pearson: 0.7248
Batch[12695] - loss: 0.000236 best_pearson: 0.7248
Batch[12696] - loss: 0.000272 best_pearson: 0.7248
Batch[12697] - loss: 0.000494 best_pearson: 0.7248
Batch[12698] - loss: 0.000568 best_pearson: 0.7248
Batch[12699] - loss: 0.000288 best_pearson: 0.7248
Batch[12700] - loss: 0.000390 best_pearson: 0.7248

Evaluation - loss: 0.000050 pearson: 0.6983 

early stop by 1500 steps.
Batch[12701] - loss: 0.000369 best_pearson: 0.7248
Batch[12702] - loss: 0.000510 best_pearson: 0.7248
Batch[12703] - loss: 0.000272 best_pearson: 0.7248
Batch[12704] - loss: 0.000507 best_pearson: 0.7248
Batch[12705] - loss: 0.000689 best_pearson: 0.7248
Batch[12706] - loss: 0.000379 best_pearson: 0.7248
Batch[12707] - loss: 0.000252 best_pearson: 0.7248
Batch[12708] - loss: 0.000474 best_pearson: 0.7248
Batch[12709] - loss: 0.000382 best_pearson: 0.7248
Batch[12710] - loss: 0.000437 best_pearson: 0.7248
Batch[12711] - loss: 0.000789 best_pearson: 0.7248
Batch[12712] - loss: 0.000389 best_pearson: 0.7248
Batch[12713] - loss: 0.000668 best_pearson: 0.7248
Batch[12714] - loss: 0.000391 best_pearson: 0.7248
Batch[12715] - loss: 0.000269 best_pearson: 0.7248
Batch[12716] - loss: 0.000909 best_pearson: 0.7248
Batch[12717] - loss: 0.000717 best_pearson: 0.7248
Batch[12718] - loss: 0.000439 best_pearson: 0.7248
Batch[12719] - loss: 0.000527 best_pearson: 0.7248
Batch[12720] - loss: 0.000937 best_pearson: 0.7248
Batch[12721] - loss: 0.000580 best_pearson: 0.7248
Batch[12722] - loss: 0.000422 best_pearson: 0.7248
Batch[12723] - loss: 0.001103 best_pearson: 0.7248
Batch[12724] - loss: 0.000604 best_pearson: 0.7248
Batch[12725] - loss: 0.000733 best_pearson: 0.7248
Batch[12726] - loss: 0.000417 best_pearson: 0.7248
Batch[12727] - loss: 0.000668 best_pearson: 0.7248
Batch[12728] - loss: 0.000589 best_pearson: 0.7248
Batch[12729] - loss: 0.000901 best_pearson: 0.7248
Batch[12730] - loss: 0.000495 best_pearson: 0.7248
Batch[12731] - loss: 0.000304 best_pearson: 0.7248
Batch[12732] - loss: 0.000625 best_pearson: 0.7248
Batch[12733] - loss: 0.000361 best_pearson: 0.7248
Batch[12734] - loss: 0.000579 best_pearson: 0.7248
Batch[12735] - loss: 0.000548 best_pearson: 0.7248
Batch[12736] - loss: 0.000499 best_pearson: 0.7248
Batch[12737] - loss: 0.000563 best_pearson: 0.7248
Batch[12738] - loss: 0.000519 best_pearson: 0.7248
Batch[12739] - loss: 0.000465 best_pearson: 0.7248
Batch[12740] - loss: 0.000433 best_pearson: 0.7248
Batch[12741] - loss: 0.000367 best_pearson: 0.7248
Batch[12742] - loss: 0.000911 best_pearson: 0.7248
Batch[12743] - loss: 0.000367 best_pearson: 0.7248
Batch[12744] - loss: 0.000562 best_pearson: 0.7248
Batch[12745] - loss: 0.000570 best_pearson: 0.7248
Batch[12746] - loss: 0.000536 best_pearson: 0.7248
Batch[12747] - loss: 0.000431 best_pearson: 0.7248
Batch[12748] - loss: 0.000378 best_pearson: 0.7248
Batch[12749] - loss: 0.000652 best_pearson: 0.7248
Batch[12750] - loss: 0.000482 best_pearson: 0.7248
Batch[12751] - loss: 0.000366 best_pearson: 0.7248
Batch[12752] - loss: 0.000359 best_pearson: 0.7248
Batch[12753] - loss: 0.000472 best_pearson: 0.7248
Batch[12754] - loss: 0.000800 best_pearson: 0.7248
Batch[12755] - loss: 0.000441 best_pearson: 0.7248
Batch[12756] - loss: 0.000714 best_pearson: 0.7248
Batch[12757] - loss: 0.000660 best_pearson: 0.7248
Batch[12758] - loss: 0.000825 best_pearson: 0.7248
Batch[12759] - loss: 0.000502 best_pearson: 0.7248
Batch[12760] - loss: 0.000551 best_pearson: 0.7248
Batch[12761] - loss: 0.000632 best_pearson: 0.7248
Batch[12762] - loss: 0.000636 best_pearson: 0.7248
Batch[12763] - loss: 0.000396 best_pearson: 0.7248
Batch[12764] - loss: 0.000541 best_pearson: 0.7248
Batch[12765] - loss: 0.001101 best_pearson: 0.7248
Batch[12766] - loss: 0.000449 best_pearson: 0.7248
Batch[12767] - loss: 0.000439 best_pearson: 0.7248
Batch[12768] - loss: 0.000304 best_pearson: 0.7248
Batch[12769] - loss: 0.000532 best_pearson: 0.7248
Batch[12770] - loss: 0.000834 best_pearson: 0.7248
Batch[12771] - loss: 0.000441 best_pearson: 0.7248
Batch[12772] - loss: 0.000447 best_pearson: 0.7248
Batch[12773] - loss: 0.000761 best_pearson: 0.7248
Batch[12774] - loss: 0.000641 best_pearson: 0.7248
Batch[12775] - loss: 0.000604 best_pearson: 0.7248
Batch[12776] - loss: 0.000558 best_pearson: 0.7248
Batch[12777] - loss: 0.000933 best_pearson: 0.7248
Batch[12778] - loss: 0.000454 best_pearson: 0.7248
Batch[12779] - loss: 0.000522 best_pearson: 0.7248
Batch[12780] - loss: 0.000648 best_pearson: 0.7248
Batch[12781] - loss: 0.001179 best_pearson: 0.7248
Batch[12782] - loss: 0.000683 best_pearson: 0.7248
Batch[12783] - loss: 0.000406 best_pearson: 0.7248
Batch[12784] - loss: 0.000656 best_pearson: 0.7248
Batch[12785] - loss: 0.000532 best_pearson: 0.7248
Batch[12786] - loss: 0.000580 best_pearson: 0.7248
Batch[12787] - loss: 0.000582 best_pearson: 0.7248
Batch[12788] - loss: 0.000973 best_pearson: 0.7248
Batch[12789] - loss: 0.000519 best_pearson: 0.7248
Batch[12790] - loss: 0.000463 best_pearson: 0.7248
Batch[12791] - loss: 0.000599 best_pearson: 0.7248
Batch[12792] - loss: 0.000534 best_pearson: 0.7248
Batch[12793] - loss: 0.000898 best_pearson: 0.7248
Batch[12794] - loss: 0.000414 best_pearson: 0.7248
Batch[12795] - loss: 0.000652 best_pearson: 0.7248
Batch[12796] - loss: 0.000448 best_pearson: 0.7248
Batch[12797] - loss: 0.000508 best_pearson: 0.7248
Batch[12798] - loss: 0.000767 best_pearson: 0.7248
Batch[12799] - loss: 0.000414 best_pearson: 0.7248
Batch[12800] - loss: 0.000735 best_pearson: 0.7248

Evaluation - loss: 0.000049 pearson: 0.6996 

early stop by 1500 steps.
Batch[12801] - loss: 0.000827 best_pearson: 0.7248
Batch[12802] - loss: 0.000408 best_pearson: 0.7248
Batch[12803] - loss: 0.000815 best_pearson: 0.7248
Batch[12804] - loss: 0.000483 best_pearson: 0.7248
Batch[12805] - loss: 0.000680 best_pearson: 0.7248
Batch[12806] - loss: 0.000256 best_pearson: 0.7248
Batch[12807] - loss: 0.000394 best_pearson: 0.7248
Batch[12808] - loss: 0.000619 best_pearson: 0.7248
Batch[12809] - loss: 0.000775 best_pearson: 0.7248
Batch[12810] - loss: 0.000490 best_pearson: 0.7248
Batch[12811] - loss: 0.000508 best_pearson: 0.7248
Batch[12812] - loss: 0.000540 best_pearson: 0.7248
Batch[12813] - loss: 0.000750 best_pearson: 0.7248
Batch[12814] - loss: 0.000535 best_pearson: 0.7248
Batch[12815] - loss: 0.000349 best_pearson: 0.7248
Batch[12816] - loss: 0.000323 best_pearson: 0.7248
Batch[12817] - loss: 0.000929 best_pearson: 0.7248
Batch[12818] - loss: 0.000427 best_pearson: 0.7248
Batch[12819] - loss: 0.000472 best_pearson: 0.7248
Batch[12820] - loss: 0.000692 best_pearson: 0.7248
Batch[12821] - loss: 0.000380 best_pearson: 0.7248
Batch[12822] - loss: 0.000464 best_pearson: 0.7248
Batch[12823] - loss: 0.000591 best_pearson: 0.7248
Batch[12824] - loss: 0.000570 best_pearson: 0.7248
Batch[12825] - loss: 0.000838 best_pearson: 0.7248
Batch[12826] - loss: 0.000364 best_pearson: 0.7248
Batch[12827] - loss: 0.000763 best_pearson: 0.7248
Batch[12828] - loss: 0.000830 best_pearson: 0.7248
Batch[12829] - loss: 0.000515 best_pearson: 0.7248
Batch[12830] - loss: 0.000632 best_pearson: 0.7248
Batch[12831] - loss: 0.000598 best_pearson: 0.7248
Batch[12832] - loss: 0.000661 best_pearson: 0.7248
Batch[12833] - loss: 0.000525 best_pearson: 0.7248
Batch[12834] - loss: 0.001062 best_pearson: 0.7248
Batch[12835] - loss: 0.000454 best_pearson: 0.7248
Batch[12836] - loss: 0.000334 best_pearson: 0.7248
Batch[12837] - loss: 0.000720 best_pearson: 0.7248
Batch[12838] - loss: 0.000509 best_pearson: 0.7248
Batch[12839] - loss: 0.000618 best_pearson: 0.7248
Batch[12840] - loss: 0.000541 best_pearson: 0.7248
Batch[12841] - loss: 0.000322 best_pearson: 0.7248
Batch[12842] - loss: 0.000731 best_pearson: 0.7248
Batch[12843] - loss: 0.000900 best_pearson: 0.7248
Batch[12844] - loss: 0.000479 best_pearson: 0.7248
Batch[12845] - loss: 0.000691 best_pearson: 0.7248
Batch[12846] - loss: 0.000866 best_pearson: 0.7248
Batch[12847] - loss: 0.000406 best_pearson: 0.7248
Batch[12848] - loss: 0.000648 best_pearson: 0.7248
Batch[12849] - loss: 0.000393 best_pearson: 0.7248
Batch[12850] - loss: 0.000934 best_pearson: 0.7248
Batch[12851] - loss: 0.000612 best_pearson: 0.7248
Batch[12852] - loss: 0.000427 best_pearson: 0.7248
Batch[12853] - loss: 0.000523 best_pearson: 0.7248
Batch[12854] - loss: 0.000548 best_pearson: 0.7248
Batch[12855] - loss: 0.000518 best_pearson: 0.7248
Batch[12856] - loss: 0.000403 best_pearson: 0.7248
Batch[12857] - loss: 0.000461 best_pearson: 0.7248
Batch[12858] - loss: 0.000641 best_pearson: 0.7248
Batch[12859] - loss: 0.000299 best_pearson: 0.7248
Batch[12860] - loss: 0.000552 best_pearson: 0.7248
Batch[12861] - loss: 0.000706 best_pearson: 0.7248
Batch[12862] - loss: 0.000567 best_pearson: 0.7248
Batch[12863] - loss: 0.000506 best_pearson: 0.7248
Batch[12864] - loss: 0.000578 best_pearson: 0.7248
Batch[12865] - loss: 0.000798 best_pearson: 0.7248
Batch[12866] - loss: 0.000483 best_pearson: 0.7248
Batch[12867] - loss: 0.000460 best_pearson: 0.7248
Batch[12868] - loss: 0.000581 best_pearson: 0.7248
Batch[12869] - loss: 0.000829 best_pearson: 0.7248
Batch[12870] - loss: 0.000556 best_pearson: 0.7248
Batch[12871] - loss: 0.001009 best_pearson: 0.7248
Batch[12872] - loss: 0.000470 best_pearson: 0.7248
Batch[12873] - loss: 0.000688 best_pearson: 0.7248
Batch[12874] - loss: 0.000931 best_pearson: 0.7248
Batch[12875] - loss: 0.000361 best_pearson: 0.7248
Batch[12876] - loss: 0.000725 best_pearson: 0.7248
Batch[12877] - loss: 0.000556 best_pearson: 0.7248
Batch[12878] - loss: 0.000353 best_pearson: 0.7248
Batch[12879] - loss: 0.000781 best_pearson: 0.7248
Batch[12880] - loss: 0.000543 best_pearson: 0.7248
Batch[12881] - loss: 0.000341 best_pearson: 0.7248
Batch[12882] - loss: 0.000546 best_pearson: 0.7248
Batch[12883] - loss: 0.000394 best_pearson: 0.7248
Batch[12884] - loss: 0.000854 best_pearson: 0.7248
Batch[12885] - loss: 0.000413 best_pearson: 0.7248
Batch[12886] - loss: 0.000902 best_pearson: 0.7248
Batch[12887] - loss: 0.000709 best_pearson: 0.7248
Batch[12888] - loss: 0.000515 best_pearson: 0.7248
Batch[12889] - loss: 0.000623 best_pearson: 0.7248
Batch[12890] - loss: 0.000415 best_pearson: 0.7248
Batch[12891] - loss: 0.000440 best_pearson: 0.7248
Batch[12892] - loss: 0.000503 best_pearson: 0.7248
Batch[12893] - loss: 0.000513 best_pearson: 0.7248
Batch[12894] - loss: 0.000635 best_pearson: 0.7248
Batch[12895] - loss: 0.000293 best_pearson: 0.7248
Batch[12896] - loss: 0.000620 best_pearson: 0.7248
Batch[12897] - loss: 0.000300 best_pearson: 0.7248
Batch[12898] - loss: 0.000677 best_pearson: 0.7248
Batch[12899] - loss: 0.000460 best_pearson: 0.7248
Batch[12900] - loss: 0.000474 best_pearson: 0.7248

Evaluation - loss: 0.000049 pearson: 0.7004 

early stop by 1500 steps.
Batch[12901] - loss: 0.000636 best_pearson: 0.7248
Batch[12902] - loss: 0.000450 best_pearson: 0.7248
Batch[12903] - loss: 0.000477 best_pearson: 0.7248
Batch[12904] - loss: 0.000431 best_pearson: 0.7248
Batch[12905] - loss: 0.000306 best_pearson: 0.7248
Batch[12906] - loss: 0.000434 best_pearson: 0.7248
Batch[12907] - loss: 0.000289 best_pearson: 0.7248
Batch[12908] - loss: 0.000459 best_pearson: 0.7248
Batch[12909] - loss: 0.000343 best_pearson: 0.7248
Batch[12910] - loss: 0.000443 best_pearson: 0.7248
Batch[12911] - loss: 0.000569 best_pearson: 0.7248
Batch[12912] - loss: 0.000332 best_pearson: 0.7248
Batch[12913] - loss: 0.000263 best_pearson: 0.7248
Batch[12914] - loss: 0.000700 best_pearson: 0.7248
Batch[12915] - loss: 0.000448 best_pearson: 0.7248
Batch[12916] - loss: 0.000562 best_pearson: 0.7248
Batch[12917] - loss: 0.000325 best_pearson: 0.7248
Batch[12918] - loss: 0.000728 best_pearson: 0.7248
Batch[12919] - loss: 0.000920 best_pearson: 0.7248
Batch[12920] - loss: 0.000723 best_pearson: 0.7248
Batch[12921] - loss: 0.000239 best_pearson: 0.7248
Batch[12922] - loss: 0.000606 best_pearson: 0.7248
Batch[12923] - loss: 0.001155 best_pearson: 0.7248
Batch[12924] - loss: 0.000633 best_pearson: 0.7248
Batch[12925] - loss: 0.000331 best_pearson: 0.7248
Batch[12926] - loss: 0.000699 best_pearson: 0.7248
Batch[12927] - loss: 0.000895 best_pearson: 0.7248
Batch[12928] - loss: 0.001232 best_pearson: 0.7248
Batch[12929] - loss: 0.000542 best_pearson: 0.7248
Batch[12930] - loss: 0.000573 best_pearson: 0.7248
Batch[12931] - loss: 0.001048 best_pearson: 0.7248
Batch[12932] - loss: 0.000384 best_pearson: 0.7248
Batch[12933] - loss: 0.000347 best_pearson: 0.7248
Batch[12934] - loss: 0.000417 best_pearson: 0.7248
Batch[12935] - loss: 0.000314 best_pearson: 0.7248
Batch[12936] - loss: 0.000404 best_pearson: 0.7248
Batch[12937] - loss: 0.000834 best_pearson: 0.7248
Batch[12938] - loss: 0.000413 best_pearson: 0.7248
Batch[12939] - loss: 0.000529 best_pearson: 0.7248
Batch[12940] - loss: 0.000324 best_pearson: 0.7248
Batch[12941] - loss: 0.000335 best_pearson: 0.7248
Batch[12942] - loss: 0.000566 best_pearson: 0.7248
Batch[12943] - loss: 0.000371 best_pearson: 0.7248
Batch[12944] - loss: 0.000763 best_pearson: 0.7248
Batch[12945] - loss: 0.000416 best_pearson: 0.7248
Batch[12946] - loss: 0.000566 best_pearson: 0.7248
Batch[12947] - loss: 0.000602 best_pearson: 0.7248
Batch[12948] - loss: 0.000524 best_pearson: 0.7248
Batch[12949] - loss: 0.000521 best_pearson: 0.7248
Batch[12950] - loss: 0.000509 best_pearson: 0.7248
Batch[12951] - loss: 0.000629 best_pearson: 0.7248
Batch[12952] - loss: 0.000898 best_pearson: 0.7248
Batch[12953] - loss: 0.000692 best_pearson: 0.7248
Batch[12954] - loss: 0.000390 best_pearson: 0.7248
Batch[12955] - loss: 0.000419 best_pearson: 0.7248
Batch[12956] - loss: 0.000746 best_pearson: 0.7248
Batch[12957] - loss: 0.000568 best_pearson: 0.7248
Batch[12958] - loss: 0.000846 best_pearson: 0.7248
Batch[12959] - loss: 0.000613 best_pearson: 0.7248
Batch[12960] - loss: 0.000333 best_pearson: 0.7248
Batch[12961] - loss: 0.000614 best_pearson: 0.7248
Batch[12962] - loss: 0.000518 best_pearson: 0.7248
Batch[12963] - loss: 0.000435 best_pearson: 0.7248
Batch[12964] - loss: 0.000480 best_pearson: 0.7248
Batch[12965] - loss: 0.000245 best_pearson: 0.7248
Batch[12966] - loss: 0.000601 best_pearson: 0.7248
Batch[12967] - loss: 0.000310 best_pearson: 0.7248
Batch[12968] - loss: 0.000759 best_pearson: 0.7248
Batch[12969] - loss: 0.000423 best_pearson: 0.7248
Batch[12970] - loss: 0.000384 best_pearson: 0.7248
Batch[12971] - loss: 0.000634 best_pearson: 0.7248
Batch[12972] - loss: 0.000476 best_pearson: 0.7248
Batch[12973] - loss: 0.000601 best_pearson: 0.7248
Batch[12974] - loss: 0.000573 best_pearson: 0.7248
Batch[12975] - loss: 0.000207 best_pearson: 0.7248
Batch[12976] - loss: 0.000377 best_pearson: 0.7248
Batch[12977] - loss: 0.000428 best_pearson: 0.7248
Batch[12978] - loss: 0.000394 best_pearson: 0.7248
Batch[12979] - loss: 0.000546 best_pearson: 0.7248
Batch[12980] - loss: 0.000597 best_pearson: 0.7248
Batch[12981] - loss: 0.000392 best_pearson: 0.7248
Batch[12982] - loss: 0.000366 best_pearson: 0.7248
Batch[12983] - loss: 0.000468 best_pearson: 0.7248
Batch[12984] - loss: 0.000697 best_pearson: 0.7248
Batch[12985] - loss: 0.000581 best_pearson: 0.7248
Batch[12986] - loss: 0.000315 best_pearson: 0.7248
Batch[12987] - loss: 0.000523 best_pearson: 0.7248
Batch[12988] - loss: 0.000620 best_pearson: 0.7248
Batch[12989] - loss: 0.000614 best_pearson: 0.7248
Batch[12990] - loss: 0.000430 best_pearson: 0.7248
Batch[12991] - loss: 0.000802 best_pearson: 0.7248
Batch[12992] - loss: 0.000492 best_pearson: 0.7248
Batch[12993] - loss: 0.001011 best_pearson: 0.7248
Batch[12994] - loss: 0.000638 best_pearson: 0.7248
Batch[12995] - loss: 0.000383 best_pearson: 0.7248
Batch[12996] - loss: 0.000825 best_pearson: 0.7248
Batch[12997] - loss: 0.000775 best_pearson: 0.7248
Batch[12998] - loss: 0.000358 best_pearson: 0.7248
Batch[12999] - loss: 0.000476 best_pearson: 0.7248
Batch[13000] - loss: 0.000480 best_pearson: 0.7248

Evaluation - loss: 0.000050 pearson: 0.6996 

early stop by 1500 steps.
Batch[13001] - loss: 0.000484 best_pearson: 0.7248
Batch[13002] - loss: 0.000474 best_pearson: 0.7248
Batch[13003] - loss: 0.000305 best_pearson: 0.7248
Batch[13004] - loss: 0.000468 best_pearson: 0.7248
Batch[13005] - loss: 0.000822 best_pearson: 0.7248
Batch[13006] - loss: 0.000880 best_pearson: 0.7248
Batch[13007] - loss: 0.000348 best_pearson: 0.7248
Batch[13008] - loss: 0.000932 best_pearson: 0.7248
Batch[13009] - loss: 0.000788 best_pearson: 0.7248
Batch[13010] - loss: 0.000447 best_pearson: 0.7248
Batch[13011] - loss: 0.000316 best_pearson: 0.7248
Batch[13012] - loss: 0.000696 best_pearson: 0.7248
Batch[13013] - loss: 0.000573 best_pearson: 0.7248
Batch[13014] - loss: 0.000432 best_pearson: 0.7248
Batch[13015] - loss: 0.000377 best_pearson: 0.7248
Batch[13016] - loss: 0.000726 best_pearson: 0.7248
Batch[13017] - loss: 0.000429 best_pearson: 0.7248
Batch[13018] - loss: 0.000584 best_pearson: 0.7248
Batch[13019] - loss: 0.000866 best_pearson: 0.7248
Batch[13020] - loss: 0.000558 best_pearson: 0.7248
Batch[13021] - loss: 0.000393 best_pearson: 0.7248
Batch[13022] - loss: 0.000625 best_pearson: 0.7248
Batch[13023] - loss: 0.000735 best_pearson: 0.7248
Batch[13024] - loss: 0.000582 best_pearson: 0.7248
Batch[13025] - loss: 0.000441 best_pearson: 0.7248
Batch[13026] - loss: 0.000365 best_pearson: 0.7248
Batch[13027] - loss: 0.001112 best_pearson: 0.7248
Batch[13028] - loss: 0.000590 best_pearson: 0.7248
Batch[13029] - loss: 0.000574 best_pearson: 0.7248
Batch[13030] - loss: 0.000542 best_pearson: 0.7248
Batch[13031] - loss: 0.000787 best_pearson: 0.7248
Batch[13032] - loss: 0.000673 best_pearson: 0.7248
Batch[13033] - loss: 0.000461 best_pearson: 0.7248
Batch[13034] - loss: 0.000417 best_pearson: 0.7248
Batch[13035] - loss: 0.000512 best_pearson: 0.7248
Batch[13036] - loss: 0.000600 best_pearson: 0.7248
Batch[13037] - loss: 0.000480 best_pearson: 0.7248
Batch[13038] - loss: 0.000890 best_pearson: 0.7248
Batch[13039] - loss: 0.000744 best_pearson: 0.7248
Batch[13040] - loss: 0.000307 best_pearson: 0.7248
Batch[13041] - loss: 0.000246 best_pearson: 0.7248
Batch[13042] - loss: 0.000345 best_pearson: 0.7248
Batch[13043] - loss: 0.000380 best_pearson: 0.7248
Batch[13044] - loss: 0.000491 best_pearson: 0.7248
Batch[13045] - loss: 0.000342 best_pearson: 0.7248
Batch[13046] - loss: 0.000269 best_pearson: 0.7248
Batch[13047] - loss: 0.000572 best_pearson: 0.7248
Batch[13048] - loss: 0.000681 best_pearson: 0.7248
Batch[13049] - loss: 0.000627 best_pearson: 0.7248
Batch[13050] - loss: 0.000611 best_pearson: 0.7248
Batch[13051] - loss: 0.000421 best_pearson: 0.7248
Batch[13052] - loss: 0.000546 best_pearson: 0.7248
Batch[13053] - loss: 0.000590 best_pearson: 0.7248
Batch[13054] - loss: 0.000769 best_pearson: 0.7248
Batch[13055] - loss: 0.000558 best_pearson: 0.7248
Batch[13056] - loss: 0.000523 best_pearson: 0.7248
Batch[13057] - loss: 0.000630 best_pearson: 0.7248
Batch[13058] - loss: 0.000698 best_pearson: 0.7248
Batch[13059] - loss: 0.000615 best_pearson: 0.7248
Batch[13060] - loss: 0.001029 best_pearson: 0.7248
Batch[13061] - loss: 0.001160 best_pearson: 0.7248
Batch[13062] - loss: 0.000612 best_pearson: 0.7248
Batch[13063] - loss: 0.000273 best_pearson: 0.7248
Batch[13064] - loss: 0.000527 best_pearson: 0.7248
Batch[13065] - loss: 0.000498 best_pearson: 0.7248
Batch[13066] - loss: 0.000584 best_pearson: 0.7248
Batch[13067] - loss: 0.000463 best_pearson: 0.7248
Batch[13068] - loss: 0.000620 best_pearson: 0.7248
Batch[13069] - loss: 0.000699 best_pearson: 0.7248
Batch[13070] - loss: 0.000331 best_pearson: 0.7248
Batch[13071] - loss: 0.000441 best_pearson: 0.7248
Batch[13072] - loss: 0.000496 best_pearson: 0.7248
Batch[13073] - loss: 0.000766 best_pearson: 0.7248
Batch[13074] - loss: 0.000511 best_pearson: 0.7248
Batch[13075] - loss: 0.000524 best_pearson: 0.7248
Batch[13076] - loss: 0.000713 best_pearson: 0.7248
Batch[13077] - loss: 0.000448 best_pearson: 0.7248
Batch[13078] - loss: 0.000601 best_pearson: 0.7248
Batch[13079] - loss: 0.000615 best_pearson: 0.7248
Batch[13080] - loss: 0.000692 best_pearson: 0.7248
Batch[13081] - loss: 0.000424 best_pearson: 0.7248
Batch[13082] - loss: 0.000703 best_pearson: 0.7248
Batch[13083] - loss: 0.000437 best_pearson: 0.7248
Batch[13084] - loss: 0.000676 best_pearson: 0.7248
Batch[13085] - loss: 0.000589 best_pearson: 0.7248
Batch[13086] - loss: 0.000645 best_pearson: 0.7248
Batch[13087] - loss: 0.000332 best_pearson: 0.7248
Batch[13088] - loss: 0.000295 best_pearson: 0.7248
Batch[13089] - loss: 0.000604 best_pearson: 0.7248
Batch[13090] - loss: 0.000663 best_pearson: 0.7248
Batch[13091] - loss: 0.000695 best_pearson: 0.7248
Batch[13092] - loss: 0.000447 best_pearson: 0.7248
Batch[13093] - loss: 0.000447 best_pearson: 0.7248
Batch[13094] - loss: 0.000768 best_pearson: 0.7248
Batch[13095] - loss: 0.000429 best_pearson: 0.7248
Batch[13096] - loss: 0.000495 best_pearson: 0.7248
Batch[13097] - loss: 0.000457 best_pearson: 0.7248
Batch[13098] - loss: 0.000671 best_pearson: 0.7248
Batch[13099] - loss: 0.000654 best_pearson: 0.7248
Batch[13100] - loss: 0.000292 best_pearson: 0.7248

Evaluation - loss: 0.000049 pearson: 0.6974 

early stop by 1500 steps.
Batch[13101] - loss: 0.000606 best_pearson: 0.7248
Batch[13102] - loss: 0.000466 best_pearson: 0.7248
Batch[13103] - loss: 0.000581 best_pearson: 0.7248
Batch[13104] - loss: 0.000721 best_pearson: 0.7248
Batch[13105] - loss: 0.000628 best_pearson: 0.7248
Batch[13106] - loss: 0.000580 best_pearson: 0.7248
Batch[13107] - loss: 0.000556 best_pearson: 0.7248
Batch[13108] - loss: 0.000458 best_pearson: 0.7248
Batch[13109] - loss: 0.000428 best_pearson: 0.7248
Batch[13110] - loss: 0.000508 best_pearson: 0.7248
Batch[13111] - loss: 0.000648 best_pearson: 0.7248
Batch[13112] - loss: 0.000455 best_pearson: 0.7248
Batch[13113] - loss: 0.000658 best_pearson: 0.7248
Batch[13114] - loss: 0.000647 best_pearson: 0.7248
Batch[13115] - loss: 0.000324 best_pearson: 0.7248
Batch[13116] - loss: 0.000449 best_pearson: 0.7248
Batch[13117] - loss: 0.000344 best_pearson: 0.7248
Batch[13118] - loss: 0.000485 best_pearson: 0.7248
Batch[13119] - loss: 0.000304 best_pearson: 0.7248
Batch[13120] - loss: 0.000578 best_pearson: 0.7248
Batch[13121] - loss: 0.000603 best_pearson: 0.7248
Batch[13122] - loss: 0.000827 best_pearson: 0.7248
Batch[13123] - loss: 0.000740 best_pearson: 0.7248
Batch[13124] - loss: 0.000543 best_pearson: 0.7248
Batch[13125] - loss: 0.000505 best_pearson: 0.7248
Batch[13126] - loss: 0.000395 best_pearson: 0.7248
Batch[13127] - loss: 0.000721 best_pearson: 0.7248
Batch[13128] - loss: 0.000419 best_pearson: 0.7248
Batch[13129] - loss: 0.000466 best_pearson: 0.7248
Batch[13130] - loss: 0.000383 best_pearson: 0.7248
Batch[13131] - loss: 0.000561 best_pearson: 0.7248
Batch[13132] - loss: 0.000346 best_pearson: 0.7248
Batch[13133] - loss: 0.000596 best_pearson: 0.7248
Batch[13134] - loss: 0.000803 best_pearson: 0.7248
Batch[13135] - loss: 0.000556 best_pearson: 0.7248
Batch[13136] - loss: 0.000324 best_pearson: 0.7248
Batch[13137] - loss: 0.000332 best_pearson: 0.7248
Batch[13138] - loss: 0.000436 best_pearson: 0.7248
Batch[13139] - loss: 0.000385 best_pearson: 0.7248
Batch[13140] - loss: 0.000497 best_pearson: 0.7248
Batch[13141] - loss: 0.000358 best_pearson: 0.7248
Batch[13142] - loss: 0.000843 best_pearson: 0.7248
Batch[13143] - loss: 0.000387 best_pearson: 0.7248
Batch[13144] - loss: 0.000595 best_pearson: 0.7248
Batch[13145] - loss: 0.000346 best_pearson: 0.7248
Batch[13146] - loss: 0.000598 best_pearson: 0.7248
Batch[13147] - loss: 0.000520 best_pearson: 0.7248
Batch[13148] - loss: 0.000857 best_pearson: 0.7248
Batch[13149] - loss: 0.000568 best_pearson: 0.7248
Batch[13150] - loss: 0.000481 best_pearson: 0.7248
Batch[13151] - loss: 0.000323 best_pearson: 0.7248
Batch[13152] - loss: 0.000850 best_pearson: 0.7248
Batch[13153] - loss: 0.000694 best_pearson: 0.7248
Batch[13154] - loss: 0.000845 best_pearson: 0.7248
Batch[13155] - loss: 0.000496 best_pearson: 0.7248
Batch[13156] - loss: 0.000519 best_pearson: 0.7248
Batch[13157] - loss: 0.000445 best_pearson: 0.7248
Batch[13158] - loss: 0.000548 best_pearson: 0.7248
Batch[13159] - loss: 0.000423 best_pearson: 0.7248
Batch[13160] - loss: 0.000712 best_pearson: 0.7248
Batch[13161] - loss: 0.000566 best_pearson: 0.7248
Batch[13162] - loss: 0.000785 best_pearson: 0.7248
Batch[13163] - loss: 0.000426 best_pearson: 0.7248
Batch[13164] - loss: 0.000489 best_pearson: 0.7248
Batch[13165] - loss: 0.000548 best_pearson: 0.7248
Batch[13166] - loss: 0.000629 best_pearson: 0.7248
Batch[13167] - loss: 0.000217 best_pearson: 0.7248
Batch[13168] - loss: 0.000617 best_pearson: 0.7248
Batch[13169] - loss: 0.000441 best_pearson: 0.7248
Batch[13170] - loss: 0.000400 best_pearson: 0.7248
Batch[13171] - loss: 0.000427 best_pearson: 0.7248
Batch[13172] - loss: 0.000471 best_pearson: 0.7248
Batch[13173] - loss: 0.000394 best_pearson: 0.7248
Batch[13174] - loss: 0.000597 best_pearson: 0.7248
Batch[13175] - loss: 0.000511 best_pearson: 0.7248
Batch[13176] - loss: 0.000442 best_pearson: 0.7248
Batch[13177] - loss: 0.000555 best_pearson: 0.7248
Batch[13178] - loss: 0.000551 best_pearson: 0.7248
Batch[13179] - loss: 0.000282 best_pearson: 0.7248
Batch[13180] - loss: 0.000523 best_pearson: 0.7248
Batch[13181] - loss: 0.000539 best_pearson: 0.7248
Batch[13182] - loss: 0.000247 best_pearson: 0.7248
Batch[13183] - loss: 0.000409 best_pearson: 0.7248
Batch[13184] - loss: 0.000473 best_pearson: 0.7248
Batch[13185] - loss: 0.000728 best_pearson: 0.7248
Batch[13186] - loss: 0.000300 best_pearson: 0.7248
Batch[13187] - loss: 0.000403 best_pearson: 0.7248
Batch[13188] - loss: 0.000457 best_pearson: 0.7248
Batch[13189] - loss: 0.000416 best_pearson: 0.7248
Batch[13190] - loss: 0.000512 best_pearson: 0.7248
Batch[13191] - loss: 0.000486 best_pearson: 0.7248
Batch[13192] - loss: 0.000378 best_pearson: 0.7248
Batch[13193] - loss: 0.000261 best_pearson: 0.7248
Batch[13194] - loss: 0.000622 best_pearson: 0.7248
Batch[13195] - loss: 0.000330 best_pearson: 0.7248
Batch[13196] - loss: 0.000478 best_pearson: 0.7248
Batch[13197] - loss: 0.000542 best_pearson: 0.7248
Batch[13198] - loss: 0.000280 best_pearson: 0.7248
Batch[13199] - loss: 0.000280 best_pearson: 0.7248
Batch[13200] - loss: 0.000677 best_pearson: 0.7248

Evaluation - loss: 0.000049 pearson: 0.6980 

early stop by 1500 steps.
Batch[13201] - loss: 0.000406 best_pearson: 0.7248
Batch[13202] - loss: 0.000522 best_pearson: 0.7248
Batch[13203] - loss: 0.000622 best_pearson: 0.7248
Batch[13204] - loss: 0.000490 best_pearson: 0.7248
Batch[13205] - loss: 0.000334 best_pearson: 0.7248
Batch[13206] - loss: 0.000571 best_pearson: 0.7248
Batch[13207] - loss: 0.000555 best_pearson: 0.7248
Batch[13208] - loss: 0.000407 best_pearson: 0.7248
Batch[13209] - loss: 0.000397 best_pearson: 0.7248
Batch[13210] - loss: 0.000514 best_pearson: 0.7248
Batch[13211] - loss: 0.000282 best_pearson: 0.7248
Batch[13212] - loss: 0.000487 best_pearson: 0.7248
Batch[13213] - loss: 0.000343 best_pearson: 0.7248
Batch[13214] - loss: 0.000550 best_pearson: 0.7248
Batch[13215] - loss: 0.000443 best_pearson: 0.7248
Batch[13216] - loss: 0.000299 best_pearson: 0.7248
Batch[13217] - loss: 0.000523 best_pearson: 0.7248
Batch[13218] - loss: 0.000702 best_pearson: 0.7248
Batch[13219] - loss: 0.000538 best_pearson: 0.7248
Batch[13220] - loss: 0.000253 best_pearson: 0.7248
Batch[13221] - loss: 0.000590 best_pearson: 0.7248
Batch[13222] - loss: 0.000672 best_pearson: 0.7248
Batch[13223] - loss: 0.000375 best_pearson: 0.7248
Batch[13224] - loss: 0.000580 best_pearson: 0.7248
Batch[13225] - loss: 0.000356 best_pearson: 0.7248
Batch[13226] - loss: 0.000308 best_pearson: 0.7248
Batch[13227] - loss: 0.000586 best_pearson: 0.7248
Batch[13228] - loss: 0.000315 best_pearson: 0.7248
Batch[13229] - loss: 0.000366 best_pearson: 0.7248
Batch[13230] - loss: 0.000413 best_pearson: 0.7248
Batch[13231] - loss: 0.000322 best_pearson: 0.7248
Batch[13232] - loss: 0.000446 best_pearson: 0.7248
Batch[13233] - loss: 0.000521 best_pearson: 0.7248
Batch[13234] - loss: 0.000487 best_pearson: 0.7248
Batch[13235] - loss: 0.000477 best_pearson: 0.7248
Batch[13236] - loss: 0.000352 best_pearson: 0.7248
Batch[13237] - loss: 0.000395 best_pearson: 0.7248
Batch[13238] - loss: 0.000296 best_pearson: 0.7248
Batch[13239] - loss: 0.000401 best_pearson: 0.7248
Batch[13240] - loss: 0.000259 best_pearson: 0.7248
Batch[13241] - loss: 0.000310 best_pearson: 0.7248
Batch[13242] - loss: 0.000432 best_pearson: 0.7248
Batch[13243] - loss: 0.000279 best_pearson: 0.7248
Batch[13244] - loss: 0.000395 best_pearson: 0.7248
Batch[13245] - loss: 0.000372 best_pearson: 0.7248
Batch[13246] - loss: 0.000298 best_pearson: 0.7248
Batch[13247] - loss: 0.000482 best_pearson: 0.7248
Batch[13248] - loss: 0.000266 best_pearson: 0.7248
Batch[13249] - loss: 0.000369 best_pearson: 0.7248
Batch[13250] - loss: 0.000567 best_pearson: 0.7248
Batch[13251] - loss: 0.000289 best_pearson: 0.7248
Batch[13252] - loss: 0.000441 best_pearson: 0.7248
Batch[13253] - loss: 0.000587 best_pearson: 0.7248
Batch[13254] - loss: 0.000238 best_pearson: 0.7248
Batch[13255] - loss: 0.000389 best_pearson: 0.7248
Batch[13256] - loss: 0.000337 best_pearson: 0.7248
Batch[13257] - loss: 0.000342 best_pearson: 0.7248
Batch[13258] - loss: 0.000332 best_pearson: 0.7248
Batch[13259] - loss: 0.000312 best_pearson: 0.7248
Batch[13260] - loss: 0.000420 best_pearson: 0.7248
Batch[13261] - loss: 0.000384 best_pearson: 0.7248
Batch[13262] - loss: 0.000299 best_pearson: 0.7248
Batch[13263] - loss: 0.000313 best_pearson: 0.7248
Batch[13264] - loss: 0.000378 best_pearson: 0.7248
Batch[13265] - loss: 0.000536 best_pearson: 0.7248
Batch[13266] - loss: 0.000407 best_pearson: 0.7248
Batch[13267] - loss: 0.000365 best_pearson: 0.7248
Batch[13268] - loss: 0.000284 best_pearson: 0.7248
Batch[13269] - loss: 0.000591 best_pearson: 0.7248
Batch[13270] - loss: 0.000450 best_pearson: 0.7248
Batch[13271] - loss: 0.000196 best_pearson: 0.7248
Batch[13272] - loss: 0.000296 best_pearson: 0.7248
Batch[13273] - loss: 0.000470 best_pearson: 0.7248
Batch[13274] - loss: 0.000422 best_pearson: 0.7248
Batch[13275] - loss: 0.000507 best_pearson: 0.7248
Batch[13276] - loss: 0.000418 best_pearson: 0.7248
Batch[13277] - loss: 0.000553 best_pearson: 0.7248
Batch[13278] - loss: 0.000400 best_pearson: 0.7248
Batch[13279] - loss: 0.000626 best_pearson: 0.7248
Batch[13280] - loss: 0.000449 best_pearson: 0.7248
Batch[13281] - loss: 0.000389 best_pearson: 0.7248
Batch[13282] - loss: 0.000675 best_pearson: 0.7248
Batch[13283] - loss: 0.000301 best_pearson: 0.7248
Batch[13284] - loss: 0.000281 best_pearson: 0.7248
Batch[13285] - loss: 0.000545 best_pearson: 0.7248
Batch[13286] - loss: 0.000477 best_pearson: 0.7248
Batch[13287] - loss: 0.000250 best_pearson: 0.7248
Batch[13288] - loss: 0.000342 best_pearson: 0.7248
Batch[13289] - loss: 0.000488 best_pearson: 0.7248
Batch[13290] - loss: 0.000326 best_pearson: 0.7248
Batch[13291] - loss: 0.000331 best_pearson: 0.7248
Batch[13292] - loss: 0.000448 best_pearson: 0.7248
Batch[13293] - loss: 0.000548 best_pearson: 0.7248
Batch[13294] - loss: 0.000243 best_pearson: 0.7248
Batch[13295] - loss: 0.000354 best_pearson: 0.7248
Batch[13296] - loss: 0.000485 best_pearson: 0.7248
Batch[13297] - loss: 0.000408 best_pearson: 0.7248
Batch[13298] - loss: 0.000353 best_pearson: 0.7248
Batch[13299] - loss: 0.000532 best_pearson: 0.7248
Batch[13300] - loss: 0.000376 best_pearson: 0.7248

Evaluation - loss: 0.000049 pearson: 0.6987 

early stop by 1500 steps.
Batch[13301] - loss: 0.000244 best_pearson: 0.7248
Batch[13302] - loss: 0.000449 best_pearson: 0.7248
Batch[13303] - loss: 0.000288 best_pearson: 0.7248
Batch[13304] - loss: 0.000313 best_pearson: 0.7248
Batch[13305] - loss: 0.000375 best_pearson: 0.7248
Batch[13306] - loss: 0.000415 best_pearson: 0.7248
Batch[13307] - loss: 0.000260 best_pearson: 0.7248
Batch[13308] - loss: 0.000462 best_pearson: 0.7248
Batch[13309] - loss: 0.000380 best_pearson: 0.7248
Batch[13310] - loss: 0.000420 best_pearson: 0.7248
Batch[13311] - loss: 0.000346 best_pearson: 0.7248
Batch[13312] - loss: 0.000213 best_pearson: 0.7248
Batch[13313] - loss: 0.000288 best_pearson: 0.7248
Batch[13314] - loss: 0.000456 best_pearson: 0.7248
Batch[13315] - loss: 0.000531 best_pearson: 0.7248
Batch[13316] - loss: 0.000475 best_pearson: 0.7248
Batch[13317] - loss: 0.000798 best_pearson: 0.7248
Batch[13318] - loss: 0.000388 best_pearson: 0.7248
Batch[13319] - loss: 0.000240 best_pearson: 0.7248
Batch[13320] - loss: 0.000379 best_pearson: 0.7248
Batch[13321] - loss: 0.000419 best_pearson: 0.7248
Batch[13322] - loss: 0.000235 best_pearson: 0.7248
Batch[13323] - loss: 0.000340 best_pearson: 0.7248
Batch[13324] - loss: 0.000472 best_pearson: 0.7248
Batch[13325] - loss: 0.000395 best_pearson: 0.7248
Batch[13326] - loss: 0.000472 best_pearson: 0.7248
Batch[13327] - loss: 0.000338 best_pearson: 0.7248
Batch[13328] - loss: 0.000284 best_pearson: 0.7248
Batch[13329] - loss: 0.000332 best_pearson: 0.7248
Batch[13330] - loss: 0.000356 best_pearson: 0.7248
Batch[13331] - loss: 0.000330 best_pearson: 0.7248
Batch[13332] - loss: 0.000516 best_pearson: 0.7248
Batch[13333] - loss: 0.000347 best_pearson: 0.7248
Batch[13334] - loss: 0.000474 best_pearson: 0.7248
Batch[13335] - loss: 0.000358 best_pearson: 0.7248
Batch[13336] - loss: 0.000327 best_pearson: 0.7248
Batch[13337] - loss: 0.000272 best_pearson: 0.7248
Batch[13338] - loss: 0.000323 best_pearson: 0.7248
Batch[13339] - loss: 0.000480 best_pearson: 0.7248
Batch[13340] - loss: 0.000421 best_pearson: 0.7248
Batch[13341] - loss: 0.000477 best_pearson: 0.7248
Batch[13342] - loss: 0.000217 best_pearson: 0.7248
Batch[13343] - loss: 0.000249 best_pearson: 0.7248
Batch[13344] - loss: 0.000374 best_pearson: 0.7248
Batch[13345] - loss: 0.000449 best_pearson: 0.7248
Batch[13346] - loss: 0.000359 best_pearson: 0.7248
Batch[13347] - loss: 0.000484 best_pearson: 0.7248
Batch[13348] - loss: 0.000270 best_pearson: 0.7248
Batch[13349] - loss: 0.000512 best_pearson: 0.7248
Batch[13350] - loss: 0.000356 best_pearson: 0.7248
Batch[13351] - loss: 0.000488 best_pearson: 0.7248
Batch[13352] - loss: 0.000354 best_pearson: 0.7248
Batch[13353] - loss: 0.000438 best_pearson: 0.7248
Batch[13354] - loss: 0.000459 best_pearson: 0.7248
Batch[13355] - loss: 0.000427 best_pearson: 0.7248
Batch[13356] - loss: 0.000263 best_pearson: 0.7248
Batch[13357] - loss: 0.000499 best_pearson: 0.7248
Batch[13358] - loss: 0.000543 best_pearson: 0.7248
Batch[13359] - loss: 0.000516 best_pearson: 0.7248
Batch[13360] - loss: 0.000421 best_pearson: 0.7248
Batch[13361] - loss: 0.000256 best_pearson: 0.7248
Batch[13362] - loss: 0.000249 best_pearson: 0.7248
Batch[13363] - loss: 0.000221 best_pearson: 0.7248
Batch[13364] - loss: 0.000245 best_pearson: 0.7248
Batch[13365] - loss: 0.000553 best_pearson: 0.7248
Batch[13366] - loss: 0.000383 best_pearson: 0.7248
Batch[13367] - loss: 0.000415 best_pearson: 0.7248
Batch[13368] - loss: 0.000312 best_pearson: 0.7248
Batch[13369] - loss: 0.000316 best_pearson: 0.7248
Batch[13370] - loss: 0.000533 best_pearson: 0.7248
Batch[13371] - loss: 0.000463 best_pearson: 0.7248
Batch[13372] - loss: 0.000619 best_pearson: 0.7248
Batch[13373] - loss: 0.000560 best_pearson: 0.7248
Batch[13374] - loss: 0.000303 best_pearson: 0.7248
Batch[13375] - loss: 0.000391 best_pearson: 0.7248
Batch[13376] - loss: 0.000363 best_pearson: 0.7248
Batch[13377] - loss: 0.000362 best_pearson: 0.7248
Batch[13378] - loss: 0.000346 best_pearson: 0.7248
Batch[13379] - loss: 0.000334 best_pearson: 0.7248
Batch[13380] - loss: 0.000565 best_pearson: 0.7248
Batch[13381] - loss: 0.000564 best_pearson: 0.7248
Batch[13382] - loss: 0.000342 best_pearson: 0.7248
Batch[13383] - loss: 0.000404 best_pearson: 0.7248
Batch[13384] - loss: 0.000352 best_pearson: 0.7248
Batch[13385] - loss: 0.000342 best_pearson: 0.7248
Batch[13386] - loss: 0.000500 best_pearson: 0.7248
Batch[13387] - loss: 0.000405 best_pearson: 0.7248
Batch[13388] - loss: 0.000322 best_pearson: 0.7248
Batch[13389] - loss: 0.000418 best_pearson: 0.7248
Batch[13390] - loss: 0.000312 best_pearson: 0.7248
Batch[13391] - loss: 0.000295 best_pearson: 0.7248
Batch[13392] - loss: 0.000490 best_pearson: 0.7248
Batch[13393] - loss: 0.000442 best_pearson: 0.7248
Batch[13394] - loss: 0.000342 best_pearson: 0.7248
Batch[13395] - loss: 0.000333 best_pearson: 0.7248
Batch[13396] - loss: 0.000279 best_pearson: 0.7248
Batch[13397] - loss: 0.000280 best_pearson: 0.7248
Batch[13398] - loss: 0.000464 best_pearson: 0.7248
Batch[13399] - loss: 0.000328 best_pearson: 0.7248
Batch[13400] - loss: 0.000286 best_pearson: 0.7248

Evaluation - loss: 0.000049 pearson: 0.6977 

early stop by 1500 steps.
Batch[13401] - loss: 0.000408 best_pearson: 0.7248
Batch[13402] - loss: 0.000324 best_pearson: 0.7248
Batch[13403] - loss: 0.000300 best_pearson: 0.7248
Batch[13404] - loss: 0.000283 best_pearson: 0.7248
Batch[13405] - loss: 0.000252 best_pearson: 0.7248
Batch[13406] - loss: 0.000370 best_pearson: 0.7248
Batch[13407] - loss: 0.000291 best_pearson: 0.7248
Batch[13408] - loss: 0.000642 best_pearson: 0.7248
Batch[13409] - loss: 0.000311 best_pearson: 0.7248
Batch[13410] - loss: 0.000550 best_pearson: 0.7248
Batch[13411] - loss: 0.000379 best_pearson: 0.7248
Batch[13412] - loss: 0.000319 best_pearson: 0.7248
Batch[13413] - loss: 0.000922 best_pearson: 0.7248
Batch[13414] - loss: 0.000635 best_pearson: 0.7248
Batch[13415] - loss: 0.000312 best_pearson: 0.7248
Batch[13416] - loss: 0.000208 best_pearson: 0.7248
Batch[13417] - loss: 0.000573 best_pearson: 0.7248
Batch[13418] - loss: 0.000249 best_pearson: 0.7248
Batch[13419] - loss: 0.000369 best_pearson: 0.7248
Batch[13420] - loss: 0.000383 best_pearson: 0.7248
Batch[13421] - loss: 0.000294 best_pearson: 0.7248
Batch[13422] - loss: 0.000269 best_pearson: 0.7248
Batch[13423] - loss: 0.000376 best_pearson: 0.7248
Batch[13424] - loss: 0.000277 best_pearson: 0.7248
Batch[13425] - loss: 0.000187 best_pearson: 0.7248
Batch[13426] - loss: 0.000555 best_pearson: 0.7248
Batch[13427] - loss: 0.000286 best_pearson: 0.7248
Batch[13428] - loss: 0.000311 best_pearson: 0.7248
Batch[13429] - loss: 0.000526 best_pearson: 0.7248
Batch[13430] - loss: 0.000512 best_pearson: 0.7248
Batch[13431] - loss: 0.000490 best_pearson: 0.7248
Batch[13432] - loss: 0.000316 best_pearson: 0.7248
Batch[13433] - loss: 0.000536 best_pearson: 0.7248
Batch[13434] - loss: 0.000574 best_pearson: 0.7248
Batch[13435] - loss: 0.000404 best_pearson: 0.7248
Batch[13436] - loss: 0.000513 best_pearson: 0.7248
Batch[13437] - loss: 0.000560 best_pearson: 0.7248
Batch[13438] - loss: 0.000359 best_pearson: 0.7248
Batch[13439] - loss: 0.000513 best_pearson: 0.7248
Batch[13440] - loss: 0.000402 best_pearson: 0.7248
Batch[13441] - loss: 0.000300 best_pearson: 0.7248
Batch[13442] - loss: 0.000430 best_pearson: 0.7248
Batch[13443] - loss: 0.000386 best_pearson: 0.7248
Batch[13444] - loss: 0.000475 best_pearson: 0.7248
Batch[13445] - loss: 0.000313 best_pearson: 0.7248
Batch[13446] - loss: 0.000300 best_pearson: 0.7248
Batch[13447] - loss: 0.000247 best_pearson: 0.7248
Batch[13448] - loss: 0.000377 best_pearson: 0.7248
Batch[13449] - loss: 0.000479 best_pearson: 0.7248
Batch[13450] - loss: 0.000410 best_pearson: 0.7248
Batch[13451] - loss: 0.000582 best_pearson: 0.7248
Batch[13452] - loss: 0.000537 best_pearson: 0.7248
Batch[13453] - loss: 0.000540 best_pearson: 0.7248
Batch[13454] - loss: 0.000353 best_pearson: 0.7248
Batch[13455] - loss: 0.000382 best_pearson: 0.7248
Batch[13456] - loss: 0.000386 best_pearson: 0.7248
Batch[13457] - loss: 0.000437 best_pearson: 0.7248
Batch[13458] - loss: 0.000377 best_pearson: 0.7248
Batch[13459] - loss: 0.000352 best_pearson: 0.7248
Batch[13460] - loss: 0.000594 best_pearson: 0.7248
Batch[13461] - loss: 0.000371 best_pearson: 0.7248
Batch[13462] - loss: 0.000459 best_pearson: 0.7248
Batch[13463] - loss: 0.000414 best_pearson: 0.7248
Batch[13464] - loss: 0.000589 best_pearson: 0.7248
Batch[13465] - loss: 0.000758 best_pearson: 0.7248
Batch[13466] - loss: 0.000311 best_pearson: 0.7248
Batch[13467] - loss: 0.000292 best_pearson: 0.7248
Batch[13468] - loss: 0.000593 best_pearson: 0.7248
Batch[13469] - loss: 0.000337 best_pearson: 0.7248
Batch[13470] - loss: 0.000637 best_pearson: 0.7248
Batch[13471] - loss: 0.000588 best_pearson: 0.7248
Batch[13472] - loss: 0.000409 best_pearson: 0.7248
Batch[13473] - loss: 0.000366 best_pearson: 0.7248
Batch[13474] - loss: 0.000390 best_pearson: 0.7248
Batch[13475] - loss: 0.000394 best_pearson: 0.7248
Batch[13476] - loss: 0.000367 best_pearson: 0.7248
Batch[13477] - loss: 0.000311 best_pearson: 0.7248
Batch[13478] - loss: 0.000365 best_pearson: 0.7248
Batch[13479] - loss: 0.000385 best_pearson: 0.7248
Batch[13480] - loss: 0.000345 best_pearson: 0.7248
Batch[13481] - loss: 0.000391 best_pearson: 0.7248
Batch[13482] - loss: 0.000236 best_pearson: 0.7248
Batch[13483] - loss: 0.000426 best_pearson: 0.7248
Batch[13484] - loss: 0.000405 best_pearson: 0.7248
Batch[13485] - loss: 0.000347 best_pearson: 0.7248
Batch[13486] - loss: 0.000312 best_pearson: 0.7248
Batch[13487] - loss: 0.000255 best_pearson: 0.7248
Batch[13488] - loss: 0.000674 best_pearson: 0.7248
Batch[13489] - loss: 0.000542 best_pearson: 0.7248
Batch[13490] - loss: 0.000505 best_pearson: 0.7248
Batch[13491] - loss: 0.000326 best_pearson: 0.7248
Batch[13492] - loss: 0.000551 best_pearson: 0.7248
Batch[13493] - loss: 0.000731 best_pearson: 0.7248
Batch[13494] - loss: 0.000272 best_pearson: 0.7248
Batch[13495] - loss: 0.000339 best_pearson: 0.7248
Batch[13496] - loss: 0.000451 best_pearson: 0.7248
Batch[13497] - loss: 0.000326 best_pearson: 0.7248
Batch[13498] - loss: 0.000322 best_pearson: 0.7248
Batch[13499] - loss: 0.000423 best_pearson: 0.7248
Batch[13500] - loss: 0.000393 best_pearson: 0.7248

Evaluation - loss: 0.000050 pearson: 0.6954 

early stop by 1500 steps.
Batch[13501] - loss: 0.000402 best_pearson: 0.7248
Batch[13502] - loss: 0.000440 best_pearson: 0.7248
Batch[13503] - loss: 0.000544 best_pearson: 0.7248
Batch[13504] - loss: 0.000391 best_pearson: 0.7248
Batch[13505] - loss: 0.000372 best_pearson: 0.7248
Batch[13506] - loss: 0.000234 best_pearson: 0.7248
Batch[13507] - loss: 0.000277 best_pearson: 0.7248
Batch[13508] - loss: 0.000263 best_pearson: 0.7248
Batch[13509] - loss: 0.000639 best_pearson: 0.7248
Batch[13510] - loss: 0.000711 best_pearson: 0.7248
Batch[13511] - loss: 0.000423 best_pearson: 0.7248
Batch[13512] - loss: 0.000447 best_pearson: 0.7248
Batch[13513] - loss: 0.000404 best_pearson: 0.7248
Batch[13514] - loss: 0.000310 best_pearson: 0.7248
Batch[13515] - loss: 0.000615 best_pearson: 0.7248
Batch[13516] - loss: 0.000321 best_pearson: 0.7248
Batch[13517] - loss: 0.000409 best_pearson: 0.7248
Batch[13518] - loss: 0.000546 best_pearson: 0.7248
Batch[13519] - loss: 0.000319 best_pearson: 0.7248
Batch[13520] - loss: 0.000331 best_pearson: 0.7248
Batch[13521] - loss: 0.000538 best_pearson: 0.7248
Batch[13522] - loss: 0.000342 best_pearson: 0.7248
Batch[13523] - loss: 0.000304 best_pearson: 0.7248
Batch[13524] - loss: 0.000524 best_pearson: 0.7248
Batch[13525] - loss: 0.000341 best_pearson: 0.7248
Batch[13526] - loss: 0.000668 best_pearson: 0.7248
Batch[13527] - loss: 0.000378 best_pearson: 0.7248
Batch[13528] - loss: 0.000477 best_pearson: 0.7248
Batch[13529] - loss: 0.000261 best_pearson: 0.7248
Batch[13530] - loss: 0.000405 best_pearson: 0.7248
Batch[13531] - loss: 0.000309 best_pearson: 0.7248
Batch[13532] - loss: 0.000690 best_pearson: 0.7248
Batch[13533] - loss: 0.000606 best_pearson: 0.7248
Batch[13534] - loss: 0.000385 best_pearson: 0.7248
Batch[13535] - loss: 0.000403 best_pearson: 0.7248
Batch[13536] - loss: 0.000270 best_pearson: 0.7248
Batch[13537] - loss: 0.000412 best_pearson: 0.7248
Batch[13538] - loss: 0.000635 best_pearson: 0.7248
Batch[13539] - loss: 0.000539 best_pearson: 0.7248
Batch[13540] - loss: 0.000272 best_pearson: 0.7248
Batch[13541] - loss: 0.000445 best_pearson: 0.7248
Batch[13542] - loss: 0.000269 best_pearson: 0.7248
Batch[13543] - loss: 0.000477 best_pearson: 0.7248
Batch[13544] - loss: 0.000396 best_pearson: 0.7248
Batch[13545] - loss: 0.000658 best_pearson: 0.7248
Batch[13546] - loss: 0.000437 best_pearson: 0.7248
Batch[13547] - loss: 0.000345 best_pearson: 0.7248
Batch[13548] - loss: 0.000393 best_pearson: 0.7248
Batch[13549] - loss: 0.000735 best_pearson: 0.7248
Batch[13550] - loss: 0.000392 best_pearson: 0.7248
Batch[13551] - loss: 0.000633 best_pearson: 0.7248
Batch[13552] - loss: 0.000739 best_pearson: 0.7248
Batch[13553] - loss: 0.000567 best_pearson: 0.7248
Batch[13554] - loss: 0.000601 best_pearson: 0.7248
Batch[13555] - loss: 0.000592 best_pearson: 0.7248
Batch[13556] - loss: 0.000769 best_pearson: 0.7248
Batch[13557] - loss: 0.000363 best_pearson: 0.7248
Batch[13558] - loss: 0.000288 best_pearson: 0.7248
Batch[13559] - loss: 0.000673 best_pearson: 0.7248
Batch[13560] - loss: 0.000402 best_pearson: 0.7248
Batch[13561] - loss: 0.000448 best_pearson: 0.7248
Batch[13562] - loss: 0.000426 best_pearson: 0.7248
Batch[13563] - loss: 0.000584 best_pearson: 0.7248
Batch[13564] - loss: 0.000479 best_pearson: 0.7248
Batch[13565] - loss: 0.000703 best_pearson: 0.7248
Batch[13566] - loss: 0.000390 best_pearson: 0.7248
Batch[13567] - loss: 0.000403 best_pearson: 0.7248
Batch[13568] - loss: 0.000337 best_pearson: 0.7248
Batch[13569] - loss: 0.000375 best_pearson: 0.7248
Batch[13570] - loss: 0.000297 best_pearson: 0.7248
Batch[13571] - loss: 0.000484 best_pearson: 0.7248
Batch[13572] - loss: 0.000638 best_pearson: 0.7248
Batch[13573] - loss: 0.000265 best_pearson: 0.7248
Batch[13574] - loss: 0.000440 best_pearson: 0.7248
Batch[13575] - loss: 0.000325 best_pearson: 0.7248
Batch[13576] - loss: 0.000506 best_pearson: 0.7248
Batch[13577] - loss: 0.000600 best_pearson: 0.7248
Batch[13578] - loss: 0.000261 best_pearson: 0.7248
Batch[13579] - loss: 0.000595 best_pearson: 0.7248
Batch[13580] - loss: 0.000327 best_pearson: 0.7248
Batch[13581] - loss: 0.000783 best_pearson: 0.7248
Batch[13582] - loss: 0.000734 best_pearson: 0.7248
Batch[13583] - loss: 0.000391 best_pearson: 0.7248
Batch[13584] - loss: 0.000604 best_pearson: 0.7248
Batch[13585] - loss: 0.000533 best_pearson: 0.7248
Batch[13586] - loss: 0.000668 best_pearson: 0.7248
Batch[13587] - loss: 0.000451 best_pearson: 0.7248
Batch[13588] - loss: 0.000524 best_pearson: 0.7248
Batch[13589] - loss: 0.000730 best_pearson: 0.7248
Batch[13590] - loss: 0.000226 best_pearson: 0.7248
Batch[13591] - loss: 0.000491 best_pearson: 0.7248
Batch[13592] - loss: 0.000704 best_pearson: 0.7248
Batch[13593] - loss: 0.000364 best_pearson: 0.7248
Batch[13594] - loss: 0.000296 best_pearson: 0.7248
Batch[13595] - loss: 0.000424 best_pearson: 0.7248
Batch[13596] - loss: 0.000420 best_pearson: 0.7248
Batch[13597] - loss: 0.000426 best_pearson: 0.7248
Batch[13598] - loss: 0.000504 best_pearson: 0.7248
Batch[13599] - loss: 0.000443 best_pearson: 0.7248
Batch[13600] - loss: 0.000457 best_pearson: 0.7248

Evaluation - loss: 0.000050 pearson: 0.6974 

early stop by 1500 steps.
Batch[13601] - loss: 0.000498 best_pearson: 0.7248
Batch[13602] - loss: 0.000746 best_pearson: 0.7248
Batch[13603] - loss: 0.000350 best_pearson: 0.7248
Batch[13604] - loss: 0.000662 best_pearson: 0.7248
Batch[13605] - loss: 0.000418 best_pearson: 0.7248
Batch[13606] - loss: 0.000270 best_pearson: 0.7248
Batch[13607] - loss: 0.000503 best_pearson: 0.7248
Batch[13608] - loss: 0.000467 best_pearson: 0.7248
Batch[13609] - loss: 0.000343 best_pearson: 0.7248
Batch[13610] - loss: 0.000447 best_pearson: 0.7248
Batch[13611] - loss: 0.000852 best_pearson: 0.7248
Batch[13612] - loss: 0.000389 best_pearson: 0.7248
Batch[13613] - loss: 0.000361 best_pearson: 0.7248
Batch[13614] - loss: 0.000288 best_pearson: 0.7248
Batch[13615] - loss: 0.000509 best_pearson: 0.7248
Batch[13616] - loss: 0.000454 best_pearson: 0.7248
Batch[13617] - loss: 0.000551 best_pearson: 0.7248
Batch[13618] - loss: 0.000556 best_pearson: 0.7248
Batch[13619] - loss: 0.000440 best_pearson: 0.7248
Batch[13620] - loss: 0.000586 best_pearson: 0.7248
Batch[13621] - loss: 0.000338 best_pearson: 0.7248
Batch[13622] - loss: 0.000588 best_pearson: 0.7248
Batch[13623] - loss: 0.000370 best_pearson: 0.7248
Batch[13624] - loss: 0.000532 best_pearson: 0.7248
Batch[13625] - loss: 0.000343 best_pearson: 0.7248
Batch[13626] - loss: 0.000348 best_pearson: 0.7248
Batch[13627] - loss: 0.000445 best_pearson: 0.7248
Batch[13628] - loss: 0.000260 best_pearson: 0.7248
Batch[13629] - loss: 0.000827 best_pearson: 0.7248
Batch[13630] - loss: 0.000374 best_pearson: 0.7248
Batch[13631] - loss: 0.000518 best_pearson: 0.7248
Batch[13632] - loss: 0.000513 best_pearson: 0.7248
Batch[13633] - loss: 0.000418 best_pearson: 0.7248
Batch[13634] - loss: 0.000600 best_pearson: 0.7248
Batch[13635] - loss: 0.000551 best_pearson: 0.7248
Batch[13636] - loss: 0.000633 best_pearson: 0.7248
Batch[13637] - loss: 0.000689 best_pearson: 0.7248
Batch[13638] - loss: 0.000631 best_pearson: 0.7248
Batch[13639] - loss: 0.000420 best_pearson: 0.7248
Batch[13640] - loss: 0.000935 best_pearson: 0.7248
Batch[13641] - loss: 0.000529 best_pearson: 0.7248
Batch[13642] - loss: 0.000514 best_pearson: 0.7248
Batch[13643] - loss: 0.000562 best_pearson: 0.7248
Batch[13644] - loss: 0.000651 best_pearson: 0.7248
Batch[13645] - loss: 0.000459 best_pearson: 0.7248
Batch[13646] - loss: 0.000345 best_pearson: 0.7248
Batch[13647] - loss: 0.000578 best_pearson: 0.7248
Batch[13648] - loss: 0.000610 best_pearson: 0.7248
Batch[13649] - loss: 0.000428 best_pearson: 0.7248
Batch[13650] - loss: 0.000414 best_pearson: 0.7248
Batch[13651] - loss: 0.000293 best_pearson: 0.7248
Batch[13652] - loss: 0.000634 best_pearson: 0.7248
Batch[13653] - loss: 0.000478 best_pearson: 0.7248
Batch[13654] - loss: 0.000434 best_pearson: 0.7248
Batch[13655] - loss: 0.000537 best_pearson: 0.7248
Batch[13656] - loss: 0.000462 best_pearson: 0.7248
Batch[13657] - loss: 0.000543 best_pearson: 0.7248
Batch[13658] - loss: 0.000389 best_pearson: 0.7248
Batch[13659] - loss: 0.000403 best_pearson: 0.7248
Batch[13660] - loss: 0.000422 best_pearson: 0.7248
Batch[13661] - loss: 0.000562 best_pearson: 0.7248
Batch[13662] - loss: 0.000797 best_pearson: 0.7248
Batch[13663] - loss: 0.000406 best_pearson: 0.7248
Batch[13664] - loss: 0.000328 best_pearson: 0.7248
Batch[13665] - loss: 0.000506 best_pearson: 0.7248
Batch[13666] - loss: 0.000403 best_pearson: 0.7248
Batch[13667] - loss: 0.000450 best_pearson: 0.7248
Batch[13668] - loss: 0.000495 best_pearson: 0.7248
Batch[13669] - loss: 0.000577 best_pearson: 0.7248
Batch[13670] - loss: 0.000470 best_pearson: 0.7248
Batch[13671] - loss: 0.000311 best_pearson: 0.7248
Batch[13672] - loss: 0.000448 best_pearson: 0.7248
Batch[13673] - loss: 0.000524 best_pearson: 0.7248
Batch[13674] - loss: 0.000490 best_pearson: 0.7248
Batch[13675] - loss: 0.000463 best_pearson: 0.7248
Batch[13676] - loss: 0.000226 best_pearson: 0.7248
Batch[13677] - loss: 0.000508 best_pearson: 0.7248
Batch[13678] - loss: 0.000479 best_pearson: 0.7248
Batch[13679] - loss: 0.000628 best_pearson: 0.7248
Batch[13680] - loss: 0.000339 best_pearson: 0.7248
Batch[13681] - loss: 0.000501 best_pearson: 0.7248
Batch[13682] - loss: 0.000484 best_pearson: 0.7248
Batch[13683] - loss: 0.000544 best_pearson: 0.7248
Batch[13684] - loss: 0.000410 best_pearson: 0.7248
Batch[13685] - loss: 0.000508 best_pearson: 0.7248
Batch[13686] - loss: 0.000771 best_pearson: 0.7248
Batch[13687] - loss: 0.000516 best_pearson: 0.7248
Batch[13688] - loss: 0.000368 best_pearson: 0.7248
Batch[13689] - loss: 0.000239 best_pearson: 0.7248
Batch[13690] - loss: 0.000491 best_pearson: 0.7248
Batch[13691] - loss: 0.000441 best_pearson: 0.7248
Batch[13692] - loss: 0.000570 best_pearson: 0.7248
Batch[13693] - loss: 0.000491 best_pearson: 0.7248
Batch[13694] - loss: 0.000782 best_pearson: 0.7248
Batch[13695] - loss: 0.000798 best_pearson: 0.7248
Batch[13696] - loss: 0.000436 best_pearson: 0.7248
Batch[13697] - loss: 0.000434 best_pearson: 0.7248
Batch[13698] - loss: 0.000817 best_pearson: 0.7248
Batch[13699] - loss: 0.000742 best_pearson: 0.7248
Batch[13700] - loss: 0.000409 best_pearson: 0.7248

Evaluation - loss: 0.000050 pearson: 0.6958 

early stop by 1500 steps.
Batch[13701] - loss: 0.000718 best_pearson: 0.7248
Batch[13702] - loss: 0.000547 best_pearson: 0.7248
Batch[13703] - loss: 0.000481 best_pearson: 0.7248
Batch[13704] - loss: 0.000572 best_pearson: 0.7248
Batch[13705] - loss: 0.000380 best_pearson: 0.7248
Batch[13706] - loss: 0.000689 best_pearson: 0.7248
Batch[13707] - loss: 0.000340 best_pearson: 0.7248
Batch[13708] - loss: 0.000474 best_pearson: 0.7248
Batch[13709] - loss: 0.000398 best_pearson: 0.7248
Batch[13710] - loss: 0.000524 best_pearson: 0.7248
Batch[13711] - loss: 0.000308 best_pearson: 0.7248
Batch[13712] - loss: 0.000395 best_pearson: 0.7248
Batch[13713] - loss: 0.000444 best_pearson: 0.7248
Batch[13714] - loss: 0.000390 best_pearson: 0.7248
Batch[13715] - loss: 0.001316 best_pearson: 0.7248
Batch[13716] - loss: 0.000321 best_pearson: 0.7248
Batch[13717] - loss: 0.000485 best_pearson: 0.7248
Batch[13718] - loss: 0.000617 best_pearson: 0.7248
Batch[13719] - loss: 0.000541 best_pearson: 0.7248
Batch[13720] - loss: 0.000543 best_pearson: 0.7248
Batch[13721] - loss: 0.000366 best_pearson: 0.7248
Batch[13722] - loss: 0.000479 best_pearson: 0.7248
Batch[13723] - loss: 0.000489 best_pearson: 0.7248
Batch[13724] - loss: 0.000713 best_pearson: 0.7248
Batch[13725] - loss: 0.000378 best_pearson: 0.7248
Batch[13726] - loss: 0.000295 best_pearson: 0.7248
Batch[13727] - loss: 0.000509 best_pearson: 0.7248
Batch[13728] - loss: 0.000366 best_pearson: 0.7248
Batch[13729] - loss: 0.000438 best_pearson: 0.7248
Batch[13730] - loss: 0.000447 best_pearson: 0.7248
Batch[13731] - loss: 0.000587 best_pearson: 0.7248
Batch[13732] - loss: 0.000682 best_pearson: 0.7248
Batch[13733] - loss: 0.000546 best_pearson: 0.7248
Batch[13734] - loss: 0.000590 best_pearson: 0.7248
Batch[13735] - loss: 0.000289 best_pearson: 0.7248
Batch[13736] - loss: 0.000624 best_pearson: 0.7248
Batch[13737] - loss: 0.000375 best_pearson: 0.7248
Batch[13738] - loss: 0.000667 best_pearson: 0.7248
Batch[13739] - loss: 0.000378 best_pearson: 0.7248
Batch[13740] - loss: 0.000499 best_pearson: 0.7248
Batch[13741] - loss: 0.000359 best_pearson: 0.7248
Batch[13742] - loss: 0.000345 best_pearson: 0.7248
Batch[13743] - loss: 0.000405 best_pearson: 0.7248
Batch[13744] - loss: 0.000521 best_pearson: 0.7248
Batch[13745] - loss: 0.000328 best_pearson: 0.7248
Batch[13746] - loss: 0.000554 best_pearson: 0.7248
Batch[13747] - loss: 0.000445 best_pearson: 0.7248
Batch[13748] - loss: 0.000477 best_pearson: 0.7248
Batch[13749] - loss: 0.000718 best_pearson: 0.7248
Batch[13750] - loss: 0.000327 best_pearson: 0.7248
Batch[13751] - loss: 0.000582 best_pearson: 0.7248
Batch[13752] - loss: 0.000452 best_pearson: 0.7248
Batch[13753] - loss: 0.000534 best_pearson: 0.7248
Batch[13754] - loss: 0.000587 best_pearson: 0.7248
Batch[13755] - loss: 0.000494 best_pearson: 0.7248
Batch[13756] - loss: 0.000431 best_pearson: 0.7248
Batch[13757] - loss: 0.000408 best_pearson: 0.7248
Batch[13758] - loss: 0.000367 best_pearson: 0.7248
Batch[13759] - loss: 0.000405 best_pearson: 0.7248
Batch[13760] - loss: 0.000603 best_pearson: 0.7248
Batch[13761] - loss: 0.000758 best_pearson: 0.7248
Batch[13762] - loss: 0.000768 best_pearson: 0.7248
Batch[13763] - loss: 0.000722 best_pearson: 0.7248
Batch[13764] - loss: 0.000355 best_pearson: 0.7248
Batch[13765] - loss: 0.000323 best_pearson: 0.7248
Batch[13766] - loss: 0.000568 best_pearson: 0.7248
Batch[13767] - loss: 0.000662 best_pearson: 0.7248
Batch[13768] - loss: 0.000452 best_pearson: 0.7248
Batch[13769] - loss: 0.000647 best_pearson: 0.7248
Batch[13770] - loss: 0.000450 best_pearson: 0.7248
Batch[13771] - loss: 0.000504 best_pearson: 0.7248
Batch[13772] - loss: 0.000438 best_pearson: 0.7248
Batch[13773] - loss: 0.000613 best_pearson: 0.7248
Batch[13774] - loss: 0.000367 best_pearson: 0.7248
Batch[13775] - loss: 0.000651 best_pearson: 0.7248
Batch[13776] - loss: 0.000313 best_pearson: 0.7248
Batch[13777] - loss: 0.000435 best_pearson: 0.7248
Batch[13778] - loss: 0.000336 best_pearson: 0.7248
Batch[13779] - loss: 0.000357 best_pearson: 0.7248
Batch[13780] - loss: 0.000515 best_pearson: 0.7248
Batch[13781] - loss: 0.000380 best_pearson: 0.7248
Batch[13782] - loss: 0.001228 best_pearson: 0.7248
Batch[13783] - loss: 0.000497 best_pearson: 0.7248
Batch[13784] - loss: 0.001124 best_pearson: 0.7248
Batch[13785] - loss: 0.000693 best_pearson: 0.7248
Batch[13786] - loss: 0.000690 best_pearson: 0.7248
Batch[13787] - loss: 0.000759 best_pearson: 0.7248
Batch[13788] - loss: 0.000847 best_pearson: 0.7248
Batch[13789] - loss: 0.000823 best_pearson: 0.7248
Batch[13790] - loss: 0.000384 best_pearson: 0.7248
Batch[13791] - loss: 0.000353 best_pearson: 0.7248
Batch[13792] - loss: 0.000557 best_pearson: 0.7248
Batch[13793] - loss: 0.000707 best_pearson: 0.7248
Batch[13794] - loss: 0.000737 best_pearson: 0.7248
Batch[13795] - loss: 0.000401 best_pearson: 0.7248
Batch[13796] - loss: 0.000549 best_pearson: 0.7248
Batch[13797] - loss: 0.000681 best_pearson: 0.7248
Batch[13798] - loss: 0.000311 best_pearson: 0.7248
Batch[13799] - loss: 0.000514 best_pearson: 0.7248
Batch[13800] - loss: 0.000658 best_pearson: 0.7248

Evaluation - loss: 0.000050 pearson: 0.6952 

early stop by 1500 steps.
Batch[13801] - loss: 0.000697 best_pearson: 0.7248
Batch[13802] - loss: 0.000432 best_pearson: 0.7248
Batch[13803] - loss: 0.000445 best_pearson: 0.7248
Batch[13804] - loss: 0.000441 best_pearson: 0.7248
Batch[13805] - loss: 0.000574 best_pearson: 0.7248
Batch[13806] - loss: 0.000568 best_pearson: 0.7248
Batch[13807] - loss: 0.000395 best_pearson: 0.7248
Batch[13808] - loss: 0.000328 best_pearson: 0.7248
Batch[13809] - loss: 0.000767 best_pearson: 0.7248
Batch[13810] - loss: 0.000480 best_pearson: 0.7248
Batch[13811] - loss: 0.000415 best_pearson: 0.7248
Batch[13812] - loss: 0.000622 best_pearson: 0.7248
Batch[13813] - loss: 0.000587 best_pearson: 0.7248
Batch[13814] - loss: 0.000478 best_pearson: 0.7248
Batch[13815] - loss: 0.000531 best_pearson: 0.7248
Batch[13816] - loss: 0.000529 best_pearson: 0.7248
Batch[13817] - loss: 0.000412 best_pearson: 0.7248
Batch[13818] - loss: 0.000655 best_pearson: 0.7248
Batch[13819] - loss: 0.000438 best_pearson: 0.7248
Batch[13820] - loss: 0.000440 best_pearson: 0.7248
Batch[13821] - loss: 0.000293 best_pearson: 0.7248
Batch[13822] - loss: 0.000828 best_pearson: 0.7248
Batch[13823] - loss: 0.000673 best_pearson: 0.7248
Batch[13824] - loss: 0.000338 best_pearson: 0.7248
Batch[13825] - loss: 0.000498 best_pearson: 0.7248
Batch[13826] - loss: 0.000442 best_pearson: 0.7248
Batch[13827] - loss: 0.000234 best_pearson: 0.7248
Batch[13828] - loss: 0.000576 best_pearson: 0.7248
Batch[13829] - loss: 0.000643 best_pearson: 0.7248
Batch[13830] - loss: 0.000596 best_pearson: 0.7248
Batch[13831] - loss: 0.000658 best_pearson: 0.7248
Batch[13832] - loss: 0.000573 best_pearson: 0.7248
Batch[13833] - loss: 0.000649 best_pearson: 0.7248
Batch[13834] - loss: 0.001130 best_pearson: 0.7248
Batch[13835] - loss: 0.000615 best_pearson: 0.7248
Batch[13836] - loss: 0.000975 best_pearson: 0.7248
Batch[13837] - loss: 0.000463 best_pearson: 0.7248
Batch[13838] - loss: 0.000511 best_pearson: 0.7248
Batch[13839] - loss: 0.000425 best_pearson: 0.7248
Batch[13840] - loss: 0.000916 best_pearson: 0.7248
Batch[13841] - loss: 0.000675 best_pearson: 0.7248
Batch[13842] - loss: 0.000345 best_pearson: 0.7248
Batch[13843] - loss: 0.000317 best_pearson: 0.7248
Batch[13844] - loss: 0.000678 best_pearson: 0.7248
Batch[13845] - loss: 0.000564 best_pearson: 0.7248
Batch[13846] - loss: 0.000391 best_pearson: 0.7248
Batch[13847] - loss: 0.000431 best_pearson: 0.7248
Batch[13848] - loss: 0.000666 best_pearson: 0.7248
Batch[13849] - loss: 0.000922 best_pearson: 0.7248
Batch[13850] - loss: 0.000694 best_pearson: 0.7248
Batch[13851] - loss: 0.000255 best_pearson: 0.7248
Batch[13852] - loss: 0.000850 best_pearson: 0.7248
Batch[13853] - loss: 0.000540 best_pearson: 0.7248
Batch[13854] - loss: 0.000298 best_pearson: 0.7248
Batch[13855] - loss: 0.000529 best_pearson: 0.7248
Batch[13856] - loss: 0.000537 best_pearson: 0.7248
Batch[13857] - loss: 0.000565 best_pearson: 0.7248
Batch[13858] - loss: 0.000376 best_pearson: 0.7248
Batch[13859] - loss: 0.000344 best_pearson: 0.7248
Batch[13860] - loss: 0.000497 best_pearson: 0.7248
Batch[13861] - loss: 0.000451 best_pearson: 0.7248
Batch[13862] - loss: 0.000601 best_pearson: 0.7248
Batch[13863] - loss: 0.000372 best_pearson: 0.7248
Batch[13864] - loss: 0.000390 best_pearson: 0.7248
Batch[13865] - loss: 0.000687 best_pearson: 0.7248
Batch[13866] - loss: 0.000450 best_pearson: 0.7248
Batch[13867] - loss: 0.000646 best_pearson: 0.7248
Batch[13868] - loss: 0.000611 best_pearson: 0.7248
Batch[13869] - loss: 0.000595 best_pearson: 0.7248
Batch[13870] - loss: 0.000416 best_pearson: 0.7248
Batch[13871] - loss: 0.000636 best_pearson: 0.7248
Batch[13872] - loss: 0.000574 best_pearson: 0.7248
Batch[13873] - loss: 0.000462 best_pearson: 0.7248
Batch[13874] - loss: 0.000514 best_pearson: 0.7248
Batch[13875] - loss: 0.000335 best_pearson: 0.7248
Batch[13876] - loss: 0.000558 best_pearson: 0.7248
Batch[13877] - loss: 0.000559 best_pearson: 0.7248
Batch[13878] - loss: 0.000378 best_pearson: 0.7248
Batch[13879] - loss: 0.000567 best_pearson: 0.7248
Batch[13880] - loss: 0.000304 best_pearson: 0.7248
Batch[13881] - loss: 0.000431 best_pearson: 0.7248
Batch[13882] - loss: 0.000340 best_pearson: 0.7248
Batch[13883] - loss: 0.000384 best_pearson: 0.7248
Batch[13884] - loss: 0.000415 best_pearson: 0.7248
Batch[13885] - loss: 0.000661 best_pearson: 0.7248
Batch[13886] - loss: 0.000869 best_pearson: 0.7248
Batch[13887] - loss: 0.000622 best_pearson: 0.7248
Batch[13888] - loss: 0.000437 best_pearson: 0.7248
Batch[13889] - loss: 0.000436 best_pearson: 0.7248
Batch[13890] - loss: 0.000383 best_pearson: 0.7248
Batch[13891] - loss: 0.000836 best_pearson: 0.7248
Batch[13892] - loss: 0.000272 best_pearson: 0.7248
Batch[13893] - loss: 0.000373 best_pearson: 0.7248
Batch[13894] - loss: 0.000864 best_pearson: 0.7248
Batch[13895] - loss: 0.000452 best_pearson: 0.7248
Batch[13896] - loss: 0.000546 best_pearson: 0.7248
Batch[13897] - loss: 0.000443 best_pearson: 0.7248
Batch[13898] - loss: 0.000365 best_pearson: 0.7248
Batch[13899] - loss: 0.000370 best_pearson: 0.7248
Batch[13900] - loss: 0.001061 best_pearson: 0.7248

Evaluation - loss: 0.000050 pearson: 0.6947 

early stop by 1500 steps.
Batch[13901] - loss: 0.000464 best_pearson: 0.7248
Batch[13902] - loss: 0.000431 best_pearson: 0.7248
Batch[13903] - loss: 0.000441 best_pearson: 0.7248
Batch[13904] - loss: 0.000388 best_pearson: 0.7248
Batch[13905] - loss: 0.000463 best_pearson: 0.7248
Batch[13906] - loss: 0.000576 best_pearson: 0.7248
Batch[13907] - loss: 0.000488 best_pearson: 0.7248
Batch[13908] - loss: 0.000518 best_pearson: 0.7248
Batch[13909] - loss: 0.000323 best_pearson: 0.7248
Batch[13910] - loss: 0.000813 best_pearson: 0.7248
Batch[13911] - loss: 0.000373 best_pearson: 0.7248
Batch[13912] - loss: 0.000360 best_pearson: 0.7248
Batch[13913] - loss: 0.000908 best_pearson: 0.7248
Batch[13914] - loss: 0.000575 best_pearson: 0.7248
Batch[13915] - loss: 0.000420 best_pearson: 0.7248
Batch[13916] - loss: 0.000698 best_pearson: 0.7248
Batch[13917] - loss: 0.000354 best_pearson: 0.7248
Batch[13918] - loss: 0.000353 best_pearson: 0.7248
Batch[13919] - loss: 0.000598 best_pearson: 0.7248
Batch[13920] - loss: 0.000394 best_pearson: 0.7248
Batch[13921] - loss: 0.000412 best_pearson: 0.7248
Batch[13922] - loss: 0.000947 best_pearson: 0.7248
Batch[13923] - loss: 0.000671 best_pearson: 0.7248
Batch[13924] - loss: 0.000503 best_pearson: 0.7248
Batch[13925] - loss: 0.000477 best_pearson: 0.7248
Batch[13926] - loss: 0.000515 best_pearson: 0.7248
Batch[13927] - loss: 0.000355 best_pearson: 0.7248
Batch[13928] - loss: 0.000579 best_pearson: 0.7248
Batch[13929] - loss: 0.000356 best_pearson: 0.7248
Batch[13930] - loss: 0.000320 best_pearson: 0.7248
Batch[13931] - loss: 0.000487 best_pearson: 0.7248
Batch[13932] - loss: 0.000460 best_pearson: 0.7248
Batch[13933] - loss: 0.000597 best_pearson: 0.7248
Batch[13934] - loss: 0.000469 best_pearson: 0.7248
Batch[13935] - loss: 0.000392 best_pearson: 0.7248
Batch[13936] - loss: 0.000290 best_pearson: 0.7248
Batch[13937] - loss: 0.000410 best_pearson: 0.7248
Batch[13938] - loss: 0.000620 best_pearson: 0.7248
Batch[13939] - loss: 0.000290 best_pearson: 0.7248
Batch[13940] - loss: 0.000279 best_pearson: 0.7248
Batch[13941] - loss: 0.000548 best_pearson: 0.7248
Batch[13942] - loss: 0.000540 best_pearson: 0.7248
Batch[13943] - loss: 0.000506 best_pearson: 0.7248
Batch[13944] - loss: 0.000641 best_pearson: 0.7248
Batch[13945] - loss: 0.000525 best_pearson: 0.7248
Batch[13946] - loss: 0.000357 best_pearson: 0.7248
Batch[13947] - loss: 0.000355 best_pearson: 0.7248
Batch[13948] - loss: 0.000499 best_pearson: 0.7248
Batch[13949] - loss: 0.000386 best_pearson: 0.7248
Batch[13950] - loss: 0.000510 best_pearson: 0.7248
Batch[13951] - loss: 0.000742 best_pearson: 0.7248
Batch[13952] - loss: 0.000340 best_pearson: 0.7248
Batch[13953] - loss: 0.000628 best_pearson: 0.7248
Batch[13954] - loss: 0.000521 best_pearson: 0.7248
Batch[13955] - loss: 0.000540 best_pearson: 0.7248
Batch[13956] - loss: 0.000512 best_pearson: 0.7248
Batch[13957] - loss: 0.000575 best_pearson: 0.7248
Batch[13958] - loss: 0.000564 best_pearson: 0.7248
Batch[13959] - loss: 0.000302 best_pearson: 0.7248
Batch[13960] - loss: 0.000464 best_pearson: 0.7248
Batch[13961] - loss: 0.000508 best_pearson: 0.7248
Batch[13962] - loss: 0.000476 best_pearson: 0.7248
Batch[13963] - loss: 0.000430 best_pearson: 0.7248
Batch[13964] - loss: 0.000625 best_pearson: 0.7248
Batch[13965] - loss: 0.000459 best_pearson: 0.7248
Batch[13966] - loss: 0.000360 best_pearson: 0.7248
Batch[13967] - loss: 0.000765 best_pearson: 0.7248
Batch[13968] - loss: 0.000567 best_pearson: 0.7248
Batch[13969] - loss: 0.000648 best_pearson: 0.7248
Batch[13970] - loss: 0.000550 best_pearson: 0.7248
Batch[13971] - loss: 0.000411 best_pearson: 0.7248
Batch[13972] - loss: 0.000651 best_pearson: 0.7248
Batch[13973] - loss: 0.000293 best_pearson: 0.7248
Batch[13974] - loss: 0.000564 best_pearson: 0.7248
Batch[13975] - loss: 0.000432 best_pearson: 0.7248
Batch[13976] - loss: 0.000694 best_pearson: 0.7248
Batch[13977] - loss: 0.000567 best_pearson: 0.7248
Batch[13978] - loss: 0.000369 best_pearson: 0.7248
Batch[13979] - loss: 0.000716 best_pearson: 0.7248
Batch[13980] - loss: 0.000403 best_pearson: 0.7248
Batch[13981] - loss: 0.000358 best_pearson: 0.7248
Batch[13982] - loss: 0.000492 best_pearson: 0.7248
Batch[13983] - loss: 0.000250 best_pearson: 0.7248
Batch[13984] - loss: 0.000500 best_pearson: 0.7248
Batch[13985] - loss: 0.000574 best_pearson: 0.7248
Batch[13986] - loss: 0.000391 best_pearson: 0.7248
Batch[13987] - loss: 0.000361 best_pearson: 0.7248
Batch[13988] - loss: 0.000735 best_pearson: 0.7248
Batch[13989] - loss: 0.000342 best_pearson: 0.7248
Batch[13990] - loss: 0.000332 best_pearson: 0.7248
Batch[13991] - loss: 0.000326 best_pearson: 0.7248
Batch[13992] - loss: 0.000392 best_pearson: 0.7248
Batch[13993] - loss: 0.000521 best_pearson: 0.7248
Batch[13994] - loss: 0.000332 best_pearson: 0.7248
Batch[13995] - loss: 0.000262 best_pearson: 0.7248
Batch[13996] - loss: 0.000309 best_pearson: 0.7248
Batch[13997] - loss: 0.000453 best_pearson: 0.7248
Batch[13998] - loss: 0.000441 best_pearson: 0.7248
Batch[13999] - loss: 0.000191 best_pearson: 0.7248
Batch[14000] - loss: 0.000503 best_pearson: 0.7248

Evaluation - loss: 0.000049 pearson: 0.6954 

early stop by 1500 steps.
Batch[14001] - loss: 0.000509 best_pearson: 0.7248
Batch[14002] - loss: 0.000579 best_pearson: 0.7248
Batch[14003] - loss: 0.000329 best_pearson: 0.7248
Batch[14004] - loss: 0.000363 best_pearson: 0.7248
Batch[14005] - loss: 0.000610 best_pearson: 0.7248
Batch[14006] - loss: 0.000721 best_pearson: 0.7248
Batch[14007] - loss: 0.000638 best_pearson: 0.7248
Batch[14008] - loss: 0.000358 best_pearson: 0.7248
Batch[14009] - loss: 0.000349 best_pearson: 0.7248
Batch[14010] - loss: 0.000286 best_pearson: 0.7248
Batch[14011] - loss: 0.000393 best_pearson: 0.7248
Batch[14012] - loss: 0.000543 best_pearson: 0.7248
Batch[14013] - loss: 0.000415 best_pearson: 0.7248
Batch[14014] - loss: 0.000493 best_pearson: 0.7248
Batch[14015] - loss: 0.000140 best_pearson: 0.7248
Batch[14016] - loss: 0.000568 best_pearson: 0.7248
Batch[14017] - loss: 0.000506 best_pearson: 0.7248
Batch[14018] - loss: 0.000237 best_pearson: 0.7248
Batch[14019] - loss: 0.000437 best_pearson: 0.7248
Batch[14020] - loss: 0.000399 best_pearson: 0.7248
Batch[14021] - loss: 0.000503 best_pearson: 0.7248
Batch[14022] - loss: 0.000752 best_pearson: 0.7248
Batch[14023] - loss: 0.000428 best_pearson: 0.7248
Batch[14024] - loss: 0.000195 best_pearson: 0.7248
Batch[14025] - loss: 0.000484 best_pearson: 0.7248
Batch[14026] - loss: 0.000397 best_pearson: 0.7248
Batch[14027] - loss: 0.000473 best_pearson: 0.7248
Batch[14028] - loss: 0.000614 best_pearson: 0.7248
Batch[14029] - loss: 0.000564 best_pearson: 0.7248
Batch[14030] - loss: 0.000402 best_pearson: 0.7248
Batch[14031] - loss: 0.000586 best_pearson: 0.7248
Batch[14032] - loss: 0.000377 best_pearson: 0.7248
Batch[14033] - loss: 0.000438 best_pearson: 0.7248
Batch[14034] - loss: 0.000429 best_pearson: 0.7248
Batch[14035] - loss: 0.000411 best_pearson: 0.7248
Batch[14036] - loss: 0.000237 best_pearson: 0.7248
Batch[14037] - loss: 0.000452 best_pearson: 0.7248
Batch[14038] - loss: 0.000392 best_pearson: 0.7248
Batch[14039] - loss: 0.000276 best_pearson: 0.7248
Batch[14040] - loss: 0.000457 best_pearson: 0.7248
Batch[14041] - loss: 0.000496 best_pearson: 0.7248
Batch[14042] - loss: 0.000486 best_pearson: 0.7248
Batch[14043] - loss: 0.000342 best_pearson: 0.7248
Batch[14044] - loss: 0.000475 best_pearson: 0.7248
Batch[14045] - loss: 0.000290 best_pearson: 0.7248
Batch[14046] - loss: 0.000435 best_pearson: 0.7248
Batch[14047] - loss: 0.000385 best_pearson: 0.7248
Batch[14048] - loss: 0.000628 best_pearson: 0.7248
Batch[14049] - loss: 0.000424 best_pearson: 0.7248
Batch[14050] - loss: 0.000378 best_pearson: 0.7248
Batch[14051] - loss: 0.000338 best_pearson: 0.7248
Batch[14052] - loss: 0.000235 best_pearson: 0.7248
Batch[14053] - loss: 0.000368 best_pearson: 0.7248
Batch[14054] - loss: 0.000240 best_pearson: 0.7248
Batch[14055] - loss: 0.000344 best_pearson: 0.7248
Batch[14056] - loss: 0.000374 best_pearson: 0.7248
Batch[14057] - loss: 0.000402 best_pearson: 0.7248
Batch[14058] - loss: 0.000607 best_pearson: 0.7248
Batch[14059] - loss: 0.000476 best_pearson: 0.7248
Batch[14060] - loss: 0.000315 best_pearson: 0.7248
Batch[14061] - loss: 0.000386 best_pearson: 0.7248
Batch[14062] - loss: 0.000589 best_pearson: 0.7248
Batch[14063] - loss: 0.000506 best_pearson: 0.7248
Batch[14064] - loss: 0.000516 best_pearson: 0.7248
Batch[14065] - loss: 0.000398 best_pearson: 0.7248
Batch[14066] - loss: 0.000480 best_pearson: 0.7248
Batch[14067] - loss: 0.000259 best_pearson: 0.7248
Batch[14068] - loss: 0.000587 best_pearson: 0.7248
Batch[14069] - loss: 0.000358 best_pearson: 0.7248
Batch[14070] - loss: 0.000323 best_pearson: 0.7248
Batch[14071] - loss: 0.000657 best_pearson: 0.7248
Batch[14072] - loss: 0.000371 best_pearson: 0.7248
Batch[14073] - loss: 0.000399 best_pearson: 0.7248
Batch[14074] - loss: 0.000378 best_pearson: 0.7248
Batch[14075] - loss: 0.000383 best_pearson: 0.7248
Batch[14076] - loss: 0.000681 best_pearson: 0.7248
Batch[14077] - loss: 0.000306 best_pearson: 0.7248
Batch[14078] - loss: 0.000488 best_pearson: 0.7248
Batch[14079] - loss: 0.000212 best_pearson: 0.7248
Batch[14080] - loss: 0.000207 best_pearson: 0.7248
Batch[14081] - loss: 0.000343 best_pearson: 0.7248
Batch[14082] - loss: 0.000523 best_pearson: 0.7248
Batch[14083] - loss: 0.000609 best_pearson: 0.7248
Batch[14084] - loss: 0.000497 best_pearson: 0.7248
Batch[14085] - loss: 0.000312 best_pearson: 0.7248
Batch[14086] - loss: 0.000454 best_pearson: 0.7248
Batch[14087] - loss: 0.000274 best_pearson: 0.7248
Batch[14088] - loss: 0.000582 best_pearson: 0.7248
Batch[14089] - loss: 0.000447 best_pearson: 0.7248
Batch[14090] - loss: 0.000673 best_pearson: 0.7248
Batch[14091] - loss: 0.000543 best_pearson: 0.7248
Batch[14092] - loss: 0.000441 best_pearson: 0.7248
Batch[14093] - loss: 0.000598 best_pearson: 0.7248
Batch[14094] - loss: 0.000476 best_pearson: 0.7248
Batch[14095] - loss: 0.000427 best_pearson: 0.7248
Batch[14096] - loss: 0.000387 best_pearson: 0.7248
Batch[14097] - loss: 0.000391 best_pearson: 0.7248
Batch[14098] - loss: 0.000527 best_pearson: 0.7248
Batch[14099] - loss: 0.000425 best_pearson: 0.7248
Batch[14100] - loss: 0.000641 best_pearson: 0.7248

Evaluation - loss: 0.000049 pearson: 0.6978 

early stop by 1500 steps.
Batch[14101] - loss: 0.000938 best_pearson: 0.7248
Batch[14102] - loss: 0.000454 best_pearson: 0.7248
Batch[14103] - loss: 0.000920 best_pearson: 0.7248
Batch[14104] - loss: 0.000350 best_pearson: 0.7248
Batch[14105] - loss: 0.000853 best_pearson: 0.7248
Batch[14106] - loss: 0.000452 best_pearson: 0.7248
Batch[14107] - loss: 0.000322 best_pearson: 0.7248
Batch[14108] - loss: 0.000442 best_pearson: 0.7248
Batch[14109] - loss: 0.000503 best_pearson: 0.7248
Batch[14110] - loss: 0.000548 best_pearson: 0.7248
Batch[14111] - loss: 0.000443 best_pearson: 0.7248
Batch[14112] - loss: 0.000443 best_pearson: 0.7248
Batch[14113] - loss: 0.000677 best_pearson: 0.7248
Batch[14114] - loss: 0.000516 best_pearson: 0.7248
Batch[14115] - loss: 0.000367 best_pearson: 0.7248
Batch[14116] - loss: 0.000315 best_pearson: 0.7248
Batch[14117] - loss: 0.000711 best_pearson: 0.7248
Batch[14118] - loss: 0.000694 best_pearson: 0.7248
Batch[14119] - loss: 0.000425 best_pearson: 0.7248
Batch[14120] - loss: 0.000447 best_pearson: 0.7248
Batch[14121] - loss: 0.000205 best_pearson: 0.7248
Batch[14122] - loss: 0.000406 best_pearson: 0.7248
Batch[14123] - loss: 0.000455 best_pearson: 0.7248
Batch[14124] - loss: 0.000682 best_pearson: 0.7248
Batch[14125] - loss: 0.000269 best_pearson: 0.7248
Batch[14126] - loss: 0.000356 best_pearson: 0.7248
Batch[14127] - loss: 0.000246 best_pearson: 0.7248
Batch[14128] - loss: 0.000463 best_pearson: 0.7248
Batch[14129] - loss: 0.000453 best_pearson: 0.7248
Batch[14130] - loss: 0.000432 best_pearson: 0.7248
Batch[14131] - loss: 0.000412 best_pearson: 0.7248
Batch[14132] - loss: 0.000519 best_pearson: 0.7248
Batch[14133] - loss: 0.000548 best_pearson: 0.7248
Batch[14134] - loss: 0.000552 best_pearson: 0.7248
Batch[14135] - loss: 0.000543 best_pearson: 0.7248
Batch[14136] - loss: 0.000392 best_pearson: 0.7248
Batch[14137] - loss: 0.000739 best_pearson: 0.7248
Batch[14138] - loss: 0.000276 best_pearson: 0.7248
Batch[14139] - loss: 0.000357 best_pearson: 0.7248
Batch[14140] - loss: 0.000288 best_pearson: 0.7248
Batch[14141] - loss: 0.000491 best_pearson: 0.7248
Batch[14142] - loss: 0.000458 best_pearson: 0.7248
Batch[14143] - loss: 0.000427 best_pearson: 0.7248
Batch[14144] - loss: 0.000256 best_pearson: 0.7248
Batch[14145] - loss: 0.000331 best_pearson: 0.7248
Batch[14146] - loss: 0.000321 best_pearson: 0.7248
Batch[14147] - loss: 0.000705 best_pearson: 0.7248
Batch[14148] - loss: 0.000456 best_pearson: 0.7248
Batch[14149] - loss: 0.000301 best_pearson: 0.7248
Batch[14150] - loss: 0.000759 best_pearson: 0.7248
Batch[14151] - loss: 0.000517 best_pearson: 0.7248
Batch[14152] - loss: 0.000512 best_pearson: 0.7248
Batch[14153] - loss: 0.000555 best_pearson: 0.7248
Batch[14154] - loss: 0.000666 best_pearson: 0.7248
Batch[14155] - loss: 0.000378 best_pearson: 0.7248
Batch[14156] - loss: 0.000456 best_pearson: 0.7248
Batch[14157] - loss: 0.000323 best_pearson: 0.7248
Batch[14158] - loss: 0.000384 best_pearson: 0.7248
Batch[14159] - loss: 0.000596 best_pearson: 0.7248
Batch[14160] - loss: 0.000317 best_pearson: 0.7248
Batch[14161] - loss: 0.000375 best_pearson: 0.7248
Batch[14162] - loss: 0.000349 best_pearson: 0.7248
Batch[14163] - loss: 0.000437 best_pearson: 0.7248
Batch[14164] - loss: 0.000397 best_pearson: 0.7248
Batch[14165] - loss: 0.000564 best_pearson: 0.7248
Batch[14166] - loss: 0.000787 best_pearson: 0.7248
Batch[14167] - loss: 0.000409 best_pearson: 0.7248
Batch[14168] - loss: 0.000347 best_pearson: 0.7248
Batch[14169] - loss: 0.000460 best_pearson: 0.7248
Batch[14170] - loss: 0.000260 best_pearson: 0.7248
Batch[14171] - loss: 0.000417 best_pearson: 0.7248
Batch[14172] - loss: 0.000404 best_pearson: 0.7248
Batch[14173] - loss: 0.000299 best_pearson: 0.7248
Batch[14174] - loss: 0.000416 best_pearson: 0.7248
Batch[14175] - loss: 0.000310 best_pearson: 0.7248
Batch[14176] - loss: 0.000407 best_pearson: 0.7248
Batch[14177] - loss: 0.000365 best_pearson: 0.7248
Batch[14178] - loss: 0.000236 best_pearson: 0.7248
Batch[14179] - loss: 0.000697 best_pearson: 0.7248
Batch[14180] - loss: 0.000473 best_pearson: 0.7248
Batch[14181] - loss: 0.000384 best_pearson: 0.7248
Batch[14182] - loss: 0.000404 best_pearson: 0.7248
Batch[14183] - loss: 0.000561 best_pearson: 0.7248
Batch[14184] - loss: 0.000366 best_pearson: 0.7248
Batch[14185] - loss: 0.000585 best_pearson: 0.7248
Batch[14186] - loss: 0.000608 best_pearson: 0.7248
Batch[14187] - loss: 0.000518 best_pearson: 0.7248
Batch[14188] - loss: 0.000687 best_pearson: 0.7248
Batch[14189] - loss: 0.000441 best_pearson: 0.7248
Batch[14190] - loss: 0.000699 best_pearson: 0.7248
Batch[14191] - loss: 0.000356 best_pearson: 0.7248
Batch[14192] - loss: 0.000500 best_pearson: 0.7248
Batch[14193] - loss: 0.000535 best_pearson: 0.7248
Batch[14194] - loss: 0.000334 best_pearson: 0.7248
Batch[14195] - loss: 0.000496 best_pearson: 0.7248
Batch[14196] - loss: 0.000297 best_pearson: 0.7248
Batch[14197] - loss: 0.000335 best_pearson: 0.7248
Batch[14198] - loss: 0.000418 best_pearson: 0.7248
Batch[14199] - loss: 0.000363 best_pearson: 0.7248
Batch[14200] - loss: 0.000612 best_pearson: 0.7248

Evaluation - loss: 0.000050 pearson: 0.6950 

early stop by 1500 steps.
Batch[14201] - loss: 0.000516 best_pearson: 0.7248
Batch[14202] - loss: 0.000347 best_pearson: 0.7248
Batch[14203] - loss: 0.000399 best_pearson: 0.7248
Batch[14204] - loss: 0.000745 best_pearson: 0.7248
Batch[14205] - loss: 0.000502 best_pearson: 0.7248
Batch[14206] - loss: 0.000419 best_pearson: 0.7248
Batch[14207] - loss: 0.000294 best_pearson: 0.7248
Batch[14208] - loss: 0.000844 best_pearson: 0.7248
Batch[14209] - loss: 0.000585 best_pearson: 0.7248
Batch[14210] - loss: 0.000459 best_pearson: 0.7248
Batch[14211] - loss: 0.000424 best_pearson: 0.7248
Batch[14212] - loss: 0.000519 best_pearson: 0.7248
Batch[14213] - loss: 0.000359 best_pearson: 0.7248
Batch[14214] - loss: 0.000280 best_pearson: 0.7248
Batch[14215] - loss: 0.000313 best_pearson: 0.7248
Batch[14216] - loss: 0.000356 best_pearson: 0.7248
Batch[14217] - loss: 0.000354 best_pearson: 0.7248
Batch[14218] - loss: 0.000357 best_pearson: 0.7248
Batch[14219] - loss: 0.000311 best_pearson: 0.7248
Batch[14220] - loss: 0.000374 best_pearson: 0.7248
Batch[14221] - loss: 0.000284 best_pearson: 0.7248
Batch[14222] - loss: 0.000384 best_pearson: 0.7248
Batch[14223] - loss: 0.000335 best_pearson: 0.7248
Batch[14224] - loss: 0.000350 best_pearson: 0.7248
Batch[14225] - loss: 0.000537 best_pearson: 0.7248
Batch[14226] - loss: 0.000325 best_pearson: 0.7248
Batch[14227] - loss: 0.000423 best_pearson: 0.7248
Batch[14228] - loss: 0.000438 best_pearson: 0.7248
Batch[14229] - loss: 0.000476 best_pearson: 0.7248
Batch[14230] - loss: 0.000483 best_pearson: 0.7248
Batch[14231] - loss: 0.000492 best_pearson: 0.7248
Batch[14232] - loss: 0.000439 best_pearson: 0.7248
Batch[14233] - loss: 0.000568 best_pearson: 0.7248
Batch[14234] - loss: 0.000512 best_pearson: 0.7248
Batch[14235] - loss: 0.000192 best_pearson: 0.7248
Batch[14236] - loss: 0.000514 best_pearson: 0.7248
Batch[14237] - loss: 0.000332 best_pearson: 0.7248
Batch[14238] - loss: 0.000755 best_pearson: 0.7248
Batch[14239] - loss: 0.000336 best_pearson: 0.7248
Batch[14240] - loss: 0.000642 best_pearson: 0.7248
Batch[14241] - loss: 0.000242 best_pearson: 0.7248
Batch[14242] - loss: 0.000418 best_pearson: 0.7248
Batch[14243] - loss: 0.000273 best_pearson: 0.7248
Batch[14244] - loss: 0.000321 best_pearson: 0.7248
Batch[14245] - loss: 0.000419 best_pearson: 0.7248
Batch[14246] - loss: 0.000557 best_pearson: 0.7248
Batch[14247] - loss: 0.000519 best_pearson: 0.7248
Batch[14248] - loss: 0.000225 best_pearson: 0.7248
Batch[14249] - loss: 0.000838 best_pearson: 0.7248
Batch[14250] - loss: 0.000415 best_pearson: 0.7248
Batch[14251] - loss: 0.000468 best_pearson: 0.7248
Batch[14252] - loss: 0.000451 best_pearson: 0.7248
Batch[14253] - loss: 0.000457 best_pearson: 0.7248
Batch[14254] - loss: 0.000671 best_pearson: 0.7248
Batch[14255] - loss: 0.000503 best_pearson: 0.7248
Batch[14256] - loss: 0.000385 best_pearson: 0.7248
Batch[14257] - loss: 0.000402 best_pearson: 0.7248
Batch[14258] - loss: 0.000456 best_pearson: 0.7248
Batch[14259] - loss: 0.000308 best_pearson: 0.7248
Batch[14260] - loss: 0.000529 best_pearson: 0.7248
Batch[14261] - loss: 0.000318 best_pearson: 0.7248
Batch[14262] - loss: 0.000224 best_pearson: 0.7248
Batch[14263] - loss: 0.000501 best_pearson: 0.7248
Batch[14264] - loss: 0.000484 best_pearson: 0.7248
Batch[14265] - loss: 0.000210 best_pearson: 0.7248
Batch[14266] - loss: 0.000479 best_pearson: 0.7248
Batch[14267] - loss: 0.000528 best_pearson: 0.7248
Batch[14268] - loss: 0.000414 best_pearson: 0.7248
Batch[14269] - loss: 0.000378 best_pearson: 0.7248
Batch[14270] - loss: 0.000423 best_pearson: 0.7248
Batch[14271] - loss: 0.000467 best_pearson: 0.7248
Batch[14272] - loss: 0.000439 best_pearson: 0.7248
Batch[14273] - loss: 0.000233 best_pearson: 0.7248
Batch[14274] - loss: 0.000408 best_pearson: 0.7248
Batch[14275] - loss: 0.000638 best_pearson: 0.7248
Batch[14276] - loss: 0.000410 best_pearson: 0.7248
Batch[14277] - loss: 0.000340 best_pearson: 0.7248
Batch[14278] - loss: 0.000630 best_pearson: 0.7248
Batch[14279] - loss: 0.000532 best_pearson: 0.7248
Batch[14280] - loss: 0.000427 best_pearson: 0.7248
Batch[14281] - loss: 0.000294 best_pearson: 0.7248
Batch[14282] - loss: 0.000373 best_pearson: 0.7248
Batch[14283] - loss: 0.000795 best_pearson: 0.7248
Batch[14284] - loss: 0.000242 best_pearson: 0.7248
Batch[14285] - loss: 0.000385 best_pearson: 0.7248
Batch[14286] - loss: 0.000334 best_pearson: 0.7248
Batch[14287] - loss: 0.000488 best_pearson: 0.7248
Batch[14288] - loss: 0.000184 best_pearson: 0.7248
Batch[14289] - loss: 0.000380 best_pearson: 0.7248
Batch[14290] - loss: 0.000389 best_pearson: 0.7248
Batch[14291] - loss: 0.000331 best_pearson: 0.7248
Batch[14292] - loss: 0.000314 best_pearson: 0.7248
Batch[14293] - loss: 0.000370 best_pearson: 0.7248
Batch[14294] - loss: 0.000435 best_pearson: 0.7248
Batch[14295] - loss: 0.000660 best_pearson: 0.7248
Batch[14296] - loss: 0.000199 best_pearson: 0.7248
Batch[14297] - loss: 0.000273 best_pearson: 0.7248
Batch[14298] - loss: 0.000430 best_pearson: 0.7248
Batch[14299] - loss: 0.000545 best_pearson: 0.7248
Batch[14300] - loss: 0.000471 best_pearson: 0.7248

Evaluation - loss: 0.000049 pearson: 0.6972 

early stop by 1500 steps.
Batch[14301] - loss: 0.000542 best_pearson: 0.7248
Batch[14302] - loss: 0.000461 best_pearson: 0.7248
Batch[14303] - loss: 0.000483 best_pearson: 0.7248
Batch[14304] - loss: 0.000468 best_pearson: 0.7248
Batch[14305] - loss: 0.000251 best_pearson: 0.7248
Batch[14306] - loss: 0.000454 best_pearson: 0.7248
Batch[14307] - loss: 0.000419 best_pearson: 0.7248
Batch[14308] - loss: 0.000316 best_pearson: 0.7248
Batch[14309] - loss: 0.000406 best_pearson: 0.7248
Batch[14310] - loss: 0.000834 best_pearson: 0.7248
Batch[14311] - loss: 0.000449 best_pearson: 0.7248
Batch[14312] - loss: 0.000571 best_pearson: 0.7248
Batch[14313] - loss: 0.000304 best_pearson: 0.7248
Batch[14314] - loss: 0.000408 best_pearson: 0.7248
Batch[14315] - loss: 0.000411 best_pearson: 0.7248
Batch[14316] - loss: 0.000444 best_pearson: 0.7248
Batch[14317] - loss: 0.000193 best_pearson: 0.7248
Batch[14318] - loss: 0.000575 best_pearson: 0.7248
Batch[14319] - loss: 0.000553 best_pearson: 0.7248
Batch[14320] - loss: 0.000453 best_pearson: 0.7248
Batch[14321] - loss: 0.000342 best_pearson: 0.7248
Batch[14322] - loss: 0.000323 best_pearson: 0.7248
Batch[14323] - loss: 0.000200 best_pearson: 0.7248
Batch[14324] - loss: 0.000360 best_pearson: 0.7248
Batch[14325] - loss: 0.000277 best_pearson: 0.7248
Batch[14326] - loss: 0.000569 best_pearson: 0.7248
Batch[14327] - loss: 0.000299 best_pearson: 0.7248
Batch[14328] - loss: 0.000343 best_pearson: 0.7248
Batch[14329] - loss: 0.000391 best_pearson: 0.7248
Batch[14330] - loss: 0.000401 best_pearson: 0.7248
Batch[14331] - loss: 0.000362 best_pearson: 0.7248
Batch[14332] - loss: 0.000511 best_pearson: 0.7248
Batch[14333] - loss: 0.000568 best_pearson: 0.7248
Batch[14334] - loss: 0.000515 best_pearson: 0.7248
Batch[14335] - loss: 0.000536 best_pearson: 0.7248
Batch[14336] - loss: 0.000492 best_pearson: 0.7248
Batch[14337] - loss: 0.000451 best_pearson: 0.7248
Batch[14338] - loss: 0.000309 best_pearson: 0.7248
Batch[14339] - loss: 0.000498 best_pearson: 0.7248
Batch[14340] - loss: 0.000517 best_pearson: 0.7248
Batch[14341] - loss: 0.000415 best_pearson: 0.7248
Batch[14342] - loss: 0.000673 best_pearson: 0.7248
Batch[14343] - loss: 0.000318 best_pearson: 0.7248
Batch[14344] - loss: 0.000251 best_pearson: 0.7248
Batch[14345] - loss: 0.000419 best_pearson: 0.7248
Batch[14346] - loss: 0.000357 best_pearson: 0.7248
Batch[14347] - loss: 0.000338 best_pearson: 0.7248
Batch[14348] - loss: 0.000348 best_pearson: 0.7248
Batch[14349] - loss: 0.000361 best_pearson: 0.7248
Batch[14350] - loss: 0.000303 best_pearson: 0.7248
Batch[14351] - loss: 0.000412 best_pearson: 0.7248
Batch[14352] - loss: 0.000347 best_pearson: 0.7248
Batch[14353] - loss: 0.000359 best_pearson: 0.7248
Batch[14354] - loss: 0.000563 best_pearson: 0.7248
Batch[14355] - loss: 0.000320 best_pearson: 0.7248
Batch[14356] - loss: 0.000214 best_pearson: 0.7248
Batch[14357] - loss: 0.000361 best_pearson: 0.7248
Batch[14358] - loss: 0.000311 best_pearson: 0.7248
Batch[14359] - loss: 0.000447 best_pearson: 0.7248
Batch[14360] - loss: 0.000384 best_pearson: 0.7248
Batch[14361] - loss: 0.000299 best_pearson: 0.7248
Batch[14362] - loss: 0.000231 best_pearson: 0.7248
Batch[14363] - loss: 0.000249 best_pearson: 0.7248
Batch[14364] - loss: 0.000712 best_pearson: 0.7248
Batch[14365] - loss: 0.000505 best_pearson: 0.7248
Batch[14366] - loss: 0.000306 best_pearson: 0.7248
Batch[14367] - loss: 0.000478 best_pearson: 0.7248
Batch[14368] - loss: 0.000465 best_pearson: 0.7248
Batch[14369] - loss: 0.000783 best_pearson: 0.7248
Batch[14370] - loss: 0.000339 best_pearson: 0.7248
Batch[14371] - loss: 0.000611 best_pearson: 0.7248
Batch[14372] - loss: 0.000592 best_pearson: 0.7248
Batch[14373] - loss: 0.000476 best_pearson: 0.7248
Batch[14374] - loss: 0.000315 best_pearson: 0.7248
Batch[14375] - loss: 0.000468 best_pearson: 0.7248
Batch[14376] - loss: 0.000233 best_pearson: 0.7248
Batch[14377] - loss: 0.000379 best_pearson: 0.7248
Batch[14378] - loss: 0.000461 best_pearson: 0.7248
Batch[14379] - loss: 0.000473 best_pearson: 0.7248
Batch[14380] - loss: 0.000978 best_pearson: 0.7248
Batch[14381] - loss: 0.000588 best_pearson: 0.7248
Batch[14382] - loss: 0.000254 best_pearson: 0.7248
Batch[14383] - loss: 0.000281 best_pearson: 0.7248
Batch[14384] - loss: 0.000627 best_pearson: 0.7248
Batch[14385] - loss: 0.000238 best_pearson: 0.7248
Batch[14386] - loss: 0.000447 best_pearson: 0.7248
Batch[14387] - loss: 0.000560 best_pearson: 0.7248
Batch[14388] - loss: 0.000418 best_pearson: 0.7248
Batch[14389] - loss: 0.000263 best_pearson: 0.7248
Batch[14390] - loss: 0.000295 best_pearson: 0.7248
Batch[14391] - loss: 0.000503 best_pearson: 0.7248
Batch[14392] - loss: 0.000366 best_pearson: 0.7248
Batch[14393] - loss: 0.000347 best_pearson: 0.7248
Batch[14394] - loss: 0.000735 best_pearson: 0.7248
Batch[14395] - loss: 0.000290 best_pearson: 0.7248
Batch[14396] - loss: 0.000602 best_pearson: 0.7248
Batch[14397] - loss: 0.000333 best_pearson: 0.7248
Batch[14398] - loss: 0.000247 best_pearson: 0.7248
Batch[14399] - loss: 0.000504 best_pearson: 0.7248
Batch[14400] - loss: 0.000420 best_pearson: 0.7248

Evaluation - loss: 0.000049 pearson: 0.6954 

early stop by 1500 steps.
Batch[14401] - loss: 0.000405 best_pearson: 0.7248
Batch[14402] - loss: 0.000484 best_pearson: 0.7248
Batch[14403] - loss: 0.000652 best_pearson: 0.7248
Batch[14404] - loss: 0.000434 best_pearson: 0.7248
Batch[14405] - loss: 0.000365 best_pearson: 0.7248
Batch[14406] - loss: 0.000557 best_pearson: 0.7248
Batch[14407] - loss: 0.000462 best_pearson: 0.7248
Batch[14408] - loss: 0.000316 best_pearson: 0.7248
Batch[14409] - loss: 0.000324 best_pearson: 0.7248
Batch[14410] - loss: 0.000412 best_pearson: 0.7248
Batch[14411] - loss: 0.000435 best_pearson: 0.7248
Batch[14412] - loss: 0.000503 best_pearson: 0.7248
Batch[14413] - loss: 0.000389 best_pearson: 0.7248
Batch[14414] - loss: 0.000638 best_pearson: 0.7248
Batch[14415] - loss: 0.000333 best_pearson: 0.7248
Batch[14416] - loss: 0.000305 best_pearson: 0.7248
Batch[14417] - loss: 0.000352 best_pearson: 0.7248
Batch[14418] - loss: 0.000312 best_pearson: 0.7248
Batch[14419] - loss: 0.000315 best_pearson: 0.7248
Batch[14420] - loss: 0.000401 best_pearson: 0.7248
Batch[14421] - loss: 0.000321 best_pearson: 0.7248
Batch[14422] - loss: 0.000461 best_pearson: 0.7248
Batch[14423] - loss: 0.000449 best_pearson: 0.7248
Batch[14424] - loss: 0.000289 best_pearson: 0.7248
Batch[14425] - loss: 0.000531 best_pearson: 0.7248
Batch[14426] - loss: 0.000510 best_pearson: 0.7248
Batch[14427] - loss: 0.000366 best_pearson: 0.7248
Batch[14428] - loss: 0.000376 best_pearson: 0.7248
Batch[14429] - loss: 0.000299 best_pearson: 0.7248
Batch[14430] - loss: 0.000376 best_pearson: 0.7248
Batch[14431] - loss: 0.000263 best_pearson: 0.7248
Batch[14432] - loss: 0.000438 best_pearson: 0.7248
Batch[14433] - loss: 0.000510 best_pearson: 0.7248
Batch[14434] - loss: 0.000382 best_pearson: 0.7248
Batch[14435] - loss: 0.000358 best_pearson: 0.7248
Batch[14436] - loss: 0.000544 best_pearson: 0.7248
Batch[14437] - loss: 0.000685 best_pearson: 0.7248
Batch[14438] - loss: 0.000500 best_pearson: 0.7248
Batch[14439] - loss: 0.000465 best_pearson: 0.7248
Batch[14440] - loss: 0.000593 best_pearson: 0.7248
Batch[14441] - loss: 0.000301 best_pearson: 0.7248
Batch[14442] - loss: 0.000515 best_pearson: 0.7248
Batch[14443] - loss: 0.000296 best_pearson: 0.7248
Batch[14444] - loss: 0.000385 best_pearson: 0.7248
Batch[14445] - loss: 0.000459 best_pearson: 0.7248
Batch[14446] - loss: 0.000237 best_pearson: 0.7248
Batch[14447] - loss: 0.000364 best_pearson: 0.7248
Batch[14448] - loss: 0.000550 best_pearson: 0.7248
Batch[14449] - loss: 0.000469 best_pearson: 0.7248
Batch[14450] - loss: 0.000256 best_pearson: 0.7248
Batch[14451] - loss: 0.000283 best_pearson: 0.7248
Batch[14452] - loss: 0.000565 best_pearson: 0.7248
Batch[14453] - loss: 0.000489 best_pearson: 0.7248
Batch[14454] - loss: 0.000640 best_pearson: 0.7248
Batch[14455] - loss: 0.000541 best_pearson: 0.7248
Batch[14456] - loss: 0.000582 best_pearson: 0.7248
Batch[14457] - loss: 0.000419 best_pearson: 0.7248
Batch[14458] - loss: 0.000452 best_pearson: 0.7248
Batch[14459] - loss: 0.000206 best_pearson: 0.7248
Batch[14460] - loss: 0.000362 best_pearson: 0.7248
Batch[14461] - loss: 0.000416 best_pearson: 0.7248
Batch[14462] - loss: 0.000149 best_pearson: 0.7248
Batch[14463] - loss: 0.000288 best_pearson: 0.7248
Batch[14464] - loss: 0.000392 best_pearson: 0.7248
Batch[14465] - loss: 0.000476 best_pearson: 0.7248
Batch[14466] - loss: 0.000343 best_pearson: 0.7248
Batch[14467] - loss: 0.000312 best_pearson: 0.7248
Batch[14468] - loss: 0.000310 best_pearson: 0.7248
Batch[14469] - loss: 0.000573 best_pearson: 0.7248
Batch[14470] - loss: 0.000490 best_pearson: 0.7248
Batch[14471] - loss: 0.000300 best_pearson: 0.7248
Batch[14472] - loss: 0.000437 best_pearson: 0.7248
Batch[14473] - loss: 0.000315 best_pearson: 0.7248
Batch[14474] - loss: 0.000551 best_pearson: 0.7248
Batch[14475] - loss: 0.000555 best_pearson: 0.7248
Batch[14476] - loss: 0.000338 best_pearson: 0.7248
Batch[14477] - loss: 0.000203 best_pearson: 0.7248
Batch[14478] - loss: 0.000234 best_pearson: 0.7248
Batch[14479] - loss: 0.000340 best_pearson: 0.7248
Batch[14480] - loss: 0.000324 best_pearson: 0.7248
Batch[14481] - loss: 0.000663 best_pearson: 0.7248
Batch[14482] - loss: 0.000462 best_pearson: 0.7248
Batch[14483] - loss: 0.000238 best_pearson: 0.7248
Batch[14484] - loss: 0.000347 best_pearson: 0.7248
Batch[14485] - loss: 0.000331 best_pearson: 0.7248
Batch[14486] - loss: 0.000420 best_pearson: 0.7248
Batch[14487] - loss: 0.000508 best_pearson: 0.7248
Batch[14488] - loss: 0.000447 best_pearson: 0.7248
Batch[14489] - loss: 0.000703 best_pearson: 0.7248
Batch[14490] - loss: 0.000387 best_pearson: 0.7248
Batch[14491] - loss: 0.000424 best_pearson: 0.7248
Batch[14492] - loss: 0.000510 best_pearson: 0.7248
Batch[14493] - loss: 0.000432 best_pearson: 0.7248
Batch[14494] - loss: 0.000450 best_pearson: 0.7248
Batch[14495] - loss: 0.000531 best_pearson: 0.7248
Batch[14496] - loss: 0.000177 best_pearson: 0.7248
Batch[14497] - loss: 0.000283 best_pearson: 0.7248
Batch[14498] - loss: 0.000402 best_pearson: 0.7248
Batch[14499] - loss: 0.000547 best_pearson: 0.7248
Batch[14500] - loss: 0.000380 best_pearson: 0.7248

Evaluation - loss: 0.000050 pearson: 0.6933 

early stop by 1500 steps.
Batch[14501] - loss: 0.000455 best_pearson: 0.7248
Batch[14502] - loss: 0.000534 best_pearson: 0.7248
Batch[14503] - loss: 0.000901 best_pearson: 0.7248
Batch[14504] - loss: 0.000543 best_pearson: 0.7248
Batch[14505] - loss: 0.000308 best_pearson: 0.7248
Batch[14506] - loss: 0.000318 best_pearson: 0.7248
Batch[14507] - loss: 0.000559 best_pearson: 0.7248
Batch[14508] - loss: 0.000330 best_pearson: 0.7248
Batch[14509] - loss: 0.000288 best_pearson: 0.7248
Batch[14510] - loss: 0.000470 best_pearson: 0.7248
Batch[14511] - loss: 0.000446 best_pearson: 0.7248
Batch[14512] - loss: 0.000575 best_pearson: 0.7248
Batch[14513] - loss: 0.000267 best_pearson: 0.7248
Batch[14514] - loss: 0.000325 best_pearson: 0.7248
Batch[14515] - loss: 0.000299 best_pearson: 0.7248
Batch[14516] - loss: 0.000507 best_pearson: 0.7248
Batch[14517] - loss: 0.000502 best_pearson: 0.7248
Batch[14518] - loss: 0.000406 best_pearson: 0.7248
Batch[14519] - loss: 0.000541 best_pearson: 0.7248
Batch[14520] - loss: 0.000460 best_pearson: 0.7248
Batch[14521] - loss: 0.000421 best_pearson: 0.7248
Batch[14522] - loss: 0.000299 best_pearson: 0.7248
Batch[14523] - loss: 0.000666 best_pearson: 0.7248
Batch[14524] - loss: 0.000224 best_pearson: 0.7248
Batch[14525] - loss: 0.000551 best_pearson: 0.7248
Batch[14526] - loss: 0.000378 best_pearson: 0.7248
Batch[14527] - loss: 0.000680 best_pearson: 0.7248
Batch[14528] - loss: 0.000400 best_pearson: 0.7248
Batch[14529] - loss: 0.000237 best_pearson: 0.7248
Batch[14530] - loss: 0.000404 best_pearson: 0.7248
Batch[14531] - loss: 0.000343 best_pearson: 0.7248
Batch[14532] - loss: 0.000357 best_pearson: 0.7248
Batch[14533] - loss: 0.000442 best_pearson: 0.7248
Batch[14534] - loss: 0.000362 best_pearson: 0.7248
Batch[14535] - loss: 0.000470 best_pearson: 0.7248
Batch[14536] - loss: 0.000396 best_pearson: 0.7248
Batch[14537] - loss: 0.000498 best_pearson: 0.7248
Batch[14538] - loss: 0.000312 best_pearson: 0.7248
Batch[14539] - loss: 0.000726 best_pearson: 0.7248
Batch[14540] - loss: 0.000448 best_pearson: 0.7248
Batch[14541] - loss: 0.000264 best_pearson: 0.7248
Batch[14542] - loss: 0.000429 best_pearson: 0.7248
Batch[14543] - loss: 0.000279 best_pearson: 0.7248
Batch[14544] - loss: 0.000577 best_pearson: 0.7248
Batch[14545] - loss: 0.000654 best_pearson: 0.7248
Batch[14546] - loss: 0.000348 best_pearson: 0.7248
Batch[14547] - loss: 0.000440 best_pearson: 0.7248
Batch[14548] - loss: 0.000442 best_pearson: 0.7248
Batch[14549] - loss: 0.000470 best_pearson: 0.7248
Batch[14550] - loss: 0.000388 best_pearson: 0.7248
Batch[14551] - loss: 0.000332 best_pearson: 0.7248
Batch[14552] - loss: 0.000419 best_pearson: 0.7248
Batch[14553] - loss: 0.000422 best_pearson: 0.7248
Batch[14554] - loss: 0.000338 best_pearson: 0.7248
Batch[14555] - loss: 0.000422 best_pearson: 0.7248
Batch[14556] - loss: 0.000386 best_pearson: 0.7248
Batch[14557] - loss: 0.000330 best_pearson: 0.7248
Batch[14558] - loss: 0.000295 best_pearson: 0.7248
Batch[14559] - loss: 0.000205 best_pearson: 0.7248
Batch[14560] - loss: 0.000514 best_pearson: 0.7248
Batch[14561] - loss: 0.000332 best_pearson: 0.7248
Batch[14562] - loss: 0.000255 best_pearson: 0.7248
Batch[14563] - loss: 0.000262 best_pearson: 0.7248
Batch[14564] - loss: 0.000537 best_pearson: 0.7248
Batch[14565] - loss: 0.000487 best_pearson: 0.7248
Batch[14566] - loss: 0.000304 best_pearson: 0.7248
Batch[14567] - loss: 0.000272 best_pearson: 0.7248
Batch[14568] - loss: 0.000563 best_pearson: 0.7248
Batch[14569] - loss: 0.000248 best_pearson: 0.7248
Batch[14570] - loss: 0.000351 best_pearson: 0.7248
Batch[14571] - loss: 0.000627 best_pearson: 0.7248
Batch[14572] - loss: 0.000305 best_pearson: 0.7248
Batch[14573] - loss: 0.000487 best_pearson: 0.7248
Batch[14574] - loss: 0.000343 best_pearson: 0.7248
Batch[14575] - loss: 0.000225 best_pearson: 0.7248
Batch[14576] - loss: 0.000410 best_pearson: 0.7248
Batch[14577] - loss: 0.000591 best_pearson: 0.7248
Batch[14578] - loss: 0.000300 best_pearson: 0.7248
Batch[14579] - loss: 0.000330 best_pearson: 0.7248
Batch[14580] - loss: 0.000474 best_pearson: 0.7248
Batch[14581] - loss: 0.000404 best_pearson: 0.7248
Batch[14582] - loss: 0.000594 best_pearson: 0.7248
Batch[14583] - loss: 0.000643 best_pearson: 0.7248
Batch[14584] - loss: 0.000279 best_pearson: 0.7248
Batch[14585] - loss: 0.000380 best_pearson: 0.7248
Batch[14586] - loss: 0.000383 best_pearson: 0.7248
Batch[14587] - loss: 0.000305 best_pearson: 0.7248
Batch[14588] - loss: 0.000466 best_pearson: 0.7248
Batch[14589] - loss: 0.000305 best_pearson: 0.7248
Batch[14590] - loss: 0.000530 best_pearson: 0.7248
Batch[14591] - loss: 0.000592 best_pearson: 0.7248
Batch[14592] - loss: 0.000599 best_pearson: 0.7248
Batch[14593] - loss: 0.000285 best_pearson: 0.7248
Batch[14594] - loss: 0.000456 best_pearson: 0.7248
Batch[14595] - loss: 0.000323 best_pearson: 0.7248
Batch[14596] - loss: 0.000361 best_pearson: 0.7248
Batch[14597] - loss: 0.000347 best_pearson: 0.7248
Batch[14598] - loss: 0.000436 best_pearson: 0.7248
Batch[14599] - loss: 0.000321 best_pearson: 0.7248
Batch[14600] - loss: 0.000277 best_pearson: 0.7248

Evaluation - loss: 0.000049 pearson: 0.6953 

early stop by 1500 steps.
Batch[14601] - loss: 0.000417 best_pearson: 0.7248
Batch[14602] - loss: 0.000460 best_pearson: 0.7248
Batch[14603] - loss: 0.000482 best_pearson: 0.7248
Batch[14604] - loss: 0.000426 best_pearson: 0.7248
Batch[14605] - loss: 0.000374 best_pearson: 0.7248
Batch[14606] - loss: 0.000485 best_pearson: 0.7248
Batch[14607] - loss: 0.000461 best_pearson: 0.7248
Batch[14608] - loss: 0.000441 best_pearson: 0.7248
Batch[14609] - loss: 0.000394 best_pearson: 0.7248
Batch[14610] - loss: 0.000488 best_pearson: 0.7248
Batch[14611] - loss: 0.000394 best_pearson: 0.7248
Batch[14612] - loss: 0.000369 best_pearson: 0.7248
Batch[14613] - loss: 0.000408 best_pearson: 0.7248
Batch[14614] - loss: 0.000272 best_pearson: 0.7248
Batch[14615] - loss: 0.000826 best_pearson: 0.7248
Batch[14616] - loss: 0.000324 best_pearson: 0.7248
Batch[14617] - loss: 0.000275 best_pearson: 0.7248
Batch[14618] - loss: 0.000394 best_pearson: 0.7248
Batch[14619] - loss: 0.000361 best_pearson: 0.7248
Batch[14620] - loss: 0.000320 best_pearson: 0.7248
Batch[14621] - loss: 0.000422 best_pearson: 0.7248
Batch[14622] - loss: 0.000493 best_pearson: 0.7248
Batch[14623] - loss: 0.000299 best_pearson: 0.7248
Batch[14624] - loss: 0.000524 best_pearson: 0.7248
Batch[14625] - loss: 0.000650 best_pearson: 0.7248
Batch[14626] - loss: 0.000229 best_pearson: 0.7248
Batch[14627] - loss: 0.000349 best_pearson: 0.7248
Batch[14628] - loss: 0.000253 best_pearson: 0.7248
Batch[14629] - loss: 0.000383 best_pearson: 0.7248
Batch[14630] - loss: 0.000294 best_pearson: 0.7248
Batch[14631] - loss: 0.000457 best_pearson: 0.7248
Batch[14632] - loss: 0.000263 best_pearson: 0.7248
Batch[14633] - loss: 0.000400 best_pearson: 0.7248
Batch[14634] - loss: 0.000230 best_pearson: 0.7248
Batch[14635] - loss: 0.000383 best_pearson: 0.7248
Batch[14636] - loss: 0.000332 best_pearson: 0.7248
Batch[14637] - loss: 0.000269 best_pearson: 0.7248
Batch[14638] - loss: 0.000340 best_pearson: 0.7248
Batch[14639] - loss: 0.000455 best_pearson: 0.7248
Batch[14640] - loss: 0.000386 best_pearson: 0.7248
Batch[14641] - loss: 0.000468 best_pearson: 0.7248
Batch[14642] - loss: 0.000263 best_pearson: 0.7248
Batch[14643] - loss: 0.000498 best_pearson: 0.7248
Batch[14644] - loss: 0.000385 best_pearson: 0.7248
Batch[14645] - loss: 0.000234 best_pearson: 0.7248
Batch[14646] - loss: 0.000255 best_pearson: 0.7248
Batch[14647] - loss: 0.000316 best_pearson: 0.7248
Batch[14648] - loss: 0.000444 best_pearson: 0.7248
Batch[14649] - loss: 0.000459 best_pearson: 0.7248
Batch[14650] - loss: 0.000288 best_pearson: 0.7248
Batch[14651] - loss: 0.000442 best_pearson: 0.7248
Batch[14652] - loss: 0.000347 best_pearson: 0.7248
Batch[14653] - loss: 0.000452 best_pearson: 0.7248
Batch[14654] - loss: 0.000365 best_pearson: 0.7248
Batch[14655] - loss: 0.000573 best_pearson: 0.7248
Batch[14656] - loss: 0.000486 best_pearson: 0.7248
Batch[14657] - loss: 0.000274 best_pearson: 0.7248
Batch[14658] - loss: 0.000299 best_pearson: 0.7248
Batch[14659] - loss: 0.000442 best_pearson: 0.7248
Batch[14660] - loss: 0.000648 best_pearson: 0.7248
Batch[14661] - loss: 0.000535 best_pearson: 0.7248
Batch[14662] - loss: 0.000482 best_pearson: 0.7248
Batch[14663] - loss: 0.000371 best_pearson: 0.7248
Batch[14664] - loss: 0.000564 best_pearson: 0.7248
Batch[14665] - loss: 0.000260 best_pearson: 0.7248
Batch[14666] - loss: 0.000541 best_pearson: 0.7248
Batch[14667] - loss: 0.000398 best_pearson: 0.7248
Batch[14668] - loss: 0.000458 best_pearson: 0.7248
Batch[14669] - loss: 0.000538 best_pearson: 0.7248
Batch[14670] - loss: 0.000632 best_pearson: 0.7248
Batch[14671] - loss: 0.000387 best_pearson: 0.7248
Batch[14672] - loss: 0.000352 best_pearson: 0.7248
Batch[14673] - loss: 0.000386 best_pearson: 0.7248
Batch[14674] - loss: 0.000466 best_pearson: 0.7248
Batch[14675] - loss: 0.000452 best_pearson: 0.7248
Batch[14676] - loss: 0.000412 best_pearson: 0.7248
Batch[14677] - loss: 0.000283 best_pearson: 0.7248
Batch[14678] - loss: 0.000418 best_pearson: 0.7248
Batch[14679] - loss: 0.000442 best_pearson: 0.7248
Batch[14680] - loss: 0.000435 best_pearson: 0.7248
Batch[14681] - loss: 0.000186 best_pearson: 0.7248
Batch[14682] - loss: 0.000332 best_pearson: 0.7248
Batch[14683] - loss: 0.000312 best_pearson: 0.7248
Batch[14684] - loss: 0.000391 best_pearson: 0.7248
Batch[14685] - loss: 0.000505 best_pearson: 0.7248
Batch[14686] - loss: 0.000610 best_pearson: 0.7248
Batch[14687] - loss: 0.000425 best_pearson: 0.7248
Batch[14688] - loss: 0.000436 best_pearson: 0.7248
Batch[14689] - loss: 0.000515 best_pearson: 0.7248
Batch[14690] - loss: 0.000321 best_pearson: 0.7248
Batch[14691] - loss: 0.000767 best_pearson: 0.7248
Batch[14692] - loss: 0.000439 best_pearson: 0.7248
Batch[14693] - loss: 0.000237 best_pearson: 0.7248
Batch[14694] - loss: 0.000291 best_pearson: 0.7248
Batch[14695] - loss: 0.000364 best_pearson: 0.7248
Batch[14696] - loss: 0.000475 best_pearson: 0.7248
Batch[14697] - loss: 0.000489 best_pearson: 0.7248
Batch[14698] - loss: 0.000318 best_pearson: 0.7248
Batch[14699] - loss: 0.000501 best_pearson: 0.7248
Batch[14700] - loss: 0.000573 best_pearson: 0.7248

Evaluation - loss: 0.000050 pearson: 0.6945 

early stop by 1500 steps.
Batch[14701] - loss: 0.000409 best_pearson: 0.7248
Batch[14702] - loss: 0.000609 best_pearson: 0.7248
Batch[14703] - loss: 0.000327 best_pearson: 0.7248
Batch[14704] - loss: 0.000415 best_pearson: 0.7248
Batch[14705] - loss: 0.000650 best_pearson: 0.7248
Batch[14706] - loss: 0.000416 best_pearson: 0.7248
Batch[14707] - loss: 0.000464 best_pearson: 0.7248
Batch[14708] - loss: 0.000601 best_pearson: 0.7248
Batch[14709] - loss: 0.000499 best_pearson: 0.7248
Batch[14710] - loss: 0.000393 best_pearson: 0.7248
Batch[14711] - loss: 0.000333 best_pearson: 0.7248
Batch[14712] - loss: 0.000472 best_pearson: 0.7248
Batch[14713] - loss: 0.000352 best_pearson: 0.7248
Batch[14714] - loss: 0.000566 best_pearson: 0.7248
Batch[14715] - loss: 0.000572 best_pearson: 0.7248
Batch[14716] - loss: 0.000351 best_pearson: 0.7248
Batch[14717] - loss: 0.000567 best_pearson: 0.7248
Batch[14718] - loss: 0.000358 best_pearson: 0.7248
Batch[14719] - loss: 0.000451 best_pearson: 0.7248
Batch[14720] - loss: 0.000264 best_pearson: 0.7248
Batch[14721] - loss: 0.000409 best_pearson: 0.7248
Batch[14722] - loss: 0.000449 best_pearson: 0.7248
Batch[14723] - loss: 0.000886 best_pearson: 0.7248
Batch[14724] - loss: 0.000533 best_pearson: 0.7248
Batch[14725] - loss: 0.000293 best_pearson: 0.7248
Batch[14726] - loss: 0.000476 best_pearson: 0.7248
Batch[14727] - loss: 0.000440 best_pearson: 0.7248
Batch[14728] - loss: 0.000275 best_pearson: 0.7248
Batch[14729] - loss: 0.000394 best_pearson: 0.7248
Batch[14730] - loss: 0.000302 best_pearson: 0.7248
Batch[14731] - loss: 0.000498 best_pearson: 0.7248
Batch[14732] - loss: 0.000422 best_pearson: 0.7248
Batch[14733] - loss: 0.000442 best_pearson: 0.7248
Batch[14734] - loss: 0.000474 best_pearson: 0.7248
Batch[14735] - loss: 0.000981 best_pearson: 0.7248
Batch[14736] - loss: 0.000298 best_pearson: 0.7248
Batch[14737] - loss: 0.000603 best_pearson: 0.7248
Batch[14738] - loss: 0.000508 best_pearson: 0.7248
Batch[14739] - loss: 0.000497 best_pearson: 0.7248
Batch[14740] - loss: 0.000362 best_pearson: 0.7248
Batch[14741] - loss: 0.000501 best_pearson: 0.7248
Batch[14742] - loss: 0.000588 best_pearson: 0.7248
Batch[14743] - loss: 0.000381 best_pearson: 0.7248
Batch[14744] - loss: 0.000410 best_pearson: 0.7248
Batch[14745] - loss: 0.000439 best_pearson: 0.7248
Batch[14746] - loss: 0.000454 best_pearson: 0.7248
Batch[14747] - loss: 0.000547 best_pearson: 0.7248
Batch[14748] - loss: 0.000315 best_pearson: 0.7248
Batch[14749] - loss: 0.000539 best_pearson: 0.7248
Batch[14750] - loss: 0.000420 best_pearson: 0.7248
Batch[14751] - loss: 0.000704 best_pearson: 0.7248
Batch[14752] - loss: 0.000461 best_pearson: 0.7248
Batch[14753] - loss: 0.000489 best_pearson: 0.7248
Batch[14754] - loss: 0.000460 best_pearson: 0.7248
Batch[14755] - loss: 0.000387 best_pearson: 0.7248
Batch[14756] - loss: 0.000240 best_pearson: 0.7248
Batch[14757] - loss: 0.000433 best_pearson: 0.7248
Batch[14758] - loss: 0.000570 best_pearson: 0.7248
Batch[14759] - loss: 0.000488 best_pearson: 0.7248
Batch[14760] - loss: 0.000675 best_pearson: 0.7248
Batch[14761] - loss: 0.000364 best_pearson: 0.7248
Batch[14762] - loss: 0.000404 best_pearson: 0.7248
Batch[14763] - loss: 0.000740 best_pearson: 0.7248
Batch[14764] - loss: 0.000317 best_pearson: 0.7248
Batch[14765] - loss: 0.000260 best_pearson: 0.7248
Batch[14766] - loss: 0.000500 best_pearson: 0.7248
Batch[14767] - loss: 0.000445 best_pearson: 0.7248
Batch[14768] - loss: 0.000227 best_pearson: 0.7248
Batch[14769] - loss: 0.000470 best_pearson: 0.7248
Batch[14770] - loss: 0.000504 best_pearson: 0.7248
Batch[14771] - loss: 0.000463 best_pearson: 0.7248
Batch[14772] - loss: 0.000316 best_pearson: 0.7248
Batch[14773] - loss: 0.000477 best_pearson: 0.7248
Batch[14774] - loss: 0.000333 best_pearson: 0.7248
Batch[14775] - loss: 0.000649 best_pearson: 0.7248
Batch[14776] - loss: 0.000583 best_pearson: 0.7248
Batch[14777] - loss: 0.000495 best_pearson: 0.7248
Batch[14778] - loss: 0.000413 best_pearson: 0.7248
Batch[14779] - loss: 0.000315 best_pearson: 0.7248
Batch[14780] - loss: 0.000578 best_pearson: 0.7248
Batch[14781] - loss: 0.000438 best_pearson: 0.7248
Batch[14782] - loss: 0.000523 best_pearson: 0.7248
Batch[14783] - loss: 0.000445 best_pearson: 0.7248
Batch[14784] - loss: 0.000294 best_pearson: 0.7248
Batch[14785] - loss: 0.000653 best_pearson: 0.7248
Batch[14786] - loss: 0.000470 best_pearson: 0.7248
Batch[14787] - loss: 0.000667 best_pearson: 0.7248
Batch[14788] - loss: 0.000372 best_pearson: 0.7248
Batch[14789] - loss: 0.000671 best_pearson: 0.7248
Batch[14790] - loss: 0.000439 best_pearson: 0.7248
Batch[14791] - loss: 0.000453 best_pearson: 0.7248
Batch[14792] - loss: 0.000721 best_pearson: 0.7248
Batch[14793] - loss: 0.000823 best_pearson: 0.7248
Batch[14794] - loss: 0.000561 best_pearson: 0.7248
Batch[14795] - loss: 0.000606 best_pearson: 0.7248
Batch[14796] - loss: 0.000504 best_pearson: 0.7248
Batch[14797] - loss: 0.000406 best_pearson: 0.7248
Batch[14798] - loss: 0.000735 best_pearson: 0.7248
Batch[14799] - loss: 0.000350 best_pearson: 0.7248
Batch[14800] - loss: 0.000491 best_pearson: 0.7248

Evaluation - loss: 0.000050 pearson: 0.6920 

early stop by 1500 steps.
Batch[14801] - loss: 0.000312 best_pearson: 0.7248
Batch[14802] - loss: 0.000491 best_pearson: 0.7248
Batch[14803] - loss: 0.000646 best_pearson: 0.7248
Batch[14804] - loss: 0.000516 best_pearson: 0.7248
Batch[14805] - loss: 0.000279 best_pearson: 0.7248
Batch[14806] - loss: 0.000779 best_pearson: 0.7248
Batch[14807] - loss: 0.000485 best_pearson: 0.7248
Batch[14808] - loss: 0.000489 best_pearson: 0.7248
Batch[14809] - loss: 0.000518 best_pearson: 0.7248
Batch[14810] - loss: 0.000410 best_pearson: 0.7248
Batch[14811] - loss: 0.000618 best_pearson: 0.7248
Batch[14812] - loss: 0.000476 best_pearson: 0.7248
Batch[14813] - loss: 0.000444 best_pearson: 0.7248
Batch[14814] - loss: 0.000416 best_pearson: 0.7248
Batch[14815] - loss: 0.000556 best_pearson: 0.7248
Batch[14816] - loss: 0.000554 best_pearson: 0.7248
Batch[14817] - loss: 0.000324 best_pearson: 0.7248
Batch[14818] - loss: 0.000667 best_pearson: 0.7248
Batch[14819] - loss: 0.000405 best_pearson: 0.7248
Batch[14820] - loss: 0.000276 best_pearson: 0.7248
Batch[14821] - loss: 0.000660 best_pearson: 0.7248
Batch[14822] - loss: 0.000452 best_pearson: 0.7248
Batch[14823] - loss: 0.000671 best_pearson: 0.7248
Batch[14824] - loss: 0.000398 best_pearson: 0.7248
Batch[14825] - loss: 0.000760 best_pearson: 0.7248
Batch[14826] - loss: 0.000258 best_pearson: 0.7248
Batch[14827] - loss: 0.000623 best_pearson: 0.7248
Batch[14828] - loss: 0.000452 best_pearson: 0.7248
Batch[14829] - loss: 0.000564 best_pearson: 0.7248
Batch[14830] - loss: 0.000246 best_pearson: 0.7248
Batch[14831] - loss: 0.000657 best_pearson: 0.7248
Batch[14832] - loss: 0.000506 best_pearson: 0.7248
Batch[14833] - loss: 0.000415 best_pearson: 0.7248
Batch[14834] - loss: 0.000582 best_pearson: 0.7248
Batch[14835] - loss: 0.000431 best_pearson: 0.7248
Batch[14836] - loss: 0.000410 best_pearson: 0.7248
Batch[14837] - loss: 0.000221 best_pearson: 0.7248
Batch[14838] - loss: 0.000249 best_pearson: 0.7248
Batch[14839] - loss: 0.000309 best_pearson: 0.7248
Batch[14840] - loss: 0.000419 best_pearson: 0.7248
Batch[14841] - loss: 0.000351 best_pearson: 0.7248
Batch[14842] - loss: 0.000359 best_pearson: 0.7248
Batch[14843] - loss: 0.000660 best_pearson: 0.7248
Batch[14844] - loss: 0.000548 best_pearson: 0.7248
Batch[14845] - loss: 0.000272 best_pearson: 0.7248
Batch[14846] - loss: 0.000528 best_pearson: 0.7248
Batch[14847] - loss: 0.000279 best_pearson: 0.7248
Batch[14848] - loss: 0.000389 best_pearson: 0.7248
Batch[14849] - loss: 0.000555 best_pearson: 0.7248
Batch[14850] - loss: 0.000635 best_pearson: 0.7248
Batch[14851] - loss: 0.000893 best_pearson: 0.7248
Batch[14852] - loss: 0.000653 best_pearson: 0.7248
Batch[14853] - loss: 0.000359 best_pearson: 0.7248
Batch[14854] - loss: 0.000578 best_pearson: 0.7248
Batch[14855] - loss: 0.000437 best_pearson: 0.7248
Batch[14856] - loss: 0.000287 best_pearson: 0.7248
Batch[14857] - loss: 0.000815 best_pearson: 0.7248
Batch[14858] - loss: 0.000413 best_pearson: 0.7248
Batch[14859] - loss: 0.000482 best_pearson: 0.7248
Batch[14860] - loss: 0.000556 best_pearson: 0.7248
Batch[14861] - loss: 0.000338 best_pearson: 0.7248
Batch[14862] - loss: 0.000589 best_pearson: 0.7248
Batch[14863] - loss: 0.000628 best_pearson: 0.7248
Batch[14864] - loss: 0.000514 best_pearson: 0.7248
Batch[14865] - loss: 0.000433 best_pearson: 0.7248
Batch[14866] - loss: 0.000465 best_pearson: 0.7248
Batch[14867] - loss: 0.000638 best_pearson: 0.7248
Batch[14868] - loss: 0.000429 best_pearson: 0.7248
Batch[14869] - loss: 0.000209 best_pearson: 0.7248
Batch[14870] - loss: 0.000488 best_pearson: 0.7248
Batch[14871] - loss: 0.000536 best_pearson: 0.7248
Batch[14872] - loss: 0.000326 best_pearson: 0.7248
Batch[14873] - loss: 0.000286 best_pearson: 0.7248
Batch[14874] - loss: 0.000580 best_pearson: 0.7248
Batch[14875] - loss: 0.000386 best_pearson: 0.7248
Batch[14876] - loss: 0.000579 best_pearson: 0.7248
Batch[14877] - loss: 0.000662 best_pearson: 0.7248
Batch[14878] - loss: 0.000405 best_pearson: 0.7248
Batch[14879] - loss: 0.000737 best_pearson: 0.7248
Batch[14880] - loss: 0.000403 best_pearson: 0.7248
Batch[14881] - loss: 0.000362 best_pearson: 0.7248
Batch[14882] - loss: 0.000582 best_pearson: 0.7248
Batch[14883] - loss: 0.000561 best_pearson: 0.7248
Batch[14884] - loss: 0.000525 best_pearson: 0.7248
Batch[14885] - loss: 0.000247 best_pearson: 0.7248
Batch[14886] - loss: 0.000767 best_pearson: 0.7248
Batch[14887] - loss: 0.000439 best_pearson: 0.7248
Batch[14888] - loss: 0.000436 best_pearson: 0.7248
Batch[14889] - loss: 0.000793 best_pearson: 0.7248
Batch[14890] - loss: 0.000554 best_pearson: 0.7248
Batch[14891] - loss: 0.000389 best_pearson: 0.7248
Batch[14892] - loss: 0.000546 best_pearson: 0.7248
Batch[14893] - loss: 0.000458 best_pearson: 0.7248
Batch[14894] - loss: 0.000583 best_pearson: 0.7248
Batch[14895] - loss: 0.000353 best_pearson: 0.7248
Batch[14896] - loss: 0.000551 best_pearson: 0.7248
Batch[14897] - loss: 0.000269 best_pearson: 0.7248
Batch[14898] - loss: 0.000684 best_pearson: 0.7248
Batch[14899] - loss: 0.000792 best_pearson: 0.7248
Batch[14900] - loss: 0.000410 best_pearson: 0.7248

Evaluation - loss: 0.000049 pearson: 0.6983 

early stop by 1500 steps.
Batch[14901] - loss: 0.000421 best_pearson: 0.7248
Batch[14902] - loss: 0.000500 best_pearson: 0.7248
Batch[14903] - loss: 0.000460 best_pearson: 0.7248
Batch[14904] - loss: 0.000467 best_pearson: 0.7248
Batch[14905] - loss: 0.000445 best_pearson: 0.7248
Batch[14906] - loss: 0.000567 best_pearson: 0.7248
Batch[14907] - loss: 0.000526 best_pearson: 0.7248
Batch[14908] - loss: 0.000413 best_pearson: 0.7248
Batch[14909] - loss: 0.000920 best_pearson: 0.7248
Batch[14910] - loss: 0.000360 best_pearson: 0.7248
Batch[14911] - loss: 0.000454 best_pearson: 0.7248
Batch[14912] - loss: 0.000520 best_pearson: 0.7248
Batch[14913] - loss: 0.000512 best_pearson: 0.7248
Batch[14914] - loss: 0.000334 best_pearson: 0.7248
Batch[14915] - loss: 0.000352 best_pearson: 0.7248
Batch[14916] - loss: 0.000557 best_pearson: 0.7248
Batch[14917] - loss: 0.000516 best_pearson: 0.7248
Batch[14918] - loss: 0.000506 best_pearson: 0.7248
Batch[14919] - loss: 0.000382 best_pearson: 0.7248
Batch[14920] - loss: 0.000528 best_pearson: 0.7248
Batch[14921] - loss: 0.000615 best_pearson: 0.7248
Batch[14922] - loss: 0.000835 best_pearson: 0.7248
Batch[14923] - loss: 0.000470 best_pearson: 0.7248
Batch[14924] - loss: 0.000550 best_pearson: 0.7248
Batch[14925] - loss: 0.000487 best_pearson: 0.7248
Batch[14926] - loss: 0.000519 best_pearson: 0.7248
Batch[14927] - loss: 0.000409 best_pearson: 0.7248
Batch[14928] - loss: 0.000598 best_pearson: 0.7248
Batch[14929] - loss: 0.000448 best_pearson: 0.7248
Batch[14930] - loss: 0.000418 best_pearson: 0.7248
Batch[14931] - loss: 0.000766 best_pearson: 0.7248
Batch[14932] - loss: 0.000708 best_pearson: 0.7248
Batch[14933] - loss: 0.000314 best_pearson: 0.7248
Batch[14934] - loss: 0.000548 best_pearson: 0.7248
Batch[14935] - loss: 0.000556 best_pearson: 0.7248
Batch[14936] - loss: 0.000229 best_pearson: 0.7248
Batch[14937] - loss: 0.000596 best_pearson: 0.7248
Batch[14938] - loss: 0.000560 best_pearson: 0.7248
Batch[14939] - loss: 0.000649 best_pearson: 0.7248
Batch[14940] - loss: 0.000591 best_pearson: 0.7248
Batch[14941] - loss: 0.000310 best_pearson: 0.7248
Batch[14942] - loss: 0.000582 best_pearson: 0.7248
Batch[14943] - loss: 0.000384 best_pearson: 0.7248
Batch[14944] - loss: 0.000471 best_pearson: 0.7248
Batch[14945] - loss: 0.000409 best_pearson: 0.7248
Batch[14946] - loss: 0.000593 best_pearson: 0.7248
Batch[14947] - loss: 0.000571 best_pearson: 0.7248
Batch[14948] - loss: 0.000416 best_pearson: 0.7248
Batch[14949] - loss: 0.000330 best_pearson: 0.7248
Batch[14950] - loss: 0.000574 best_pearson: 0.7248
Batch[14951] - loss: 0.000426 best_pearson: 0.7248
Batch[14952] - loss: 0.000574 best_pearson: 0.7248
Batch[14953] - loss: 0.000399 best_pearson: 0.7248
Batch[14954] - loss: 0.000426 best_pearson: 0.7248
Batch[14955] - loss: 0.000508 best_pearson: 0.7248
Batch[14956] - loss: 0.000518 best_pearson: 0.7248
Batch[14957] - loss: 0.000510 best_pearson: 0.7248
Batch[14958] - loss: 0.000366 best_pearson: 0.7248
Batch[14959] - loss: 0.000767 best_pearson: 0.7248
Batch[14960] - loss: 0.000507 best_pearson: 0.7248
Batch[14961] - loss: 0.000504 best_pearson: 0.7248
Batch[14962] - loss: 0.000316 best_pearson: 0.7248
Batch[14963] - loss: 0.000511 best_pearson: 0.7248
Batch[14964] - loss: 0.000554 best_pearson: 0.7248
Batch[14965] - loss: 0.000506 best_pearson: 0.7248
Batch[14966] - loss: 0.000491 best_pearson: 0.7248
Batch[14967] - loss: 0.000439 best_pearson: 0.7248
Batch[14968] - loss: 0.000434 best_pearson: 0.7248
Batch[14969] - loss: 0.000473 best_pearson: 0.7248
Batch[14970] - loss: 0.000707 best_pearson: 0.7248
Batch[14971] - loss: 0.000382 best_pearson: 0.7248
Batch[14972] - loss: 0.000474 best_pearson: 0.7248
Batch[14973] - loss: 0.000488 best_pearson: 0.7248
Batch[14974] - loss: 0.000444 best_pearson: 0.7248
Batch[14975] - loss: 0.000378 best_pearson: 0.7248
Batch[14976] - loss: 0.000565 best_pearson: 0.7248
Batch[14977] - loss: 0.000518 best_pearson: 0.7248
Batch[14978] - loss: 0.000654 best_pearson: 0.7248
Batch[14979] - loss: 0.000435 best_pearson: 0.7248
Batch[14980] - loss: 0.000356 best_pearson: 0.7248
Batch[14981] - loss: 0.000267 best_pearson: 0.7248
Batch[14982] - loss: 0.000323 best_pearson: 0.7248
Batch[14983] - loss: 0.000399 best_pearson: 0.7248
Batch[14984] - loss: 0.000423 best_pearson: 0.7248
Batch[14985] - loss: 0.000390 best_pearson: 0.7248
Batch[14986] - loss: 0.000532 best_pearson: 0.7248
Batch[14987] - loss: 0.000786 best_pearson: 0.7248
Batch[14988] - loss: 0.000588 best_pearson: 0.7248
Batch[14989] - loss: 0.000591 best_pearson: 0.7248
Batch[14990] - loss: 0.000835 best_pearson: 0.7248
Batch[14991] - loss: 0.000367 best_pearson: 0.7248
Batch[14992] - loss: 0.000562 best_pearson: 0.7248
Batch[14993] - loss: 0.000483 best_pearson: 0.7248
Batch[14994] - loss: 0.000420 best_pearson: 0.7248
Batch[14995] - loss: 0.000728 best_pearson: 0.7248
Batch[14996] - loss: 0.000479 best_pearson: 0.7248
Batch[14997] - loss: 0.000691 best_pearson: 0.7248
Batch[14998] - loss: 0.000687 best_pearson: 0.7248
Batch[14999] - loss: 0.000583 best_pearson: 0.7248
Batch[15000] - loss: 0.000443 best_pearson: 0.7248

Evaluation - loss: 0.000050 pearson: 0.6913 

early stop by 1500 steps.
Batch[15001] - loss: 0.000466 best_pearson: 0.7248
Batch[15002] - loss: 0.000677 best_pearson: 0.7248
Batch[15003] - loss: 0.000195 best_pearson: 0.7248
Batch[15004] - loss: 0.000373 best_pearson: 0.7248
Batch[15005] - loss: 0.000514 best_pearson: 0.7248
Batch[15006] - loss: 0.000622 best_pearson: 0.7248
Batch[15007] - loss: 0.000380 best_pearson: 0.7248
Batch[15008] - loss: 0.000676 best_pearson: 0.7248
Batch[15009] - loss: 0.000339 best_pearson: 0.7248
Batch[15010] - loss: 0.000421 best_pearson: 0.7248
Batch[15011] - loss: 0.000647 best_pearson: 0.7248
Batch[15012] - loss: 0.000541 best_pearson: 0.7248
Batch[15013] - loss: 0.000529 best_pearson: 0.7248
Batch[15014] - loss: 0.000544 best_pearson: 0.7248
Batch[15015] - loss: 0.000371 best_pearson: 0.7248
Batch[15016] - loss: 0.000670 best_pearson: 0.7248
Batch[15017] - loss: 0.000412 best_pearson: 0.7248
Batch[15018] - loss: 0.000450 best_pearson: 0.7248
Batch[15019] - loss: 0.000527 best_pearson: 0.7248
Batch[15020] - loss: 0.000375 best_pearson: 0.7248
Batch[15021] - loss: 0.000353 best_pearson: 0.7248
Batch[15022] - loss: 0.000397 best_pearson: 0.7248
Batch[15023] - loss: 0.000505 best_pearson: 0.7248
Batch[15024] - loss: 0.000189 best_pearson: 0.7248
Batch[15025] - loss: 0.000451 best_pearson: 0.7248
Batch[15026] - loss: 0.000432 best_pearson: 0.7248
Batch[15027] - loss: 0.000483 best_pearson: 0.7248
Batch[15028] - loss: 0.000378 best_pearson: 0.7248
Batch[15029] - loss: 0.000568 best_pearson: 0.7248
Batch[15030] - loss: 0.000424 best_pearson: 0.7248
Batch[15031] - loss: 0.000425 best_pearson: 0.7248
Batch[15032] - loss: 0.000477 best_pearson: 0.7248
Batch[15033] - loss: 0.000324 best_pearson: 0.7248
Batch[15034] - loss: 0.000687 best_pearson: 0.7248
Batch[15035] - loss: 0.000326 best_pearson: 0.7248
Batch[15036] - loss: 0.000715 best_pearson: 0.7248
Batch[15037] - loss: 0.000253 best_pearson: 0.7248
Batch[15038] - loss: 0.000338 best_pearson: 0.7248
Batch[15039] - loss: 0.000556 best_pearson: 0.7248
Batch[15040] - loss: 0.000376 best_pearson: 0.7248
Batch[15041] - loss: 0.000389 best_pearson: 0.7248
Batch[15042] - loss: 0.000614 best_pearson: 0.7248
Batch[15043] - loss: 0.000644 best_pearson: 0.7248
Batch[15044] - loss: 0.000469 best_pearson: 0.7248
Batch[15045] - loss: 0.000591 best_pearson: 0.7248
Batch[15046] - loss: 0.000322 best_pearson: 0.7248
Batch[15047] - loss: 0.000392 best_pearson: 0.7248
Batch[15048] - loss: 0.000607 best_pearson: 0.7248
Batch[15049] - loss: 0.000455 best_pearson: 0.7248
Batch[15050] - loss: 0.000425 best_pearson: 0.7248
Batch[15051] - loss: 0.000417 best_pearson: 0.7248
Batch[15052] - loss: 0.000326 best_pearson: 0.7248
Batch[15053] - loss: 0.000559 best_pearson: 0.7248
Batch[15054] - loss: 0.000390 best_pearson: 0.7248
Batch[15055] - loss: 0.000279 best_pearson: 0.7248
Batch[15056] - loss: 0.000658 best_pearson: 0.7248
Batch[15057] - loss: 0.000533 best_pearson: 0.7248
Batch[15058] - loss: 0.000335 best_pearson: 0.7248
Batch[15059] - loss: 0.000254 best_pearson: 0.7248
Batch[15060] - loss: 0.000562 best_pearson: 0.7248
Batch[15061] - loss: 0.000614 best_pearson: 0.7248
Batch[15062] - loss: 0.000247 best_pearson: 0.7248
Batch[15063] - loss: 0.000604 best_pearson: 0.7248
Batch[15064] - loss: 0.000366 best_pearson: 0.7248
Batch[15065] - loss: 0.000400 best_pearson: 0.7248
Batch[15066] - loss: 0.000451 best_pearson: 0.7248
Batch[15067] - loss: 0.000636 best_pearson: 0.7248
Batch[15068] - loss: 0.000399 best_pearson: 0.7248
Batch[15069] - loss: 0.000630 best_pearson: 0.7248
Batch[15070] - loss: 0.000383 best_pearson: 0.7248
Batch[15071] - loss: 0.000355 best_pearson: 0.7248
Batch[15072] - loss: 0.000701 best_pearson: 0.7248
Batch[15073] - loss: 0.000350 best_pearson: 0.7248
Batch[15074] - loss: 0.000501 best_pearson: 0.7248
Batch[15075] - loss: 0.000456 best_pearson: 0.7248
Batch[15076] - loss: 0.000377 best_pearson: 0.7248
Batch[15077] - loss: 0.000280 best_pearson: 0.7248
Batch[15078] - loss: 0.000464 best_pearson: 0.7248
Batch[15079] - loss: 0.000640 best_pearson: 0.7248
Batch[15080] - loss: 0.000377 best_pearson: 0.7248
Batch[15081] - loss: 0.000424 best_pearson: 0.7248
Batch[15082] - loss: 0.000346 best_pearson: 0.7248
Batch[15083] - loss: 0.000660 best_pearson: 0.7248
Batch[15084] - loss: 0.000549 best_pearson: 0.7248
Batch[15085] - loss: 0.000427 best_pearson: 0.7248
Batch[15086] - loss: 0.000278 best_pearson: 0.7248
Batch[15087] - loss: 0.000352 best_pearson: 0.7248
Batch[15088] - loss: 0.000568 best_pearson: 0.7248
Batch[15089] - loss: 0.000494 best_pearson: 0.7248
Batch[15090] - loss: 0.000345 best_pearson: 0.7248
Batch[15091] - loss: 0.000416 best_pearson: 0.7248
Batch[15092] - loss: 0.000587 best_pearson: 0.7248
Batch[15093] - loss: 0.000469 best_pearson: 0.7248
Batch[15094] - loss: 0.000207 best_pearson: 0.7248
Batch[15095] - loss: 0.000532 best_pearson: 0.7248
Batch[15096] - loss: 0.000377 best_pearson: 0.7248
Batch[15097] - loss: 0.000371 best_pearson: 0.7248
Batch[15098] - loss: 0.000392 best_pearson: 0.7248
Batch[15099] - loss: 0.000484 best_pearson: 0.7248
Batch[15100] - loss: 0.000707 best_pearson: 0.7248

Evaluation - loss: 0.000050 pearson: 0.6928 

early stop by 1500 steps.
Batch[15101] - loss: 0.000310 best_pearson: 0.7248
Batch[15102] - loss: 0.000442 best_pearson: 0.7248
Batch[15103] - loss: 0.000566 best_pearson: 0.7248
Batch[15104] - loss: 0.000350 best_pearson: 0.7248
Batch[15105] - loss: 0.000456 best_pearson: 0.7248
Batch[15106] - loss: 0.000482 best_pearson: 0.7248
Batch[15107] - loss: 0.000334 best_pearson: 0.7248
Batch[15108] - loss: 0.000330 best_pearson: 0.7248
Batch[15109] - loss: 0.000404 best_pearson: 0.7248
Batch[15110] - loss: 0.000276 best_pearson: 0.7248
Batch[15111] - loss: 0.000171 best_pearson: 0.7248
Batch[15112] - loss: 0.000354 best_pearson: 0.7248
Batch[15113] - loss: 0.000522 best_pearson: 0.7248
Batch[15114] - loss: 0.000695 best_pearson: 0.7248
Batch[15115] - loss: 0.000587 best_pearson: 0.7248
Batch[15116] - loss: 0.000530 best_pearson: 0.7248
Batch[15117] - loss: 0.000394 best_pearson: 0.7248
Batch[15118] - loss: 0.000421 best_pearson: 0.7248
Batch[15119] - loss: 0.000504 best_pearson: 0.7248
Batch[15120] - loss: 0.000280 best_pearson: 0.7248
Batch[15121] - loss: 0.000624 best_pearson: 0.7248
Batch[15122] - loss: 0.000398 best_pearson: 0.7248
Batch[15123] - loss: 0.000370 best_pearson: 0.7248
Batch[15124] - loss: 0.000576 best_pearson: 0.7248
Batch[15125] - loss: 0.000560 best_pearson: 0.7248
Batch[15126] - loss: 0.000309 best_pearson: 0.7248
Batch[15127] - loss: 0.000422 best_pearson: 0.7248
Batch[15128] - loss: 0.000260 best_pearson: 0.7248
Batch[15129] - loss: 0.000352 best_pearson: 0.7248
Batch[15130] - loss: 0.000568 best_pearson: 0.7248
Batch[15131] - loss: 0.000510 best_pearson: 0.7248
Batch[15132] - loss: 0.000430 best_pearson: 0.7248
Batch[15133] - loss: 0.000415 best_pearson: 0.7248
Batch[15134] - loss: 0.000495 best_pearson: 0.7248
Batch[15135] - loss: 0.000334 best_pearson: 0.7248
Batch[15136] - loss: 0.000415 best_pearson: 0.7248
Batch[15137] - loss: 0.000262 best_pearson: 0.7248
Batch[15138] - loss: 0.000360 best_pearson: 0.7248
Batch[15139] - loss: 0.000341 best_pearson: 0.7248
Batch[15140] - loss: 0.000352 best_pearson: 0.7248
Batch[15141] - loss: 0.000362 best_pearson: 0.7248
Batch[15142] - loss: 0.000417 best_pearson: 0.7248
Batch[15143] - loss: 0.000395 best_pearson: 0.7248
Batch[15144] - loss: 0.000305 best_pearson: 0.7248
Batch[15145] - loss: 0.000486 best_pearson: 0.7248
Batch[15146] - loss: 0.000324 best_pearson: 0.7248
Batch[15147] - loss: 0.000525 best_pearson: 0.7248
Batch[15148] - loss: 0.000564 best_pearson: 0.7248
Batch[15149] - loss: 0.000712 best_pearson: 0.7248
Batch[15150] - loss: 0.000313 best_pearson: 0.7248
Batch[15151] - loss: 0.000252 best_pearson: 0.7248
Batch[15152] - loss: 0.000360 best_pearson: 0.7248
Batch[15153] - loss: 0.000600 best_pearson: 0.7248
Batch[15154] - loss: 0.000392 best_pearson: 0.7248
Batch[15155] - loss: 0.000620 best_pearson: 0.7248
Batch[15156] - loss: 0.000497 best_pearson: 0.7248
Batch[15157] - loss: 0.000403 best_pearson: 0.7248
Batch[15158] - loss: 0.000365 best_pearson: 0.7248
Batch[15159] - loss: 0.000347 best_pearson: 0.7248
Batch[15160] - loss: 0.000292 best_pearson: 0.7248
Batch[15161] - loss: 0.000333 best_pearson: 0.7248
Batch[15162] - loss: 0.000310 best_pearson: 0.7248
Batch[15163] - loss: 0.000347 best_pearson: 0.7248
Batch[15164] - loss: 0.000521 best_pearson: 0.7248
Batch[15165] - loss: 0.000462 best_pearson: 0.7248
Batch[15166] - loss: 0.000584 best_pearson: 0.7248
Batch[15167] - loss: 0.000347 best_pearson: 0.7248
Batch[15168] - loss: 0.000389 best_pearson: 0.7248
Batch[15169] - loss: 0.000465 best_pearson: 0.7248
Batch[15170] - loss: 0.000491 best_pearson: 0.7248
Batch[15171] - loss: 0.000372 best_pearson: 0.7248
Batch[15172] - loss: 0.000531 best_pearson: 0.7248
Batch[15173] - loss: 0.000478 best_pearson: 0.7248
Batch[15174] - loss: 0.000473 best_pearson: 0.7248
Batch[15175] - loss: 0.000303 best_pearson: 0.7248
Batch[15176] - loss: 0.000403 best_pearson: 0.7248
Batch[15177] - loss: 0.000550 best_pearson: 0.7248
Batch[15178] - loss: 0.000261 best_pearson: 0.7248
Batch[15179] - loss: 0.000448 best_pearson: 0.7248
Batch[15180] - loss: 0.000236 best_pearson: 0.7248
Batch[15181] - loss: 0.000433 best_pearson: 0.7248
Batch[15182] - loss: 0.000254 best_pearson: 0.7248
Batch[15183] - loss: 0.000249 best_pearson: 0.7248
Batch[15184] - loss: 0.000504 best_pearson: 0.7248
Batch[15185] - loss: 0.000368 best_pearson: 0.7248
Batch[15186] - loss: 0.000598 best_pearson: 0.7248
Batch[15187] - loss: 0.000306 best_pearson: 0.7248
Batch[15188] - loss: 0.000343 best_pearson: 0.7248
Batch[15189] - loss: 0.000498 best_pearson: 0.7248
Batch[15190] - loss: 0.000362 best_pearson: 0.7248
Batch[15191] - loss: 0.000287 best_pearson: 0.7248
Batch[15192] - loss: 0.000472 best_pearson: 0.7248
Batch[15193] - loss: 0.000291 best_pearson: 0.7248
Batch[15194] - loss: 0.000461 best_pearson: 0.7248
Batch[15195] - loss: 0.000445 best_pearson: 0.7248
Batch[15196] - loss: 0.000364 best_pearson: 0.7248
Batch[15197] - loss: 0.000471 best_pearson: 0.7248
Batch[15198] - loss: 0.000502 best_pearson: 0.7248
Batch[15199] - loss: 0.000325 best_pearson: 0.7248
Batch[15200] - loss: 0.000440 best_pearson: 0.7248

Evaluation - loss: 0.000049 pearson: 0.6929 

early stop by 1500 steps.
Batch[15201] - loss: 0.000544 best_pearson: 0.7248
Batch[15202] - loss: 0.000349 best_pearson: 0.7248
Batch[15203] - loss: 0.000448 best_pearson: 0.7248
Batch[15204] - loss: 0.000356 best_pearson: 0.7248
Batch[15205] - loss: 0.000513 best_pearson: 0.7248
Batch[15206] - loss: 0.000489 best_pearson: 0.7248
Batch[15207] - loss: 0.000644 best_pearson: 0.7248
Batch[15208] - loss: 0.000466 best_pearson: 0.7248
Batch[15209] - loss: 0.000399 best_pearson: 0.7248
Batch[15210] - loss: 0.000501 best_pearson: 0.7248
Batch[15211] - loss: 0.000396 best_pearson: 0.7248
Batch[15212] - loss: 0.000555 best_pearson: 0.7248
Batch[15213] - loss: 0.000510 best_pearson: 0.7248
Batch[15214] - loss: 0.000435 best_pearson: 0.7248
Batch[15215] - loss: 0.000421 best_pearson: 0.7248
Batch[15216] - loss: 0.000646 best_pearson: 0.7248
Batch[15217] - loss: 0.000510 best_pearson: 0.7248
Batch[15218] - loss: 0.000905 best_pearson: 0.7248
Batch[15219] - loss: 0.000509 best_pearson: 0.7248
Batch[15220] - loss: 0.000398 best_pearson: 0.7248
Batch[15221] - loss: 0.000640 best_pearson: 0.7248
Batch[15222] - loss: 0.000395 best_pearson: 0.7248
Batch[15223] - loss: 0.000554 best_pearson: 0.7248
Batch[15224] - loss: 0.000246 best_pearson: 0.7248
Batch[15225] - loss: 0.000507 best_pearson: 0.7248
Batch[15226] - loss: 0.000635 best_pearson: 0.7248
Batch[15227] - loss: 0.000311 best_pearson: 0.7248
Batch[15228] - loss: 0.000387 best_pearson: 0.7248
Batch[15229] - loss: 0.000461 best_pearson: 0.7248
Batch[15230] - loss: 0.000342 best_pearson: 0.7248
Batch[15231] - loss: 0.000415 best_pearson: 0.7248
Batch[15232] - loss: 0.000317 best_pearson: 0.7248
Batch[15233] - loss: 0.000370 best_pearson: 0.7248
Batch[15234] - loss: 0.000548 best_pearson: 0.7248
Batch[15235] - loss: 0.000421 best_pearson: 0.7248
Batch[15236] - loss: 0.000485 best_pearson: 0.7248
Batch[15237] - loss: 0.000471 best_pearson: 0.7248
Batch[15238] - loss: 0.000416 best_pearson: 0.7248
Batch[15239] - loss: 0.000321 best_pearson: 0.7248
Batch[15240] - loss: 0.000376 best_pearson: 0.7248
Batch[15241] - loss: 0.000411 best_pearson: 0.7248
Batch[15242] - loss: 0.000378 best_pearson: 0.7248
Batch[15243] - loss: 0.000661 best_pearson: 0.7248
Batch[15244] - loss: 0.000415 best_pearson: 0.7248
Batch[15245] - loss: 0.000335 best_pearson: 0.7248
Batch[15246] - loss: 0.000397 best_pearson: 0.7248
Batch[15247] - loss: 0.000248 best_pearson: 0.7248
Batch[15248] - loss: 0.000486 best_pearson: 0.7248
Batch[15249] - loss: 0.000345 best_pearson: 0.7248
Batch[15250] - loss: 0.000289 best_pearson: 0.7248
Batch[15251] - loss: 0.000560 best_pearson: 0.7248
Batch[15252] - loss: 0.000250 best_pearson: 0.7248
Batch[15253] - loss: 0.000348 best_pearson: 0.7248
Batch[15254] - loss: 0.000391 best_pearson: 0.7248
Batch[15255] - loss: 0.000241 best_pearson: 0.7248
Batch[15256] - loss: 0.000489 best_pearson: 0.7248
Batch[15257] - loss: 0.000429 best_pearson: 0.7248
Batch[15258] - loss: 0.000285 best_pearson: 0.7248
Batch[15259] - loss: 0.000322 best_pearson: 0.7248
Batch[15260] - loss: 0.000396 best_pearson: 0.7248
Batch[15261] - loss: 0.000468 best_pearson: 0.7248
Batch[15262] - loss: 0.000562 best_pearson: 0.7248
Batch[15263] - loss: 0.000329 best_pearson: 0.7248
Batch[15264] - loss: 0.000545 best_pearson: 0.7248
Batch[15265] - loss: 0.000444 best_pearson: 0.7248
Batch[15266] - loss: 0.000391 best_pearson: 0.7248
Batch[15267] - loss: 0.000281 best_pearson: 0.7248
Batch[15268] - loss: 0.000370 best_pearson: 0.7248
Batch[15269] - loss: 0.000386 best_pearson: 0.7248
Batch[15270] - loss: 0.000524 best_pearson: 0.7248
Batch[15271] - loss: 0.000301 best_pearson: 0.7248
Batch[15272] - loss: 0.000463 best_pearson: 0.7248
Batch[15273] - loss: 0.000345 best_pearson: 0.7248
Batch[15274] - loss: 0.000382 best_pearson: 0.7248
Batch[15275] - loss: 0.000663 best_pearson: 0.7248
Batch[15276] - loss: 0.000551 best_pearson: 0.7248
Batch[15277] - loss: 0.000474 best_pearson: 0.7248
Batch[15278] - loss: 0.000768 best_pearson: 0.7248
Batch[15279] - loss: 0.000583 best_pearson: 0.7248
Batch[15280] - loss: 0.000385 best_pearson: 0.7248
Batch[15281] - loss: 0.000505 best_pearson: 0.7248
Batch[15282] - loss: 0.000273 best_pearson: 0.7248
Batch[15283] - loss: 0.000520 best_pearson: 0.7248
Batch[15284] - loss: 0.000398 best_pearson: 0.7248
Batch[15285] - loss: 0.000562 best_pearson: 0.7248
Batch[15286] - loss: 0.000488 best_pearson: 0.7248
Batch[15287] - loss: 0.000542 best_pearson: 0.7248
Batch[15288] - loss: 0.000309 best_pearson: 0.7248
Batch[15289] - loss: 0.002187 best_pearson: 0.7248
Batch[15290] - loss: 0.000468 best_pearson: 0.7248
Batch[15291] - loss: 0.000468 best_pearson: 0.7248
Batch[15292] - loss: 0.000469 best_pearson: 0.7248
Batch[15293] - loss: 0.000461 best_pearson: 0.7248
Batch[15294] - loss: 0.000608 best_pearson: 0.7248
Batch[15295] - loss: 0.000410 best_pearson: 0.7248
Batch[15296] - loss: 0.000447 best_pearson: 0.7248
Batch[15297] - loss: 0.000396 best_pearson: 0.7248
Batch[15298] - loss: 0.000301 best_pearson: 0.7248
Batch[15299] - loss: 0.000530 best_pearson: 0.7248
Batch[15300] - loss: 0.000385 best_pearson: 0.7248

Evaluation - loss: 0.000050 pearson: 0.6904 

early stop by 1500 steps.
Batch[15301] - loss: 0.000272 best_pearson: 0.7248
Batch[15302] - loss: 0.000391 best_pearson: 0.7248
Batch[15303] - loss: 0.000243 best_pearson: 0.7248
Batch[15304] - loss: 0.000393 best_pearson: 0.7248
Batch[15305] - loss: 0.000396 best_pearson: 0.7248
Batch[15306] - loss: 0.000472 best_pearson: 0.7248
Batch[15307] - loss: 0.000353 best_pearson: 0.7248
Batch[15308] - loss: 0.000520 best_pearson: 0.7248
Batch[15309] - loss: 0.000397 best_pearson: 0.7248
Batch[15310] - loss: 0.000386 best_pearson: 0.7248
Batch[15311] - loss: 0.000484 best_pearson: 0.7248
Batch[15312] - loss: 0.000197 best_pearson: 0.7248
Batch[15313] - loss: 0.000467 best_pearson: 0.7248
Batch[15314] - loss: 0.000946 best_pearson: 0.7248
Batch[15315] - loss: 0.000341 best_pearson: 0.7248
Batch[15316] - loss: 0.000414 best_pearson: 0.7248
Batch[15317] - loss: 0.000541 best_pearson: 0.7248
Batch[15318] - loss: 0.000581 best_pearson: 0.7248
Batch[15319] - loss: 0.000337 best_pearson: 0.7248
Batch[15320] - loss: 0.000230 best_pearson: 0.7248
Batch[15321] - loss: 0.000433 best_pearson: 0.7248
Batch[15322] - loss: 0.000216 best_pearson: 0.7248
Batch[15323] - loss: 0.000579 best_pearson: 0.7248
Batch[15324] - loss: 0.000206 best_pearson: 0.7248
Batch[15325] - loss: 0.000266 best_pearson: 0.7248
Batch[15326] - loss: 0.000295 best_pearson: 0.7248
Batch[15327] - loss: 0.000277 best_pearson: 0.7248
Batch[15328] - loss: 0.000270 best_pearson: 0.7248
Batch[15329] - loss: 0.000346 best_pearson: 0.7248
Batch[15330] - loss: 0.000490 best_pearson: 0.7248
Batch[15331] - loss: 0.000537 best_pearson: 0.7248
Batch[15332] - loss: 0.000435 best_pearson: 0.7248
Batch[15333] - loss: 0.000556 best_pearson: 0.7248
Batch[15334] - loss: 0.000584 best_pearson: 0.7248
Batch[15335] - loss: 0.000395 best_pearson: 0.7248
Batch[15336] - loss: 0.000388 best_pearson: 0.7248
Batch[15337] - loss: 0.000449 best_pearson: 0.7248
Batch[15338] - loss: 0.000404 best_pearson: 0.7248
Batch[15339] - loss: 0.000588 best_pearson: 0.7248
Batch[15340] - loss: 0.000361 best_pearson: 0.7248
Batch[15341] - loss: 0.000324 best_pearson: 0.7248
Batch[15342] - loss: 0.000576 best_pearson: 0.7248
Batch[15343] - loss: 0.000556 best_pearson: 0.7248
Batch[15344] - loss: 0.000536 best_pearson: 0.7248
Batch[15345] - loss: 0.000449 best_pearson: 0.7248
Batch[15346] - loss: 0.000524 best_pearson: 0.7248
Batch[15347] - loss: 0.000533 best_pearson: 0.7248
Batch[15348] - loss: 0.000664 best_pearson: 0.7248
Batch[15349] - loss: 0.000337 best_pearson: 0.7248
Batch[15350] - loss: 0.000236 best_pearson: 0.7248
Batch[15351] - loss: 0.000440 best_pearson: 0.7248
Batch[15352] - loss: 0.000394 best_pearson: 0.7248
Batch[15353] - loss: 0.000359 best_pearson: 0.7248
Batch[15354] - loss: 0.000571 best_pearson: 0.7248
Batch[15355] - loss: 0.000602 best_pearson: 0.7248
Batch[15356] - loss: 0.000292 best_pearson: 0.7248
Batch[15357] - loss: 0.000569 best_pearson: 0.7248
Batch[15358] - loss: 0.000384 best_pearson: 0.7248
Batch[15359] - loss: 0.000570 best_pearson: 0.7248
Batch[15360] - loss: 0.000641 best_pearson: 0.7248
Batch[15361] - loss: 0.000229 best_pearson: 0.7248
Batch[15362] - loss: 0.000362 best_pearson: 0.7248
Batch[15363] - loss: 0.000461 best_pearson: 0.7248
Batch[15364] - loss: 0.000735 best_pearson: 0.7248
Batch[15365] - loss: 0.000482 best_pearson: 0.7248
Batch[15366] - loss: 0.000482 best_pearson: 0.7248
Batch[15367] - loss: 0.000396 best_pearson: 0.7248
Batch[15368] - loss: 0.000366 best_pearson: 0.7248
Batch[15369] - loss: 0.000268 best_pearson: 0.7248
Batch[15370] - loss: 0.000416 best_pearson: 0.7248
Batch[15371] - loss: 0.000293 best_pearson: 0.7248
Batch[15372] - loss: 0.000404 best_pearson: 0.7248
Batch[15373] - loss: 0.000405 best_pearson: 0.7248
Batch[15374] - loss: 0.000772 best_pearson: 0.7248
Batch[15375] - loss: 0.000397 best_pearson: 0.7248
Batch[15376] - loss: 0.000436 best_pearson: 0.7248
Batch[15377] - loss: 0.000884 best_pearson: 0.7248
Batch[15378] - loss: 0.000368 best_pearson: 0.7248
Batch[15379] - loss: 0.000255 best_pearson: 0.7248
Batch[15380] - loss: 0.000498 best_pearson: 0.7248
Batch[15381] - loss: 0.000513 best_pearson: 0.7248
Batch[15382] - loss: 0.000396 best_pearson: 0.7248
Batch[15383] - loss: 0.000460 best_pearson: 0.7248
Batch[15384] - loss: 0.000484 best_pearson: 0.7248
Batch[15385] - loss: 0.000563 best_pearson: 0.7248
Batch[15386] - loss: 0.000572 best_pearson: 0.7248
Batch[15387] - loss: 0.000343 best_pearson: 0.7248
Batch[15388] - loss: 0.000526 best_pearson: 0.7248
Batch[15389] - loss: 0.000341 best_pearson: 0.7248
Batch[15390] - loss: 0.000512 best_pearson: 0.7248
Batch[15391] - loss: 0.000580 best_pearson: 0.7248
Batch[15392] - loss: 0.000519 best_pearson: 0.7248
Batch[15393] - loss: 0.000615 best_pearson: 0.7248
Batch[15394] - loss: 0.000292 best_pearson: 0.7248
Batch[15395] - loss: 0.000511 best_pearson: 0.7248
Batch[15396] - loss: 0.000316 best_pearson: 0.7248
Batch[15397] - loss: 0.000500 best_pearson: 0.7248
Batch[15398] - loss: 0.000888 best_pearson: 0.7248
Batch[15399] - loss: 0.000542 best_pearson: 0.7248
Batch[15400] - loss: 0.000547 best_pearson: 0.7248

Evaluation - loss: 0.000050 pearson: 0.6941 

early stop by 1500 steps.
Batch[15401] - loss: 0.000320 best_pearson: 0.7248
Batch[15402] - loss: 0.000531 best_pearson: 0.7248
Batch[15403] - loss: 0.000290 best_pearson: 0.7248
Batch[15404] - loss: 0.000506 best_pearson: 0.7248
Batch[15405] - loss: 0.000347 best_pearson: 0.7248
Batch[15406] - loss: 0.000552 best_pearson: 0.7248
Batch[15407] - loss: 0.000380 best_pearson: 0.7248
Batch[15408] - loss: 0.000387 best_pearson: 0.7248
Batch[15409] - loss: 0.000527 best_pearson: 0.7248
Batch[15410] - loss: 0.000511 best_pearson: 0.7248
Batch[15411] - loss: 0.000300 best_pearson: 0.7248
Batch[15412] - loss: 0.000315 best_pearson: 0.7248
Batch[15413] - loss: 0.000378 best_pearson: 0.7248
Batch[15414] - loss: 0.000283 best_pearson: 0.7248
Batch[15415] - loss: 0.000794 best_pearson: 0.7248
Batch[15416] - loss: 0.000638 best_pearson: 0.7248
Batch[15417] - loss: 0.000415 best_pearson: 0.7248
Batch[15418] - loss: 0.000673 best_pearson: 0.7248
Batch[15419] - loss: 0.000451 best_pearson: 0.7248
Batch[15420] - loss: 0.000255 best_pearson: 0.7248
Batch[15421] - loss: 0.000455 best_pearson: 0.7248
Batch[15422] - loss: 0.000601 best_pearson: 0.7248
Batch[15423] - loss: 0.000267 best_pearson: 0.7248
Batch[15424] - loss: 0.000372 best_pearson: 0.7248
Batch[15425] - loss: 0.000431 best_pearson: 0.7248
Batch[15426] - loss: 0.000286 best_pearson: 0.7248
Batch[15427] - loss: 0.000378 best_pearson: 0.7248
Batch[15428] - loss: 0.000531 best_pearson: 0.7248
Batch[15429] - loss: 0.000338 best_pearson: 0.7248
Batch[15430] - loss: 0.000287 best_pearson: 0.7248
Batch[15431] - loss: 0.000495 best_pearson: 0.7248
Batch[15432] - loss: 0.000675 best_pearson: 0.7248
Batch[15433] - loss: 0.000366 best_pearson: 0.7248
Batch[15434] - loss: 0.000518 best_pearson: 0.7248
Batch[15435] - loss: 0.000515 best_pearson: 0.7248
Batch[15436] - loss: 0.000672 best_pearson: 0.7248
Batch[15437] - loss: 0.000279 best_pearson: 0.7248
Batch[15438] - loss: 0.000461 best_pearson: 0.7248
Batch[15439] - loss: 0.000421 best_pearson: 0.7248
Batch[15440] - loss: 0.000514 best_pearson: 0.7248
Batch[15441] - loss: 0.000427 best_pearson: 0.7248
Batch[15442] - loss: 0.000438 best_pearson: 0.7248
Batch[15443] - loss: 0.000443 best_pearson: 0.7248
Batch[15444] - loss: 0.000705 best_pearson: 0.7248
Batch[15445] - loss: 0.000435 best_pearson: 0.7248
Batch[15446] - loss: 0.000173 best_pearson: 0.7248
Batch[15447] - loss: 0.000529 best_pearson: 0.7248
Batch[15448] - loss: 0.000504 best_pearson: 0.7248
Batch[15449] - loss: 0.000314 best_pearson: 0.7248
Batch[15450] - loss: 0.000369 best_pearson: 0.7248
Batch[15451] - loss: 0.000513 best_pearson: 0.7248
Batch[15452] - loss: 0.000544 best_pearson: 0.7248
Batch[15453] - loss: 0.000453 best_pearson: 0.7248
Batch[15454] - loss: 0.000358 best_pearson: 0.7248
Batch[15455] - loss: 0.000211 best_pearson: 0.7248
Batch[15456] - loss: 0.000452 best_pearson: 0.7248
Batch[15457] - loss: 0.000706 best_pearson: 0.7248
Batch[15458] - loss: 0.000268 best_pearson: 0.7248
Batch[15459] - loss: 0.000341 best_pearson: 0.7248
Batch[15460] - loss: 0.000312 best_pearson: 0.7248
Batch[15461] - loss: 0.000455 best_pearson: 0.7248
Batch[15462] - loss: 0.000439 best_pearson: 0.7248
Batch[15463] - loss: 0.000313 best_pearson: 0.7248
Batch[15464] - loss: 0.000580 best_pearson: 0.7248
Batch[15465] - loss: 0.000636 best_pearson: 0.7248
Batch[15466] - loss: 0.000360 best_pearson: 0.7248
Batch[15467] - loss: 0.000454 best_pearson: 0.7248
Batch[15468] - loss: 0.000600 best_pearson: 0.7248
Batch[15469] - loss: 0.000510 best_pearson: 0.7248
Batch[15470] - loss: 0.000389 best_pearson: 0.7248
Batch[15471] - loss: 0.000657 best_pearson: 0.7248
Batch[15472] - loss: 0.000419 best_pearson: 0.7248
Batch[15473] - loss: 0.000520 best_pearson: 0.7248
Batch[15474] - loss: 0.000432 best_pearson: 0.7248
Batch[15475] - loss: 0.000384 best_pearson: 0.7248
Batch[15476] - loss: 0.000423 best_pearson: 0.7248
Batch[15477] - loss: 0.000412 best_pearson: 0.7248
Batch[15478] - loss: 0.000319 best_pearson: 0.7248
Batch[15479] - loss: 0.000362 best_pearson: 0.7248
Batch[15480] - loss: 0.000765 best_pearson: 0.7248
Batch[15481] - loss: 0.000416 best_pearson: 0.7248
Batch[15482] - loss: 0.000442 best_pearson: 0.7248
Batch[15483] - loss: 0.000429 best_pearson: 0.7248
Batch[15484] - loss: 0.000571 best_pearson: 0.7248
Batch[15485] - loss: 0.000562 best_pearson: 0.7248
Batch[15486] - loss: 0.000312 best_pearson: 0.7248
Batch[15487] - loss: 0.000611 best_pearson: 0.7248
Batch[15488] - loss: 0.000350 best_pearson: 0.7248
Batch[15489] - loss: 0.000282 best_pearson: 0.7248
Batch[15490] - loss: 0.000505 best_pearson: 0.7248
Batch[15491] - loss: 0.000469 best_pearson: 0.7248
Batch[15492] - loss: 0.000599 best_pearson: 0.7248
Batch[15493] - loss: 0.000520 best_pearson: 0.7248
Batch[15494] - loss: 0.000433 best_pearson: 0.7248
Batch[15495] - loss: 0.000301 best_pearson: 0.7248
Batch[15496] - loss: 0.000318 best_pearson: 0.7248
Batch[15497] - loss: 0.000411 best_pearson: 0.7248
Batch[15498] - loss: 0.000423 best_pearson: 0.7248
Batch[15499] - loss: 0.000525 best_pearson: 0.7248
Batch[15500] - loss: 0.000606 best_pearson: 0.7248

Evaluation - loss: 0.000050 pearson: 0.6908 

early stop by 1500 steps.
Batch[15501] - loss: 0.000531 best_pearson: 0.7248
Batch[15502] - loss: 0.000350 best_pearson: 0.7248
Batch[15503] - loss: 0.000603 best_pearson: 0.7248
Batch[15504] - loss: 0.000709 best_pearson: 0.7248
Batch[15505] - loss: 0.000552 best_pearson: 0.7248
Batch[15506] - loss: 0.000310 best_pearson: 0.7248
Batch[15507] - loss: 0.000384 best_pearson: 0.7248
Batch[15508] - loss: 0.000479 best_pearson: 0.7248
Batch[15509] - loss: 0.000337 best_pearson: 0.7248
Batch[15510] - loss: 0.000406 best_pearson: 0.7248
Batch[15511] - loss: 0.000615 best_pearson: 0.7248
Batch[15512] - loss: 0.000449 best_pearson: 0.7248
Batch[15513] - loss: 0.000294 best_pearson: 0.7248
Batch[15514] - loss: 0.000447 best_pearson: 0.7248
Batch[15515] - loss: 0.000426 best_pearson: 0.7248
Batch[15516] - loss: 0.000285 best_pearson: 0.7248
Batch[15517] - loss: 0.000314 best_pearson: 0.7248
Batch[15518] - loss: 0.000562 best_pearson: 0.7248
Batch[15519] - loss: 0.000338 best_pearson: 0.7248
Batch[15520] - loss: 0.000301 best_pearson: 0.7248
Batch[15521] - loss: 0.000533 best_pearson: 0.7248
Batch[15522] - loss: 0.000391 best_pearson: 0.7248
Batch[15523] - loss: 0.000447 best_pearson: 0.7248
Batch[15524] - loss: 0.000606 best_pearson: 0.7248
Batch[15525] - loss: 0.000372 best_pearson: 0.7248
Batch[15526] - loss: 0.000562 best_pearson: 0.7248
Batch[15527] - loss: 0.000311 best_pearson: 0.7248
Batch[15528] - loss: 0.000418 best_pearson: 0.7248
Batch[15529] - loss: 0.000571 best_pearson: 0.7248
Batch[15530] - loss: 0.000539 best_pearson: 0.7248
Batch[15531] - loss: 0.000362 best_pearson: 0.7248
Batch[15532] - loss: 0.000654 best_pearson: 0.7248
Batch[15533] - loss: 0.000528 best_pearson: 0.7248
Batch[15534] - loss: 0.000751 best_pearson: 0.7248
Batch[15535] - loss: 0.000413 best_pearson: 0.7248
Batch[15536] - loss: 0.000485 best_pearson: 0.7248
Batch[15537] - loss: 0.000324 best_pearson: 0.7248
Batch[15538] - loss: 0.000847 best_pearson: 0.7248
Batch[15539] - loss: 0.000588 best_pearson: 0.7248
Batch[15540] - loss: 0.000331 best_pearson: 0.7248
Batch[15541] - loss: 0.000562 best_pearson: 0.7248
Batch[15542] - loss: 0.000805 best_pearson: 0.7248
Batch[15543] - loss: 0.000416 best_pearson: 0.7248
Batch[15544] - loss: 0.000490 best_pearson: 0.7248
Batch[15545] - loss: 0.000383 best_pearson: 0.7248
Batch[15546] - loss: 0.000414 best_pearson: 0.7248
Batch[15547] - loss: 0.000256 best_pearson: 0.7248
Batch[15548] - loss: 0.000344 best_pearson: 0.7248
Batch[15549] - loss: 0.000496 best_pearson: 0.7248
Batch[15550] - loss: 0.000946 best_pearson: 0.7248
Batch[15551] - loss: 0.000480 best_pearson: 0.7248
Batch[15552] - loss: 0.000585 best_pearson: 0.7248
Batch[15553] - loss: 0.000525 best_pearson: 0.7248
Batch[15554] - loss: 0.000372 best_pearson: 0.7248
Batch[15555] - loss: 0.000322 best_pearson: 0.7248
Batch[15556] - loss: 0.000589 best_pearson: 0.7248
Batch[15557] - loss: 0.000424 best_pearson: 0.7248
Batch[15558] - loss: 0.000357 best_pearson: 0.7248
Batch[15559] - loss: 0.000423 best_pearson: 0.7248
Batch[15560] - loss: 0.000490 best_pearson: 0.7248
Batch[15561] - loss: 0.000622 best_pearson: 0.7248
Batch[15562] - loss: 0.000327 best_pearson: 0.7248
Batch[15563] - loss: 0.000485 best_pearson: 0.7248
Batch[15564] - loss: 0.000424 best_pearson: 0.7248
Batch[15565] - loss: 0.000418 best_pearson: 0.7248
Batch[15566] - loss: 0.000391 best_pearson: 0.7248
Batch[15567] - loss: 0.000437 best_pearson: 0.7248
Batch[15568] - loss: 0.000359 best_pearson: 0.7248
Batch[15569] - loss: 0.000797 best_pearson: 0.7248
Batch[15570] - loss: 0.000408 best_pearson: 0.7248
Batch[15571] - loss: 0.000400 best_pearson: 0.7248
Batch[15572] - loss: 0.000322 best_pearson: 0.7248
Batch[15573] - loss: 0.000582 best_pearson: 0.7248
Batch[15574] - loss: 0.000267 best_pearson: 0.7248
Batch[15575] - loss: 0.000408 best_pearson: 0.7248
Batch[15576] - loss: 0.000578 best_pearson: 0.7248
Batch[15577] - loss: 0.000411 best_pearson: 0.7248
Batch[15578] - loss: 0.000771 best_pearson: 0.7248
Batch[15579] - loss: 0.000423 best_pearson: 0.7248
Batch[15580] - loss: 0.000463 best_pearson: 0.7248
Batch[15581] - loss: 0.000466 best_pearson: 0.7248
Batch[15582] - loss: 0.000472 best_pearson: 0.7248
Batch[15583] - loss: 0.000678 best_pearson: 0.7248
Batch[15584] - loss: 0.000592 best_pearson: 0.7248
Batch[15585] - loss: 0.000642 best_pearson: 0.7248
Batch[15586] - loss: 0.000466 best_pearson: 0.7248
Batch[15587] - loss: 0.000541 best_pearson: 0.7248
Batch[15588] - loss: 0.000477 best_pearson: 0.7248
Batch[15589] - loss: 0.000546 best_pearson: 0.7248
Batch[15590] - loss: 0.000408 best_pearson: 0.7248
Batch[15591] - loss: 0.000604 best_pearson: 0.7248
Batch[15592] - loss: 0.000447 best_pearson: 0.7248
Batch[15593] - loss: 0.000629 best_pearson: 0.7248
Batch[15594] - loss: 0.000433 best_pearson: 0.7248
Batch[15595] - loss: 0.000330 best_pearson: 0.7248
Batch[15596] - loss: 0.000220 best_pearson: 0.7248
Batch[15597] - loss: 0.000627 best_pearson: 0.7248
Batch[15598] - loss: 0.000450 best_pearson: 0.7248
Batch[15599] - loss: 0.000560 best_pearson: 0.7248
Batch[15600] - loss: 0.000622 best_pearson: 0.7248

Evaluation - loss: 0.000049 pearson: 0.6929 

early stop by 1500 steps.
Batch[15601] - loss: 0.000421 best_pearson: 0.7248
Batch[15602] - loss: 0.000521 best_pearson: 0.7248
Batch[15603] - loss: 0.000353 best_pearson: 0.7248
Batch[15604] - loss: 0.000314 best_pearson: 0.7248
Batch[15605] - loss: 0.000572 best_pearson: 0.7248
Batch[15606] - loss: 0.000342 best_pearson: 0.7248
Batch[15607] - loss: 0.000796 best_pearson: 0.7248
Batch[15608] - loss: 0.000557 best_pearson: 0.7248
Batch[15609] - loss: 0.000382 best_pearson: 0.7248
Batch[15610] - loss: 0.000500 best_pearson: 0.7248
Batch[15611] - loss: 0.000506 best_pearson: 0.7248
Batch[15612] - loss: 0.000865 best_pearson: 0.7248
Batch[15613] - loss: 0.000540 best_pearson: 0.7248
Batch[15614] - loss: 0.000506 best_pearson: 0.7248
Batch[15615] - loss: 0.000556 best_pearson: 0.7248
Batch[15616] - loss: 0.000854 best_pearson: 0.7248
Batch[15617] - loss: 0.000624 best_pearson: 0.7248
Batch[15618] - loss: 0.000634 best_pearson: 0.7248
Batch[15619] - loss: 0.000545 best_pearson: 0.7248
Batch[15620] - loss: 0.000848 best_pearson: 0.7248
Batch[15621] - loss: 0.000530 best_pearson: 0.7248
Batch[15622] - loss: 0.000461 best_pearson: 0.7248
Batch[15623] - loss: 0.000895 best_pearson: 0.7248
Batch[15624] - loss: 0.000979 best_pearson: 0.7248
Batch[15625] - loss: 0.000461 best_pearson: 0.7248
Batch[15626] - loss: 0.000500 best_pearson: 0.7248
Batch[15627] - loss: 0.000877 best_pearson: 0.7248
Batch[15628] - loss: 0.000748 best_pearson: 0.7248
Batch[15629] - loss: 0.000577 best_pearson: 0.7248
Batch[15630] - loss: 0.000595 best_pearson: 0.7248
Batch[15631] - loss: 0.000604 best_pearson: 0.7248
Batch[15632] - loss: 0.000533 best_pearson: 0.7248
Batch[15633] - loss: 0.000423 best_pearson: 0.7248
Batch[15634] - loss: 0.000545 best_pearson: 0.7248
Batch[15635] - loss: 0.000617 best_pearson: 0.7248
Batch[15636] - loss: 0.000568 best_pearson: 0.7248
Batch[15637] - loss: 0.000682 best_pearson: 0.7248
Batch[15638] - loss: 0.000339 best_pearson: 0.7248
Batch[15639] - loss: 0.000501 best_pearson: 0.7248
Batch[15640] - loss: 0.000592 best_pearson: 0.7248
Batch[15641] - loss: 0.000611 best_pearson: 0.7248
Batch[15642] - loss: 0.000718 best_pearson: 0.7248
Batch[15643] - loss: 0.000715 best_pearson: 0.7248
Batch[15644] - loss: 0.000573 best_pearson: 0.7248
Batch[15645] - loss: 0.000706 best_pearson: 0.7248
Batch[15646] - loss: 0.000320 best_pearson: 0.7248
Batch[15647] - loss: 0.000571 best_pearson: 0.7248
Batch[15648] - loss: 0.000483 best_pearson: 0.7248
Batch[15649] - loss: 0.000485 best_pearson: 0.7248
Batch[15650] - loss: 0.000438 best_pearson: 0.7248
Batch[15651] - loss: 0.000471 best_pearson: 0.7248
Batch[15652] - loss: 0.000332 best_pearson: 0.7248
Batch[15653] - loss: 0.000353 best_pearson: 0.7248
Batch[15654] - loss: 0.000775 best_pearson: 0.7248
Batch[15655] - loss: 0.000720 best_pearson: 0.7248
Batch[15656] - loss: 0.000338 best_pearson: 0.7248
Batch[15657] - loss: 0.000508 best_pearson: 0.7248
Batch[15658] - loss: 0.000535 best_pearson: 0.7248
Batch[15659] - loss: 0.000713 best_pearson: 0.7248
Batch[15660] - loss: 0.000536 best_pearson: 0.7248
Batch[15661] - loss: 0.000485 best_pearson: 0.7248
Batch[15662] - loss: 0.000451 best_pearson: 0.7248
Batch[15663] - loss: 0.000745 best_pearson: 0.7248
Batch[15664] - loss: 0.000440 best_pearson: 0.7248
Batch[15665] - loss: 0.000680 best_pearson: 0.7248
Batch[15666] - loss: 0.000707 best_pearson: 0.7248
Batch[15667] - loss: 0.000405 best_pearson: 0.7248
Batch[15668] - loss: 0.000473 best_pearson: 0.7248
Batch[15669] - loss: 0.000383 best_pearson: 0.7248
Batch[15670] - loss: 0.000628 best_pearson: 0.7248
Batch[15671] - loss: 0.000692 best_pearson: 0.7248
Batch[15672] - loss: 0.000403 best_pearson: 0.7248
Batch[15673] - loss: 0.000544 best_pearson: 0.7248
Batch[15674] - loss: 0.000739 best_pearson: 0.7248
Batch[15675] - loss: 0.000645 best_pearson: 0.7248
Batch[15676] - loss: 0.000610 best_pearson: 0.7248
Batch[15677] - loss: 0.000383 best_pearson: 0.7248
Batch[15678] - loss: 0.000894 best_pearson: 0.7248
Batch[15679] - loss: 0.000471 best_pearson: 0.7248
Batch[15680] - loss: 0.000395 best_pearson: 0.7248
Batch[15681] - loss: 0.000428 best_pearson: 0.7248
Batch[15682] - loss: 0.000535 best_pearson: 0.7248
Batch[15683] - loss: 0.000681 best_pearson: 0.7248
Batch[15684] - loss: 0.000581 best_pearson: 0.7248
Batch[15685] - loss: 0.000408 best_pearson: 0.7248
Batch[15686] - loss: 0.000619 best_pearson: 0.7248
Batch[15687] - loss: 0.000500 best_pearson: 0.7248
Batch[15688] - loss: 0.000484 best_pearson: 0.7248
Batch[15689] - loss: 0.000765 best_pearson: 0.7248
Batch[15690] - loss: 0.000525 best_pearson: 0.7248
Batch[15691] - loss: 0.000515 best_pearson: 0.7248
Batch[15692] - loss: 0.000440 best_pearson: 0.7248
Batch[15693] - loss: 0.000556 best_pearson: 0.7248
Batch[15694] - loss: 0.000547 best_pearson: 0.7248
Batch[15695] - loss: 0.000582 best_pearson: 0.7248
Batch[15696] - loss: 0.000407 best_pearson: 0.7248
Batch[15697] - loss: 0.000561 best_pearson: 0.7248
Batch[15698] - loss: 0.000454 best_pearson: 0.7248
Batch[15699] - loss: 0.000591 best_pearson: 0.7248
Batch[15700] - loss: 0.000414 best_pearson: 0.7248

Evaluation - loss: 0.000050 pearson: 0.6900 

early stop by 1500 steps.
Batch[15701] - loss: 0.000406 best_pearson: 0.7248
Batch[15702] - loss: 0.000589 best_pearson: 0.7248
Batch[15703] - loss: 0.000496 best_pearson: 0.7248
Batch[15704] - loss: 0.000609 best_pearson: 0.7248
Batch[15705] - loss: 0.000510 best_pearson: 0.7248
Batch[15706] - loss: 0.000330 best_pearson: 0.7248
Batch[15707] - loss: 0.000370 best_pearson: 0.7248
Batch[15708] - loss: 0.000603 best_pearson: 0.7248
Batch[15709] - loss: 0.000663 best_pearson: 0.7248
Batch[15710] - loss: 0.000430 best_pearson: 0.7248
Batch[15711] - loss: 0.000345 best_pearson: 0.7248
Batch[15712] - loss: 0.000381 best_pearson: 0.7248
Batch[15713] - loss: 0.000445 best_pearson: 0.7248
Batch[15714] - loss: 0.000428 best_pearson: 0.7248
Batch[15715] - loss: 0.000676 best_pearson: 0.7248
Batch[15716] - loss: 0.000295 best_pearson: 0.7248
Batch[15717] - loss: 0.000534 best_pearson: 0.7248
Batch[15718] - loss: 0.000385 best_pearson: 0.7248
Batch[15719] - loss: 0.000257 best_pearson: 0.7248
Batch[15720] - loss: 0.000567 best_pearson: 0.7248
Batch[15721] - loss: 0.000544 best_pearson: 0.7248
Batch[15722] - loss: 0.000462 best_pearson: 0.7248
Batch[15723] - loss: 0.000562 best_pearson: 0.7248
Batch[15724] - loss: 0.000658 best_pearson: 0.7248
Batch[15725] - loss: 0.000705 best_pearson: 0.7248
Batch[15726] - loss: 0.000333 best_pearson: 0.7248
Batch[15727] - loss: 0.000757 best_pearson: 0.7248
Batch[15728] - loss: 0.000613 best_pearson: 0.7248
Batch[15729] - loss: 0.000558 best_pearson: 0.7248
Batch[15730] - loss: 0.000754 best_pearson: 0.7248
Batch[15731] - loss: 0.000661 best_pearson: 0.7248
Batch[15732] - loss: 0.001057 best_pearson: 0.7248
Batch[15733] - loss: 0.000689 best_pearson: 0.7248
Batch[15734] - loss: 0.000634 best_pearson: 0.7248
Batch[15735] - loss: 0.000328 best_pearson: 0.7248
Batch[15736] - loss: 0.000425 best_pearson: 0.7248
Batch[15737] - loss: 0.000381 best_pearson: 0.7248
Batch[15738] - loss: 0.000420 best_pearson: 0.7248
Batch[15739] - loss: 0.000317 best_pearson: 0.7248
Batch[15740] - loss: 0.000279 best_pearson: 0.7248
Batch[15741] - loss: 0.000426 best_pearson: 0.7248
Batch[15742] - loss: 0.000331 best_pearson: 0.7248
Batch[15743] - loss: 0.000371 best_pearson: 0.7248
Batch[15744] - loss: 0.000421 best_pearson: 0.7248
Batch[15745] - loss: 0.000357 best_pearson: 0.7248
Batch[15746] - loss: 0.000340 best_pearson: 0.7248
Batch[15747] - loss: 0.000590 best_pearson: 0.7248
Batch[15748] - loss: 0.000468 best_pearson: 0.7248
Batch[15749] - loss: 0.000781 best_pearson: 0.7248
Batch[15750] - loss: 0.000476 best_pearson: 0.7248
Batch[15751] - loss: 0.000374 best_pearson: 0.7248
Batch[15752] - loss: 0.000373 best_pearson: 0.7248
Batch[15753] - loss: 0.000429 best_pearson: 0.7248
Batch[15754] - loss: 0.000394 best_pearson: 0.7248
Batch[15755] - loss: 0.000520 best_pearson: 0.7248
Batch[15756] - loss: 0.000280 best_pearson: 0.7248
Batch[15757] - loss: 0.000547 best_pearson: 0.7248
Batch[15758] - loss: 0.000495 best_pearson: 0.7248
Batch[15759] - loss: 0.000369 best_pearson: 0.7248
Batch[15760] - loss: 0.000508 best_pearson: 0.7248
Batch[15761] - loss: 0.000419 best_pearson: 0.7248
Batch[15762] - loss: 0.000762 best_pearson: 0.7248
Batch[15763] - loss: 0.000320 best_pearson: 0.7248
Batch[15764] - loss: 0.000491 best_pearson: 0.7248
Batch[15765] - loss: 0.000529 best_pearson: 0.7248
Batch[15766] - loss: 0.000422 best_pearson: 0.7248
Batch[15767] - loss: 0.000493 best_pearson: 0.7248
Batch[15768] - loss: 0.000405 best_pearson: 0.7248
Batch[15769] - loss: 0.000555 best_pearson: 0.7248
Batch[15770] - loss: 0.000397 best_pearson: 0.7248
Batch[15771] - loss: 0.000357 best_pearson: 0.7248
Batch[15772] - loss: 0.000381 best_pearson: 0.7248
Batch[15773] - loss: 0.000287 best_pearson: 0.7248
Batch[15774] - loss: 0.000351 best_pearson: 0.7248
Batch[15775] - loss: 0.000642 best_pearson: 0.7248
Batch[15776] - loss: 0.000409 best_pearson: 0.7248
Batch[15777] - loss: 0.000392 best_pearson: 0.7248
Batch[15778] - loss: 0.000433 best_pearson: 0.7248
Batch[15779] - loss: 0.000410 best_pearson: 0.7248
Batch[15780] - loss: 0.000529 best_pearson: 0.7248
Batch[15781] - loss: 0.000342 best_pearson: 0.7248
Batch[15782] - loss: 0.000367 best_pearson: 0.7248
Batch[15783] - loss: 0.000431 best_pearson: 0.7248
Batch[15784] - loss: 0.000267 best_pearson: 0.7248
Batch[15785] - loss: 0.000431 best_pearson: 0.7248
Batch[15786] - loss: 0.000369 best_pearson: 0.7248
Batch[15787] - loss: 0.000274 best_pearson: 0.7248
Batch[15788] - loss: 0.000152 best_pearson: 0.7248
Batch[15789] - loss: 0.000503 best_pearson: 0.7248
Batch[15790] - loss: 0.000364 best_pearson: 0.7248
Batch[15791] - loss: 0.000236 best_pearson: 0.7248
Batch[15792] - loss: 0.000246 best_pearson: 0.7248
Batch[15793] - loss: 0.000316 best_pearson: 0.7248
Batch[15794] - loss: 0.000333 best_pearson: 0.7248
Batch[15795] - loss: 0.000439 best_pearson: 0.7248
Batch[15796] - loss: 0.000405 best_pearson: 0.7248
Batch[15797] - loss: 0.000374 best_pearson: 0.7248
Batch[15798] - loss: 0.000471 best_pearson: 0.7248
Batch[15799] - loss: 0.000458 best_pearson: 0.7248
Batch[15800] - loss: 0.000338 best_pearson: 0.7248

Evaluation - loss: 0.000051 pearson: 0.6898 

early stop by 1500 steps.
Batch[15801] - loss: 0.000735 best_pearson: 0.7248
Batch[15802] - loss: 0.000339 best_pearson: 0.7248
Batch[15803] - loss: 0.000477 best_pearson: 0.7248
Batch[15804] - loss: 0.000323 best_pearson: 0.7248
Batch[15805] - loss: 0.000371 best_pearson: 0.7248
Batch[15806] - loss: 0.000348 best_pearson: 0.7248
Batch[15807] - loss: 0.000490 best_pearson: 0.7248
Batch[15808] - loss: 0.000502 best_pearson: 0.7248
Batch[15809] - loss: 0.000553 best_pearson: 0.7248
Batch[15810] - loss: 0.000259 best_pearson: 0.7248
Batch[15811] - loss: 0.000559 best_pearson: 0.7248
Batch[15812] - loss: 0.000164 best_pearson: 0.7248
Batch[15813] - loss: 0.000271 best_pearson: 0.7248
Batch[15814] - loss: 0.000401 best_pearson: 0.7248
Batch[15815] - loss: 0.000429 best_pearson: 0.7248
Batch[15816] - loss: 0.000400 best_pearson: 0.7248
Batch[15817] - loss: 0.000699 best_pearson: 0.7248
Batch[15818] - loss: 0.000378 best_pearson: 0.7248
Batch[15819] - loss: 0.000218 best_pearson: 0.7248
Batch[15820] - loss: 0.000261 best_pearson: 0.7248
Batch[15821] - loss: 0.000319 best_pearson: 0.7248
Batch[15822] - loss: 0.000660 best_pearson: 0.7248
Batch[15823] - loss: 0.000550 best_pearson: 0.7248
Batch[15824] - loss: 0.000409 best_pearson: 0.7248
Batch[15825] - loss: 0.000397 best_pearson: 0.7248
Batch[15826] - loss: 0.000747 best_pearson: 0.7248
Batch[15827] - loss: 0.000466 best_pearson: 0.7248
Batch[15828] - loss: 0.000522 best_pearson: 0.7248
Batch[15829] - loss: 0.000439 best_pearson: 0.7248
Batch[15830] - loss: 0.000379 best_pearson: 0.7248
Batch[15831] - loss: 0.000336 best_pearson: 0.7248
Batch[15832] - loss: 0.000757 best_pearson: 0.7248
Batch[15833] - loss: 0.000505 best_pearson: 0.7248
Batch[15834] - loss: 0.000626 best_pearson: 0.7248
Batch[15835] - loss: 0.000591 best_pearson: 0.7248
Batch[15836] - loss: 0.000235 best_pearson: 0.7248
Batch[15837] - loss: 0.000451 best_pearson: 0.7248
Batch[15838] - loss: 0.000386 best_pearson: 0.7248
Batch[15839] - loss: 0.000324 best_pearson: 0.7248
Batch[15840] - loss: 0.000351 best_pearson: 0.7248
Batch[15841] - loss: 0.000409 best_pearson: 0.7248
Batch[15842] - loss: 0.000436 best_pearson: 0.7248
Batch[15843] - loss: 0.001348 best_pearson: 0.7248
Batch[15844] - loss: 0.000280 best_pearson: 0.7248
Batch[15845] - loss: 0.000349 best_pearson: 0.7248
Batch[15846] - loss: 0.000671 best_pearson: 0.7248
Batch[15847] - loss: 0.000279 best_pearson: 0.7248
Batch[15848] - loss: 0.000295 best_pearson: 0.7248
Batch[15849] - loss: 0.000371 best_pearson: 0.7248
Batch[15850] - loss: 0.000553 best_pearson: 0.7248
Batch[15851] - loss: 0.000321 best_pearson: 0.7248
Batch[15852] - loss: 0.000450 best_pearson: 0.7248
Batch[15853] - loss: 0.000485 best_pearson: 0.7248
Batch[15854] - loss: 0.000480 best_pearson: 0.7248
Batch[15855] - loss: 0.000538 best_pearson: 0.7248
Batch[15856] - loss: 0.000491 best_pearson: 0.7248
Batch[15857] - loss: 0.000463 best_pearson: 0.7248
Batch[15858] - loss: 0.000281 best_pearson: 0.7248
Batch[15859] - loss: 0.000405 best_pearson: 0.7248
Batch[15860] - loss: 0.000381 best_pearson: 0.7248
Batch[15861] - loss: 0.000334 best_pearson: 0.7248
Batch[15862] - loss: 0.000277 best_pearson: 0.7248
Batch[15863] - loss: 0.000263 best_pearson: 0.7248
Batch[15864] - loss: 0.000435 best_pearson: 0.7248
Batch[15865] - loss: 0.000483 best_pearson: 0.7248
Batch[15866] - loss: 0.000381 best_pearson: 0.7248
Batch[15867] - loss: 0.000408 best_pearson: 0.7248
Batch[15868] - loss: 0.000519 best_pearson: 0.7248
Batch[15869] - loss: 0.000535 best_pearson: 0.7248
Batch[15870] - loss: 0.000437 best_pearson: 0.7248
Batch[15871] - loss: 0.000440 best_pearson: 0.7248
Batch[15872] - loss: 0.000580 best_pearson: 0.7248
Batch[15873] - loss: 0.000532 best_pearson: 0.7248
Batch[15874] - loss: 0.000384 best_pearson: 0.7248
Batch[15875] - loss: 0.000424 best_pearson: 0.7248
Batch[15876] - loss: 0.000413 best_pearson: 0.7248
Batch[15877] - loss: 0.000495 best_pearson: 0.7248
Batch[15878] - loss: 0.000551 best_pearson: 0.7248
Batch[15879] - loss: 0.000341 best_pearson: 0.7248
Batch[15880] - loss: 0.000890 best_pearson: 0.7248
Batch[15881] - loss: 0.000267 best_pearson: 0.7248
Batch[15882] - loss: 0.000566 best_pearson: 0.7248
Batch[15883] - loss: 0.000356 best_pearson: 0.7248
Batch[15884] - loss: 0.000392 best_pearson: 0.7248
Batch[15885] - loss: 0.000748 best_pearson: 0.7248
Batch[15886] - loss: 0.000385 best_pearson: 0.7248
Batch[15887] - loss: 0.000476 best_pearson: 0.7248
Batch[15888] - loss: 0.000413 best_pearson: 0.7248
Batch[15889] - loss: 0.000591 best_pearson: 0.7248
Batch[15890] - loss: 0.000469 best_pearson: 0.7248
Batch[15891] - loss: 0.000460 best_pearson: 0.7248
Batch[15892] - loss: 0.000411 best_pearson: 0.7248
Batch[15893] - loss: 0.000332 best_pearson: 0.7248
Batch[15894] - loss: 0.000471 best_pearson: 0.7248
Batch[15895] - loss: 0.000482 best_pearson: 0.7248
Batch[15896] - loss: 0.000576 best_pearson: 0.7248
Batch[15897] - loss: 0.000583 best_pearson: 0.7248
Batch[15898] - loss: 0.000753 best_pearson: 0.7248
Batch[15899] - loss: 0.000572 best_pearson: 0.7248
Batch[15900] - loss: 0.000476 best_pearson: 0.7248

Evaluation - loss: 0.000050 pearson: 0.6899 

early stop by 1500 steps.
Batch[15901] - loss: 0.000414 best_pearson: 0.7248
Batch[15902] - loss: 0.000920 best_pearson: 0.7248
Batch[15903] - loss: 0.000607 best_pearson: 0.7248
Batch[15904] - loss: 0.000376 best_pearson: 0.7248
Batch[15905] - loss: 0.000365 best_pearson: 0.7248
Batch[15906] - loss: 0.000666 best_pearson: 0.7248
Batch[15907] - loss: 0.000492 best_pearson: 0.7248
Batch[15908] - loss: 0.000562 best_pearson: 0.7248
Batch[15909] - loss: 0.000524 best_pearson: 0.7248
Batch[15910] - loss: 0.000470 best_pearson: 0.7248
Batch[15911] - loss: 0.000554 best_pearson: 0.7248
Batch[15912] - loss: 0.000686 best_pearson: 0.7248
Batch[15913] - loss: 0.000720 best_pearson: 0.7248
Batch[15914] - loss: 0.001072 best_pearson: 0.7248
Batch[15915] - loss: 0.000604 best_pearson: 0.7248
Batch[15916] - loss: 0.000910 best_pearson: 0.7248
Batch[15917] - loss: 0.000626 best_pearson: 0.7248
Batch[15918] - loss: 0.000355 best_pearson: 0.7248
Batch[15919] - loss: 0.001218 best_pearson: 0.7248
Batch[15920] - loss: 0.000524 best_pearson: 0.7248
Batch[15921] - loss: 0.000719 best_pearson: 0.7248
Batch[15922] - loss: 0.000382 best_pearson: 0.7248
Batch[15923] - loss: 0.000639 best_pearson: 0.7248
Batch[15924] - loss: 0.000622 best_pearson: 0.7248
Batch[15925] - loss: 0.000555 best_pearson: 0.7248
Batch[15926] - loss: 0.000745 best_pearson: 0.7248
Batch[15927] - loss: 0.000417 best_pearson: 0.7248
Batch[15928] - loss: 0.000710 best_pearson: 0.7248
Batch[15929] - loss: 0.001181 best_pearson: 0.7248
Batch[15930] - loss: 0.000362 best_pearson: 0.7248
Batch[15931] - loss: 0.000542 best_pearson: 0.7248
Batch[15932] - loss: 0.000655 best_pearson: 0.7248
Batch[15933] - loss: 0.000540 best_pearson: 0.7248
Batch[15934] - loss: 0.000592 best_pearson: 0.7248
Batch[15935] - loss: 0.000323 best_pearson: 0.7248
Batch[15936] - loss: 0.000416 best_pearson: 0.7248
Batch[15937] - loss: 0.000277 best_pearson: 0.7248
Batch[15938] - loss: 0.000488 best_pearson: 0.7248
Batch[15939] - loss: 0.000630 best_pearson: 0.7248
Batch[15940] - loss: 0.000680 best_pearson: 0.7248
Batch[15941] - loss: 0.000404 best_pearson: 0.7248
Batch[15942] - loss: 0.000302 best_pearson: 0.7248
Batch[15943] - loss: 0.000496 best_pearson: 0.7248
Batch[15944] - loss: 0.000592 best_pearson: 0.7248
Batch[15945] - loss: 0.000497 best_pearson: 0.7248
Batch[15946] - loss: 0.000514 best_pearson: 0.7248
Batch[15947] - loss: 0.000453 best_pearson: 0.7248
Batch[15948] - loss: 0.000587 best_pearson: 0.7248
Batch[15949] - loss: 0.000588 best_pearson: 0.7248
Batch[15950] - loss: 0.000398 best_pearson: 0.7248
Batch[15951] - loss: 0.000519 best_pearson: 0.7248
Batch[15952] - loss: 0.000484 best_pearson: 0.7248
Batch[15953] - loss: 0.000566 best_pearson: 0.7248
Batch[15954] - loss: 0.000625 best_pearson: 0.7248
Batch[15955] - loss: 0.000565 best_pearson: 0.7248
Batch[15956] - loss: 0.000561 best_pearson: 0.7248
Batch[15957] - loss: 0.000468 best_pearson: 0.7248
Batch[15958] - loss: 0.000600 best_pearson: 0.7248
Batch[15959] - loss: 0.000409 best_pearson: 0.7248
Batch[15960] - loss: 0.000870 best_pearson: 0.7248
Batch[15961] - loss: 0.000574 best_pearson: 0.7248
Batch[15962] - loss: 0.000506 best_pearson: 0.7248
Batch[15963] - loss: 0.000675 best_pearson: 0.7248
Batch[15964] - loss: 0.000405 best_pearson: 0.7248
Batch[15965] - loss: 0.000278 best_pearson: 0.7248
Batch[15966] - loss: 0.000759 best_pearson: 0.7248
Batch[15967] - loss: 0.000532 best_pearson: 0.7248
Batch[15968] - loss: 0.000425 best_pearson: 0.7248
Batch[15969] - loss: 0.000451 best_pearson: 0.7248
Batch[15970] - loss: 0.000595 best_pearson: 0.7248
Batch[15971] - loss: 0.000494 best_pearson: 0.7248
Batch[15972] - loss: 0.000420 best_pearson: 0.7248
Batch[15973] - loss: 0.000392 best_pearson: 0.7248
Batch[15974] - loss: 0.000459 best_pearson: 0.7248
Batch[15975] - loss: 0.000893 best_pearson: 0.7248
Batch[15976] - loss: 0.000606 best_pearson: 0.7248
Batch[15977] - loss: 0.000481 best_pearson: 0.7248
Batch[15978] - loss: 0.000552 best_pearson: 0.7248
Batch[15979] - loss: 0.000718 best_pearson: 0.7248
Batch[15980] - loss: 0.000636 best_pearson: 0.7248
Batch[15981] - loss: 0.000270 best_pearson: 0.7248
Batch[15982] - loss: 0.000436 best_pearson: 0.7248
Batch[15983] - loss: 0.000402 best_pearson: 0.7248
Batch[15984] - loss: 0.000386 best_pearson: 0.7248
Batch[15985] - loss: 0.000699 best_pearson: 0.7248
Batch[15986] - loss: 0.000379 best_pearson: 0.7248
Batch[15987] - loss: 0.000546 best_pearson: 0.7248
Batch[15988] - loss: 0.000489 best_pearson: 0.7248
Batch[15989] - loss: 0.000408 best_pearson: 0.7248
Batch[15990] - loss: 0.000628 best_pearson: 0.7248
Batch[15991] - loss: 0.000600 best_pearson: 0.7248
Batch[15992] - loss: 0.000539 best_pearson: 0.7248
Batch[15993] - loss: 0.000436 best_pearson: 0.7248
Batch[15994] - loss: 0.000526 best_pearson: 0.7248
Batch[15995] - loss: 0.000429 best_pearson: 0.7248
Batch[15996] - loss: 0.001168 best_pearson: 0.7248
Batch[15997] - loss: 0.000538 best_pearson: 0.7248
Batch[15998] - loss: 0.000611 best_pearson: 0.7248
Batch[15999] - loss: 0.000518 best_pearson: 0.7248
Batch[16000] - loss: 0.000602 best_pearson: 0.7248

Evaluation - loss: 0.000051 pearson: 0.6883 

early stop by 1500 steps.
Batch[16001] - loss: 0.000359 best_pearson: 0.7248
Batch[16002] - loss: 0.000706 best_pearson: 0.7248
Batch[16003] - loss: 0.000821 best_pearson: 0.7248
Batch[16004] - loss: 0.000394 best_pearson: 0.7248
Batch[16005] - loss: 0.000569 best_pearson: 0.7248
Batch[16006] - loss: 0.000351 best_pearson: 0.7248
Batch[16007] - loss: 0.000447 best_pearson: 0.7248
Batch[16008] - loss: 0.000398 best_pearson: 0.7248
Batch[16009] - loss: 0.000267 best_pearson: 0.7248
Batch[16010] - loss: 0.000340 best_pearson: 0.7248
Batch[16011] - loss: 0.000407 best_pearson: 0.7248
Batch[16012] - loss: 0.000413 best_pearson: 0.7248
Batch[16013] - loss: 0.000389 best_pearson: 0.7248
Batch[16014] - loss: 0.000463 best_pearson: 0.7248
Batch[16015] - loss: 0.000295 best_pearson: 0.7248
Batch[16016] - loss: 0.000485 best_pearson: 0.7248
Batch[16017] - loss: 0.000255 best_pearson: 0.7248
Batch[16018] - loss: 0.000498 best_pearson: 0.7248
Batch[16019] - loss: 0.000379 best_pearson: 0.7248
Batch[16020] - loss: 0.000319 best_pearson: 0.7248
Batch[16021] - loss: 0.000445 best_pearson: 0.7248
Batch[16022] - loss: 0.000578 best_pearson: 0.7248
Batch[16023] - loss: 0.000299 best_pearson: 0.7248
Batch[16024] - loss: 0.000360 best_pearson: 0.7248
Batch[16025] - loss: 0.000407 best_pearson: 0.7248
Batch[16026] - loss: 0.000376 best_pearson: 0.7248
Batch[16027] - loss: 0.000853 best_pearson: 0.7248
Batch[16028] - loss: 0.000413 best_pearson: 0.7248
Batch[16029] - loss: 0.000340 best_pearson: 0.7248
Batch[16030] - loss: 0.000222 best_pearson: 0.7248
Batch[16031] - loss: 0.000306 best_pearson: 0.7248
Batch[16032] - loss: 0.000812 best_pearson: 0.7248
Batch[16033] - loss: 0.000702 best_pearson: 0.7248
Batch[16034] - loss: 0.000343 best_pearson: 0.7248
Batch[16035] - loss: 0.000327 best_pearson: 0.7248
Batch[16036] - loss: 0.000328 best_pearson: 0.7248
Batch[16037] - loss: 0.000638 best_pearson: 0.7248
Batch[16038] - loss: 0.000488 best_pearson: 0.7248
Batch[16039] - loss: 0.000465 best_pearson: 0.7248
Batch[16040] - loss: 0.000372 best_pearson: 0.7248
Batch[16041] - loss: 0.000167 best_pearson: 0.7248
Batch[16042] - loss: 0.000450 best_pearson: 0.7248
Batch[16043] - loss: 0.000248 best_pearson: 0.7248
Batch[16044] - loss: 0.000288 best_pearson: 0.7248
Batch[16045] - loss: 0.000558 best_pearson: 0.7248
Batch[16046] - loss: 0.000448 best_pearson: 0.7248
Batch[16047] - loss: 0.000385 best_pearson: 0.7248
Batch[16048] - loss: 0.000372 best_pearson: 0.7248
Batch[16049] - loss: 0.000465 best_pearson: 0.7248
Batch[16050] - loss: 0.000416 best_pearson: 0.7248
Batch[16051] - loss: 0.000484 best_pearson: 0.7248
Batch[16052] - loss: 0.000318 best_pearson: 0.7248
Batch[16053] - loss: 0.000413 best_pearson: 0.7248
Batch[16054] - loss: 0.000424 best_pearson: 0.7248
Batch[16055] - loss: 0.000484 best_pearson: 0.7248
Batch[16056] - loss: 0.000348 best_pearson: 0.7248
Batch[16057] - loss: 0.000468 best_pearson: 0.7248
Batch[16058] - loss: 0.000386 best_pearson: 0.7248
Batch[16059] - loss: 0.000403 best_pearson: 0.7248
Batch[16060] - loss: 0.000566 best_pearson: 0.7248
Batch[16061] - loss: 0.000353 best_pearson: 0.7248
Batch[16062] - loss: 0.000536 best_pearson: 0.7248
Batch[16063] - loss: 0.000863 best_pearson: 0.7248
Batch[16064] - loss: 0.000377 best_pearson: 0.7248
Batch[16065] - loss: 0.000626 best_pearson: 0.7248
Batch[16066] - loss: 0.000860 best_pearson: 0.7248
Batch[16067] - loss: 0.000768 best_pearson: 0.7248
Batch[16068] - loss: 0.000359 best_pearson: 0.7248
Batch[16069] - loss: 0.000664 best_pearson: 0.7248
Batch[16070] - loss: 0.000832 best_pearson: 0.7248
Batch[16071] - loss: 0.000439 best_pearson: 0.7248
Batch[16072] - loss: 0.000434 best_pearson: 0.7248
Batch[16073] - loss: 0.000436 best_pearson: 0.7248
Batch[16074] - loss: 0.000560 best_pearson: 0.7248
Batch[16075] - loss: 0.000565 best_pearson: 0.7248
Batch[16076] - loss: 0.000441 best_pearson: 0.7248
Batch[16077] - loss: 0.000377 best_pearson: 0.7248
Batch[16078] - loss: 0.000381 best_pearson: 0.7248
Batch[16079] - loss: 0.000260 best_pearson: 0.7248
Batch[16080] - loss: 0.000396 best_pearson: 0.7248
Batch[16081] - loss: 0.000424 best_pearson: 0.7248
Batch[16082] - loss: 0.000478 best_pearson: 0.7248
Batch[16083] - loss: 0.000253 best_pearson: 0.7248
Batch[16084] - loss: 0.000634 best_pearson: 0.7248
Batch[16085] - loss: 0.000350 best_pearson: 0.7248
Batch[16086] - loss: 0.000319 best_pearson: 0.7248
Batch[16087] - loss: 0.000538 best_pearson: 0.7248
Batch[16088] - loss: 0.000445 best_pearson: 0.7248
Batch[16089] - loss: 0.000558 best_pearson: 0.7248
Batch[16090] - loss: 0.000337 best_pearson: 0.7248
Batch[16091] - loss: 0.000523 best_pearson: 0.7248
Batch[16092] - loss: 0.000549 best_pearson: 0.7248
Batch[16093] - loss: 0.000369 best_pearson: 0.7248
Batch[16094] - loss: 0.000367 best_pearson: 0.7248
Batch[16095] - loss: 0.000310 best_pearson: 0.7248
Batch[16096] - loss: 0.000339 best_pearson: 0.7248
Batch[16097] - loss: 0.000393 best_pearson: 0.7248
Batch[16098] - loss: 0.000440 best_pearson: 0.7248
Batch[16099] - loss: 0.000469 best_pearson: 0.7248
Batch[16100] - loss: 0.000399 best_pearson: 0.7248

Evaluation - loss: 0.000050 pearson: 0.6903 

early stop by 1500 steps.
Batch[16101] - loss: 0.000713 best_pearson: 0.7248
Batch[16102] - loss: 0.000473 best_pearson: 0.7248
Batch[16103] - loss: 0.000385 best_pearson: 0.7248
Batch[16104] - loss: 0.000497 best_pearson: 0.7248
Batch[16105] - loss: 0.000343 best_pearson: 0.7248
Batch[16106] - loss: 0.000543 best_pearson: 0.7248
Batch[16107] - loss: 0.000259 best_pearson: 0.7248
Batch[16108] - loss: 0.000605 best_pearson: 0.7248
Batch[16109] - loss: 0.000353 best_pearson: 0.7248
Batch[16110] - loss: 0.000576 best_pearson: 0.7248
Batch[16111] - loss: 0.000325 best_pearson: 0.7248
Batch[16112] - loss: 0.000332 best_pearson: 0.7248
Batch[16113] - loss: 0.000186 best_pearson: 0.7248
Batch[16114] - loss: 0.000585 best_pearson: 0.7248
Batch[16115] - loss: 0.000515 best_pearson: 0.7248
Batch[16116] - loss: 0.000741 best_pearson: 0.7248
Batch[16117] - loss: 0.000489 best_pearson: 0.7248
Batch[16118] - loss: 0.000427 best_pearson: 0.7248
Batch[16119] - loss: 0.000713 best_pearson: 0.7248
Batch[16120] - loss: 0.000696 best_pearson: 0.7248
Batch[16121] - loss: 0.000168 best_pearson: 0.7248
Batch[16122] - loss: 0.000373 best_pearson: 0.7248
Batch[16123] - loss: 0.000626 best_pearson: 0.7248
Batch[16124] - loss: 0.000383 best_pearson: 0.7248
Batch[16125] - loss: 0.000338 best_pearson: 0.7248
Batch[16126] - loss: 0.000547 best_pearson: 0.7248
Batch[16127] - loss: 0.000446 best_pearson: 0.7248
Batch[16128] - loss: 0.000312 best_pearson: 0.7248
Batch[16129] - loss: 0.000332 best_pearson: 0.7248
Batch[16130] - loss: 0.000324 best_pearson: 0.7248
Batch[16131] - loss: 0.000422 best_pearson: 0.7248
Batch[16132] - loss: 0.000578 best_pearson: 0.7248
Batch[16133] - loss: 0.000328 best_pearson: 0.7248
Batch[16134] - loss: 0.000387 best_pearson: 0.7248
Batch[16135] - loss: 0.000390 best_pearson: 0.7248
Batch[16136] - loss: 0.000299 best_pearson: 0.7248
Batch[16137] - loss: 0.000482 best_pearson: 0.7248
Batch[16138] - loss: 0.000382 best_pearson: 0.7248
Batch[16139] - loss: 0.000373 best_pearson: 0.7248
Batch[16140] - loss: 0.000665 best_pearson: 0.7248
Batch[16141] - loss: 0.000422 best_pearson: 0.7248
Batch[16142] - loss: 0.000536 best_pearson: 0.7248
Batch[16143] - loss: 0.000371 best_pearson: 0.7248
Batch[16144] - loss: 0.000723 best_pearson: 0.7248
Batch[16145] - loss: 0.000281 best_pearson: 0.7248
Batch[16146] - loss: 0.000410 best_pearson: 0.7248
Batch[16147] - loss: 0.000340 best_pearson: 0.7248
Batch[16148] - loss: 0.000389 best_pearson: 0.7248
Batch[16149] - loss: 0.000535 best_pearson: 0.7248
Batch[16150] - loss: 0.000368 best_pearson: 0.7248
Batch[16151] - loss: 0.000331 best_pearson: 0.7248
Batch[16152] - loss: 0.000359 best_pearson: 0.7248
Batch[16153] - loss: 0.000526 best_pearson: 0.7248
Batch[16154] - loss: 0.000459 best_pearson: 0.7248
Batch[16155] - loss: 0.000365 best_pearson: 0.7248
Batch[16156] - loss: 0.000544 best_pearson: 0.7248
Batch[16157] - loss: 0.000591 best_pearson: 0.7248
Batch[16158] - loss: 0.000909 best_pearson: 0.7248
Batch[16159] - loss: 0.000310 best_pearson: 0.7248
Batch[16160] - loss: 0.000407 best_pearson: 0.7248
Batch[16161] - loss: 0.000429 best_pearson: 0.7248
Batch[16162] - loss: 0.000395 best_pearson: 0.7248
Batch[16163] - loss: 0.000412 best_pearson: 0.7248
Batch[16164] - loss: 0.000605 best_pearson: 0.7248
Batch[16165] - loss: 0.000293 best_pearson: 0.7248
Batch[16166] - loss: 0.000312 best_pearson: 0.7248
Batch[16167] - loss: 0.000492 best_pearson: 0.7248
Batch[16168] - loss: 0.000495 best_pearson: 0.7248
Batch[16169] - loss: 0.000399 best_pearson: 0.7248
Batch[16170] - loss: 0.000423 best_pearson: 0.7248
Batch[16171] - loss: 0.000471 best_pearson: 0.7248
Batch[16172] - loss: 0.000360 best_pearson: 0.7248
Batch[16173] - loss: 0.000341 best_pearson: 0.7248
Batch[16174] - loss: 0.000279 best_pearson: 0.7248
Batch[16175] - loss: 0.000455 best_pearson: 0.7248
Batch[16176] - loss: 0.000647 best_pearson: 0.7248
Batch[16177] - loss: 0.000580 best_pearson: 0.7248
Batch[16178] - loss: 0.000373 best_pearson: 0.7248
Batch[16179] - loss: 0.000371 best_pearson: 0.7248
Batch[16180] - loss: 0.000468 best_pearson: 0.7248
Batch[16181] - loss: 0.000166 best_pearson: 0.7248
Batch[16182] - loss: 0.000241 best_pearson: 0.7248
Batch[16183] - loss: 0.000452 best_pearson: 0.7248
Batch[16184] - loss: 0.000458 best_pearson: 0.7248
Batch[16185] - loss: 0.000468 best_pearson: 0.7248
Batch[16186] - loss: 0.000389 best_pearson: 0.7248
Batch[16187] - loss: 0.000416 best_pearson: 0.7248
Batch[16188] - loss: 0.000375 best_pearson: 0.7248
Batch[16189] - loss: 0.000350 best_pearson: 0.7248
Batch[16190] - loss: 0.000222 best_pearson: 0.7248
Batch[16191] - loss: 0.000592 best_pearson: 0.7248
Batch[16192] - loss: 0.000323 best_pearson: 0.7248
Batch[16193] - loss: 0.000643 best_pearson: 0.7248
Batch[16194] - loss: 0.000286 best_pearson: 0.7248
Batch[16195] - loss: 0.000237 best_pearson: 0.7248
Batch[16196] - loss: 0.000342 best_pearson: 0.7248
Batch[16197] - loss: 0.000409 best_pearson: 0.7248
Batch[16198] - loss: 0.000396 best_pearson: 0.7248
Batch[16199] - loss: 0.000308 best_pearson: 0.7248
Batch[16200] - loss: 0.000431 best_pearson: 0.7248

Evaluation - loss: 0.000051 pearson: 0.6865 

early stop by 1500 steps.
Batch[16201] - loss: 0.000526 best_pearson: 0.7248
Batch[16202] - loss: 0.000318 best_pearson: 0.7248
Batch[16203] - loss: 0.000352 best_pearson: 0.7248
Batch[16204] - loss: 0.000275 best_pearson: 0.7248
Batch[16205] - loss: 0.000460 best_pearson: 0.7248
Batch[16206] - loss: 0.000485 best_pearson: 0.7248
Batch[16207] - loss: 0.000393 best_pearson: 0.7248
Batch[16208] - loss: 0.000262 best_pearson: 0.7248
Batch[16209] - loss: 0.000474 best_pearson: 0.7248
Batch[16210] - loss: 0.000559 best_pearson: 0.7248
Batch[16211] - loss: 0.000427 best_pearson: 0.7248
Batch[16212] - loss: 0.000441 best_pearson: 0.7248
Batch[16213] - loss: 0.000508 best_pearson: 0.7248
Batch[16214] - loss: 0.000389 best_pearson: 0.7248
Batch[16215] - loss: 0.000407 best_pearson: 0.7248
Batch[16216] - loss: 0.000457 best_pearson: 0.7248
Batch[16217] - loss: 0.000341 best_pearson: 0.7248
Batch[16218] - loss: 0.000378 best_pearson: 0.7248
Batch[16219] - loss: 0.000301 best_pearson: 0.7248
Batch[16220] - loss: 0.000462 best_pearson: 0.7248
Batch[16221] - loss: 0.000699 best_pearson: 0.7248
Batch[16222] - loss: 0.000234 best_pearson: 0.7248
Batch[16223] - loss: 0.000303 best_pearson: 0.7248
Batch[16224] - loss: 0.000378 best_pearson: 0.7248
Batch[16225] - loss: 0.000490 best_pearson: 0.7248
Batch[16226] - loss: 0.000285 best_pearson: 0.7248
Batch[16227] - loss: 0.000492 best_pearson: 0.7248
Batch[16228] - loss: 0.000421 best_pearson: 0.7248
Batch[16229] - loss: 0.000392 best_pearson: 0.7248
Batch[16230] - loss: 0.000345 best_pearson: 0.7248
Batch[16231] - loss: 0.000203 best_pearson: 0.7248
Batch[16232] - loss: 0.000293 best_pearson: 0.7248
Batch[16233] - loss: 0.000297 best_pearson: 0.7248
Batch[16234] - loss: 0.000380 best_pearson: 0.7248
Batch[16235] - loss: 0.000370 best_pearson: 0.7248
Batch[16236] - loss: 0.000477 best_pearson: 0.7248
Batch[16237] - loss: 0.000514 best_pearson: 0.7248
Batch[16238] - loss: 0.000346 best_pearson: 0.7248
Batch[16239] - loss: 0.000610 best_pearson: 0.7248
Batch[16240] - loss: 0.000308 best_pearson: 0.7248
Batch[16241] - loss: 0.000320 best_pearson: 0.7248
Batch[16242] - loss: 0.000457 best_pearson: 0.7248
Batch[16243] - loss: 0.000385 best_pearson: 0.7248
Batch[16244] - loss: 0.000290 best_pearson: 0.7248
Batch[16245] - loss: 0.000602 best_pearson: 0.7248
Batch[16246] - loss: 0.000404 best_pearson: 0.7248
Batch[16247] - loss: 0.000447 best_pearson: 0.7248
Batch[16248] - loss: 0.000440 best_pearson: 0.7248
Batch[16249] - loss: 0.000317 best_pearson: 0.7248
Batch[16250] - loss: 0.000436 best_pearson: 0.7248
Batch[16251] - loss: 0.000481 best_pearson: 0.7248
Batch[16252] - loss: 0.000531 best_pearson: 0.7248
Batch[16253] - loss: 0.000335 best_pearson: 0.7248
Batch[16254] - loss: 0.000433 best_pearson: 0.7248
Batch[16255] - loss: 0.000390 best_pearson: 0.7248
Batch[16256] - loss: 0.000235 best_pearson: 0.7248
Batch[16257] - loss: 0.000490 best_pearson: 0.7248
Batch[16258] - loss: 0.000414 best_pearson: 0.7248
Batch[16259] - loss: 0.000304 best_pearson: 0.7248
Batch[16260] - loss: 0.000317 best_pearson: 0.7248
Batch[16261] - loss: 0.000372 best_pearson: 0.7248
Batch[16262] - loss: 0.000634 best_pearson: 0.7248
Batch[16263] - loss: 0.000406 best_pearson: 0.7248
Batch[16264] - loss: 0.000425 best_pearson: 0.7248
Batch[16265] - loss: 0.000590 best_pearson: 0.7248
Batch[16266] - loss: 0.000419 best_pearson: 0.7248
Batch[16267] - loss: 0.000376 best_pearson: 0.7248
Batch[16268] - loss: 0.000357 best_pearson: 0.7248
Batch[16269] - loss: 0.000333 best_pearson: 0.7248
Batch[16270] - loss: 0.000302 best_pearson: 0.7248
Batch[16271] - loss: 0.000252 best_pearson: 0.7248
Batch[16272] - loss: 0.000299 best_pearson: 0.7248
Batch[16273] - loss: 0.000336 best_pearson: 0.7248
Batch[16274] - loss: 0.000357 best_pearson: 0.7248
Batch[16275] - loss: 0.000373 best_pearson: 0.7248
Batch[16276] - loss: 0.000526 best_pearson: 0.7248
Batch[16277] - loss: 0.000318 best_pearson: 0.7248
Batch[16278] - loss: 0.000230 best_pearson: 0.7248
Batch[16279] - loss: 0.000358 best_pearson: 0.7248
Batch[16280] - loss: 0.000391 best_pearson: 0.7248
Batch[16281] - loss: 0.001152 best_pearson: 0.7248
Batch[16282] - loss: 0.000485 best_pearson: 0.7248
Batch[16283] - loss: 0.000688 best_pearson: 0.7248
Batch[16284] - loss: 0.000536 best_pearson: 0.7248
Batch[16285] - loss: 0.000248 best_pearson: 0.7248
Batch[16286] - loss: 0.000298 best_pearson: 0.7248
Batch[16287] - loss: 0.000333 best_pearson: 0.7248
Batch[16288] - loss: 0.000343 best_pearson: 0.7248
Batch[16289] - loss: 0.000223 best_pearson: 0.7248
Batch[16290] - loss: 0.000450 best_pearson: 0.7248
Batch[16291] - loss: 0.000433 best_pearson: 0.7248
Batch[16292] - loss: 0.000438 best_pearson: 0.7248
Batch[16293] - loss: 0.000306 best_pearson: 0.7248
Batch[16294] - loss: 0.000412 best_pearson: 0.7248
Batch[16295] - loss: 0.000328 best_pearson: 0.7248
Batch[16296] - loss: 0.000433 best_pearson: 0.7248
Batch[16297] - loss: 0.000379 best_pearson: 0.7248
Batch[16298] - loss: 0.000768 best_pearson: 0.7248
Batch[16299] - loss: 0.000333 best_pearson: 0.7248
Batch[16300] - loss: 0.000432 best_pearson: 0.7248

Evaluation - loss: 0.000051 pearson: 0.6862 

early stop by 1500 steps.
Batch[16301] - loss: 0.000533 best_pearson: 0.7248
Batch[16302] - loss: 0.000504 best_pearson: 0.7248
Batch[16303] - loss: 0.000615 best_pearson: 0.7248
Batch[16304] - loss: 0.000473 best_pearson: 0.7248
Batch[16305] - loss: 0.000447 best_pearson: 0.7248
Batch[16306] - loss: 0.000331 best_pearson: 0.7248
Batch[16307] - loss: 0.000379 best_pearson: 0.7248
Batch[16308] - loss: 0.000249 best_pearson: 0.7248
Batch[16309] - loss: 0.000477 best_pearson: 0.7248
Batch[16310] - loss: 0.000312 best_pearson: 0.7248
Batch[16311] - loss: 0.000292 best_pearson: 0.7248
Batch[16312] - loss: 0.000349 best_pearson: 0.7248
Batch[16313] - loss: 0.000305 best_pearson: 0.7248
Batch[16314] - loss: 0.000327 best_pearson: 0.7248
Batch[16315] - loss: 0.000435 best_pearson: 0.7248
Batch[16316] - loss: 0.000391 best_pearson: 0.7248
Batch[16317] - loss: 0.000268 best_pearson: 0.7248
Batch[16318] - loss: 0.000523 best_pearson: 0.7248
Batch[16319] - loss: 0.000451 best_pearson: 0.7248
Batch[16320] - loss: 0.000335 best_pearson: 0.7248
Batch[16321] - loss: 0.000847 best_pearson: 0.7248
Batch[16322] - loss: 0.000531 best_pearson: 0.7248
Batch[16323] - loss: 0.000310 best_pearson: 0.7248
Batch[16324] - loss: 0.000200 best_pearson: 0.7248
Batch[16325] - loss: 0.000331 best_pearson: 0.7248
Batch[16326] - loss: 0.000627 best_pearson: 0.7248
Batch[16327] - loss: 0.000420 best_pearson: 0.7248
Batch[16328] - loss: 0.000474 best_pearson: 0.7248
Batch[16329] - loss: 0.000266 best_pearson: 0.7248
Batch[16330] - loss: 0.000516 best_pearson: 0.7248
Batch[16331] - loss: 0.000315 best_pearson: 0.7248
Batch[16332] - loss: 0.000374 best_pearson: 0.7248
Batch[16333] - loss: 0.000454 best_pearson: 0.7248
Batch[16334] - loss: 0.000562 best_pearson: 0.7248
Batch[16335] - loss: 0.000198 best_pearson: 0.7248
Batch[16336] - loss: 0.000295 best_pearson: 0.7248
Batch[16337] - loss: 0.000241 best_pearson: 0.7248
Batch[16338] - loss: 0.000452 best_pearson: 0.7248
Batch[16339] - loss: 0.000520 best_pearson: 0.7248
Batch[16340] - loss: 0.000393 best_pearson: 0.7248
Batch[16341] - loss: 0.000365 best_pearson: 0.7248
Batch[16342] - loss: 0.000294 best_pearson: 0.7248
Batch[16343] - loss: 0.000286 best_pearson: 0.7248
Batch[16344] - loss: 0.000243 best_pearson: 0.7248
Batch[16345] - loss: 0.000722 best_pearson: 0.7248
Batch[16346] - loss: 0.000298 best_pearson: 0.7248
Batch[16347] - loss: 0.000696 best_pearson: 0.7248
Batch[16348] - loss: 0.000398 best_pearson: 0.7248
Batch[16349] - loss: 0.000308 best_pearson: 0.7248
Batch[16350] - loss: 0.000331 best_pearson: 0.7248
Batch[16351] - loss: 0.000258 best_pearson: 0.7248
Batch[16352] - loss: 0.000235 best_pearson: 0.7248
Batch[16353] - loss: 0.000090 best_pearson: 0.7248
Batch[16354] - loss: 0.000389 best_pearson: 0.7248
Batch[16355] - loss: 0.000479 best_pearson: 0.7248
Batch[16356] - loss: 0.000420 best_pearson: 0.7248
Batch[16357] - loss: 0.000216 best_pearson: 0.7248
Batch[16358] - loss: 0.000325 best_pearson: 0.7248
Batch[16359] - loss: 0.000337 best_pearson: 0.7248
Batch[16360] - loss: 0.000259 best_pearson: 0.7248
Batch[16361] - loss: 0.000273 best_pearson: 0.7248
Batch[16362] - loss: 0.000259 best_pearson: 0.7248
Batch[16363] - loss: 0.000336 best_pearson: 0.7248
Batch[16364] - loss: 0.000374 best_pearson: 0.7248
Batch[16365] - loss: 0.000354 best_pearson: 0.7248
Batch[16366] - loss: 0.000336 best_pearson: 0.7248
Batch[16367] - loss: 0.000417 best_pearson: 0.7248
Batch[16368] - loss: 0.000301 best_pearson: 0.7248
Batch[16369] - loss: 0.000264 best_pearson: 0.7248
Batch[16370] - loss: 0.000234 best_pearson: 0.7248
Batch[16371] - loss: 0.000192 best_pearson: 0.7248
Batch[16372] - loss: 0.000230 best_pearson: 0.7248
Batch[16373] - loss: 0.000369 best_pearson: 0.7248
Batch[16374] - loss: 0.000269 best_pearson: 0.7248
Batch[16375] - loss: 0.000506 best_pearson: 0.7248
Batch[16376] - loss: 0.000330 best_pearson: 0.7248
Batch[16377] - loss: 0.000197 best_pearson: 0.7248
Batch[16378] - loss: 0.000344 best_pearson: 0.7248
Batch[16379] - loss: 0.000277 best_pearson: 0.7248
Batch[16380] - loss: 0.000258 best_pearson: 0.7248
Batch[16381] - loss: 0.000298 best_pearson: 0.7248
Batch[16382] - loss: 0.000303 best_pearson: 0.7248
Batch[16383] - loss: 0.000285 best_pearson: 0.7248
Batch[16384] - loss: 0.000330 best_pearson: 0.7248
Batch[16385] - loss: 0.000293 best_pearson: 0.7248
Batch[16386] - loss: 0.000391 best_pearson: 0.7248
Batch[16387] - loss: 0.000243 best_pearson: 0.7248
Batch[16388] - loss: 0.000283 best_pearson: 0.7248
Batch[16389] - loss: 0.000313 best_pearson: 0.7248
Batch[16390] - loss: 0.000270 best_pearson: 0.7248
Batch[16391] - loss: 0.000431 best_pearson: 0.7248
Batch[16392] - loss: 0.000295 best_pearson: 0.7248
Batch[16393] - loss: 0.000498 best_pearson: 0.7248
Batch[16394] - loss: 0.000387 best_pearson: 0.7248
Batch[16395] - loss: 0.000157 best_pearson: 0.7248
Batch[16396] - loss: 0.000255 best_pearson: 0.7248
Batch[16397] - loss: 0.000360 best_pearson: 0.7248
Batch[16398] - loss: 0.000377 best_pearson: 0.7248
Batch[16399] - loss: 0.000337 best_pearson: 0.7248
Batch[16400] - loss: 0.000274 best_pearson: 0.7248

Evaluation - loss: 0.000050 pearson: 0.6882 

early stop by 1500 steps.
Batch[16401] - loss: 0.000421 best_pearson: 0.7248
Batch[16402] - loss: 0.000274 best_pearson: 0.7248
Batch[16403] - loss: 0.000297 best_pearson: 0.7248
Batch[16404] - loss: 0.000398 best_pearson: 0.7248
Batch[16405] - loss: 0.000355 best_pearson: 0.7248
Batch[16406] - loss: 0.000433 best_pearson: 0.7248
Batch[16407] - loss: 0.000484 best_pearson: 0.7248
Batch[16408] - loss: 0.000199 best_pearson: 0.7248
Batch[16409] - loss: 0.000249 best_pearson: 0.7248
Batch[16410] - loss: 0.000306 best_pearson: 0.7248
Batch[16411] - loss: 0.000304 best_pearson: 0.7248
Batch[16412] - loss: 0.000279 best_pearson: 0.7248
Batch[16413] - loss: 0.000356 best_pearson: 0.7248
Batch[16414] - loss: 0.000473 best_pearson: 0.7248
Batch[16415] - loss: 0.000400 best_pearson: 0.7248
Batch[16416] - loss: 0.000392 best_pearson: 0.7248
Batch[16417] - loss: 0.000154 best_pearson: 0.7248
Batch[16418] - loss: 0.000288 best_pearson: 0.7248
Batch[16419] - loss: 0.000220 best_pearson: 0.7248
Batch[16420] - loss: 0.000337 best_pearson: 0.7248
Batch[16421] - loss: 0.000282 best_pearson: 0.7248
Batch[16422] - loss: 0.000230 best_pearson: 0.7248
Batch[16423] - loss: 0.000267 best_pearson: 0.7248
Batch[16424] - loss: 0.000273 best_pearson: 0.7248
Batch[16425] - loss: 0.000201 best_pearson: 0.7248
Batch[16426] - loss: 0.000304 best_pearson: 0.7248
Batch[16427] - loss: 0.000301 best_pearson: 0.7248
Batch[16428] - loss: 0.000367 best_pearson: 0.7248
Batch[16429] - loss: 0.000479 best_pearson: 0.7248
Batch[16430] - loss: 0.000261 best_pearson: 0.7248
Batch[16431] - loss: 0.000283 best_pearson: 0.7248
Batch[16432] - loss: 0.000233 best_pearson: 0.7248
Batch[16433] - loss: 0.000429 best_pearson: 0.7248
Batch[16434] - loss: 0.000510 best_pearson: 0.7248
Batch[16435] - loss: 0.000353 best_pearson: 0.7248
Batch[16436] - loss: 0.000470 best_pearson: 0.7248
Batch[16437] - loss: 0.000460 best_pearson: 0.7248
Batch[16438] - loss: 0.000224 best_pearson: 0.7248
Batch[16439] - loss: 0.000250 best_pearson: 0.7248
Batch[16440] - loss: 0.000549 best_pearson: 0.7248
Batch[16441] - loss: 0.000346 best_pearson: 0.7248
Batch[16442] - loss: 0.000306 best_pearson: 0.7248
Batch[16443] - loss: 0.000282 best_pearson: 0.7248
Batch[16444] - loss: 0.000428 best_pearson: 0.7248
Batch[16445] - loss: 0.000345 best_pearson: 0.7248
Batch[16446] - loss: 0.000306 best_pearson: 0.7248
Batch[16447] - loss: 0.000347 best_pearson: 0.7248
Batch[16448] - loss: 0.000446 best_pearson: 0.7248
Batch[16449] - loss: 0.000351 best_pearson: 0.7248
Batch[16450] - loss: 0.000402 best_pearson: 0.7248
Batch[16451] - loss: 0.000275 best_pearson: 0.7248
Batch[16452] - loss: 0.000273 best_pearson: 0.7248
Batch[16453] - loss: 0.000411 best_pearson: 0.7248
Batch[16454] - loss: 0.000360 best_pearson: 0.7248
Batch[16455] - loss: 0.000595 best_pearson: 0.7248
Batch[16456] - loss: 0.000393 best_pearson: 0.7248
Batch[16457] - loss: 0.000423 best_pearson: 0.7248
Batch[16458] - loss: 0.000415 best_pearson: 0.7248
Batch[16459] - loss: 0.000307 best_pearson: 0.7248
Batch[16460] - loss: 0.000278 best_pearson: 0.7248
Batch[16461] - loss: 0.000230 best_pearson: 0.7248
Batch[16462] - loss: 0.000348 best_pearson: 0.7248
Batch[16463] - loss: 0.000271 best_pearson: 0.7248
Batch[16464] - loss: 0.000237 best_pearson: 0.7248
Batch[16465] - loss: 0.000336 best_pearson: 0.7248
Batch[16466] - loss: 0.000285 best_pearson: 0.7248
Batch[16467] - loss: 0.000243 best_pearson: 0.7248
Batch[16468] - loss: 0.000509 best_pearson: 0.7248
Batch[16469] - loss: 0.000380 best_pearson: 0.7248
Batch[16470] - loss: 0.000429 best_pearson: 0.7248
Batch[16471] - loss: 0.000277 best_pearson: 0.7248
Batch[16472] - loss: 0.000388 best_pearson: 0.7248
Batch[16473] - loss: 0.000490 best_pearson: 0.7248
Batch[16474] - loss: 0.000403 best_pearson: 0.7248
Batch[16475] - loss: 0.000254 best_pearson: 0.7248
Batch[16476] - loss: 0.000275 best_pearson: 0.7248
Batch[16477] - loss: 0.000661 best_pearson: 0.7248
Batch[16478] - loss: 0.000271 best_pearson: 0.7248
Batch[16479] - loss: 0.000313 best_pearson: 0.7248
Batch[16480] - loss: 0.000301 best_pearson: 0.7248
Batch[16481] - loss: 0.000335 best_pearson: 0.7248
Batch[16482] - loss: 0.000383 best_pearson: 0.7248
Batch[16483] - loss: 0.000401 best_pearson: 0.7248
Batch[16484] - loss: 0.000348 best_pearson: 0.7248
Batch[16485] - loss: 0.000275 best_pearson: 0.7248
Batch[16486] - loss: 0.000288 best_pearson: 0.7248
Batch[16487] - loss: 0.000169 best_pearson: 0.7248
Batch[16488] - loss: 0.000261 best_pearson: 0.7248
Batch[16489] - loss: 0.000430 best_pearson: 0.7248
Batch[16490] - loss: 0.000265 best_pearson: 0.7248
Batch[16491] - loss: 0.000333 best_pearson: 0.7248
Batch[16492] - loss: 0.000247 best_pearson: 0.7248
Batch[16493] - loss: 0.000416 best_pearson: 0.7248
Batch[16494] - loss: 0.000548 best_pearson: 0.7248
Batch[16495] - loss: 0.000302 best_pearson: 0.7248
Batch[16496] - loss: 0.000156 best_pearson: 0.7248
Batch[16497] - loss: 0.000329 best_pearson: 0.7248
Batch[16498] - loss: 0.000414 best_pearson: 0.7248
Batch[16499] - loss: 0.000372 best_pearson: 0.7248
Batch[16500] - loss: 0.000420 best_pearson: 0.7248

Evaluation - loss: 0.000051 pearson: 0.6852 

early stop by 1500 steps.
Batch[16501] - loss: 0.000766 best_pearson: 0.7248
Batch[16502] - loss: 0.000404 best_pearson: 0.7248
Batch[16503] - loss: 0.000290 best_pearson: 0.7248
Batch[16504] - loss: 0.000320 best_pearson: 0.7248
Batch[16505] - loss: 0.000507 best_pearson: 0.7248
Batch[16506] - loss: 0.000348 best_pearson: 0.7248
Batch[16507] - loss: 0.000585 best_pearson: 0.7248
Batch[16508] - loss: 0.000440 best_pearson: 0.7248
Batch[16509] - loss: 0.000797 best_pearson: 0.7248
Batch[16510] - loss: 0.000749 best_pearson: 0.7248
Batch[16511] - loss: 0.000784 best_pearson: 0.7248
Batch[16512] - loss: 0.000709 best_pearson: 0.7248
Batch[16513] - loss: 0.000545 best_pearson: 0.7248
Batch[16514] - loss: 0.000391 best_pearson: 0.7248
Batch[16515] - loss: 0.000451 best_pearson: 0.7248
Batch[16516] - loss: 0.000690 best_pearson: 0.7248
Batch[16517] - loss: 0.000603 best_pearson: 0.7248
Batch[16518] - loss: 0.000535 best_pearson: 0.7248
Batch[16519] - loss: 0.000368 best_pearson: 0.7248
Batch[16520] - loss: 0.000464 best_pearson: 0.7248
Batch[16521] - loss: 0.000484 best_pearson: 0.7248
Batch[16522] - loss: 0.000452 best_pearson: 0.7248
Batch[16523] - loss: 0.000374 best_pearson: 0.7248
Batch[16524] - loss: 0.000422 best_pearson: 0.7248
Batch[16525] - loss: 0.000391 best_pearson: 0.7248
Batch[16526] - loss: 0.000310 best_pearson: 0.7248
Batch[16527] - loss: 0.000992 best_pearson: 0.7248
Batch[16528] - loss: 0.000600 best_pearson: 0.7248
Batch[16529] - loss: 0.000355 best_pearson: 0.7248
Batch[16530] - loss: 0.000603 best_pearson: 0.7248
Batch[16531] - loss: 0.000357 best_pearson: 0.7248
Batch[16532] - loss: 0.000351 best_pearson: 0.7248
Batch[16533] - loss: 0.000409 best_pearson: 0.7248
Batch[16534] - loss: 0.000367 best_pearson: 0.7248
Batch[16535] - loss: 0.000173 best_pearson: 0.7248
Batch[16536] - loss: 0.000301 best_pearson: 0.7248
Batch[16537] - loss: 0.000356 best_pearson: 0.7248
Batch[16538] - loss: 0.000280 best_pearson: 0.7248
Batch[16539] - loss: 0.000402 best_pearson: 0.7248
Batch[16540] - loss: 0.000426 best_pearson: 0.7248
Batch[16541] - loss: 0.000360 best_pearson: 0.7248
Batch[16542] - loss: 0.000412 best_pearson: 0.7248
Batch[16543] - loss: 0.000293 best_pearson: 0.7248
Batch[16544] - loss: 0.000447 best_pearson: 0.7248
Batch[16545] - loss: 0.000679 best_pearson: 0.7248
Batch[16546] - loss: 0.000189 best_pearson: 0.7248
Batch[16547] - loss: 0.000309 best_pearson: 0.7248
Batch[16548] - loss: 0.000547 best_pearson: 0.7248
Batch[16549] - loss: 0.000461 best_pearson: 0.7248
Batch[16550] - loss: 0.000294 best_pearson: 0.7248
Batch[16551] - loss: 0.000480 best_pearson: 0.7248
Batch[16552] - loss: 0.000465 best_pearson: 0.7248
Batch[16553] - loss: 0.000356 best_pearson: 0.7248
Batch[16554] - loss: 0.000318 best_pearson: 0.7248
Batch[16555] - loss: 0.000291 best_pearson: 0.7248
Batch[16556] - loss: 0.000484 best_pearson: 0.7248
Batch[16557] - loss: 0.000480 best_pearson: 0.7248
Batch[16558] - loss: 0.000370 best_pearson: 0.7248
Batch[16559] - loss: 0.000345 best_pearson: 0.7248
Batch[16560] - loss: 0.000437 best_pearson: 0.7248
Batch[16561] - loss: 0.000419 best_pearson: 0.7248
Batch[16562] - loss: 0.000312 best_pearson: 0.7248
Batch[16563] - loss: 0.000237 best_pearson: 0.7248
Batch[16564] - loss: 0.000621 best_pearson: 0.7248
Batch[16565] - loss: 0.000437 best_pearson: 0.7248
Batch[16566] - loss: 0.000276 best_pearson: 0.7248
Batch[16567] - loss: 0.000616 best_pearson: 0.7248
Batch[16568] - loss: 0.000241 best_pearson: 0.7248
Batch[16569] - loss: 0.000291 best_pearson: 0.7248
Batch[16570] - loss: 0.000744 best_pearson: 0.7248
Batch[16571] - loss: 0.000551 best_pearson: 0.7248
Batch[16572] - loss: 0.000395 best_pearson: 0.7248
Batch[16573] - loss: 0.000454 best_pearson: 0.7248
Batch[16574] - loss: 0.000588 best_pearson: 0.7248
Batch[16575] - loss: 0.000504 best_pearson: 0.7248
Batch[16576] - loss: 0.000257 best_pearson: 0.7248
Batch[16577] - loss: 0.000349 best_pearson: 0.7248
Batch[16578] - loss: 0.000523 best_pearson: 0.7248
Batch[16579] - loss: 0.000436 best_pearson: 0.7248
Batch[16580] - loss: 0.000272 best_pearson: 0.7248
Batch[16581] - loss: 0.000630 best_pearson: 0.7248
Batch[16582] - loss: 0.000196 best_pearson: 0.7248
Batch[16583] - loss: 0.000330 best_pearson: 0.7248
Batch[16584] - loss: 0.000281 best_pearson: 0.7248
Batch[16585] - loss: 0.000412 best_pearson: 0.7248
Batch[16586] - loss: 0.000273 best_pearson: 0.7248
Batch[16587] - loss: 0.000240 best_pearson: 0.7248
Batch[16588] - loss: 0.000268 best_pearson: 0.7248
Batch[16589] - loss: 0.000335 best_pearson: 0.7248
Batch[16590] - loss: 0.000264 best_pearson: 0.7248
Batch[16591] - loss: 0.000353 best_pearson: 0.7248
Batch[16592] - loss: 0.000297 best_pearson: 0.7248
Batch[16593] - loss: 0.000230 best_pearson: 0.7248
Batch[16594] - loss: 0.000428 best_pearson: 0.7248
Batch[16595] - loss: 0.000398 best_pearson: 0.7248
Batch[16596] - loss: 0.000266 best_pearson: 0.7248
Batch[16597] - loss: 0.000351 best_pearson: 0.7248
Batch[16598] - loss: 0.000353 best_pearson: 0.7248
Batch[16599] - loss: 0.000600 best_pearson: 0.7248
Batch[16600] - loss: 0.000397 best_pearson: 0.7248

Evaluation - loss: 0.000050 pearson: 0.6858 

early stop by 1500 steps.
Batch[16601] - loss: 0.000428 best_pearson: 0.7248
Batch[16602] - loss: 0.000291 best_pearson: 0.7248
Batch[16603] - loss: 0.000295 best_pearson: 0.7248
Batch[16604] - loss: 0.000375 best_pearson: 0.7248
Batch[16605] - loss: 0.000412 best_pearson: 0.7248
Batch[16606] - loss: 0.000415 best_pearson: 0.7248
Batch[16607] - loss: 0.000305 best_pearson: 0.7248
Batch[16608] - loss: 0.000696 best_pearson: 0.7248
Batch[16609] - loss: 0.000322 best_pearson: 0.7248
Batch[16610] - loss: 0.000303 best_pearson: 0.7248
Batch[16611] - loss: 0.000418 best_pearson: 0.7248
Batch[16612] - loss: 0.000579 best_pearson: 0.7248
Batch[16613] - loss: 0.000443 best_pearson: 0.7248
Batch[16614] - loss: 0.000366 best_pearson: 0.7248
Batch[16615] - loss: 0.000386 best_pearson: 0.7248
Batch[16616] - loss: 0.000539 best_pearson: 0.7248
Batch[16617] - loss: 0.000266 best_pearson: 0.7248
Batch[16618] - loss: 0.000316 best_pearson: 0.7248
Batch[16619] - loss: 0.000554 best_pearson: 0.7248
Batch[16620] - loss: 0.000360 best_pearson: 0.7248
Batch[16621] - loss: 0.000420 best_pearson: 0.7248
Batch[16622] - loss: 0.000310 best_pearson: 0.7248
Batch[16623] - loss: 0.000667 best_pearson: 0.7248
Batch[16624] - loss: 0.000555 best_pearson: 0.7248
Batch[16625] - loss: 0.000524 best_pearson: 0.7248
Batch[16626] - loss: 0.000363 best_pearson: 0.7248
Batch[16627] - loss: 0.000476 best_pearson: 0.7248
Batch[16628] - loss: 0.000396 best_pearson: 0.7248
Batch[16629] - loss: 0.001276 best_pearson: 0.7248
Batch[16630] - loss: 0.001041 best_pearson: 0.7248
Batch[16631] - loss: 0.000726 best_pearson: 0.7248
Batch[16632] - loss: 0.000388 best_pearson: 0.7248
Batch[16633] - loss: 0.000363 best_pearson: 0.7248
Batch[16634] - loss: 0.000308 best_pearson: 0.7248
Batch[16635] - loss: 0.000432 best_pearson: 0.7248
Batch[16636] - loss: 0.000377 best_pearson: 0.7248
Batch[16637] - loss: 0.000290 best_pearson: 0.7248
Batch[16638] - loss: 0.000378 best_pearson: 0.7248
Batch[16639] - loss: 0.000466 best_pearson: 0.7248
Batch[16640] - loss: 0.000420 best_pearson: 0.7248
Batch[16641] - loss: 0.000314 best_pearson: 0.7248
Batch[16642] - loss: 0.000351 best_pearson: 0.7248
Batch[16643] - loss: 0.000321 best_pearson: 0.7248
Batch[16644] - loss: 0.000453 best_pearson: 0.7248
Batch[16645] - loss: 0.000245 best_pearson: 0.7248
Batch[16646] - loss: 0.000544 best_pearson: 0.7248
Batch[16647] - loss: 0.000379 best_pearson: 0.7248
Batch[16648] - loss: 0.000480 best_pearson: 0.7248
Batch[16649] - loss: 0.000520 best_pearson: 0.7248
Batch[16650] - loss: 0.000512 best_pearson: 0.7248
Batch[16651] - loss: 0.000331 best_pearson: 0.7248
Batch[16652] - loss: 0.000519 best_pearson: 0.7248
Batch[16653] - loss: 0.000655 best_pearson: 0.7248
Batch[16654] - loss: 0.000261 best_pearson: 0.7248
Batch[16655] - loss: 0.000211 best_pearson: 0.7248
Batch[16656] - loss: 0.000371 best_pearson: 0.7248
Batch[16657] - loss: 0.000219 best_pearson: 0.7248
Batch[16658] - loss: 0.000870 best_pearson: 0.7248
Batch[16659] - loss: 0.000470 best_pearson: 0.7248
Batch[16660] - loss: 0.000308 best_pearson: 0.7248
Batch[16661] - loss: 0.000376 best_pearson: 0.7248
Batch[16662] - loss: 0.000402 best_pearson: 0.7248
Batch[16663] - loss: 0.000790 best_pearson: 0.7248
Batch[16664] - loss: 0.000239 best_pearson: 0.7248
Batch[16665] - loss: 0.000291 best_pearson: 0.7248
Batch[16666] - loss: 0.000326 best_pearson: 0.7248
Batch[16667] - loss: 0.000334 best_pearson: 0.7248
Batch[16668] - loss: 0.000408 best_pearson: 0.7248
Batch[16669] - loss: 0.000397 best_pearson: 0.7248
Batch[16670] - loss: 0.000604 best_pearson: 0.7248
Batch[16671] - loss: 0.000514 best_pearson: 0.7248
Batch[16672] - loss: 0.000417 best_pearson: 0.7248
Batch[16673] - loss: 0.000385 best_pearson: 0.7248
Batch[16674] - loss: 0.000356 best_pearson: 0.7248
Batch[16675] - loss: 0.000440 best_pearson: 0.7248
Batch[16676] - loss: 0.000520 best_pearson: 0.7248
Batch[16677] - loss: 0.000349 best_pearson: 0.7248
Batch[16678] - loss: 0.000352 best_pearson: 0.7248
Batch[16679] - loss: 0.000326 best_pearson: 0.7248
Batch[16680] - loss: 0.000508 best_pearson: 0.7248
Batch[16681] - loss: 0.000993 best_pearson: 0.7248
Batch[16682] - loss: 0.000436 best_pearson: 0.7248
Batch[16683] - loss: 0.000409 best_pearson: 0.7248
Batch[16684] - loss: 0.000585 best_pearson: 0.7248
Batch[16685] - loss: 0.000412 best_pearson: 0.7248
Batch[16686] - loss: 0.000607 best_pearson: 0.7248
Batch[16687] - loss: 0.000257 best_pearson: 0.7248
Batch[16688] - loss: 0.000659 best_pearson: 0.7248
Batch[16689] - loss: 0.000672 best_pearson: 0.7248
Batch[16690] - loss: 0.000431 best_pearson: 0.7248
Batch[16691] - loss: 0.000304 best_pearson: 0.7248
Batch[16692] - loss: 0.000525 best_pearson: 0.7248
Batch[16693] - loss: 0.000570 best_pearson: 0.7248
Batch[16694] - loss: 0.000329 best_pearson: 0.7248
Batch[16695] - loss: 0.000656 best_pearson: 0.7248
Batch[16696] - loss: 0.000355 best_pearson: 0.7248
Batch[16697] - loss: 0.000339 best_pearson: 0.7248
Batch[16698] - loss: 0.000551 best_pearson: 0.7248
Batch[16699] - loss: 0.000375 best_pearson: 0.7248
Batch[16700] - loss: 0.000419 best_pearson: 0.7248

Evaluation - loss: 0.000051 pearson: 0.6854 

early stop by 1500 steps.
Batch[16701] - loss: 0.000435 best_pearson: 0.7248
Batch[16702] - loss: 0.000370 best_pearson: 0.7248
Batch[16703] - loss: 0.000333 best_pearson: 0.7248
Batch[16704] - loss: 0.000610 best_pearson: 0.7248
Batch[16705] - loss: 0.000489 best_pearson: 0.7248
Batch[16706] - loss: 0.000345 best_pearson: 0.7248
Batch[16707] - loss: 0.000566 best_pearson: 0.7248
Batch[16708] - loss: 0.000680 best_pearson: 0.7248
Batch[16709] - loss: 0.000597 best_pearson: 0.7248
Batch[16710] - loss: 0.000302 best_pearson: 0.7248
Batch[16711] - loss: 0.000364 best_pearson: 0.7248
Batch[16712] - loss: 0.000581 best_pearson: 0.7248
Batch[16713] - loss: 0.000405 best_pearson: 0.7248
Batch[16714] - loss: 0.000348 best_pearson: 0.7248
Batch[16715] - loss: 0.000389 best_pearson: 0.7248
Batch[16716] - loss: 0.001036 best_pearson: 0.7248
Batch[16717] - loss: 0.000618 best_pearson: 0.7248
Batch[16718] - loss: 0.000490 best_pearson: 0.7248
Batch[16719] - loss: 0.000361 best_pearson: 0.7248
Batch[16720] - loss: 0.000400 best_pearson: 0.7248
Batch[16721] - loss: 0.000316 best_pearson: 0.7248
Batch[16722] - loss: 0.000316 best_pearson: 0.7248
Batch[16723] - loss: 0.000322 best_pearson: 0.7248
Batch[16724] - loss: 0.000276 best_pearson: 0.7248
Batch[16725] - loss: 0.000292 best_pearson: 0.7248
Batch[16726] - loss: 0.000293 best_pearson: 0.7248
Batch[16727] - loss: 0.000629 best_pearson: 0.7248
Batch[16728] - loss: 0.000641 best_pearson: 0.7248
Batch[16729] - loss: 0.000324 best_pearson: 0.7248
Batch[16730] - loss: 0.000707 best_pearson: 0.7248
Batch[16731] - loss: 0.000413 best_pearson: 0.7248
Batch[16732] - loss: 0.000406 best_pearson: 0.7248
Batch[16733] - loss: 0.000390 best_pearson: 0.7248
Batch[16734] - loss: 0.000541 best_pearson: 0.7248
Batch[16735] - loss: 0.000712 best_pearson: 0.7248
Batch[16736] - loss: 0.000566 best_pearson: 0.7248
Batch[16737] - loss: 0.000595 best_pearson: 0.7248
Batch[16738] - loss: 0.000533 best_pearson: 0.7248
Batch[16739] - loss: 0.000379 best_pearson: 0.7248
Batch[16740] - loss: 0.000645 best_pearson: 0.7248
Batch[16741] - loss: 0.000811 best_pearson: 0.7248
Batch[16742] - loss: 0.000434 best_pearson: 0.7248
Batch[16743] - loss: 0.000528 best_pearson: 0.7248
Batch[16744] - loss: 0.000393 best_pearson: 0.7248
Batch[16745] - loss: 0.000487 best_pearson: 0.7248
Batch[16746] - loss: 0.000572 best_pearson: 0.7248
Batch[16747] - loss: 0.000337 best_pearson: 0.7248
Batch[16748] - loss: 0.000483 best_pearson: 0.7248
Batch[16749] - loss: 0.000435 best_pearson: 0.7248
Batch[16750] - loss: 0.000324 best_pearson: 0.7248
Batch[16751] - loss: 0.000320 best_pearson: 0.7248
Batch[16752] - loss: 0.000270 best_pearson: 0.7248
Batch[16753] - loss: 0.000630 best_pearson: 0.7248
Batch[16754] - loss: 0.000575 best_pearson: 0.7248
Batch[16755] - loss: 0.000410 best_pearson: 0.7248
Batch[16756] - loss: 0.000374 best_pearson: 0.7248
Batch[16757] - loss: 0.000164 best_pearson: 0.7248
Batch[16758] - loss: 0.000382 best_pearson: 0.7248
Batch[16759] - loss: 0.000370 best_pearson: 0.7248
Batch[16760] - loss: 0.000545 best_pearson: 0.7248
Batch[16761] - loss: 0.000460 best_pearson: 0.7248
Batch[16762] - loss: 0.000639 best_pearson: 0.7248
Batch[16763] - loss: 0.000359 best_pearson: 0.7248
Batch[16764] - loss: 0.000452 best_pearson: 0.7248
Batch[16765] - loss: 0.000433 best_pearson: 0.7248
Batch[16766] - loss: 0.000487 best_pearson: 0.7248
Batch[16767] - loss: 0.000268 best_pearson: 0.7248
Batch[16768] - loss: 0.000390 best_pearson: 0.7248
Batch[16769] - loss: 0.000256 best_pearson: 0.7248
Batch[16770] - loss: 0.000403 best_pearson: 0.7248
Batch[16771] - loss: 0.000402 best_pearson: 0.7248
Batch[16772] - loss: 0.000749 best_pearson: 0.7248
Batch[16773] - loss: 0.000278 best_pearson: 0.7248
Batch[16774] - loss: 0.000321 best_pearson: 0.7248
Batch[16775] - loss: 0.000440 best_pearson: 0.7248
Batch[16776] - loss: 0.000352 best_pearson: 0.7248
Batch[16777] - loss: 0.000257 best_pearson: 0.7248
Batch[16778] - loss: 0.000451 best_pearson: 0.7248
Batch[16779] - loss: 0.000774 best_pearson: 0.7248
Batch[16780] - loss: 0.000312 best_pearson: 0.7248
Batch[16781] - loss: 0.000318 best_pearson: 0.7248
Batch[16782] - loss: 0.000354 best_pearson: 0.7248
Batch[16783] - loss: 0.000585 best_pearson: 0.7248
Batch[16784] - loss: 0.000340 best_pearson: 0.7248
Batch[16785] - loss: 0.000585 best_pearson: 0.7248
Batch[16786] - loss: 0.000465 best_pearson: 0.7248
Batch[16787] - loss: 0.000467 best_pearson: 0.7248
Batch[16788] - loss: 0.000398 best_pearson: 0.7248
Batch[16789] - loss: 0.000401 best_pearson: 0.7248
Batch[16790] - loss: 0.000408 best_pearson: 0.7248
Batch[16791] - loss: 0.000318 best_pearson: 0.7248
Batch[16792] - loss: 0.000477 best_pearson: 0.7248
Batch[16793] - loss: 0.000191 best_pearson: 0.7248
Batch[16794] - loss: 0.000349 best_pearson: 0.7248
Batch[16795] - loss: 0.000511 best_pearson: 0.7248
Batch[16796] - loss: 0.000547 best_pearson: 0.7248
Batch[16797] - loss: 0.000377 best_pearson: 0.7248
Batch[16798] - loss: 0.000453 best_pearson: 0.7248
Batch[16799] - loss: 0.000325 best_pearson: 0.7248
Batch[16800] - loss: 0.000389 best_pearson: 0.7248

Evaluation - loss: 0.000050 pearson: 0.6869 

early stop by 1500 steps.
Batch[16801] - loss: 0.000568 best_pearson: 0.7248
Batch[16802] - loss: 0.000288 best_pearson: 0.7248
Batch[16803] - loss: 0.000310 best_pearson: 0.7248
Batch[16804] - loss: 0.000412 best_pearson: 0.7248
Batch[16805] - loss: 0.000516 best_pearson: 0.7248
Batch[16806] - loss: 0.000166 best_pearson: 0.7248
Batch[16807] - loss: 0.000364 best_pearson: 0.7248
Batch[16808] - loss: 0.000322 best_pearson: 0.7248
Batch[16809] - loss: 0.000381 best_pearson: 0.7248
Batch[16810] - loss: 0.000350 best_pearson: 0.7248
Batch[16811] - loss: 0.000374 best_pearson: 0.7248
Batch[16812] - loss: 0.000700 best_pearson: 0.7248
Batch[16813] - loss: 0.000607 best_pearson: 0.7248
Batch[16814] - loss: 0.000310 best_pearson: 0.7248
Batch[16815] - loss: 0.000267 best_pearson: 0.7248
Batch[16816] - loss: 0.000465 best_pearson: 0.7248
Batch[16817] - loss: 0.000483 best_pearson: 0.7248
Batch[16818] - loss: 0.000369 best_pearson: 0.7248
Batch[16819] - loss: 0.000405 best_pearson: 0.7248
Batch[16820] - loss: 0.000501 best_pearson: 0.7248
Batch[16821] - loss: 0.000349 best_pearson: 0.7248
Batch[16822] - loss: 0.000682 best_pearson: 0.7248
Batch[16823] - loss: 0.000171 best_pearson: 0.7248
Batch[16824] - loss: 0.000253 best_pearson: 0.7248
Batch[16825] - loss: 0.000547 best_pearson: 0.7248
Batch[16826] - loss: 0.000495 best_pearson: 0.7248
Batch[16827] - loss: 0.000411 best_pearson: 0.7248
Batch[16828] - loss: 0.000459 best_pearson: 0.7248
Batch[16829] - loss: 0.000409 best_pearson: 0.7248
Batch[16830] - loss: 0.000399 best_pearson: 0.7248
Batch[16831] - loss: 0.000275 best_pearson: 0.7248
Batch[16832] - loss: 0.000410 best_pearson: 0.7248
Batch[16833] - loss: 0.000482 best_pearson: 0.7248
Batch[16834] - loss: 0.000369 best_pearson: 0.7248
Batch[16835] - loss: 0.000201 best_pearson: 0.7248
Batch[16836] - loss: 0.000237 best_pearson: 0.7248
Batch[16837] - loss: 0.000255 best_pearson: 0.7248
Batch[16838] - loss: 0.000298 best_pearson: 0.7248
Batch[16839] - loss: 0.000475 best_pearson: 0.7248
Batch[16840] - loss: 0.000288 best_pearson: 0.7248
Batch[16841] - loss: 0.000296 best_pearson: 0.7248
Batch[16842] - loss: 0.000303 best_pearson: 0.7248
Batch[16843] - loss: 0.000299 best_pearson: 0.7248
Batch[16844] - loss: 0.000318 best_pearson: 0.7248
Batch[16845] - loss: 0.000222 best_pearson: 0.7248
Batch[16846] - loss: 0.000219 best_pearson: 0.7248
Batch[16847] - loss: 0.000397 best_pearson: 0.7248
Batch[16848] - loss: 0.000397 best_pearson: 0.7248
Batch[16849] - loss: 0.000351 best_pearson: 0.7248
Batch[16850] - loss: 0.000547 best_pearson: 0.7248
Batch[16851] - loss: 0.000392 best_pearson: 0.7248
Batch[16852] - loss: 0.000455 best_pearson: 0.7248
Batch[16853] - loss: 0.000339 best_pearson: 0.7248
Batch[16854] - loss: 0.000685 best_pearson: 0.7248
Batch[16855] - loss: 0.000321 best_pearson: 0.7248
Batch[16856] - loss: 0.000246 best_pearson: 0.7248
Batch[16857] - loss: 0.000295 best_pearson: 0.7248
Batch[16858] - loss: 0.000279 best_pearson: 0.7248
Batch[16859] - loss: 0.000746 best_pearson: 0.7248
Batch[16860] - loss: 0.000256 best_pearson: 0.7248
Batch[16861] - loss: 0.000376 best_pearson: 0.7248
Batch[16862] - loss: 0.000540 best_pearson: 0.7248
Batch[16863] - loss: 0.000276 best_pearson: 0.7248
Batch[16864] - loss: 0.000577 best_pearson: 0.7248
Batch[16865] - loss: 0.000330 best_pearson: 0.7248
Batch[16866] - loss: 0.000406 best_pearson: 0.7248
Batch[16867] - loss: 0.000387 best_pearson: 0.7248
Batch[16868] - loss: 0.000480 best_pearson: 0.7248
Batch[16869] - loss: 0.000264 best_pearson: 0.7248
Batch[16870] - loss: 0.000508 best_pearson: 0.7248
Batch[16871] - loss: 0.000234 best_pearson: 0.7248
Batch[16872] - loss: 0.000330 best_pearson: 0.7248
Batch[16873] - loss: 0.000302 best_pearson: 0.7248
Batch[16874] - loss: 0.000237 best_pearson: 0.7248
Batch[16875] - loss: 0.000270 best_pearson: 0.7248
Batch[16876] - loss: 0.000449 best_pearson: 0.7248
Batch[16877] - loss: 0.000399 best_pearson: 0.7248
Batch[16878] - loss: 0.000343 best_pearson: 0.7248
Batch[16879] - loss: 0.000380 best_pearson: 0.7248
Batch[16880] - loss: 0.000292 best_pearson: 0.7248
Batch[16881] - loss: 0.000321 best_pearson: 0.7248
Batch[16882] - loss: 0.000289 best_pearson: 0.7248
Batch[16883] - loss: 0.000419 best_pearson: 0.7248
Batch[16884] - loss: 0.000309 best_pearson: 0.7248
Batch[16885] - loss: 0.000300 best_pearson: 0.7248
Batch[16886] - loss: 0.000283 best_pearson: 0.7248
Batch[16887] - loss: 0.000242 best_pearson: 0.7248
Batch[16888] - loss: 0.000298 best_pearson: 0.7248
Batch[16889] - loss: 0.000469 best_pearson: 0.7248
Batch[16890] - loss: 0.000504 best_pearson: 0.7248
Batch[16891] - loss: 0.000406 best_pearson: 0.7248
Batch[16892] - loss: 0.000374 best_pearson: 0.7248
Batch[16893] - loss: 0.000213 best_pearson: 0.7248
Batch[16894] - loss: 0.000519 best_pearson: 0.7248
Batch[16895] - loss: 0.000290 best_pearson: 0.7248
Batch[16896] - loss: 0.000514 best_pearson: 0.7248
Batch[16897] - loss: 0.000348 best_pearson: 0.7248
Batch[16898] - loss: 0.000365 best_pearson: 0.7248
Batch[16899] - loss: 0.000458 best_pearson: 0.7248
Batch[16900] - loss: 0.000205 best_pearson: 0.7248

Evaluation - loss: 0.000050 pearson: 0.6875 

early stop by 1500 steps.
Batch[16901] - loss: 0.000315 best_pearson: 0.7248
Batch[16902] - loss: 0.000328 best_pearson: 0.7248
Batch[16903] - loss: 0.000271 best_pearson: 0.7248
Batch[16904] - loss: 0.000250 best_pearson: 0.7248
Batch[16905] - loss: 0.000475 best_pearson: 0.7248
Batch[16906] - loss: 0.000409 best_pearson: 0.7248
Batch[16907] - loss: 0.000177 best_pearson: 0.7248
Batch[16908] - loss: 0.000290 best_pearson: 0.7248
Batch[16909] - loss: 0.000193 best_pearson: 0.7248
Batch[16910] - loss: 0.000336 best_pearson: 0.7248
Batch[16911] - loss: 0.000304 best_pearson: 0.7248
Batch[16912] - loss: 0.000266 best_pearson: 0.7248
Batch[16913] - loss: 0.000297 best_pearson: 0.7248
Batch[16914] - loss: 0.000281 best_pearson: 0.7248
Batch[16915] - loss: 0.000413 best_pearson: 0.7248
Batch[16916] - loss: 0.000271 best_pearson: 0.7248
Batch[16917] - loss: 0.000353 best_pearson: 0.7248
Batch[16918] - loss: 0.000386 best_pearson: 0.7248
Batch[16919] - loss: 0.000269 best_pearson: 0.7248
Batch[16920] - loss: 0.000270 best_pearson: 0.7248
Batch[16921] - loss: 0.000208 best_pearson: 0.7248
Batch[16922] - loss: 0.000334 best_pearson: 0.7248
Batch[16923] - loss: 0.000296 best_pearson: 0.7248
Batch[16924] - loss: 0.000185 best_pearson: 0.7248
Batch[16925] - loss: 0.000371 best_pearson: 0.7248
Batch[16926] - loss: 0.000266 best_pearson: 0.7248
Batch[16927] - loss: 0.000357 best_pearson: 0.7248
Batch[16928] - loss: 0.000325 best_pearson: 0.7248
Batch[16929] - loss: 0.000210 best_pearson: 0.7248
Batch[16930] - loss: 0.000450 best_pearson: 0.7248
Batch[16931] - loss: 0.000326 best_pearson: 0.7248
Batch[16932] - loss: 0.000429 best_pearson: 0.7248
Batch[16933] - loss: 0.000302 best_pearson: 0.7248
Batch[16934] - loss: 0.000257 best_pearson: 0.7248
Batch[16935] - loss: 0.000236 best_pearson: 0.7248
Batch[16936] - loss: 0.000304 best_pearson: 0.7248
Batch[16937] - loss: 0.000450 best_pearson: 0.7248
Batch[16938] - loss: 0.000249 best_pearson: 0.7248
Batch[16939] - loss: 0.000452 best_pearson: 0.7248
Batch[16940] - loss: 0.000276 best_pearson: 0.7248
Batch[16941] - loss: 0.000220 best_pearson: 0.7248
Batch[16942] - loss: 0.000498 best_pearson: 0.7248
Batch[16943] - loss: 0.000422 best_pearson: 0.7248
Batch[16944] - loss: 0.000350 best_pearson: 0.7248
Batch[16945] - loss: 0.000254 best_pearson: 0.7248
Batch[16946] - loss: 0.000316 best_pearson: 0.7248
Batch[16947] - loss: 0.000236 best_pearson: 0.7248
Batch[16948] - loss: 0.000390 best_pearson: 0.7248
Batch[16949] - loss: 0.000534 best_pearson: 0.7248
Batch[16950] - loss: 0.000463 best_pearson: 0.7248
Batch[16951] - loss: 0.000384 best_pearson: 0.7248
Batch[16952] - loss: 0.000299 best_pearson: 0.7248
Batch[16953] - loss: 0.000306 best_pearson: 0.7248
Batch[16954] - loss: 0.000406 best_pearson: 0.7248
Batch[16955] - loss: 0.000198 best_pearson: 0.7248
Batch[16956] - loss: 0.000401 best_pearson: 0.7248
Batch[16957] - loss: 0.000267 best_pearson: 0.7248
Batch[16958] - loss: 0.000296 best_pearson: 0.7248
Batch[16959] - loss: 0.000184 best_pearson: 0.7248
Batch[16960] - loss: 0.000287 best_pearson: 0.7248
Batch[16961] - loss: 0.000195 best_pearson: 0.7248
Batch[16962] - loss: 0.000216 best_pearson: 0.7248
Batch[16963] - loss: 0.000429 best_pearson: 0.7248
Batch[16964] - loss: 0.000449 best_pearson: 0.7248
Batch[16965] - loss: 0.000317 best_pearson: 0.7248
Batch[16966] - loss: 0.000475 best_pearson: 0.7248
Batch[16967] - loss: 0.000193 best_pearson: 0.7248
Batch[16968] - loss: 0.000322 best_pearson: 0.7248
Batch[16969] - loss: 0.000239 best_pearson: 0.7248
Batch[16970] - loss: 0.000474 best_pearson: 0.7248
Batch[16971] - loss: 0.000299 best_pearson: 0.7248
Batch[16972] - loss: 0.000514 best_pearson: 0.7248
Batch[16973] - loss: 0.000420 best_pearson: 0.7248
Batch[16974] - loss: 0.000321 best_pearson: 0.7248
Batch[16975] - loss: 0.000665 best_pearson: 0.7248
Batch[16976] - loss: 0.000403 best_pearson: 0.7248
Batch[16977] - loss: 0.000215 best_pearson: 0.7248
Batch[16978] - loss: 0.000332 best_pearson: 0.7248
Batch[16979] - loss: 0.000577 best_pearson: 0.7248
Batch[16980] - loss: 0.000319 best_pearson: 0.7248
Batch[16981] - loss: 0.000378 best_pearson: 0.7248
Batch[16982] - loss: 0.000292 best_pearson: 0.7248
Batch[16983] - loss: 0.000219 best_pearson: 0.7248
Batch[16984] - loss: 0.000251 best_pearson: 0.7248
Batch[16985] - loss: 0.000470 best_pearson: 0.7248
Batch[16986] - loss: 0.000273 best_pearson: 0.7248
Batch[16987] - loss: 0.000315 best_pearson: 0.7248
Batch[16988] - loss: 0.000406 best_pearson: 0.7248
Batch[16989] - loss: 0.000255 best_pearson: 0.7248
Batch[16990] - loss: 0.000389 best_pearson: 0.7248
Batch[16991] - loss: 0.000239 best_pearson: 0.7248
Batch[16992] - loss: 0.000253 best_pearson: 0.7248
Batch[16993] - loss: 0.000414 best_pearson: 0.7248
Batch[16994] - loss: 0.000369 best_pearson: 0.7248
Batch[16995] - loss: 0.000335 best_pearson: 0.7248
Batch[16996] - loss: 0.000238 best_pearson: 0.7248
Batch[16997] - loss: 0.000363 best_pearson: 0.7248
Batch[16998] - loss: 0.000318 best_pearson: 0.7248
Batch[16999] - loss: 0.000187 best_pearson: 0.7248
Batch[17000] - loss: 0.000328 best_pearson: 0.7248

Evaluation - loss: 0.000050 pearson: 0.6876 

early stop by 1500 steps.
Batch[17001] - loss: 0.000386 best_pearson: 0.7248
Batch[17002] - loss: 0.000533 best_pearson: 0.7248
Batch[17003] - loss: 0.000182 best_pearson: 0.7248
Batch[17004] - loss: 0.000205 best_pearson: 0.7248
Batch[17005] - loss: 0.000248 best_pearson: 0.7248
Batch[17006] - loss: 0.000544 best_pearson: 0.7248
Batch[17007] - loss: 0.000405 best_pearson: 0.7248
Batch[17008] - loss: 0.000256 best_pearson: 0.7248
Batch[17009] - loss: 0.000338 best_pearson: 0.7248
Batch[17010] - loss: 0.000228 best_pearson: 0.7248
Batch[17011] - loss: 0.000552 best_pearson: 0.7248
Batch[17012] - loss: 0.000240 best_pearson: 0.7248
Batch[17013] - loss: 0.000230 best_pearson: 0.7248
Batch[17014] - loss: 0.000334 best_pearson: 0.7248
Batch[17015] - loss: 0.000381 best_pearson: 0.7248
Batch[17016] - loss: 0.000351 best_pearson: 0.7248
Batch[17017] - loss: 0.000194 best_pearson: 0.7248
Batch[17018] - loss: 0.000585 best_pearson: 0.7248
Batch[17019] - loss: 0.000180 best_pearson: 0.7248
Batch[17020] - loss: 0.000325 best_pearson: 0.7248
Batch[17021] - loss: 0.000316 best_pearson: 0.7248
Batch[17022] - loss: 0.000220 best_pearson: 0.7248
Batch[17023] - loss: 0.000697 best_pearson: 0.7248
Batch[17024] - loss: 0.000291 best_pearson: 0.7248
Batch[17025] - loss: 0.000320 best_pearson: 0.7248
Batch[17026] - loss: 0.000236 best_pearson: 0.7248
Batch[17027] - loss: 0.000378 best_pearson: 0.7248
Batch[17028] - loss: 0.000288 best_pearson: 0.7248
Batch[17029] - loss: 0.000287 best_pearson: 0.7248
Batch[17030] - loss: 0.000234 best_pearson: 0.7248
Batch[17031] - loss: 0.000403 best_pearson: 0.7248
Batch[17032] - loss: 0.000380 best_pearson: 0.7248
Batch[17033] - loss: 0.000333 best_pearson: 0.7248
Batch[17034] - loss: 0.000362 best_pearson: 0.7248
Batch[17035] - loss: 0.000449 best_pearson: 0.7248
Batch[17036] - loss: 0.000502 best_pearson: 0.7248
Batch[17037] - loss: 0.000185 best_pearson: 0.7248
Batch[17038] - loss: 0.000232 best_pearson: 0.7248
Batch[17039] - loss: 0.000341 best_pearson: 0.7248
Batch[17040] - loss: 0.000612 best_pearson: 0.7248
Batch[17041] - loss: 0.000282 best_pearson: 0.7248
Batch[17042] - loss: 0.000348 best_pearson: 0.7248
Batch[17043] - loss: 0.000221 best_pearson: 0.7248
Batch[17044] - loss: 0.000307 best_pearson: 0.7248
Batch[17045] - loss: 0.000380 best_pearson: 0.7248
Batch[17046] - loss: 0.000339 best_pearson: 0.7248
Batch[17047] - loss: 0.000255 best_pearson: 0.7248
Batch[17048] - loss: 0.000280 best_pearson: 0.7248
Batch[17049] - loss: 0.000178 best_pearson: 0.7248
Batch[17050] - loss: 0.000341 best_pearson: 0.7248
Batch[17051] - loss: 0.000309 best_pearson: 0.7248
Batch[17052] - loss: 0.000337 best_pearson: 0.7248
Batch[17053] - loss: 0.000208 best_pearson: 0.7248
Batch[17054] - loss: 0.000245 best_pearson: 0.7248
Batch[17055] - loss: 0.000238 best_pearson: 0.7248
Batch[17056] - loss: 0.000276 best_pearson: 0.7248
Batch[17057] - loss: 0.000323 best_pearson: 0.7248
Batch[17058] - loss: 0.000290 best_pearson: 0.7248
Batch[17059] - loss: 0.000328 best_pearson: 0.7248
Batch[17060] - loss: 0.000375 best_pearson: 0.7248
Batch[17061] - loss: 0.000372 best_pearson: 0.7248
Batch[17062] - loss: 0.000222 best_pearson: 0.7248
Batch[17063] - loss: 0.000257 best_pearson: 0.7248
Batch[17064] - loss: 0.000380 best_pearson: 0.7248
Batch[17065] - loss: 0.000402 best_pearson: 0.7248
Batch[17066] - loss: 0.000261 best_pearson: 0.7248
Batch[17067] - loss: 0.000297 best_pearson: 0.7248
Batch[17068] - loss: 0.000250 best_pearson: 0.7248
Batch[17069] - loss: 0.000274 best_pearson: 0.7248
Batch[17070] - loss: 0.000236 best_pearson: 0.7248
Batch[17071] - loss: 0.000216 best_pearson: 0.7248
Batch[17072] - loss: 0.000486 best_pearson: 0.7248
Batch[17073] - loss: 0.000484 best_pearson: 0.7248
Batch[17074] - loss: 0.000364 best_pearson: 0.7248
Batch[17075] - loss: 0.000354 best_pearson: 0.7248
Batch[17076] - loss: 0.000378 best_pearson: 0.7248
Batch[17077] - loss: 0.000344 best_pearson: 0.7248
Batch[17078] - loss: 0.000275 best_pearson: 0.7248
Batch[17079] - loss: 0.000263 best_pearson: 0.7248
Batch[17080] - loss: 0.000379 best_pearson: 0.7248
Batch[17081] - loss: 0.000350 best_pearson: 0.7248
Batch[17082] - loss: 0.000396 best_pearson: 0.7248
Batch[17083] - loss: 0.000432 best_pearson: 0.7248
Batch[17084] - loss: 0.000399 best_pearson: 0.7248
Batch[17085] - loss: 0.000154 best_pearson: 0.7248
Batch[17086] - loss: 0.000409 best_pearson: 0.7248
Batch[17087] - loss: 0.000419 best_pearson: 0.7248
Batch[17088] - loss: 0.000379 best_pearson: 0.7248
Batch[17089] - loss: 0.000339 best_pearson: 0.7248
Batch[17090] - loss: 0.000290 best_pearson: 0.7248
Batch[17091] - loss: 0.000386 best_pearson: 0.7248
Batch[17092] - loss: 0.000314 best_pearson: 0.7248
Batch[17093] - loss: 0.000319 best_pearson: 0.7248
Batch[17094] - loss: 0.000437 best_pearson: 0.7248
Batch[17095] - loss: 0.000375 best_pearson: 0.7248
Batch[17096] - loss: 0.000234 best_pearson: 0.7248
Batch[17097] - loss: 0.000197 best_pearson: 0.7248
Batch[17098] - loss: 0.000278 best_pearson: 0.7248
Batch[17099] - loss: 0.000192 best_pearson: 0.7248
Batch[17100] - loss: 0.000273 best_pearson: 0.7248

Evaluation - loss: 0.000051 pearson: 0.6850 

early stop by 1500 steps.
Batch[17101] - loss: 0.000425 best_pearson: 0.7248
Batch[17102] - loss: 0.000223 best_pearson: 0.7248
Batch[17103] - loss: 0.000264 best_pearson: 0.7248
Batch[17104] - loss: 0.000507 best_pearson: 0.7248
Batch[17105] - loss: 0.000365 best_pearson: 0.7248
Batch[17106] - loss: 0.000428 best_pearson: 0.7248
Batch[17107] - loss: 0.000258 best_pearson: 0.7248
Batch[17108] - loss: 0.000341 best_pearson: 0.7248
Batch[17109] - loss: 0.000277 best_pearson: 0.7248
Batch[17110] - loss: 0.000230 best_pearson: 0.7248
Batch[17111] - loss: 0.000277 best_pearson: 0.7248
Batch[17112] - loss: 0.000461 best_pearson: 0.7248
Batch[17113] - loss: 0.000250 best_pearson: 0.7248
Batch[17114] - loss: 0.000263 best_pearson: 0.7248
Batch[17115] - loss: 0.000356 best_pearson: 0.7248
Batch[17116] - loss: 0.000322 best_pearson: 0.7248
Batch[17117] - loss: 0.000298 best_pearson: 0.7248
Batch[17118] - loss: 0.000328 best_pearson: 0.7248
Batch[17119] - loss: 0.000338 best_pearson: 0.7248
Batch[17120] - loss: 0.000232 best_pearson: 0.7248
Batch[17121] - loss: 0.000624 best_pearson: 0.7248
Batch[17122] - loss: 0.000384 best_pearson: 0.7248
Batch[17123] - loss: 0.000339 best_pearson: 0.7248
Batch[17124] - loss: 0.000299 best_pearson: 0.7248
Batch[17125] - loss: 0.000348 best_pearson: 0.7248
Batch[17126] - loss: 0.000294 best_pearson: 0.7248
Batch[17127] - loss: 0.000290 best_pearson: 0.7248
Batch[17128] - loss: 0.000262 best_pearson: 0.7248
Batch[17129] - loss: 0.000314 best_pearson: 0.7248
Batch[17130] - loss: 0.000283 best_pearson: 0.7248
Batch[17131] - loss: 0.000319 best_pearson: 0.7248
Batch[17132] - loss: 0.000353 best_pearson: 0.7248
Batch[17133] - loss: 0.000259 best_pearson: 0.7248
Batch[17134] - loss: 0.000429 best_pearson: 0.7248
Batch[17135] - loss: 0.000468 best_pearson: 0.7248
Batch[17136] - loss: 0.000399 best_pearson: 0.7248
Batch[17137] - loss: 0.000251 best_pearson: 0.7248
Batch[17138] - loss: 0.000231 best_pearson: 0.7248
Batch[17139] - loss: 0.000359 best_pearson: 0.7248
Batch[17140] - loss: 0.000285 best_pearson: 0.7248
Batch[17141] - loss: 0.000164 best_pearson: 0.7248
Batch[17142] - loss: 0.000310 best_pearson: 0.7248
Batch[17143] - loss: 0.000287 best_pearson: 0.7248
Batch[17144] - loss: 0.000465 best_pearson: 0.7248
Batch[17145] - loss: 0.000599 best_pearson: 0.7248
Batch[17146] - loss: 0.000326 best_pearson: 0.7248
Batch[17147] - loss: 0.000272 best_pearson: 0.7248
Batch[17148] - loss: 0.000341 best_pearson: 0.7248
Batch[17149] - loss: 0.000316 best_pearson: 0.7248
Batch[17150] - loss: 0.000339 best_pearson: 0.7248
Batch[17151] - loss: 0.000218 best_pearson: 0.7248
Batch[17152] - loss: 0.000380 best_pearson: 0.7248
Batch[17153] - loss: 0.000374 best_pearson: 0.7248
Batch[17154] - loss: 0.000263 best_pearson: 0.7248
Batch[17155] - loss: 0.000353 best_pearson: 0.7248
Batch[17156] - loss: 0.000325 best_pearson: 0.7248
Batch[17157] - loss: 0.000349 best_pearson: 0.7248
Batch[17158] - loss: 0.000296 best_pearson: 0.7248
Batch[17159] - loss: 0.000454 best_pearson: 0.7248
Batch[17160] - loss: 0.000218 best_pearson: 0.7248
Batch[17161] - loss: 0.000298 best_pearson: 0.7248
Batch[17162] - loss: 0.000186 best_pearson: 0.7248
Batch[17163] - loss: 0.000399 best_pearson: 0.7248
Batch[17164] - loss: 0.000367 best_pearson: 0.7248
Batch[17165] - loss: 0.000451 best_pearson: 0.7248
Batch[17166] - loss: 0.000460 best_pearson: 0.7248
Batch[17167] - loss: 0.000244 best_pearson: 0.7248
Batch[17168] - loss: 0.000388 best_pearson: 0.7248
Batch[17169] - loss: 0.000333 best_pearson: 0.7248
Batch[17170] - loss: 0.000203 best_pearson: 0.7248
Batch[17171] - loss: 0.000274 best_pearson: 0.7248
Batch[17172] - loss: 0.000433 best_pearson: 0.7248
Batch[17173] - loss: 0.000305 best_pearson: 0.7248
Batch[17174] - loss: 0.000273 best_pearson: 0.7248
Batch[17175] - loss: 0.000380 best_pearson: 0.7248
Batch[17176] - loss: 0.000257 best_pearson: 0.7248
Batch[17177] - loss: 0.000249 best_pearson: 0.7248
Batch[17178] - loss: 0.000291 best_pearson: 0.7248
Batch[17179] - loss: 0.000274 best_pearson: 0.7248
Batch[17180] - loss: 0.000549 best_pearson: 0.7248
Batch[17181] - loss: 0.000333 best_pearson: 0.7248
Batch[17182] - loss: 0.000435 best_pearson: 0.7248
Batch[17183] - loss: 0.000311 best_pearson: 0.7248
Batch[17184] - loss: 0.000329 best_pearson: 0.7248
Batch[17185] - loss: 0.000333 best_pearson: 0.7248
Batch[17186] - loss: 0.000206 best_pearson: 0.7248
Batch[17187] - loss: 0.000230 best_pearson: 0.7248
Batch[17188] - loss: 0.000382 best_pearson: 0.7248
Batch[17189] - loss: 0.000357 best_pearson: 0.7248
Batch[17190] - loss: 0.000396 best_pearson: 0.7248
Batch[17191] - loss: 0.000427 best_pearson: 0.7248
Batch[17192] - loss: 0.000310 best_pearson: 0.7248
Batch[17193] - loss: 0.000359 best_pearson: 0.7248
Batch[17194] - loss: 0.000265 best_pearson: 0.7248
Batch[17195] - loss: 0.000245 best_pearson: 0.7248
Batch[17196] - loss: 0.000265 best_pearson: 0.7248
Batch[17197] - loss: 0.000301 best_pearson: 0.7248
Batch[17198] - loss: 0.000398 best_pearson: 0.7248
Batch[17199] - loss: 0.000403 best_pearson: 0.7248
Batch[17200] - loss: 0.000308 best_pearson: 0.7248

Evaluation - loss: 0.000050 pearson: 0.6888 

early stop by 1500 steps.
Batch[17201] - loss: 0.000400 best_pearson: 0.7248
Batch[17202] - loss: 0.000240 best_pearson: 0.7248
Batch[17203] - loss: 0.000479 best_pearson: 0.7248
Batch[17204] - loss: 0.000418 best_pearson: 0.7248
Batch[17205] - loss: 0.000290 best_pearson: 0.7248
Batch[17206] - loss: 0.000240 best_pearson: 0.7248
Batch[17207] - loss: 0.000242 best_pearson: 0.7248
Batch[17208] - loss: 0.000361 best_pearson: 0.7248
Batch[17209] - loss: 0.000231 best_pearson: 0.7248
Batch[17210] - loss: 0.000248 best_pearson: 0.7248
Batch[17211] - loss: 0.000429 best_pearson: 0.7248
Batch[17212] - loss: 0.000361 best_pearson: 0.7248
Batch[17213] - loss: 0.000321 best_pearson: 0.7248
Batch[17214] - loss: 0.000170 best_pearson: 0.7248
Batch[17215] - loss: 0.000671 best_pearson: 0.7248
Batch[17216] - loss: 0.000255 best_pearson: 0.7248
Batch[17217] - loss: 0.000247 best_pearson: 0.7248
Batch[17218] - loss: 0.000278 best_pearson: 0.7248
Batch[17219] - loss: 0.000189 best_pearson: 0.7248
Batch[17220] - loss: 0.000284 best_pearson: 0.7248
Batch[17221] - loss: 0.000382 best_pearson: 0.7248
Batch[17222] - loss: 0.000229 best_pearson: 0.7248
Batch[17223] - loss: 0.000430 best_pearson: 0.7248
Batch[17224] - loss: 0.000376 best_pearson: 0.7248
Batch[17225] - loss: 0.000273 best_pearson: 0.7248
Batch[17226] - loss: 0.000320 best_pearson: 0.7248
Batch[17227] - loss: 0.000373 best_pearson: 0.7248
Batch[17228] - loss: 0.000344 best_pearson: 0.7248
Batch[17229] - loss: 0.000343 best_pearson: 0.7248
Batch[17230] - loss: 0.000438 best_pearson: 0.7248
Batch[17231] - loss: 0.000870 best_pearson: 0.7248
Batch[17232] - loss: 0.000400 best_pearson: 0.7248
Batch[17233] - loss: 0.000322 best_pearson: 0.7248
Batch[17234] - loss: 0.000490 best_pearson: 0.7248
Batch[17235] - loss: 0.000514 best_pearson: 0.7248
Batch[17236] - loss: 0.000270 best_pearson: 0.7248
Batch[17237] - loss: 0.000482 best_pearson: 0.7248
Batch[17238] - loss: 0.000404 best_pearson: 0.7248
Batch[17239] - loss: 0.000340 best_pearson: 0.7248
Batch[17240] - loss: 0.000290 best_pearson: 0.7248
Batch[17241] - loss: 0.000513 best_pearson: 0.7248
Batch[17242] - loss: 0.000387 best_pearson: 0.7248
Batch[17243] - loss: 0.000645 best_pearson: 0.7248
Batch[17244] - loss: 0.000390 best_pearson: 0.7248
Batch[17245] - loss: 0.000407 best_pearson: 0.7248
Batch[17246] - loss: 0.000337 best_pearson: 0.7248
Batch[17247] - loss: 0.000374 best_pearson: 0.7248
Batch[17248] - loss: 0.000736 best_pearson: 0.7248
Batch[17249] - loss: 0.000199 best_pearson: 0.7248
Batch[17250] - loss: 0.000306 best_pearson: 0.7248
Batch[17251] - loss: 0.000316 best_pearson: 0.7248
Batch[17252] - loss: 0.000594 best_pearson: 0.7248
Batch[17253] - loss: 0.000606 best_pearson: 0.7248
Batch[17254] - loss: 0.000560 best_pearson: 0.7248
Batch[17255] - loss: 0.000385 best_pearson: 0.7248
Batch[17256] - loss: 0.000747 best_pearson: 0.7248
Batch[17257] - loss: 0.000344 best_pearson: 0.7248
Batch[17258] - loss: 0.000355 best_pearson: 0.7248
Batch[17259] - loss: 0.000374 best_pearson: 0.7248
Batch[17260] - loss: 0.000318 best_pearson: 0.7248
Batch[17261] - loss: 0.001058 best_pearson: 0.7248
Batch[17262] - loss: 0.000595 best_pearson: 0.7248
Batch[17263] - loss: 0.000333 best_pearson: 0.7248
Batch[17264] - loss: 0.000409 best_pearson: 0.7248
Batch[17265] - loss: 0.000384 best_pearson: 0.7248
Batch[17266] - loss: 0.000389 best_pearson: 0.7248
Batch[17267] - loss: 0.000651 best_pearson: 0.7248
Batch[17268] - loss: 0.000404 best_pearson: 0.7248
Batch[17269] - loss: 0.000634 best_pearson: 0.7248
Batch[17270] - loss: 0.000219 best_pearson: 0.7248
Batch[17271] - loss: 0.000272 best_pearson: 0.7248
Batch[17272] - loss: 0.000495 best_pearson: 0.7248
Batch[17273] - loss: 0.000378 best_pearson: 0.7248
Batch[17274] - loss: 0.000427 best_pearson: 0.7248
Batch[17275] - loss: 0.000448 best_pearson: 0.7248
Batch[17276] - loss: 0.000567 best_pearson: 0.7248
Batch[17277] - loss: 0.000346 best_pearson: 0.7248
Batch[17278] - loss: 0.000375 best_pearson: 0.7248
Batch[17279] - loss: 0.000319 best_pearson: 0.7248
Batch[17280] - loss: 0.000260 best_pearson: 0.7248
Batch[17281] - loss: 0.000358 best_pearson: 0.7248
Batch[17282] - loss: 0.000343 best_pearson: 0.7248
Batch[17283] - loss: 0.000640 best_pearson: 0.7248
Batch[17284] - loss: 0.000345 best_pearson: 0.7248
Batch[17285] - loss: 0.000265 best_pearson: 0.7248
Batch[17286] - loss: 0.000414 best_pearson: 0.7248
Batch[17287] - loss: 0.000616 best_pearson: 0.7248
Batch[17288] - loss: 0.000270 best_pearson: 0.7248
Batch[17289] - loss: 0.000437 best_pearson: 0.7248
Batch[17290] - loss: 0.000625 best_pearson: 0.7248
Batch[17291] - loss: 0.000303 best_pearson: 0.7248
Batch[17292] - loss: 0.000217 best_pearson: 0.7248
Batch[17293] - loss: 0.000379 best_pearson: 0.7248
Batch[17294] - loss: 0.000439 best_pearson: 0.7248
Batch[17295] - loss: 0.000334 best_pearson: 0.7248
Batch[17296] - loss: 0.000362 best_pearson: 0.7248
Batch[17297] - loss: 0.000596 best_pearson: 0.7248
Batch[17298] - loss: 0.000477 best_pearson: 0.7248
Batch[17299] - loss: 0.000345 best_pearson: 0.7248
Batch[17300] - loss: 0.000235 best_pearson: 0.7248

Evaluation - loss: 0.000050 pearson: 0.6879 

early stop by 1500 steps.
Batch[17301] - loss: 0.000277 best_pearson: 0.7248
Batch[17302] - loss: 0.000403 best_pearson: 0.7248
Batch[17303] - loss: 0.000229 best_pearson: 0.7248
Batch[17304] - loss: 0.000508 best_pearson: 0.7248
Batch[17305] - loss: 0.000346 best_pearson: 0.7248
Batch[17306] - loss: 0.000354 best_pearson: 0.7248
Batch[17307] - loss: 0.000519 best_pearson: 0.7248
Batch[17308] - loss: 0.000426 best_pearson: 0.7248
Batch[17309] - loss: 0.000333 best_pearson: 0.7248
Batch[17310] - loss: 0.000422 best_pearson: 0.7248
Batch[17311] - loss: 0.000640 best_pearson: 0.7248
Batch[17312] - loss: 0.000547 best_pearson: 0.7248
Batch[17313] - loss: 0.000646 best_pearson: 0.7248
Batch[17314] - loss: 0.000391 best_pearson: 0.7248
Batch[17315] - loss: 0.000315 best_pearson: 0.7248
Batch[17316] - loss: 0.000226 best_pearson: 0.7248
Batch[17317] - loss: 0.000750 best_pearson: 0.7248
Batch[17318] - loss: 0.000512 best_pearson: 0.7248
Batch[17319] - loss: 0.000361 best_pearson: 0.7248
Batch[17320] - loss: 0.000249 best_pearson: 0.7248
Batch[17321] - loss: 0.000352 best_pearson: 0.7248
Batch[17322] - loss: 0.000449 best_pearson: 0.7248
Batch[17323] - loss: 0.000402 best_pearson: 0.7248
Batch[17324] - loss: 0.000412 best_pearson: 0.7248
Batch[17325] - loss: 0.000336 best_pearson: 0.7248
Batch[17326] - loss: 0.000381 best_pearson: 0.7248
Batch[17327] - loss: 0.000293 best_pearson: 0.7248
Batch[17328] - loss: 0.000515 best_pearson: 0.7248
Batch[17329] - loss: 0.000282 best_pearson: 0.7248
Batch[17330] - loss: 0.000385 best_pearson: 0.7248
Batch[17331] - loss: 0.000264 best_pearson: 0.7248
Batch[17332] - loss: 0.000377 best_pearson: 0.7248
Batch[17333] - loss: 0.000393 best_pearson: 0.7248
Batch[17334] - loss: 0.000306 best_pearson: 0.7248
Batch[17335] - loss: 0.000346 best_pearson: 0.7248
Batch[17336] - loss: 0.000322 best_pearson: 0.7248
Batch[17337] - loss: 0.000384 best_pearson: 0.7248
Batch[17338] - loss: 0.000563 best_pearson: 0.7248
Batch[17339] - loss: 0.000395 best_pearson: 0.7248
Batch[17340] - loss: 0.000196 best_pearson: 0.7248
Batch[17341] - loss: 0.000520 best_pearson: 0.7248
Batch[17342] - loss: 0.000229 best_pearson: 0.7248
Batch[17343] - loss: 0.000288 best_pearson: 0.7248
Batch[17344] - loss: 0.000359 best_pearson: 0.7248
Batch[17345] - loss: 0.000509 best_pearson: 0.7248
Batch[17346] - loss: 0.000347 best_pearson: 0.7248
Batch[17347] - loss: 0.000471 best_pearson: 0.7248
Batch[17348] - loss: 0.000410 best_pearson: 0.7248
Batch[17349] - loss: 0.000214 best_pearson: 0.7248
Batch[17350] - loss: 0.000623 best_pearson: 0.7248
Batch[17351] - loss: 0.000312 best_pearson: 0.7248
Batch[17352] - loss: 0.000370 best_pearson: 0.7248
Batch[17353] - loss: 0.000630 best_pearson: 0.7248
Batch[17354] - loss: 0.000521 best_pearson: 0.7248
Batch[17355] - loss: 0.000605 best_pearson: 0.7248
Batch[17356] - loss: 0.000289 best_pearson: 0.7248
Batch[17357] - loss: 0.000805 best_pearson: 0.7248
Batch[17358] - loss: 0.000445 best_pearson: 0.7248
Batch[17359] - loss: 0.000397 best_pearson: 0.7248
Batch[17360] - loss: 0.000472 best_pearson: 0.7248
Batch[17361] - loss: 0.000431 best_pearson: 0.7248
Batch[17362] - loss: 0.000413 best_pearson: 0.7248
Batch[17363] - loss: 0.000650 best_pearson: 0.7248
Batch[17364] - loss: 0.000382 best_pearson: 0.7248
Batch[17365] - loss: 0.000287 best_pearson: 0.7248
Batch[17366] - loss: 0.000879 best_pearson: 0.7248
Batch[17367] - loss: 0.000414 best_pearson: 0.7248
Batch[17368] - loss: 0.000483 best_pearson: 0.7248
Batch[17369] - loss: 0.000664 best_pearson: 0.7248
Batch[17370] - loss: 0.000465 best_pearson: 0.7248
Batch[17371] - loss: 0.000324 best_pearson: 0.7248
Batch[17372] - loss: 0.000337 best_pearson: 0.7248
Batch[17373] - loss: 0.000403 best_pearson: 0.7248
Batch[17374] - loss: 0.000227 best_pearson: 0.7248
Batch[17375] - loss: 0.000464 best_pearson: 0.7248
Batch[17376] - loss: 0.000523 best_pearson: 0.7248
Batch[17377] - loss: 0.000396 best_pearson: 0.7248
Batch[17378] - loss: 0.000204 best_pearson: 0.7248
Batch[17379] - loss: 0.000327 best_pearson: 0.7248
Batch[17380] - loss: 0.000370 best_pearson: 0.7248
Batch[17381] - loss: 0.000376 best_pearson: 0.7248
Batch[17382] - loss: 0.000448 best_pearson: 0.7248
Batch[17383] - loss: 0.000274 best_pearson: 0.7248
Batch[17384] - loss: 0.000493 best_pearson: 0.7248
Batch[17385] - loss: 0.000683 best_pearson: 0.7248
Batch[17386] - loss: 0.000360 best_pearson: 0.7248
Batch[17387] - loss: 0.000451 best_pearson: 0.7248
Batch[17388] - loss: 0.000336 best_pearson: 0.7248
Batch[17389] - loss: 0.000655 best_pearson: 0.7248
Batch[17390] - loss: 0.000417 best_pearson: 0.7248
Batch[17391] - loss: 0.000270 best_pearson: 0.7248
Batch[17392] - loss: 0.000608 best_pearson: 0.7248
Batch[17393] - loss: 0.000300 best_pearson: 0.7248
Batch[17394] - loss: 0.000455 best_pearson: 0.7248
Batch[17395] - loss: 0.000382 best_pearson: 0.7248
Batch[17396] - loss: 0.000381 best_pearson: 0.7248
Batch[17397] - loss: 0.000443 best_pearson: 0.7248
Batch[17398] - loss: 0.000511 best_pearson: 0.7248
Batch[17399] - loss: 0.000351 best_pearson: 0.7248
Batch[17400] - loss: 0.000383 best_pearson: 0.7248

Evaluation - loss: 0.000051 pearson: 0.6842 

early stop by 1500 steps.
Batch[17401] - loss: 0.000493 best_pearson: 0.7248
Batch[17402] - loss: 0.000565 best_pearson: 0.7248
Batch[17403] - loss: 0.000484 best_pearson: 0.7248
Batch[17404] - loss: 0.000210 best_pearson: 0.7248
Batch[17405] - loss: 0.000715 best_pearson: 0.7248
Batch[17406] - loss: 0.000229 best_pearson: 0.7248
Batch[17407] - loss: 0.000391 best_pearson: 0.7248
Batch[17408] - loss: 0.000418 best_pearson: 0.7248
Batch[17409] - loss: 0.000389 best_pearson: 0.7248
Batch[17410] - loss: 0.000206 best_pearson: 0.7248
Batch[17411] - loss: 0.000326 best_pearson: 0.7248
Batch[17412] - loss: 0.000337 best_pearson: 0.7248
Batch[17413] - loss: 0.000393 best_pearson: 0.7248
Batch[17414] - loss: 0.000458 best_pearson: 0.7248
Batch[17415] - loss: 0.000561 best_pearson: 0.7248
Batch[17416] - loss: 0.000208 best_pearson: 0.7248
Batch[17417] - loss: 0.000878 best_pearson: 0.7248
Batch[17418] - loss: 0.000700 best_pearson: 0.7248
Batch[17419] - loss: 0.000480 best_pearson: 0.7248
Batch[17420] - loss: 0.000468 best_pearson: 0.7248
Batch[17421] - loss: 0.000537 best_pearson: 0.7248
Batch[17422] - loss: 0.000307 best_pearson: 0.7248
Batch[17423] - loss: 0.000305 best_pearson: 0.7248
Batch[17424] - loss: 0.000302 best_pearson: 0.7248
Batch[17425] - loss: 0.000550 best_pearson: 0.7248
Batch[17426] - loss: 0.000429 best_pearson: 0.7248
Batch[17427] - loss: 0.000401 best_pearson: 0.7248
Batch[17428] - loss: 0.000344 best_pearson: 0.7248
Batch[17429] - loss: 0.000450 best_pearson: 0.7248
Batch[17430] - loss: 0.000400 best_pearson: 0.7248
Batch[17431] - loss: 0.000519 best_pearson: 0.7248
Batch[17432] - loss: 0.000313 best_pearson: 0.7248
Batch[17433] - loss: 0.000307 best_pearson: 0.7248
Batch[17434] - loss: 0.000433 best_pearson: 0.7248
Batch[17435] - loss: 0.000252 best_pearson: 0.7248
Batch[17436] - loss: 0.000370 best_pearson: 0.7248
Batch[17437] - loss: 0.000293 best_pearson: 0.7248
Batch[17438] - loss: 0.000468 best_pearson: 0.7248
Batch[17439] - loss: 0.000258 best_pearson: 0.7248
Batch[17440] - loss: 0.000378 best_pearson: 0.7248
Batch[17441] - loss: 0.000437 best_pearson: 0.7248
Batch[17442] - loss: 0.000484 best_pearson: 0.7248
Batch[17443] - loss: 0.000425 best_pearson: 0.7248
Batch[17444] - loss: 0.000203 best_pearson: 0.7248
Batch[17445] - loss: 0.000712 best_pearson: 0.7248
Batch[17446] - loss: 0.000612 best_pearson: 0.7248
Batch[17447] - loss: 0.000345 best_pearson: 0.7248
Batch[17448] - loss: 0.000367 best_pearson: 0.7248
Batch[17449] - loss: 0.000328 best_pearson: 0.7248
Batch[17450] - loss: 0.000353 best_pearson: 0.7248
Batch[17451] - loss: 0.000415 best_pearson: 0.7248
Batch[17452] - loss: 0.000419 best_pearson: 0.7248
Batch[17453] - loss: 0.000246 best_pearson: 0.7248
Batch[17454] - loss: 0.000660 best_pearson: 0.7248
Batch[17455] - loss: 0.000240 best_pearson: 0.7248
Batch[17456] - loss: 0.000362 best_pearson: 0.7248
Batch[17457] - loss: 0.000618 best_pearson: 0.7248
Batch[17458] - loss: 0.000554 best_pearson: 0.7248
Batch[17459] - loss: 0.000397 best_pearson: 0.7248
Batch[17460] - loss: 0.000414 best_pearson: 0.7248
Batch[17461] - loss: 0.000315 best_pearson: 0.7248
Batch[17462] - loss: 0.000360 best_pearson: 0.7248
Batch[17463] - loss: 0.000241 best_pearson: 0.7248
Batch[17464] - loss: 0.000258 best_pearson: 0.7248
Batch[17465] - loss: 0.000218 best_pearson: 0.7248
Batch[17466] - loss: 0.000402 best_pearson: 0.7248
Batch[17467] - loss: 0.000348 best_pearson: 0.7248
Batch[17468] - loss: 0.000415 best_pearson: 0.7248
Batch[17469] - loss: 0.000383 best_pearson: 0.7248
Batch[17470] - loss: 0.000533 best_pearson: 0.7248
Batch[17471] - loss: 0.000545 best_pearson: 0.7248
Batch[17472] - loss: 0.000325 best_pearson: 0.7248
Batch[17473] - loss: 0.000368 best_pearson: 0.7248
Batch[17474] - loss: 0.000573 best_pearson: 0.7248
Batch[17475] - loss: 0.000538 best_pearson: 0.7248
Batch[17476] - loss: 0.000378 best_pearson: 0.7248
Batch[17477] - loss: 0.000297 best_pearson: 0.7248
Batch[17478] - loss: 0.000527 best_pearson: 0.7248
Batch[17479] - loss: 0.000287 best_pearson: 0.7248
Batch[17480] - loss: 0.000460 best_pearson: 0.7248
Batch[17481] - loss: 0.000478 best_pearson: 0.7248
Batch[17482] - loss: 0.000222 best_pearson: 0.7248
Batch[17483] - loss: 0.000429 best_pearson: 0.7248
Batch[17484] - loss: 0.000263 best_pearson: 0.7248
Batch[17485] - loss: 0.000448 best_pearson: 0.7248
Batch[17486] - loss: 0.000453 best_pearson: 0.7248
Batch[17487] - loss: 0.000247 best_pearson: 0.7248
Batch[17488] - loss: 0.000508 best_pearson: 0.7248
Batch[17489] - loss: 0.000935 best_pearson: 0.7248
Batch[17490] - loss: 0.000329 best_pearson: 0.7248
Batch[17491] - loss: 0.000419 best_pearson: 0.7248
Batch[17492] - loss: 0.000273 best_pearson: 0.7248
Batch[17493] - loss: 0.000421 best_pearson: 0.7248
Batch[17494] - loss: 0.000335 best_pearson: 0.7248
Batch[17495] - loss: 0.000463 best_pearson: 0.7248
Batch[17496] - loss: 0.000260 best_pearson: 0.7248
Batch[17497] - loss: 0.000333 best_pearson: 0.7248
Batch[17498] - loss: 0.000490 best_pearson: 0.7248
Batch[17499] - loss: 0.000343 best_pearson: 0.7248
Batch[17500] - loss: 0.000273 best_pearson: 0.7248

Evaluation - loss: 0.000050 pearson: 0.6884 

early stop by 1500 steps.
Batch[17501] - loss: 0.000723 best_pearson: 0.7248
Batch[17502] - loss: 0.000457 best_pearson: 0.7248
Batch[17503] - loss: 0.000342 best_pearson: 0.7248
Batch[17504] - loss: 0.000442 best_pearson: 0.7248
Batch[17505] - loss: 0.000644 best_pearson: 0.7248
Batch[17506] - loss: 0.000318 best_pearson: 0.7248
Batch[17507] - loss: 0.000484 best_pearson: 0.7248
Batch[17508] - loss: 0.000565 best_pearson: 0.7248
Batch[17509] - loss: 0.000470 best_pearson: 0.7248
Batch[17510] - loss: 0.000401 best_pearson: 0.7248
Batch[17511] - loss: 0.000360 best_pearson: 0.7248
Batch[17512] - loss: 0.000526 best_pearson: 0.7248
Batch[17513] - loss: 0.000407 best_pearson: 0.7248
Batch[17514] - loss: 0.000305 best_pearson: 0.7248
Batch[17515] - loss: 0.000772 best_pearson: 0.7248
Batch[17516] - loss: 0.000277 best_pearson: 0.7248
Batch[17517] - loss: 0.000281 best_pearson: 0.7248
Batch[17518] - loss: 0.000601 best_pearson: 0.7248
Batch[17519] - loss: 0.000497 best_pearson: 0.7248
Batch[17520] - loss: 0.000343 best_pearson: 0.7248
Batch[17521] - loss: 0.000372 best_pearson: 0.7248
Batch[17522] - loss: 0.000431 best_pearson: 0.7248
Batch[17523] - loss: 0.000322 best_pearson: 0.7248
/Users/zengjielin/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /Users/distiller/project/conda/conda-bld/pytorch_1623459044803/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)
/Users/zengjielin/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
Batch[17524] - loss: 0.000288 best_pearson: 0.7248
Batch[17525] - loss: 0.000377 best_pearson: 0.7248
Batch[17526] - loss: 0.000489 best_pearson: 0.7248
Batch[17527] - loss: 0.000417 best_pearson: 0.7248
Batch[17528] - loss: 0.000288 best_pearson: 0.7248
Batch[17529] - loss: 0.000344 best_pearson: 0.7248
Batch[17530] - loss: 0.000331 best_pearson: 0.7248
Batch[17531] - loss: 0.000377 best_pearson: 0.7248
Batch[17532] - loss: 0.000253 best_pearson: 0.7248
Batch[17533] - loss: 0.000487 best_pearson: 0.7248
Batch[17534] - loss: 0.000378 best_pearson: 0.7248
Batch[17535] - loss: 0.000378 best_pearson: 0.7248
Batch[17536] - loss: 0.000245 best_pearson: 0.7248
Batch[17537] - loss: 0.000303 best_pearson: 0.7248
Batch[17538] - loss: 0.000217 best_pearson: 0.7248
Batch[17539] - loss: 0.000442 best_pearson: 0.7248
Batch[17540] - loss: 0.000473 best_pearson: 0.7248
Batch[17541] - loss: 0.000359 best_pearson: 0.7248
Batch[17542] - loss: 0.000225 best_pearson: 0.7248
Batch[17543] - loss: 0.000280 best_pearson: 0.7248
Batch[17544] - loss: 0.000400 best_pearson: 0.7248
Batch[17545] - loss: 0.000436 best_pearson: 0.7248
Batch[17546] - loss: 0.000421 best_pearson: 0.7248
Batch[17547] - loss: 0.000525 best_pearson: 0.7248
Batch[17548] - loss: 0.000399 best_pearson: 0.7248
Batch[17549] - loss: 0.000436 best_pearson: 0.7248
Batch[17550] - loss: 0.000410 best_pearson: 0.7248
Batch[17551] - loss: 0.000472 best_pearson: 0.7248
Batch[17552] - loss: 0.000464 best_pearson: 0.7248
Batch[17553] - loss: 0.000271 best_pearson: 0.7248
Batch[17554] - loss: 0.000350 best_pearson: 0.7248
Batch[17555] - loss: 0.000396 best_pearson: 0.7248
Batch[17556] - loss: 0.000335 best_pearson: 0.7248
Batch[17557] - loss: 0.000342 best_pearson: 0.7248
Batch[17558] - loss: 0.000212 best_pearson: 0.7248
Batch[17559] - loss: 0.000250 best_pearson: 0.7248
Batch[17560] - loss: 0.000515 best_pearson: 0.7248
Batch[17561] - loss: 0.000317 best_pearson: 0.7248
Batch[17562] - loss: 0.000415 best_pearson: 0.7248
Batch[17563] - loss: 0.000257 best_pearson: 0.7248
Batch[17564] - loss: 0.000306 best_pearson: 0.7248
Batch[17565] - loss: 0.000406 best_pearson: 0.7248
Batch[17566] - loss: 0.000703 best_pearson: 0.7248
Batch[17567] - loss: 0.000475 best_pearson: 0.7248
Batch[17568] - loss: 0.000557 best_pearson: 0.7248
Batch[17569] - loss: 0.000402 best_pearson: 0.7248
Batch[17570] - loss: 0.000517 best_pearson: 0.7248
Batch[17571] - loss: 0.000292 best_pearson: 0.7248
Batch[17572] - loss: 0.000290 best_pearson: 0.7248
Batch[17573] - loss: 0.001096 best_pearson: 0.7248
Batch[17574] - loss: 0.000260 best_pearson: 0.7248
Batch[17575] - loss: 0.000406 best_pearson: 0.7248
Batch[17576] - loss: 0.000274 best_pearson: 0.7248
Batch[17577] - loss: 0.000344 best_pearson: 0.7248
Batch[17578] - loss: 0.000253 best_pearson: 0.7248
Batch[17579] - loss: 0.000426 best_pearson: 0.7248
Batch[17580] - loss: 0.000405 best_pearson: 0.7248
Batch[17581] - loss: 0.000591 best_pearson: 0.7248
Batch[17582] - loss: 0.000657 best_pearson: 0.7248
Batch[17583] - loss: 0.000290 best_pearson: 0.7248
Batch[17584] - loss: 0.000573 best_pearson: 0.7248
Batch[17585] - loss: 0.000604 best_pearson: 0.7248
Batch[17586] - loss: 0.000452 best_pearson: 0.7248
Batch[17587] - loss: 0.000421 best_pearson: 0.7248
Batch[17588] - loss: 0.000526 best_pearson: 0.7248
Batch[17589] - loss: 0.000251 best_pearson: 0.7248
Batch[17590] - loss: 0.000388 best_pearson: 0.7248
Batch[17591] - loss: 0.000457 best_pearson: 0.7248
Batch[17592] - loss: 0.000360 best_pearson: 0.7248
Batch[17593] - loss: 0.000442 best_pearson: 0.7248
Batch[17594] - loss: 0.000308 best_pearson: 0.7248
Batch[17595] - loss: 0.000281 best_pearson: 0.7248
Batch[17596] - loss: 0.000401 best_pearson: 0.7248
Batch[17597] - loss: 0.000323 best_pearson: 0.7248
Batch[17598] - loss: 0.000240 best_pearson: 0.7248
Batch[17599] - loss: 0.000524 best_pearson: 0.7248
Batch[17600] - loss: 0.000281 best_pearson: 0.7248

Evaluation - loss: 0.000051 pearson: 0.6847 

early stop by 1500 steps.
Batch[17601] - loss: 0.000294 best_pearson: 0.7248
Batch[17602] - loss: 0.000300 best_pearson: 0.7248
Batch[17603] - loss: 0.000437 best_pearson: 0.7248
Batch[17604] - loss: 0.000438 best_pearson: 0.7248
Batch[17605] - loss: 0.000651 best_pearson: 0.7248
Batch[17606] - loss: 0.000328 best_pearson: 0.7248
Batch[17607] - loss: 0.000291 best_pearson: 0.7248
Batch[17608] - loss: 0.000539 best_pearson: 0.7248
Batch[17609] - loss: 0.000262 best_pearson: 0.7248
Batch[17610] - loss: 0.000295 best_pearson: 0.7248
Batch[17611] - loss: 0.000399 best_pearson: 0.7248
Batch[17612] - loss: 0.000356 best_pearson: 0.7248
Batch[17613] - loss: 0.000250 best_pearson: 0.7248
Batch[17614] - loss: 0.000449 best_pearson: 0.7248
Batch[17615] - loss: 0.000281 best_pearson: 0.7248
Batch[17616] - loss: 0.000267 best_pearson: 0.7248
Batch[17617] - loss: 0.000369 best_pearson: 0.7248
Batch[17618] - loss: 0.000327 best_pearson: 0.7248
Batch[17619] - loss: 0.000300 best_pearson: 0.7248
Batch[17620] - loss: 0.000408 best_pearson: 0.7248
Batch[17621] - loss: 0.000204 best_pearson: 0.7248
Batch[17622] - loss: 0.000364 best_pearson: 0.7248
Batch[17623] - loss: 0.000624 best_pearson: 0.7248
Batch[17624] - loss: 0.000463 best_pearson: 0.7248
Batch[17625] - loss: 0.000329 best_pearson: 0.7248
Batch[17626] - loss: 0.000492 best_pearson: 0.7248
Batch[17627] - loss: 0.000491 best_pearson: 0.7248
Batch[17628] - loss: 0.000323 best_pearson: 0.7248
Batch[17629] - loss: 0.000455 best_pearson: 0.7248
Batch[17630] - loss: 0.000356 best_pearson: 0.7248
Batch[17631] - loss: 0.000418 best_pearson: 0.7248
Batch[17632] - loss: 0.000401 best_pearson: 0.7248
Batch[17633] - loss: 0.000334 best_pearson: 0.7248
Batch[17634] - loss: 0.000647 best_pearson: 0.7248
Batch[17635] - loss: 0.000321 best_pearson: 0.7248
Batch[17636] - loss: 0.000416 best_pearson: 0.7248
Batch[17637] - loss: 0.000280 best_pearson: 0.7248
Batch[17638] - loss: 0.000326 best_pearson: 0.7248
Batch[17639] - loss: 0.000311 best_pearson: 0.7248
Batch[17640] - loss: 0.000388 best_pearson: 0.7248
Batch[17641] - loss: 0.000253 best_pearson: 0.7248
Batch[17642] - loss: 0.000299 best_pearson: 0.7248
Batch[17643] - loss: 0.000281 best_pearson: 0.7248
Batch[17644] - loss: 0.000346 best_pearson: 0.7248
Batch[17645] - loss: 0.000366 best_pearson: 0.7248
Batch[17646] - loss: 0.000430 best_pearson: 0.7248
Batch[17647] - loss: 0.000399 best_pearson: 0.7248
Batch[17648] - loss: 0.000287 best_pearson: 0.7248
Batch[17649] - loss: 0.000299 best_pearson: 0.7248
Batch[17650] - loss: 0.000218 best_pearson: 0.7248
Batch[17651] - loss: 0.000234 best_pearson: 0.7248
Batch[17652] - loss: 0.000396 best_pearson: 0.7248
Batch[17653] - loss: 0.000445 best_pearson: 0.7248
Batch[17654] - loss: 0.000343 best_pearson: 0.7248
Batch[17655] - loss: 0.000379 best_pearson: 0.7248
Batch[17656] - loss: 0.000262 best_pearson: 0.7248
Batch[17657] - loss: 0.000575 best_pearson: 0.7248
Batch[17658] - loss: 0.000437 best_pearson: 0.7248
Batch[17659] - loss: 0.000380 best_pearson: 0.7248
Batch[17660] - loss: 0.000434 best_pearson: 0.7248
Batch[17661] - loss: 0.000330 best_pearson: 0.7248
Batch[17662] - loss: 0.000282 best_pearson: 0.7248
Batch[17663] - loss: 0.000410 best_pearson: 0.7248
Batch[17664] - loss: 0.000230 best_pearson: 0.7248
